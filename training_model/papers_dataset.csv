Title,ArXiv Link,Paper Date,Date Added,In_Downloaded,In_Kept,Abstract
Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts,https://arxiv.org/abs/2406.12845,2024-06-18,2024-06-19,1.0,0.0,"Reinforcement learning from human feedback (RLHF) has emerged as the primary
method for aligning large language models (LLMs) with human preferences. The
RLHF process typically starts by training a reward model (RM) using human
preference data. Conventional RMs are trained on pairwise responses to the same
user request, with relative ratings indicating which response humans prefer.
The trained RM serves as a proxy for human preferences. However, due to the
black-box nature of RMs, their outputs lack interpretability, as humans cannot
intuitively understand why an RM thinks a response is good or not. As RMs act
as human preference proxies, we believe they should be human-interpretable to
ensure that their internal decision processes are consistent with human
preferences and to prevent reward hacking in LLM alignment. To build RMs with
interpretable preferences, we propose a two-stage approach: i) train an
Absolute-Rating Multi-Objective Reward Model (ArmoRM) with multi-dimensional
absolute-rating data, each dimension corresponding to a human-interpretable
objective (e.g., honesty, verbosity, safety); ii) employ a Mixture-of-Experts
(MoE) strategy with a gating network that automatically selects the most
suitable reward objectives based on the context. We efficiently trained an
ArmoRM with Llama-3 8B and a gating network consisting of a shallow MLP on top
of the ArmoRM. Our trained model, ArmoRM-Llama3-8B, obtains state-of-the-art
performance on RewardBench, a benchmark evaluating RMs for language modeling.
Notably, the performance of our model surpasses the LLM-as-a-judge method with
GPT-4 judges by a margin, and approaches the performance of the much larger
Nemotron-4 340B reward model."
Synergizing Foundation Models and Federated Learning - A Survey,https://arxiv.org/abs/2406.12844,2024-06-18,2024-06-19,1.0,0.0,"The recent development of Foundation Models (FMs), represented by large
language models, vision transformers, and multimodal models, has been making a
significant impact on both academia and industry. Compared with small-scale
models, FMs have a much stronger demand for high-volume data during the
pre-training phase. Although general FMs can be pre-trained on data collected
from open sources such as the Internet, domain-specific FMs need proprietary
data, posing a practical challenge regarding the amount of data available due
to privacy concerns. Federated Learning (FL) is a collaborative learning
paradigm that breaks the barrier of data availability from different
participants. Therefore, it provides a promising solution to customize and
adapt FMs to a wide range of domain-specific tasks using distributed datasets
whilst preserving privacy. This survey paper discusses the potentials and
challenges of synergizing FL and FMs and summarizes core techniques, future
directions, and applications. A periodically updated paper collection on FM-FL
is available at https://github.com/lishenghui/awesome-fm-fl."
Demystifying Higher-Order Graph Neural Networks,https://arxiv.org/abs/2406.12841,2024-06-18,2024-06-19,0.0,0.0,"Higher-order graph neural networks (HOGNNs) are an important class of GNN
models that harness polyadic relations between vertices beyond plain edges.
They have been used to eliminate issues such as over-smoothing or
over-squashing, to significantly enhance the accuracy of GNN predictions, to
improve the expressiveness of GNN architectures, and for numerous other goals.
A plethora of HOGNN models have been introduced, and they come with diverse
neural architectures, and even with different notions of what the
""higher-order"" means. This richness makes it very challenging to appropriately
analyze and compare HOGNN models, and to decide in what scenario to use
specific ones. To alleviate this, we first design an in-depth taxonomy and a
blueprint for HOGNNs. This facilitates designing models that maximize
performance. Then, we use our taxonomy to analyze and compare the available
HOGNN models. The outcomes of our analysis are synthesized in a set of insights
that help to select the most beneficial GNN model in a given scenario, and a
comprehensive list of challenges and opportunities for further research into
more powerful HOGNNs."
Evaluating the design space of diffusion-based generative models,https://arxiv.org/abs/2406.12839,2024-06-18,2024-06-19,0.0,0.0,"Most existing theoretical investigations of the accuracy of diffusion models,
albeit significant, assume the score function has been approximated to a
certain accuracy, and then use this a priori bound to control the error of
generation. This article instead provides a first quantitative understanding of
the whole generation process, i.e., both training and sampling. More precisely,
it conducts a non-asymptotic convergence analysis of denoising score matching
under gradient descent. In addition, a refined sampling error analysis for
variance exploding models is also provided. The combination of these two
results yields a full error analysis, which elucidates (again, but this time
theoretically) how to design the training and sampling processes for effective
generation. For instance, our theory implies a preference toward noise
distribution and loss weighting in training that qualitatively agree with the
ones used in [Karras et al. 2022]. It also provides perspectives on the choices
of time and variance schedules in sampling: when the score is well trained, the
design in [Song et al. 2020] is more preferable, but when it is less trained,
the design in [Karras et al. 2022] becomes more preferable."
LayerMerge - Neural Network Depth Compression through Layer Pruning and Merging,https://arxiv.org/abs/2406.12837,2024-06-18,2024-06-19,1.0,0.0,"Recent works show that reducing the number of layers in a convolutional
neural network can enhance efficiency while maintaining the performance of the
network. Existing depth compression methods remove redundant non-linear
activation functions and merge the consecutive convolution layers into a single
layer. However, these methods suffer from a critical drawback; the kernel size
of the merged layers becomes larger, significantly undermining the latency
reduction gained from reducing the depth of the network. We show that this
problem can be addressed by jointly pruning convolution layers and activation
functions. To this end, we propose LayerMerge, a novel depth compression method
that selects which activation layers and convolution layers to remove, to
achieve a desired inference speed-up while minimizing performance loss. Since
the corresponding selection problem involves an exponential search space, we
formulate a novel surrogate optimization problem and efficiently solve it via
dynamic programming. Empirical results demonstrate that our method consistently
outperforms existing depth compression and layer pruning methods on various
network architectures, both on image classification and generation tasks. We
release the code at https://github.com/snu-mllab/LayerMerge."
Influence Maximization via Graph Neural Bandits,https://arxiv.org/abs/2406.12835,2024-06-18,2024-06-19,0.0,0.0,"We consider a ubiquitous scenario in the study of Influence Maximization
(IM), in which there is limited knowledge about the topology of the diffusion
network. We set the IM problem in a multi-round diffusion campaign, aiming to
maximize the number of distinct users that are influenced. Leveraging the
capability of bandit algorithms to effectively balance the objectives of
exploration and exploitation, as well as the expressivity of neural networks,
our study explores the application of neural bandit algorithms to the IM
problem. We propose the framework IM-GNB (Influence Maximization with Graph
Neural Bandits), where we provide an estimate of the users' probabilities of
being influenced by influencers (also known as diffusion seeds). This initial
estimate forms the basis for constructing both an exploitation graph and an
exploration one. Subsequently, IM-GNB handles the exploration-exploitation
tradeoff, by selecting seed nodes in real-time using Graph Convolutional
Networks (GCN), in which the pre-estimated graphs are employed to refine the
influencers' estimated rewards in each contextual setting. Through extensive
experiments on two large real-world datasets, we demonstrate the effectiveness
of IM-GNB compared with other baseline methods, significantly improving the
spread outcome of such diffusion campaigns, when the underlying network is
unknown."
LaMDA - Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation,https://arxiv.org/abs/2406.12832,2024-06-18,2024-06-19,1.0,0.0,"Low-rank adaptation (LoRA) has become the default approach to fine-tune large
language models (LLMs) due to its significant reduction in trainable
parameters. However, trainable parameter demand for LoRA increases with
increasing model embedding dimensions, leading to high compute costs.
Additionally, its backward updates require storing high-dimensional
intermediate activations and optimizer states, demanding high peak GPU memory.
In this paper, we introduce large model fine-tuning via spectrally decomposed
low-dimensional adaptation (LaMDA), a novel approach to fine-tuning large
language models, which leverages low-dimensional adaptation to achieve
significant reductions in trainable parameters and peak GPU memory footprint.
LaMDA freezes a first projection matrix (PMA) in the adaptation path while
introducing a low-dimensional trainable square matrix, resulting in substantial
reductions in trainable parameters and peak GPU memory usage. LaMDA gradually
freezes a second projection matrix (PMB) during the early fine-tuning stages,
reducing the compute cost associated with weight updates to enhance parameter
efficiency further. We also present an enhancement, LaMDA++, incorporating a
``lite-weight"" adaptive rank allocation for the LoRA path via normalized
spectrum analysis of pre-trained model weights. We evaluate LaMDA/LaMDA++
across various tasks, including natural language understanding with the GLUE
benchmark, text summarization, natural language generation, and complex
reasoning on different LLMs. Results show that LaMDA matches or surpasses the
performance of existing alternatives while requiring up to 17.7x fewer
parameter updates and up to 1.32x lower peak GPU memory usage during
fine-tuning. Code will be publicly available."
VIA - A Spatiotemporal Video Adaptation Framework for Global and Local Video Editing,https://arxiv.org/abs/2406.12831,2024-06-18,2024-06-19,0.0,0.0,"Video editing stands as a cornerstone of digital media, from entertainment
and education to professional communication. However, previous methods often
overlook the necessity of comprehensively understanding both global and local
contexts, leading to inaccurate and inconsistency edits in the spatiotemporal
dimension, especially for long videos. In this paper, we introduce VIA, a
unified spatiotemporal VIdeo Adaptation framework for global and local video
editing, pushing the limits of consistently editing minute-long videos. First,
to ensure local consistency within individual frames, the foundation of VIA is
a novel test-time editing adaptation method, which adapts a pre-trained image
editing model for improving consistency between potential editing directions
and the text instruction, and adapts masked latent variables for precise local
control. Furthermore, to maintain global consistency over the video sequence,
we introduce spatiotemporal adaptation that adapts consistent attention
variables in key frames and strategically applies them across the whole
sequence to realize the editing effects. Extensive experiments demonstrate
that, compared to baseline methods, our VIA approach produces edits that are
more faithful to the source videos, more coherent in the spatiotemporal
context, and more precise in local control. More importantly, we show that VIA
can achieve consistent long video editing in minutes, unlocking the potentials
for advanced video editing tasks over long video sequences."
What Are the Odds? Language Models Are Capable of Probabilistic Reasoning,https://arxiv.org/abs/2406.12830,2024-06-18,2024-06-19,1.0,0.0,"Language models (LM) are capable of remarkably complex linguistic tasks;
however, numerical reasoning is an area in which they frequently struggle. An
important but rarely evaluated form of reasoning is understanding probability
distributions. In this paper, we focus on evaluating the probabilistic
reasoning capabilities of LMs using idealized and real-world statistical
distributions. We perform a systematic evaluation of state-of-the-art LMs on
three tasks: estimating percentiles, drawing samples, and calculating
probabilities. We evaluate three ways to provide context to LMs 1) anchoring
examples from within a distribution or family of distributions, 2) real-world
context, 3) summary statistics on which to base a Normal approximation. Models
can make inferences about distributions, and can be further aided by the
incorporation of real-world context, example shots and simplified assumptions,
even if these assumptions are incorrect or misspecified. To conduct this work,
we developed a comprehensive benchmark distribution dataset with associated
question-answer pairs that we have released publicly."
From RAGs to rich parameters - Probing how language models utilize external knowledge over parametric information for factual queries,https://arxiv.org/abs/2406.12824,2024-06-18,2024-06-19,0.0,0.0,"Retrieval Augmented Generation (RAG) enriches the ability of language models
to reason using external context to augment responses for a given user prompt.
This approach has risen in popularity due to practical applications in various
applications of language models in search, question/answering, and chat-bots.
However, the exact nature of how this approach works isn't clearly understood.
In this paper, we mechanistically examine the RAG pipeline to highlight that
language models take shortcut and have a strong bias towards utilizing only the
context information to answer the question, while relying minimally on their
parametric memory. We probe this mechanistic behavior in language models with:
(i) Causal Mediation Analysis to show that the parametric memory is minimally
utilized when answering a question and (ii) Attention Contributions and
Knockouts to show that the last token residual stream do not get enriched from
the subject token in the question, but gets enriched from other informative
tokens in the context. We find this pronounced shortcut behaviour true across
both LLaMa and Phi family of models."
Neural Approximate Mirror Maps for Constrained Diffusion Models,https://arxiv.org/abs/2406.12816,2024-06-18,2024-06-19,0.0,0.0,"Diffusion models excel at creating visually-convincing images, but they often
struggle to meet subtle constraints inherent in the training data. Such
constraints could be physics-based (e.g., satisfying a PDE), geometric (e.g.,
respecting symmetry), or semantic (e.g., including a particular number of
objects). When the training data all satisfy a certain constraint, enforcing
this constraint on a diffusion model not only improves its
distribution-matching accuracy but also makes it more reliable for generating
valid synthetic data and solving constrained inverse problems. However,
existing methods for constrained diffusion models are inflexible with different
types of constraints. Recent work proposed to learn mirror diffusion models
(MDMs) in an unconstrained space defined by a mirror map and to impose the
constraint with an inverse mirror map, but analytical mirror maps are
challenging to derive for complex constraints. We propose neural approximate
mirror maps (NAMMs) for general constraints. Our approach only requires a
differentiable distance function from the constraint set. We learn an
approximate mirror map that pushes data into an unconstrained space and a
corresponding approximate inverse that maps data back to the constraint set. A
generative model, such as an MDM, can then be trained in the learned mirror
space and its samples restored to the constraint set by the inverse map. We
validate our approach on a variety of constraints, showing that compared to an
unconstrained diffusion model, a NAMM-based MDM substantially improves
constraint satisfaction. We also demonstrate how existing diffusion-based
inverse-problem solvers can be easily applied in the learned mirror space to
solve constrained inverse problems."
Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation,https://arxiv.org/abs/2406.12815,2024-06-18,2024-06-19,0.0,0.0,"Machine learning (ML) and Artificial Intelligence (AI) have fueled remarkable
advancements, particularly in healthcare. Within medical imaging, ML models
hold the promise of improving disease diagnoses, treatment planning, and
post-treatment monitoring. Various computer vision tasks like image
classification, object detection, and image segmentation are poised to become
routine in clinical analysis. However, privacy concerns surrounding patient
data hinder the assembly of large training datasets needed for developing and
training accurate, robust, and generalizable models. Federated Learning (FL)
emerges as a compelling solution, enabling organizations to collaborate on ML
model training by sharing model training information (gradients) rather than
data (e.g., medical images). FL's distributed learning framework facilitates
inter-institutional collaboration while preserving patient privacy. However,
FL, while robust in privacy preservation, faces several challenges. Sensitive
information can still be gleaned from shared gradients that are passed on
between organizations during model training. Additionally, in medical imaging,
quantifying model confidence\uncertainty accurately is crucial due to the noise
and artifacts present in the data. Uncertainty estimation in FL encounters
unique hurdles due to data heterogeneity across organizations. This paper
offers a comprehensive review of FL, privacy preservation, and uncertainty
estimation, with a focus on medical imaging. Alongside a survey of current
research, we identify gaps in the field and suggest future directions for FL
research to enhance privacy and address noisy medical imaging data challenges."
Adversarial Attacks on Multimodal Agents,https://arxiv.org/abs/2406.12814,2024-06-18,2024-06-19,0.0,0.0,"Vision-enabled language models (VLMs) are now used to build autonomous
multimodal agents capable of taking actions in real environments. In this
paper, we show that multimodal agents raise new safety risks, even though
attacking agents is more challenging than prior attacks due to limited access
to and knowledge about the environment. Our attacks use adversarial text
strings to guide gradient-based perturbation over one trigger image in the
environment: (1) our captioner attack attacks white-box captioners if they are
used to process images into captions as additional inputs to the VLM; (2) our
CLIP attack attacks a set of CLIP models jointly, which can transfer to
proprietary VLMs. To evaluate the attacks, we curated VisualWebArena-Adv, a set
of adversarial tasks based on VisualWebArena, an environment for web-based
multimodal agent tasks. Within an L-infinity norm of $16/256$ on a single
image, the captioner attack can make a captioner-augmented GPT-4V agent execute
the adversarial goals with a 75% success rate. When we remove the captioner or
use GPT-4V to generate its own captions, the CLIP attack can achieve success
rates of 21% and 43%, respectively. Experiments on agents based on other VLMs,
such as Gemini-1.5, Claude-3, and GPT-4o, show interesting differences in their
robustness. Further analysis reveals several key factors contributing to the
attack's success, and we also discuss the implications for defenses as well.
Project page: https://chenwu.io/attack-agent Code and data:
https://github.com/ChenWu98/agent-attack"
Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?,https://arxiv.org/abs/2406.12809,2024-06-18,2024-06-19,1.0,0.0,"Large language models (LLMs) have demonstrated impressive capabilities, but
still suffer from inconsistency issues (e.g. LLMs can react differently to
disturbances like rephrasing or inconsequential order change). In addition to
these inconsistencies, we also observe that LLMs, while capable of solving hard
problems, can paradoxically fail at easier ones. To evaluate this hard-to-easy
inconsistency, we develop the ConsisEval benchmark, where each entry comprises
a pair of questions with a strict order of difficulty. Furthermore, we
introduce the concept of consistency score to quantitatively measure this
inconsistency and analyze the potential for improvement in consistency by
relative consistency score. Based on comprehensive experiments across a variety
of existing models, we find: (1) GPT-4 achieves the highest consistency score
of 92.2\% but is still inconsistent to specific questions due to distraction by
redundant information, misinterpretation of questions, etc.; (2) models with
stronger capabilities typically exhibit higher consistency, but exceptions also
exist; (3) hard data enhances consistency for both fine-tuning and in-context
learning. Our data and code will be publicly available on GitHub."
Graph Neural Networks in Histopathology - Emerging Trends and Future Directions,https://arxiv.org/abs/2406.12808,2024-06-18,2024-06-19,0.0,0.0,"Histopathological analysis of Whole Slide Images (WSIs) has seen a surge in
the utilization of deep learning methods, particularly Convolutional Neural
Networks (CNNs). However, CNNs often fall short in capturing the intricate
spatial dependencies inherent in WSIs. Graph Neural Networks (GNNs) present a
promising alternative, adept at directly modeling pairwise interactions and
effectively discerning the topological tissue and cellular structures within
WSIs. Recognizing the pressing need for deep learning techniques that harness
the topological structure of WSIs, the application of GNNs in histopathology
has experienced rapid growth. In this comprehensive review, we survey GNNs in
histopathology, discuss their applications, and explore emerging trends that
pave the way for future advancements in the field. We begin by elucidating the
fundamentals of GNNs and their potential applications in histopathology.
Leveraging quantitative literature analysis, we identify four emerging trends:
Hierarchical GNNs, Adaptive Graph Structure Learning, Multimodal GNNs, and
Higher-order GNNs. Through an in-depth exploration of these trends, we offer
insights into the evolving landscape of GNNs in histopathological analysis.
Based on our findings, we propose future directions to propel the field
forward. Our analysis serves to guide researchers and practitioners towards
innovative approaches and methodologies, fostering advancements in
histopathological analysis through the lens of graph neural networks."
Probabilistic Temporal Prediction of Continuous Disease Trajectories and Treatment Effects Using Neural SDEs,https://arxiv.org/abs/2406.12807,2024-06-18,2024-06-19,0.0,0.0,"Personalized medicine based on medical images, including predicting future
individualized clinical disease progression and treatment response, would have
an enormous impact on healthcare and drug development, particularly for
diseases (e.g. multiple sclerosis (MS)) with long term, complex, heterogeneous
evolutions and no cure. In this work, we present the first stochastic causal
temporal framework to model the continuous temporal evolution of disease
progression via Neural Stochastic Differential Equations (NSDE). The proposed
causal inference model takes as input the patient's high dimensional images
(MRI) and tabular data, and predicts both factual and counterfactual
progression trajectories on different treatments in latent space. The NSDE
permits the estimation of high-confidence personalized trajectories and
treatment effects. Extensive experiments were performed on a large,
multi-centre, proprietary dataset of patient 3D MRI and clinical data acquired
during several randomized clinical trials for MS treatments. Our results
present the first successful uncertainty-based causal Deep Learning (DL) model
to: (a) accurately predict future patient MS disability evolution (e.g. EDSS)
and treatment effects leveraging baseline MRI, and (b) permit the discovery of
subgroups of patients for which the model has high confidence in their response
to treatment even in clinical trials which did not reach their clinical
endpoints."
Identifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents,https://arxiv.org/abs/2406.12806,2024-06-18,2024-06-19,0.0,0.0,"Configuration settings are essential for tailoring software behavior to meet
specific performance requirements. However, incorrect configurations are
widespread, and identifying those that impact system performance is challenging
due to the vast number and complexity of possible settings. In this work, we
present PerfSense, a lightweight framework that leverages Large Language Models
(LLMs) to efficiently identify performance-sensitive configurations with
minimal overhead. PerfSense employs LLM agents to simulate interactions between
developers and performance engineers using advanced prompting techniques such
as prompt chaining and retrieval-augmented generation (RAG). Our evaluation of
seven open-source Java systems demonstrates that PerfSense achieves an average
accuracy of 64.77% in classifying performance-sensitive configurations,
outperforming both our LLM baseline (50.36%) and the previous state-of-the-art
method (61.75%). Notably, our prompt chaining technique improves recall by 10%
to 30% while maintaining similar precision levels. Additionally, a manual
analysis of 362 misclassifications reveals common issues, including LLMs'
misunderstandings of requirements (26.8%). In summary, PerfSense significantly
reduces manual effort in classifying performance-sensitive configurations and
offers valuable insights for future LLM-based code analysis research."
Scalable Rule Lists Learning with Sampling,https://arxiv.org/abs/2406.12803,2024-06-18,2024-06-19,0.0,0.0,"Learning interpretable models has become a major focus of machine learning
research, given the increasing prominence of machine learning in socially
important decision-making. Among interpretable models, rule lists are among the
best-known and easily interpretable ones. However, finding optimal rule lists
is computationally challenging, and current approaches are impractical for
large datasets.
  We present a novel and scalable approach to learn nearly optimal rule lists
from large datasets. Our algorithm uses sampling to efficiently obtain an
approximation of the optimal rule list with rigorous guarantees on the quality
of the approximation. In particular, our algorithm guarantees to find a rule
list with accuracy very close to the optimal rule list when a rule list with
high accuracy exists. Our algorithm builds on the VC-dimension of rule lists,
for which we prove novel upper and lower bounds. Our experimental evaluation on
large datasets shows that our algorithm identifies nearly optimal rule lists
with a speed-up up to two orders of magnitude over state-of-the-art exact
approaches. Moreover, our algorithm is as fast as, and sometimes faster than,
recent heuristic approaches, while reporting higher quality rule lists. In
addition, the rules reported by our algorithm are more similar to the rules in
the optimal rule list than the rules from heuristic approaches."
The Limits of Pure Exploration in POMDPs - When the Observation Entropy is Enough,https://arxiv.org/abs/2406.12795,2024-06-18,2024-06-19,0.0,0.0,"The problem of pure exploration in Markov decision processes has been cast as
maximizing the entropy over the state distribution induced by the agent's
policy, an objective that has been extensively studied. However, little
attention has been dedicated to state entropy maximization under partial
observability, despite the latter being ubiquitous in applications, e.g.,
finance and robotics, in which the agent only receives noisy observations of
the true state governing the system's dynamics. How can we address state
entropy maximization in those domains? In this paper, we study the simple
approach of maximizing the entropy over observations in place of true latent
states. First, we provide lower and upper bounds to the approximation of the
true state entropy that only depends on some properties of the observation
function. Then, we show how knowledge of the latter can be exploited to compute
a principled regularization of the observation entropy to improve performance.
With this work, we provide both a flexible approach to bring advances in state
entropy maximization to the POMDP setting and a theoretical characterization of
its intrinsic limits."
ChatGLM - A Family of Large Language Models from GLM-130B to GLM-4 All Tools,https://arxiv.org/abs/2406.12793,2024-06-18,2024-06-19,1.0,0.0,"We introduce ChatGLM, an evolving family of large language models that we
have been developing over time. This report primarily focuses on the GLM-4
language series, which includes GLM-4, GLM-4-Air, and GLM-4-9B. They represent
our most capable models that are trained with all the insights and lessons
gained from the preceding three generations of ChatGLM. To date, the GLM-4
models are pre-trained on ten trillions of tokens mostly in Chinese and
English, along with a small set of corpus from 24 languages, and aligned
primarily for Chinese and English usage. The high-quality alignment is achieved
via a multi-stage post-training process, which involves supervised fine-tuning
and learning from human feedback. Evaluations show that GLM-4 1) closely rivals
or outperforms GPT-4 in terms of general metrics such as MMLU, GSM8K, MATH,
BBH, GPQA, and HumanEval, 2) gets close to GPT-4-Turbo in instruction following
as measured by IFEval, 3) matches GPT-4 Turbo (128K) and Claude 3 for long
context tasks, and 4) outperforms GPT-4 in Chinese alignments as measured by
AlignBench. The GLM-4 All Tools model is further aligned to understand user
intent and autonomously decide when and which tool(s) touse -- including web
browser, Python interpreter, text-to-image model, and user-defined functions --
to effectively complete complex tasks. In practical applications, it matches
and even surpasses GPT-4 All Tools in tasks like accessing online information
via web browsing and solving math problems using Python interpreter. Over the
course, we have open-sourced a series of models, including ChatGLM-6B (three
generations), GLM-4-9B (128K, 1M), GLM-4V-9B, WebGLM, and CodeGeeX, attracting
over 10 million downloads on Hugging face in the year 2023 alone. The open
models can be accessed through https://github.com/THUDM and
https://huggingface.co/THUDM."
Generating Educational Materials with Different Levels of Readability using LLMs,https://arxiv.org/abs/2406.12787,2024-06-18,2024-06-19,0.0,0.0,"This study introduces the leveled-text generation task, aiming to rewrite
educational materials to specific readability levels while preserving meaning.
We assess the capability of GPT-3.5, LLaMA-2 70B, and Mixtral 8x7B, to generate
content at various readability levels through zero-shot and few-shot prompting.
Evaluating 100 processed educational materials reveals that few-shot prompting
significantly improves performance in readability manipulation and information
preservation. LLaMA-2 70B performs better in achieving the desired difficulty
range, while GPT-3.5 maintains original meaning. However, manual inspection
highlights concerns such as misinformation introduction and inconsistent edit
distribution. These findings emphasize the need for further research to ensure
the quality of generated educational content."
In-Context Learning of Energy Functions,https://arxiv.org/abs/2406.12785,2024-06-18,2024-06-19,0.0,0.0,"In-context learning is a powerful capability of certain machine learning
models that arguably underpins the success of today's frontier AI models.
However, in-context learning is critically limited to settings where the
in-context distribution of interest $p_{\theta}^{ICL}( x|\mathcal{D})$ can be
straightforwardly expressed and/or parameterized by the model; for instance,
language modeling relies on expressing the next-token distribution as a
categorical distribution parameterized by the network's output logits. In this
work, we present a more general form of in-context learning without such a
limitation that we call \textit{in-context learning of energy functions}. The
idea is to instead learn the unconstrained and arbitrary in-context energy
function $E_{\theta}^{ICL}(x|\mathcal{D})$ corresponding to the in-context
distribution $p_{\theta}^{ICL}(x|\mathcal{D})$. To do this, we use classic
ideas from energy-based modeling. We provide preliminary evidence that our
method empirically works on synthetic data. Interestingly, our work contributes
(to the best of our knowledge) the first example of in-context learning where
the input space and output space differ from one another, suggesting that
in-context learning is a more-general capability than previously realized."
UBENCH - Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions,https://arxiv.org/abs/2406.12784,2024-06-18,2024-06-19,0.0,0.0,"The rapid development of large language models (LLMs) has shown promising
practical results. However, their low interpretability often leads to errors in
unforeseen circumstances, limiting their utility. Many works have focused on
creating comprehensive evaluation systems, but previous benchmarks have
primarily assessed problem-solving abilities while neglecting the response's
uncertainty, which may result in unreliability. Recent methods for measuring
LLM reliability are resource-intensive and unable to test black-box models. To
address this, we propose UBENCH, a comprehensive benchmark for evaluating LLM
reliability. UBENCH includes 3,978 multiple-choice questions covering
knowledge, language, understanding, and reasoning abilities. Experimental
results show that UBENCH has achieved state-of-the-art performance, while its
single-sampling method significantly saves computational resources compared to
baseline methods that require multiple samplings. Additionally, based on
UBENCH, we evaluate the reliability of 15 popular LLMs, finding GLM4 to be the
most outstanding, closely followed by GPT-4. We also explore the impact of
Chain-of-Thought prompts, role-playing prompts, option order, and temperature
on LLM reliability, analyzing the varying effects on different LLMs."
Composited-Nested-Learning with Data Augmentation for Nested Named Entity Recognition,https://arxiv.org/abs/2406.12779,2024-06-18,2024-06-19,0.0,0.0,"Nested Named Entity Recognition (NNER) focuses on addressing overlapped
entity recognition. Compared to Flat Named Entity Recognition (FNER), annotated
resources are scarce in the corpus for NNER. Data augmentation is an effective
approach to address the insufficient annotated corpus. However, there is a
significant lack of exploration in data augmentation methods for NNER. Due to
the presence of nested entities in NNER, existing data augmentation methods
cannot be directly applied to NNER tasks. Therefore, in this work, we focus on
data augmentation for NNER and resort to more expressive structures,
Composited-Nested-Label Classification (CNLC) in which constituents are
combined by nested-word and nested-label, to model nested entities. The dataset
is augmented using the Composited-Nested-Learning (CNL). In addition, we
propose the Confidence Filtering Mechanism (CFM) for a more efficient selection
of generated data. Experimental results demonstrate that this approach results
in improvements in ACE2004 and ACE2005 and alleviates the impact of sample
imbalance."
Hopping Too Late - Exploring the Limitations of Large Language Models on Multi-Hop Queries,https://arxiv.org/abs/2406.12775,2024-06-18,2024-06-19,0.0,0.0,"Large language models (LLMs) can solve complex multi-step problems, but
little is known about how these computations are implemented internally.
Motivated by this, we study how LLMs answer multi-hop queries such as ""The
spouse of the performer of Imagine is"". These queries require two information
extraction steps: a latent one for resolving the first hop (""the performer of
Imagine"") into the bridge entity (John Lennon), and one for resolving the
second hop (""the spouse of John Lennon"") into the target entity (Yoko Ono).
Understanding how the latent step is computed internally is key to
understanding the overall computation. By carefully analyzing the internal
computations of transformer-based LLMs, we discover that the bridge entity is
resolved in the early layers of the model. Then, only after this resolution,
the two-hop query is solved in the later layers. Because the second hop
commences in later layers, there could be cases where these layers no longer
encode the necessary knowledge for correctly predicting the answer. Motivated
by this, we propose a novel ""back-patching"" analysis method whereby a hidden
representation from a later layer is patched back to an earlier layer. We find
that in up to 57% of previously incorrect cases there exists a back-patch that
results in the correct generation of the answer, showing that the later layers
indeed sometimes lack the needed functionality. Overall our methods and
findings open further opportunities for understanding and improving latent
reasoning in transformer-based LLMs."
Towards Exact Gradient-based Training on Analog In-memory Computing,https://arxiv.org/abs/2406.12774,2024-06-18,2024-06-19,0.0,0.0,"Given the high economic and environmental costs of using large vision or
language models, analog in-memory accelerators present a promising solution for
energy-efficient AI. While inference on analog accelerators has been studied
recently, the training perspective is underexplored. Recent studies have shown
that the ""workhorse"" of digital AI training - stochastic gradient descent (SGD)
algorithm converges inexactly when applied to model training on non-ideal
devices. This paper puts forth a theoretical foundation for gradient-based
training on analog devices. We begin by characterizing the non-convergent issue
of SGD, which is caused by the asymmetric updates on the analog devices. We
then provide a lower bound of the asymptotic error to show that there is a
fundamental performance limit of SGD-based analog training rather than an
artifact of our analysis. To address this issue, we study a heuristic analog
algorithm called Tiki-Taka that has recently exhibited superior empirical
performance compared to SGD and rigorously show its ability to exactly converge
to a critical point and hence eliminates the asymptotic error. The simulations
verify the correctness of the analyses."
First-Order Methods for Linearly Constrained Bilevel Optimization,https://arxiv.org/abs/2406.12771,2024-06-18,2024-06-19,0.0,0.0,"Algorithms for bilevel optimization often encounter Hessian computations,
which are prohibitive in high dimensions. While recent works offer first-order
methods for unconstrained bilevel problems, the constrained setting remains
relatively underexplored. We present first-order linearly constrained
optimization methods with finite-time hypergradient stationarity guarantees.
For linear equality constraints, we attain $\epsilon$-stationarity in
$\widetilde{O}(\epsilon^{-2})$ gradient oracle calls, which is nearly-optimal.
For linear inequality constraints, we attain $(\delta,\epsilon)$-Goldstein
stationarity in $\widetilde{O}(d{\delta^{-1} \epsilon^{-3}})$ gradient oracle
calls, where $d$ is the upper-level dimension. Finally, we obtain for the
linear inequality setting dimension-free rates of $\widetilde{O}({\delta^{-1}
\epsilon^{-4}})$ oracle complexity under the additional assumption of oracle
access to the optimal dual variable. Along the way, we develop new nonsmooth
nonconvex optimization methods with inexact oracles. We verify these guarantees
with preliminary numerical experiments."
Formatics & dairy industry coalition - AI trends and present challenges,https://arxiv.org/abs/2406.12770,2024-06-18,2024-06-19,0.0,0.0,"Artificial Intelligence (AI) can potentially transform the industry,
enhancing the production process and minimizing manual, repetitive tasks.
Accordingly, the synergy between high-performance computing and powerful
mathematical models enables the application of sophisticated data analysis
procedures like Machine Learning. However, challenges exist regarding
effective, efficient, and flexible processing to generate valuable knowledge.
Consequently, this work comprehensively describes industrial challenges where
AI can be exploited, focusing on the dairy industry. The conclusions presented
can help researchers apply novel approaches for cattle monitoring and farmers
by proposing advanced technological solutions to their needs."
Latent Intuitive Physics - Learning to Transfer Hidden Physics from A 3D Video,https://arxiv.org/abs/2406.12769,2024-06-18,2024-06-19,0.0,0.0,"We introduce latent intuitive physics, a transfer learning framework for
physics simulation that can infer hidden properties of fluids from a single 3D
video and simulate the observed fluid in novel scenes. Our key insight is to
use latent features drawn from a learnable prior distribution conditioned on
the underlying particle states to capture the invisible and complex physical
properties. To achieve this, we train a parametrized prior learner given visual
observations to approximate the visual posterior of inverse graphics, and both
the particle states and the visual posterior are obtained from a learned neural
renderer. The converged prior learner is embedded in our probabilistic physics
engine, allowing us to perform novel simulations on unseen geometries,
boundaries, and dynamics without knowledge of the true physical parameters. We
validate our model in three ways: (i) novel scene simulation with the learned
visual-world physics, (ii) future prediction of the observed fluid dynamics,
and (iii) supervised particle simulation. Our model demonstrates strong
performance in all three tasks."
Quasi-Bayes meets Vines,https://arxiv.org/abs/2406.12764,2024-06-18,2024-06-19,0.0,0.0,"Recently proposed quasi-Bayesian (QB) methods initiated a new era in Bayesian
computation by directly constructing the Bayesian predictive distribution
through recursion, removing the need for expensive computations involved in
sampling the Bayesian posterior distribution. This has proved to be
data-efficient for univariate predictions, but extensions to multiple
dimensions rely on a conditional decomposition resulting from predefined
assumptions on the kernel of the Dirichlet Process Mixture Model, which is the
implicit nonparametric model used. Here, we propose a different way to extend
Quasi-Bayesian prediction to high dimensions through the use of Sklar's theorem
by decomposing the predictive distribution into one-dimensional predictive
marginals and a high-dimensional copula. Thus, we use the efficient recursive
QB construction for the one-dimensional marginals and model the dependence
using highly expressive vine copulas. Further, we tune hyperparameters using
robust divergences (eg. energy score) and show that our proposed Quasi-Bayesian
Vine (QB-Vine) is a fully non-parametric density estimator with \emph{an
analytical form} and convergence rate independent of the dimension of data in
some situations. Our experiments illustrate that the QB-Vine is appropriate for
high dimensional distributions ($\sim$64), needs very few samples to train
($\sim$200) and outperforms state-of-the-art methods with analytical forms for
density estimation and supervised tasks by a considerable margin."
Implicit Bias of Mirror Flow on Separable Data,https://arxiv.org/abs/2406.12763,2024-06-18,2024-06-19,0.0,0.0,"We examine the continuous-time counterpart of mirror descent, namely mirror
flow, on classification problems which are linearly separable. Such problems
are minimised `at infinity' and have many possible solutions; we study which
solution is preferred by the algorithm depending on the mirror potential. For
exponential tailed losses and under mild assumptions on the potential, we show
that the iterates converge in direction towards a $\phi_\infty$-maximum margin
classifier. The function $\phi_\infty$ is the $\textit{horizon function}$ of
the mirror potential and characterises its shape `at infinity'. When the
potential is separable, a simple formula allows to compute this function. We
analyse several examples of potentials and provide numerical experiments
highlighting our results."
Unsupervised explainable activity prediction in competitive Nordic Walking from experimental data,https://arxiv.org/abs/2406.12762,2024-06-18,2024-06-19,0.0,0.0,"Artificial Intelligence (AI) has found application in Human Activity
Recognition (HAR) in competitive sports. To date, most Machine Learning (ML)
approaches for HAR have relied on offline (batch) training, imposing higher
computational and tagging burdens compared to online processing unsupervised
approaches. Additionally, the decisions behind traditional ML predictors are
opaque and require human interpretation. In this work, we apply an online
processing unsupervised clustering approach based on low-cost wearable Inertial
Measurement Units (IMUs). The outcomes generated by the system allow for the
automatic expansion of limited tagging available (e.g., by referees) within
those clusters, producing pertinent information for the explainable
classification stage. Specifically, our work focuses on achieving automatic
explainability for predictions related to athletes' activities, distinguishing
between correct, incorrect, and cheating practices in Nordic Walking. The
proposed solution achieved performance metrics of close to 100 % on average."
GFM4MPM - Towards Geospatial Foundation Models for Mineral Prospectivity Mapping,https://arxiv.org/abs/2406.12756,2024-06-18,2024-06-19,0.0,0.0,"Machine Learning (ML) for Mineral Prospectivity Mapping (MPM) remains a
challenging problem as it requires the analysis of associations between
large-scale multi-modal geospatial data and few historical mineral commodity
observations (positive labels). Recent MPM works have explored Deep Learning
(DL) as a modeling tool with more representation capacity. However, these
overparameterized methods may be more prone to overfitting due to their
reliance on scarce labeled data. While a large quantity of unlabeled geospatial
data exists, no prior MPM works have considered using such information in a
self-supervised manner. Our MPM approach uses a masked image modeling framework
to pretrain a backbone neural network in a self-supervised manner using
unlabeled geospatial data alone. After pretraining, the backbone network
provides feature extraction for downstream MPM tasks. We evaluated our approach
alongside existing methods to assess mineral prospectivity of Mississippi
Valley Type (MVT) and Clastic-Dominated (CD) Lead-Zinc deposits in North
America and Australia. Our results demonstrate that self-supervision promotes
robustness in learned features, improving prospectivity predictions.
Additionally, we leverage explainable artificial intelligence techniques to
demonstrate that individual predictions can be interpreted from a geological
perspective."
Chumor 1.0 - A Truly Funny and Challenging Chinese Humor Understanding Dataset from Ruo Zhi Ba,https://arxiv.org/abs/2406.12754,2024-06-18,2024-06-19,0.0,0.0,"Existing humor datasets and evaluations predominantly focus on English,
lacking resources for culturally nuanced humor in non-English languages like
Chinese. To address this gap, we construct Chumor, a dataset sourced from Ruo
Zhi Ba (RZB), a Chinese Reddit-like platform dedicated to sharing
intellectually challenging and culturally specific jokes. We annotate
explanations for each joke and evaluate human explanations against two
state-of-the-art LLMs, GPT-4o and ERNIE Bot, through A/B testing by native
Chinese speakers. Our evaluation shows that Chumor is challenging even for SOTA
LLMs, and the human explanations for Chumor jokes are significantly better than
explanations generated by the LLMs."
OlympicArena - Benchmarking Multi-discipline Cognitive Reasoning for Superintelligent AI,https://arxiv.org/abs/2406.12753,2024-06-18,2024-06-19,0.0,0.0,"The evolution of Artificial Intelligence (AI) has been significantly
accelerated by advancements in Large Language Models (LLMs) and Large
Multimodal Models (LMMs), gradually showcasing potential cognitive reasoning
abilities in problem-solving and scientific discovery (i.e., AI4Science) once
exclusive to human intellect. To comprehensively evaluate current models'
performance in cognitive reasoning abilities, we introduce OlympicArena, which
includes 11,163 bilingual problems across both text-only and interleaved
text-image modalities. These challenges encompass a wide range of disciplines
spanning seven fields and 62 international Olympic competitions, rigorously
examined for data leakage. We argue that the challenges in Olympic competition
problems are ideal for evaluating AI's cognitive reasoning due to their
complexity and interdisciplinary nature, which are essential for tackling
complex scientific challenges and facilitating discoveries. Beyond evaluating
performance across various disciplines using answer-only criteria, we conduct
detailed experiments and analyses from multiple perspectives. We delve into the
models' cognitive reasoning abilities, their performance across different
modalities, and their outcomes in process-level evaluations, which are vital
for tasks requiring complex reasoning with lengthy solutions. Our extensive
evaluations reveal that even advanced models like GPT-4o only achieve a 39.97%
overall accuracy, illustrating current AI limitations in complex reasoning and
multimodal integration. Through the OlympicArena, we aim to advance AI towards
superintelligence, equipping it to address more complex challenges in science
and beyond. We also provide a comprehensive set of resources to support AI
research, including a benchmark dataset, an open-source annotation platform, a
detailed evaluation tool, and a leaderboard with automatic submission features."
Extracting Training Data from Unconditional Diffusion Models,https://arxiv.org/abs/2406.12752,2024-06-18,2024-06-19,0.0,0.0,"As diffusion probabilistic models (DPMs) are being employed as mainstream
models for generative artificial intelligence (AI), the study of their
memorization of the raw training data has attracted growing attention. Existing
works in this direction aim to establish an understanding of whether or to what
extent DPMs learn by memorization. Such an understanding is crucial for
identifying potential risks of data leakage and copyright infringement in
diffusion models and, more importantly, for more controllable generation and
trustworthy application of Artificial Intelligence Generated Content (AIGC).
While previous works have made important observations of when DPMs are prone to
memorization, these findings are mostly empirical, and the developed data
extraction methods only work for conditional diffusion models. In this work, we
aim to establish a theoretical understanding of memorization in DPMs with 1) a
memorization metric for theoretical analysis, 2) an analysis of conditional
memorization with informative and random labels, and 3) two better evaluation
metrics for measuring memorization. Based on the theoretical analysis, we
further propose a novel data extraction method called \textbf{Surrogate
condItional Data Extraction (SIDE)} that leverages a classifier trained on
generated data as a surrogate condition to extract training data directly from
unconditional diffusion models. Our empirical results demonstrate that SIDE can
extract training data from diffusion models where previous methods fail, and it
is on average over 50\% more effective across different scales of the CelebA
dataset."
TSI-Bench - Benchmarking Time Series Imputation,https://arxiv.org/abs/2406.12747,2024-06-18,2024-06-19,0.0,0.0,"Effective imputation is a crucial preprocessing step for time series
analysis. Despite the development of numerous deep learning algorithms for time
series imputation, the community lacks standardized and comprehensive benchmark
platforms to effectively evaluate imputation performance across different
settings. Moreover, although many deep learning forecasting algorithms have
demonstrated excellent performance, whether their modeling achievements can be
transferred to time series imputation tasks remains unexplored. To bridge these
gaps, we develop TSI-Bench, the first (to our knowledge) comprehensive
benchmark suite for time series imputation utilizing deep learning techniques.
The TSI-Bench pipeline standardizes experimental settings to enable fair
evaluation of imputation algorithms and identification of meaningful insights
into the influence of domain-appropriate missingness ratios and patterns on
model performance. Furthermore, TSI-Bench innovatively provides a systematic
paradigm to tailor time series forecasting algorithms for imputation purposes.
Our extensive study across 34,804 experiments, 28 algorithms, and 8 datasets
with diverse missingness scenarios demonstrates TSI-Bench's effectiveness in
diverse downstream tasks and potential to unlock future directions in time
series imputation research and analysis. The source code and experiment logs
are available at https://github.com/WenjieDu/AwesomeImputation."
Rationale-based Ensemble of Multiple QA Strategies for Zero-shot Knowledge-based VQA,https://arxiv.org/abs/2406.12746,2024-06-18,2024-06-19,0.0,0.0,"Knowledge-based Visual Qustion-answering (K-VQA) necessitates the use of
background knowledge beyond what is depicted in the image. Current zero-shot
K-VQA methods usually translate an image to a single type of textual decision
context and use a text-based model to answer the question based on it, which
conflicts with the fact that K-VQA questions often require the combination of
multiple question-answering strategies. In light of this, we propose
Rationale-based Ensemble of Answer Context Tactics (REACT) to achieve a dynamic
ensemble of multiple question-answering tactics, comprising Answer Candidate
Generation (ACG) and Rationale-based Strategy Fusion (RSF). In ACG, we generate
three distinctive decision contexts to provide different strategies for each
question, resulting in the generation of three answer candidates. RSF generates
automatic and mechanistic rationales from decision contexts for each candidate,
allowing the model to select the correct answer from all candidates. We conduct
comprehensive experiments on the OK-VQA and A-OKVQA datasets, and our method
significantly outperforms state-of-the-art LLM-based baselines on all datasets."
Ensuring Both Positivity and Stability Using Sector-Bounded Nonlinearity for Systems with Neural Network Controllers,https://arxiv.org/abs/2406.12744,2024-06-18,2024-06-19,0.0,0.0,"This paper introduces a novel method for the stability analysis of positive
feedback systems with a class of fully connected feedforward neural networks
(FFNN) controllers. By establishing sector bounds for fully connected FFNNs
without biases, we present a stability theorem that demonstrates the global
exponential stability of linear systems under fully connected FFNN control.
Utilizing principles from positive Lur'e systems and the positive Aizerman
conjecture, our approach effectively addresses the challenge of ensuring
stability in highly nonlinear systems. The crux of our method lies in
maintaining sector bounds that preserve the positivity and Hurwitz property of
the overall Lur'e system. We showcase the practical applicability of our
methodology through its implementation in a linear system managed by a FFNN
trained on output feedback controller data, highlighting its potential for
enhancing stability in dynamic systems."
"Benchmarking Multi-Image Understanding in Vision and Language Models - Perception, Knowledge, Reasoning, and Multi-Hop Reasoning",https://arxiv.org/abs/2406.12742,2024-06-18,2024-06-19,0.0,0.0,"The advancement of large language models (LLMs) has significantly broadened
the scope of applications in natural language processing, with multi-modal LLMs
extending these capabilities to integrate and interpret visual data. However,
existing benchmarks for visual language models (VLMs) predominantly focus on
single-image inputs, neglecting the crucial aspect of multi-image
understanding. In this paper, we introduce a Multi-Image Relational Benchmark
MIRB, designed to evaluate VLMs' ability to compare, analyze, and reason across
multiple images. Our benchmark encompasses four categories: perception, visual
world knowledge, reasoning, and multi-hop reasoning. Through a comprehensive
evaluation of a wide range of open-source and closed-source models, we
demonstrate that while open-source VLMs were shown to approach the performance
of GPT-4V in single-image tasks, a significant performance gap remains in
multi-image reasoning tasks. Our findings also reveal that even the
state-of-the-art GPT-4V model struggles with our benchmark, underscoring the
need for further research and development in this area. We believe our
contribution of MIRB could serve as a testbed for developing the
next-generation multi-modal models."
Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages,https://arxiv.org/abs/2406.12739,2024-06-18,2024-06-19,0.0,0.0,"LLMs have become a go-to solution not just for text generation, but also for
natural language understanding (NLU) tasks. Acquiring extensive knowledge
through language modeling on web-scale corpora, they excel on English NLU, yet
struggle to extend their NLU capabilities to underrepresented languages. In
contrast, machine translation models (MT) produce excellent multilingual
representations, resulting in strong translation performance even for
low-resource languages. MT encoders, however, lack the knowledge necessary for
comprehensive NLU that LLMs obtain through language modeling training on
immense corpora. In this work, we get the best both worlds by integrating MT
encoders directly into LLM backbones via sample-efficient self-distillation.
The resulting MT-LLMs preserve the inherent multilingual representational
alignment from the MT encoder, allowing lower-resource languages to tap into
the rich knowledge embedded in English-centric LLMs. Merging the MT encoder and
LLM in a single model, we mitigate the propagation of translation errors and
inference overhead of MT decoding inherent to discrete translation-based
cross-lingual transfer (e.g., translate-test). Evaluation spanning three
prominent NLU tasks and 127 predominantly low-resource languages renders
MT-LLMs highly effective in cross-lingual transfer. MT-LLMs substantially and
consistently outperform translate-test based on the same MT model, showing that
we truly unlock multilingual language understanding for LLMs."
Large Language Model as a Universal Clinical Multi-task Decoder,https://arxiv.org/abs/2406.12738,2024-06-18,2024-06-19,0.0,0.0,"The development of effective machine learning methodologies for enhancing the
efficiency and accuracy of clinical systems is crucial. Despite significant
research efforts, managing a plethora of diversified clinical tasks and
adapting to emerging new tasks remain significant challenges. This paper
presents a novel paradigm that employs a pre-trained large language model as a
universal clinical multi-task decoder. This approach leverages the flexibility
and diversity of language expressions to handle task topic variations and
associated arguments. The introduction of a new task simply requires the
addition of a new instruction template. We validate this framework across
hundreds of tasks, demonstrating its robustness in facilitating multi-task
predictions, performing on par with traditional multi-task learning and
single-task learning approaches. Moreover, it shows exceptional adaptability to
new tasks, with impressive zero-shot performance in some instances and superior
data efficiency in few-shot scenarios. This novel approach offers a unified
solution to manage a wide array of new and emerging tasks in clinical
applications."
Beyond Visual Appearances - Privacy-sensitive Objects Identification via Hybrid Graph Reasoning,https://arxiv.org/abs/2406.12736,2024-06-18,2024-06-19,0.0,0.0,"The Privacy-sensitive Object Identification (POI) task allocates bounding
boxes for privacy-sensitive objects in a scene. The key to POI is settling an
object's privacy class (privacy-sensitive or non-privacy-sensitive). In
contrast to conventional object classes which are determined by the visual
appearance of an object, one object's privacy class is derived from the scene
contexts and is subject to various implicit factors beyond its visual
appearance. That is, visually similar objects may be totally opposite in their
privacy classes. To explicitly derive the objects' privacy class from the scene
contexts, in this paper, we interpret the POI task as a visual reasoning task
aimed at the privacy of each object in the scene. Following this
interpretation, we propose the PrivacyGuard framework for POI. PrivacyGuard
contains three stages. i) Structuring: an unstructured image is first converted
into a structured, heterogeneous scene graph that embeds rich scene contexts.
ii) Data Augmentation: a contextual perturbation oversampling strategy is
proposed to create slightly perturbed privacy-sensitive objects in a scene
graph, thereby balancing the skewed distribution of privacy classes. iii)
Hybrid Graph Generation & Reasoning: the balanced, heterogeneous scene graph is
then transformed into a hybrid graph by endowing it with extra ""node-node"" and
""edge-edge"" homogeneous paths. These homogeneous paths allow direct message
passing between nodes or edges, thereby accelerating reasoning and facilitating
the capturing of subtle context changes. Based on this hybrid graph... **For
the full abstract, see the original paper.**"
Automatic generation of insights from workers' actions in industrial workflows with explainable Machine Learning,https://arxiv.org/abs/2406.12732,2024-06-18,2024-06-19,0.0,0.0,"New technologies such as Machine Learning (ML) gave great potential for
evaluating industry workflows and automatically generating key performance
indicators (KPIs). However, despite established standards for measuring the
efficiency of industrial machinery, there is no precise equivalent for workers'
productivity, which would be highly desirable given the lack of a skilled
workforce for the next generation of industry workflows. Therefore, an ML
solution combining data from manufacturing processes and workers' performance
for that goal is required. Additionally, in recent times intense effort has
been devoted to explainable ML approaches that can automatically explain their
decisions to a human operator, thus increasing their trustworthiness. We
propose to apply explainable ML solutions to differentiate between expert and
inexpert workers in industrial workflows, which we validate at a quality
assessment industrial workstation. Regarding the methodology used, input data
are captured by a manufacturing machine and stored in a NoSQL database. Data
are processed to engineer features used in automatic classification and to
compute workers' KPIs to predict their level of expertise (with all
classification metrics exceeding 90 %). These KPIs, and the relevant features
in the decisions are textually explained by natural language expansion on an
explainability dashboard. These automatic explanations made it possible to
infer knowledge from expert workers for inexpert workers. The latter
illustrates the interest of research in self-explainable ML for automatically
generating insights to improve productivity in industrial workflows."
Predicting the energetic proton flux with a machine learning regression algorithm,https://arxiv.org/abs/2406.12730,2024-06-18,2024-06-19,0.0,0.0,"The need of real-time of monitoring and alerting systems for Space Weather
hazards has grown significantly in the last two decades. One of the most
important challenge for space mission operations and planning is the prediction
of solar proton events (SPEs). In this context, artificial intelligence and
machine learning techniques have opened a new frontier, providing a new
paradigm for statistical forecasting algorithms. The great majority of these
models aim to predict the occurrence of a SPE, i.e., they are based on the
classification approach. In this work we present a simple and efficient machine
learning regression algorithm which is able to forecast the energetic proton
flux up to 1 hour ahead by exploiting features derived from the electron flux
only. This approach could be helpful to improve monitoring systems of the
radiation risk in both deep space and near-Earth environments. The model is
very relevant for mission operations and planning, especially when flare
characteristics and source location are not available in real time, as at Mars
distance."
Can Large Language Models Code Like a Linguist? - A Case Study in Low Resource Sound Law Induction,https://arxiv.org/abs/2406.12725,2024-06-18,2024-06-19,0.0,0.0,"Historical linguists have long written a kind of incompletely formalized
''program'' that converts reconstructed words in an ancestor language into
words in one of its attested descendants that consist of a series of ordered
string rewrite functions (called sound laws). They do this by observing pairs
of words in the reconstructed language (protoforms) and the descendent language
(reflexes) and constructing a program that transforms protoforms into reflexes.
However, writing these programs is error-prone and time-consuming. Prior work
has successfully scaffolded this process computationally, but fewer researchers
have tackled Sound Law Induction (SLI), which we approach in this paper by
casting it as Programming by Examples. We propose a language-agnostic solution
that utilizes the programming ability of Large Language Models (LLMs) by
generating Python sound law programs from sound change examples. We evaluate
the effectiveness of our approach for various LLMs, propose effective methods
to generate additional language-agnostic synthetic data to fine-tune LLMs for
SLI, and compare our method with existing automated SLI methods showing that
while LLMs lag behind them they can complement some of their weaknesses."
BIOSCAN-5M - A Multimodal Dataset for Insect Biodiversity,https://arxiv.org/abs/2406.12723,2024-06-18,2024-06-19,0.0,0.0,"As part of an ongoing worldwide effort to comprehend and monitor insect
biodiversity, this paper presents the BIOSCAN-5M Insect dataset to the machine
learning community and establish several benchmark tasks. BIOSCAN-5M is a
comprehensive dataset containing multi-modal information for over 5 million
insect specimens, and it significantly expands existing image-based biological
datasets by including taxonomic labels, raw nucleotide barcode sequences,
assigned barcode index numbers, and geographical information. We propose three
benchmark experiments to demonstrate the impact of the multi-modal data types
on the classification and clustering accuracy. First, we pretrain a masked
language model on the DNA barcode sequences of the BIOSCAN-5M dataset, and
demonstrate the impact of using this large reference library on species- and
genus-level classification performance. Second, we propose a zero-shot transfer
learning task applied to images and DNA barcodes to cluster feature embeddings
obtained from self-supervised learning, to investigate whether meaningful
clusters can be derived from these representation embeddings. Third, we
benchmark multi-modality by performing contrastive learning on DNA barcodes,
image data, and taxonomic information. This yields a general shared embedding
space enabling taxonomic classification using multiple types of information and
modalities. The code repository of the BIOSCAN-5M Insect dataset is available
at https://github.com/zahrag/BIOSCAN-5M."
On the Robustness of Language Models for Tabular Question Answering,https://arxiv.org/abs/2406.12719,2024-06-18,2024-06-19,0.0,0.0,"Large Language Models (LLMs), originally shown to ace various text
comprehension tasks have also remarkably been shown to tackle table
comprehension tasks without specific training. While previous research has
explored LLM capabilities with tabular dataset tasks, our study assesses the
influence of $\textit{in-context learning}$,$ \textit{model scale}$,
$\textit{instruction tuning}$, and $\textit{domain biases}$ on Tabular Question
Answering (TQA). We evaluate the robustness of LLMs on Wikipedia-based
$\textbf{WTQ}$ and financial report-based $\textbf{TAT-QA}$ TQA datasets,
focusing on their ability to robustly interpret tabular data under various
augmentations and perturbations. Our findings indicate that instructions
significantly enhance performance, with recent models like Llama3 exhibiting
greater robustness over earlier versions. However, data contamination and
practical reliability issues persist, especially with WTQ. We highlight the
need for improved methodologies, including structure-aware self-attention
mechanisms and better handling of domain-specific tabular data, to develop more
reliable LLMs for table comprehension."
AGLA - Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention,https://arxiv.org/abs/2406.12718,2024-06-18,2024-06-19,0.0,0.0,"Despite their great success across various multimodal tasks, Large
Vision-Language Models (LVLMs) are facing a prevalent problem with object
hallucinations, where the generated textual responses are inconsistent with
ground-truth objects in the given image. This paper investigates various LVLMs
and pinpoints attention deficiency toward discriminative local image features
as one root cause of object hallucinations. Specifically, LVLMs predominantly
attend to prompt-independent global image features, while failing to capture
prompt-relevant local features, consequently undermining the visual grounding
capacity of LVLMs and leading to hallucinations. To this end, we propose
Assembly of Global and Local Attention (AGLA), a training-free and
plug-and-play approach that mitigates object hallucinations by exploring an
ensemble of global features for response generation and local features for
visual discrimination simultaneously. Our approach exhibits an image-prompt
matching scheme that captures prompt-relevant local features from images,
leading to an augmented view of the input image where prompt-relevant content
is reserved while irrelevant distractions are masked. With the augmented view,
a calibrated decoding distribution can be derived by integrating generative
global features from the original image and discriminative local features from
the augmented image. Extensive experiments show that AGLA consistently
mitigates object hallucinations and enhances general perception capability for
LVLMs across various discriminative and generative benchmarks. Our code will be
released at https://github.com/Lackel/AGLA."
Enhancing Spatio-temporal Quantile Forecasting with Curriculum Learning - Lessons Learned,https://arxiv.org/abs/2406.12709,2024-06-18,2024-06-19,0.0,0.0,"Training models on spatio-temporal (ST) data poses an open problem due to the
complicated and diverse nature of the data itself, and it is challenging to
ensure the model's performance directly trained on the original ST data. While
limiting the variety of training data can make training easier, it can also
lead to a lack of knowledge and information for the model, resulting in a
decrease in performance. To address this challenge, we presented an innovative
paradigm that incorporates three separate forms of curriculum learning
specifically targeting from spatial, temporal, and quantile perspectives.
Furthermore, our framework incorporates a stacking fusion module to combine
diverse information from three types of curriculum learning, resulting in a
strong and thorough learning process. We demonstrated the effectiveness of this
framework with extensive empirical evaluations, highlighting its better
performance in addressing complex ST challenges. We provided thorough ablation
studies to investigate the effectiveness of our curriculum and to explain how
it contributes to the improvement of learning efficiency on ST data."
AgentReview - Exploring Peer Review Dynamics with LLM Agents,https://arxiv.org/abs/2406.12708,2024-06-18,2024-06-19,0.0,0.0,"Peer review is fundamental to the integrity and advancement of scientific
publication. Traditional methods of peer review analyses often rely on
exploration and statistics of existing peer review data, which do not
adequately address the multivariate nature of the process, account for the
latent variables, and are further constrained by privacy concerns due to the
sensitive nature of the data. We introduce AgentReview, the first large
language model (LLM) based peer review simulation framework, which effectively
disentangles the impacts of multiple latent factors and addresses the privacy
issue. Our study reveals significant insights, including a notable 37.1%
variation in paper decisions due to reviewers' biases, supported by
sociological theories such as the social influence theory, altruism fatigue,
and authority bias. We believe that this study could offer valuable insights to
improve the design of peer review mechanisms."
Talk With Human-like Agents - Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction,https://arxiv.org/abs/2406.12707,2024-06-18,2024-06-19,0.0,0.0,"Large Language Model (LLM)-enhanced agents become increasingly prevalent in
Human-AI communication, offering vast potential from entertainment to
professional domains. However, current multi-modal dialogue systems overlook
the acoustic information present in speech, which is crucial for understanding
human communication nuances. This oversight can lead to misinterpretations of
speakers' intentions, resulting in inconsistent or even contradictory responses
within dialogues. To bridge this gap, in this paper, we propose
PerceptiveAgent, an empathetic multi-modal dialogue system designed to discern
deeper or more subtle meanings beyond the literal interpretations of words
through the integration of speech modality perception. Employing LLMs as a
cognitive core, PerceptiveAgent perceives acoustic information from input
speech and generates empathetic responses based on speaking styles described in
natural language. Experimental results indicate that PerceptiveAgent excels in
contextual understanding by accurately discerning the speakers' true intentions
in scenarios where the linguistic meaning is either contrary to or inconsistent
with the speaker's true feelings, producing more nuanced and expressive spoken
dialogues. Code is publicly available at:
\url{https://github.com/Haoqiu-Yan/PerceptiveAgent}."
Jailbreak Paradox - The Achilles' Heel of LLMs,https://arxiv.org/abs/2406.12702,2024-06-18,2024-06-19,1.0,0.0,"We introduce two paradoxes concerning jailbreak of foundation models: First,
it is impossible to construct a perfect jailbreak classifier, and second, a
weaker model cannot consistently detect whether a stronger (in a
pareto-dominant sense) model is jailbroken or not. We provide formal proofs for
these paradoxes and a short case study on Llama and GPT4-o to demonstrate this.
We discuss broader theoretical and practical repercussions of these results."
SUPER - Selfie Undistortion and Head Pose Editing with Identity Preservation,https://arxiv.org/abs/2406.12700,2024-06-18,2024-06-19,0.0,0.0,"Self-portraits captured from a short distance might look unnatural or even
unattractive due to heavy distortions making facial features malformed, and
ill-placed head poses. In this paper, we propose SUPER, a novel method of
eliminating distortions and adjusting head pose in a close-up face crop. We
perform 3D GAN inversion for a facial image by optimizing camera parameters and
face latent code, which gives a generated image. Besides, we estimate depth
from the obtained latent code, create a depth-induced 3D mesh, and render it
with updated camera parameters to obtain a warped portrait. Finally, we apply
the visibility-based blending so that visible regions are reprojected, and
occluded parts are restored with a generative model. Experiments on face
undistortion benchmarks and on our self-collected Head Rotation dataset (HeRo),
show that SUPER outperforms previous approaches both qualitatively and
quantitatively, opening new possibilities for photorealistic selfie editing."
Online-Adaptive Anomaly Detection for Defect Identification in Aircraft Assembly,https://arxiv.org/abs/2406.12698,2024-06-18,2024-06-19,0.0,0.0,"Anomaly detection deals with detecting deviations from established patterns
within data. It has various applications like autonomous driving, predictive
maintenance, and medical diagnosis. To improve anomaly detection accuracy,
transfer learning can be applied to large, pre-trained models and adapt them to
the specific application context. In this paper, we propose a novel framework
for online-adaptive anomaly detection using transfer learning. The approach
adapts to different environments by selecting visually similar training images
and online fitting a normality model to EfficientNet features extracted from
the training subset. Anomaly detection is then performed by computing the
Mahalanobis distance between the normality model and the test image features.
Different similarity measures (SIFT/FLANN, Cosine) and normality models (MVG,
OCSVM) are employed and compared with each other. We evaluate the approach on
different anomaly detection benchmarks and data collected in controlled
laboratory settings. Experimental results showcase a detection accuracy
exceeding 0.975, outperforming the state-of-the-art ET-NET approach."
XXLTraffic - Expanding and Extremely Long Traffic Dataset for Ultra-Dynamic Forecasting Challenges,https://arxiv.org/abs/2406.12693,2024-06-18,2024-06-19,0.0,0.0,"Traffic forecasting is crucial for smart cities and intelligent
transportation initiatives, where deep learning has made significant progress
in modeling complex spatio-temporal patterns in recent years. However, current
public datasets have limitations in reflecting the ultra-dynamic nature of
real-world scenarios, characterized by continuously evolving infrastructures,
varying temporal distributions, and temporal gaps due to sensor downtimes or
changes in traffic patterns. These limitations inevitably restrict the
practical applicability of existing traffic forecasting datasets. To bridge
this gap, we present XXLTraffic, the largest available public traffic dataset
with the longest timespan and increasing number of sensor nodes over the
multiple years observed in the data, curated to support research in
ultra-dynamic forecasting. Our benchmark includes both typical time-series
forecasting settings with hourly and daily aggregated data and novel
configurations that introduce gaps and down-sample the training size to better
simulate practical constraints. We anticipate the new XXLTraffic will provide a
fresh perspective for the time-series and traffic forecasting communities. It
would also offer a robust platform for developing and evaluating models
designed to tackle ultra-dynamic and extremely long forecasting problems. Our
dataset supplements existing spatio-temporal data resources and leads to new
research directions in this domain."
MAGIC - Generating Self-Correction Guideline for In-Context Text-to-SQL,https://arxiv.org/abs/2406.12692,2024-06-18,2024-06-19,0.0,0.0,"Self-correction in text-to-SQL is the process of prompting large language
model (LLM) to revise its previously incorrectly generated SQL, and commonly
relies on manually crafted self-correction guidelines by human experts that are
not only labor-intensive to produce but also limited by the human ability in
identifying all potential error patterns in LLM responses. We introduce MAGIC,
a novel multi-agent method that automates the creation of the self-correction
guideline. MAGIC uses three specialized agents: a manager, a correction, and a
feedback agent. These agents collaborate on the failures of an LLM-based method
on the training set to iteratively generate and refine a self-correction
guideline tailored to LLM mistakes, mirroring human processes but without human
involvement. Our extensive experiments show that MAGIC's guideline outperforms
expert human's created ones. We empirically find out that the guideline
produced by MAGIC enhance the interpretability of the corrections made,
providing insights in analyzing the reason behind the failures and successes of
LLMs in self-correction. We make all agent interactions publicly available to
the research community, to foster further research in this area, offering a
synthetic dataset for future explorations into automatic self-correction
guideline generation."
Using LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia,https://arxiv.org/abs/2406.12687,2024-06-18,2024-06-19,0.0,0.0,"NLP in mental health has been primarily social media focused. Real world
practitioners also have high case loads and often domain specific variables, of
which modern LLMs lack context. We take a dataset made by recruiting 644
participants, including individuals diagnosed with Bipolar Disorder (BD),
Schizophrenia (SZ), and Healthy Controls (HC). Participants undertook tasks
derived from a standardized mental health instrument, and the resulting data
were transcribed and annotated by experts across five clinical variables. This
paper demonstrates the application of contemporary language models in
sequence-to-sequence tasks to enhance mental health research. Specifically, we
illustrate how these models can facilitate the deployment of mental health
instruments, data collection, and data annotation with high accuracy and
scalability. We show that small models are capable of annotation for
domain-specific clinical variables, data collection for mental-health
instruments, and perform better then commercial large models."
Spatial Sequence Attention Network for Schizophrenia Classification from Structural Brain MR Images,https://arxiv.org/abs/2406.12683,2024-06-18,2024-06-19,0.0,0.0,"Schizophrenia is a debilitating, chronic mental disorder that significantly
impacts an individual's cognitive abilities, behavior, and social interactions.
It is characterized by subtle morphological changes in the brain, particularly
in the gray matter. These changes are often imperceptible through manual
observation, demanding an automated approach to diagnosis. This study
introduces a deep learning methodology for the classification of individuals
with Schizophrenia. We achieve this by implementing a diversified attention
mechanism known as Spatial Sequence Attention (SSA) which is designed to
extract and emphasize significant feature representations from structural MRI
(sMRI). Initially, we employ the transfer learning paradigm by leveraging
pre-trained DenseNet to extract initial feature maps from the final
convolutional block which contains morphological alterations associated with
Schizophrenia. These features are further processed by the proposed SSA to
capture and emphasize intricate spatial interactions and relationships across
volumes within the brain. Our experimental studies conducted on a clinical
dataset have revealed that the proposed attention mechanism outperforms the
existing Squeeze & Excitation Network for Schizophrenia classification."
Measuring Psychological Depth in Language Models,https://arxiv.org/abs/2406.12680,2024-06-18,2024-06-19,0.0,0.0,"Evaluations of creative stories generated by large language models (LLMs)
often focus on objective properties of the text, such as its style, coherence,
and toxicity. While these metrics are indispensable, they do not speak to a
story's subjective, psychological impact from a reader's perspective. We
introduce the Psychological Depth Scale (PDS), a novel framework rooted in
literary theory that measures an LLM's ability to produce authentic and
narratively complex stories that provoke emotion, empathy, and engagement. We
empirically validate our framework by showing that humans can consistently
evaluate stories based on PDS (0.72 Krippendorff's alpha). We also explore
techniques for automating the PDS to easily scale future analyses. GPT-4o,
combined with a novel Mixture-of-Personas (MoP) prompting strategy, achieves an
average Spearman correlation of $0.51$ with human judgment while Llama-3-70B
scores as high as 0.68 for empathy. Finally, we compared the depth of stories
authored by both humans and LLMs. Surprisingly, GPT-4 stories either surpassed
or were statistically indistinguishable from highly-rated human-written stories
sourced from Reddit. By shifting the focus from text to reader, the
Psychological Depth Scale is a validated, automated, and systematic means of
measuring the capacity of LLMs to connect with humans through the stories they
tell."
Vernacular? I Barely Know Her - Challenges with Style Control and Stereotyping,https://arxiv.org/abs/2406.12679,2024-06-18,2024-06-19,0.0,0.0,"Large Language Models (LLMs) are increasingly being used in educational and
learning applications. Research has demonstrated that controlling for style, to
fit the needs of the learner, fosters increased understanding, promotes
inclusion, and helps with knowledge distillation. To understand the
capabilities and limitations of contemporary LLMs in style control, we
evaluated five state-of-the-art models: GPT-3.5, GPT-4, GPT-4o, Llama-3, and
Mistral-instruct- 7B across two style control tasks. We observed significant
inconsistencies in the first task, with model performances averaging between
5th and 8th grade reading levels for tasks intended for first-graders, and
standard deviations up to 27.6. For our second task, we observed a
statistically significant improvement in performance from 0.02 to 0.26.
However, we find that even without stereotypes in reference texts, LLMs often
generated culturally insensitive content during their tasks. We provide a
thorough analysis and discussion of the results."
Contraction rates for conjugate gradient and Lanczos approximate posteriors in Gaussian process regression,https://arxiv.org/abs/2406.12678,2024-06-18,2024-06-19,0.0,0.0,"Due to their flexibility and theoretical tractability Gaussian process (GP)
regression models have become a central topic in modern statistics and machine
learning. While the true posterior in these models is given explicitly,
numerical evaluations depend on the inversion of the augmented kernel matrix $
K + \sigma^2 I $, which requires up to $ O(n^3) $ operations. For large sample
sizes n, which are typically given in modern applications, this is
computationally infeasible and necessitates the use of an approximate version
of the posterior. Although such methods are widely used in practice, they
typically have very limtied theoretical underpinning.
  In this context, we analyze a class of recently proposed approximation
algorithms from the field of Probabilistic numerics. They can be interpreted in
terms of Lanczos approximate eigenvectors of the kernel matrix or a conjugate
gradient approximation of the posterior mean, which are particularly
advantageous in truly large scale applications, as they are fundamentally only
based on matrix vector multiplications amenable to the GPU acceleration of
modern software frameworks. We combine result from the numerical analysis
literature with state of the art concentration results for spectra of kernel
matrices to obtain minimax contraction rates. Our theoretical findings are
illustrated by numerical experiments."
Estimating Knowledge in Large Language Models Without Generating a Single Token,https://arxiv.org/abs/2406.12673,2024-06-18,2024-06-19,1.0,0.0,"To evaluate knowledge in large language models (LLMs), current methods query
the model and then evaluate its generated responses. In this work, we ask
whether evaluation can be done $\textit{before}$ the model has generated any
text. Concretely, is it possible to estimate how knowledgeable a model is about
a certain entity, only from its internal computation? We study this question
with two tasks: given a subject entity, the goal is to predict (a) the ability
of the model to answer common questions about the entity, and (b) the
factuality of responses generated by the model about the entity. Experiments
with a variety of LLMs show that KEEN, a simple probe trained over internal
subject representations, succeeds at both tasks - strongly correlating with
both the QA accuracy of the model per-subject and FActScore, a recent
factuality metric in open-ended generation. Moreover, KEEN naturally aligns
with the model's hedging behavior and faithfully reflects changes in the
model's knowledge after fine-tuning. Lastly, we show a more interpretable yet
equally performant variant of KEEN, which highlights a small set of tokens that
correlates with the model's lack of knowledge. Being simple and lightweight,
KEEN can be leveraged to identify gaps and clusters of entity knowledge in
LLMs, and guide decisions such as augmenting queries with retrieval."
Sparsifying dimensionality reduction of PDE solution data with Bregman learning,https://arxiv.org/abs/2406.12672,2024-06-18,2024-06-19,0.0,0.0,"Classical model reduction techniques project the governing equations onto a
linear subspace of the original state space. More recent data-driven techniques
use neural networks to enable nonlinear projections. Whilst those often enable
stronger compression, they may have redundant parameters and lead to suboptimal
latent dimensionality. To overcome these, we propose a multistep algorithm that
induces sparsity in the encoder-decoder networks for effective reduction in the
number of parameters and additional compression of the latent space. This
algorithm starts with sparsely initialized a network and training it using
linearized Bregman iterations. These iterations have been very successful in
computer vision and compressed sensing tasks, but have not yet been used for
reduced-order modelling. After the training, we further compress the latent
space dimensionality by using a form of proper orthogonal decomposition. Last,
we use a bias propagation technique to change the induced sparsity into an
effective reduction of parameters. We apply this algorithm to three
representative PDE models: 1D diffusion, 1D advection, and 2D
reaction-diffusion. Compared to conventional training methods like Adam, the
proposed method achieves similar accuracy with 30% less parameters and a
significantly smaller latent space."
Stealth edits for provably fixing or attacking large language models,https://arxiv.org/abs/2406.12670,2024-06-18,2024-06-19,0.0,0.0,"We reveal new methods and the theoretical foundations of techniques for
editing large language models. We also show how the new theory can be used to
assess the editability of models and to expose their susceptibility to
previously unknown malicious attacks. Our theoretical approach shows that a
single metric (a specific measure of the intrinsic dimensionality of the
model's features) is fundamental to predicting the success of popular editing
approaches, and reveals new bridges between disparate families of editing
methods. We collectively refer to these approaches as stealth editing methods,
because they aim to directly and inexpensively update a model's weights to
correct the model's responses to known hallucinating prompts without otherwise
affecting the model's behaviour, without requiring retraining. By carefully
applying the insight gleaned from our theoretical investigation, we are able to
introduce a new network block -- named a jet-pack block -- which is optimised
for highly selective model editing, uses only standard network operations, and
can be inserted into existing networks. The intrinsic dimensionality metric
also determines the vulnerability of a language model to a stealth attack: a
small change to a model's weights which changes its response to a single
attacker-chosen prompt. Stealth attacks do not require access to or knowledge
of the model's training data, therefore representing a potent yet previously
unrecognised threat to redistributed foundation models. They are
computationally simple enough to be implemented in malware in many cases.
Extensive experimental results illustrate and support the method and its
theoretical underpinnings. Demos and source code for editing language models
are available at https://github.com/qinghua-zhou/stealth-edits."
A Systematization of the Wagner Framework - Graph Theory Conjectures and Reinforcement Learning,https://arxiv.org/abs/2406.12667,2024-06-18,2024-06-19,0.0,0.0,"In 2021, Adam Zsolt Wagner proposed an approach to disprove conjectures in
graph theory using Reinforcement Learning (RL). Wagner's idea can be framed as
follows: consider a conjecture, such as a certain quantity f(G) < 0 for every
graph G; one can then play a single-player graph-building game, where at each
turn the player decides whether to add an edge or not. The game ends when all
edges have been considered, resulting in a certain graph G_T, and f(G_T) is the
final score of the game; RL is then used to maximize this score. This brilliant
idea is as simple as innovative, and it lends itself to systematic
generalization. Several different single-player graph-building games can be
employed, along with various RL algorithms. Moreover, RL maximizes the
cumulative reward, allowing for step-by-step rewards instead of a single final
score, provided the final cumulative reward represents the quantity of interest
f(G_T). In this paper, we discuss these and various other choices that can be
significant in Wagner's framework. As a contribution to this systematization,
we present four distinct single-player graph-building games. Each game employs
both a step-by-step reward system and a single final score. We also propose a
principled approach to select the most suitable neural network architecture for
any given conjecture, and introduce a new dataset of graphs labeled with their
Laplacian spectra. Furthermore, we provide a counterexample for a conjecture
regarding the sum of the matching number and the spectral radius, which is
simpler than the example provided in Wagner's original paper.
  The games have been implemented as environments in the Gymnasium framework,
and along with the dataset, are available as open-source supplementary
materials."
CollabStory - Multi-LLM Collaborative Story Generation and Authorship Analysis,https://arxiv.org/abs/2406.12665,2024-06-18,2024-06-19,0.0,0.0,"The rise of unifying frameworks that enable seamless interoperability of
Large Language Models (LLMs) has made LLM-LLM collaboration for open-ended
tasks a possibility. Despite this, there have not been efforts to explore such
collaborative writing. We take the next step beyond human-LLM collaboration to
explore this multi-LLM scenario by generating the first exclusively
LLM-generated collaborative stories dataset called CollabStory. We focus on
single-author ($N=1$) to multi-author (up to $N=5$) scenarios, where multiple
LLMs co-author stories. We generate over 32k stories using open-source
instruction-tuned LLMs. Further, we take inspiration from the PAN tasks that
have set the standard for human-human multi-author writing tasks and analysis.
We extend their authorship-related tasks for multi-LLM settings and present
baselines for LLM-LLM collaboration. We find that current baselines are not
able to handle this emerging scenario. Thus, CollabStory is a resource that
could help propel an understanding as well as the development of techniques to
discern the use of multiple LLMs. This is crucial to study in the context of
writing tasks since LLM-LLM collaboration could potentially overwhelm ongoing
challenges related to plagiarism detection, credit assignment, maintaining
academic integrity in educational settings, and addressing copyright
infringement concerns. We make our dataset and code available at
\texttt{\url{https://github.com/saranya-venkatraman/multi_llm_story_writing}}."
Do More Details Always Introduce More Hallucinations in LVLM-based Image Captioning?,https://arxiv.org/abs/2406.12663,2024-06-18,2024-06-19,0.0,0.0,"Large Vision-Language Models (LVLMs) excel in integrating visual and
linguistic contexts to produce detailed content, facilitating applications such
as image captioning. However, using LVLMs to generate descriptions often faces
the challenge of object hallucination (OH), where the output text misrepresents
actual objects in the input image. While previous studies attribute the
occurrence of OH to the inclusion of more details, our study finds technical
flaws in existing metrics, leading to unreliable evaluations of models and
conclusions about OH. This has sparked a debate on the question: Do more
details always introduce more hallucinations in LVLM-based image captioning?
  In this paper, we address this debate by proposing a novel decoding strategy,
Differentiated Beam Decoding (DBD), along with a reliable new set of evaluation
metrics: CLIP-Precision, CLIP-Recall, and CLIP-F1. DBD decodes the wealth of
information hidden in visual input into distinct language representations
called unit facts in parallel. This decoding is achieved via a well-designed
differential score that guides the parallel search and candidate screening. The
selected unit facts are then aggregated to generate the final caption. Our
proposed metrics evaluate the comprehensiveness and accuracy of image captions
by comparing the embedding groups of ground-truth image regions and generated
text partitions. Extensive experiments on the Visual Genome dataset validate
the effectiveness of our approach, demonstrating that it produces detailed
descriptions while maintaining low hallucination levels."
SCORE - A 1D Reparameterization Technique to Break Bayesian Optimization's Curse of Dimensionality,https://arxiv.org/abs/2406.12661,2024-06-18,2024-06-19,0.0,0.0,"Bayesian optimization (BO) has emerged as a powerful tool for navigating
complex search spaces, showcasing practical applications in the fields of
science and engineering.However, since it typically relies on a surrogate model
to approximate the objective function, BO grapples with heightened
computational costs that tend to escalate as the number of parameters and
experiments grows. Several methods such as parallelization, surrogate model
approximations, and memory pruning have been proposed to cut down computing
time, but they all fall short of resolving the core issue behind BO's curse of
dimensionality. In this paper, a 1D reparametrization trick is proposed to
break this curse and sustain linear time complexity for BO in high-dimensional
landscapes. This fast and scalable approach named SCORE can successfully find
the global minimum of needle-in-a-haystack optimization functions and fit
real-world data without the high-performance computing resources typically
required by state-of-the-art techniques."
Investigating the Role of Explainability and AI Literacy in User Compliance,https://arxiv.org/abs/2406.12660,2024-06-18,2024-06-19,0.0,0.0,"AI is becoming increasingly common across different domains. However, as
sophisticated AI-based systems are often black-boxed, rendering the
decision-making logic opaque, users find it challenging to comply with their
recommendations. Although researchers are investigating Explainable AI (XAI) to
increase the transparency of the underlying machine learning models, it is
unclear what types of explanations are effective and what other factors
increase compliance. To better understand the interplay of these factors, we
conducted an experiment with 562 participants who were presented with the
recommendations of an AI and two different types of XAI. We find that users'
compliance increases with the introduction of XAI but is also affected by AI
literacy. We also find that the relationships between AI literacy XAI and
users' compliance are mediated by the users' mental model of AI. Our study has
several implications for successfully designing AI-based systems utilizing XAI."
A variational Bayes approach to debiased inference for low-dimensional parameters in high-dimensional linear regression,https://arxiv.org/abs/2406.12659,2024-06-18,2024-06-19,0.0,0.0,"We propose a scalable variational Bayes method for statistical inference for
a single or low-dimensional subset of the coordinates of a high-dimensional
parameter in sparse linear regression. Our approach relies on assigning a
mean-field approximation to the nuisance coordinates and carefully modelling
the conditional distribution of the target given the nuisance. This requires
only a preprocessing step and preserves the computational advantages of
mean-field variational Bayes, while ensuring accurate and reliable inference
for the target parameter, including for uncertainty quantification. We
investigate the numerical performance of our algorithm, showing that it
performs competitively with existing methods. We further establish accompanying
theoretical guarantees for estimation and uncertainty quantification in the
form of a Bernstein--von Mises theorem."
Federated Learning with a Single Shared Image,https://arxiv.org/abs/2406.12658,2024-06-18,2024-06-19,0.0,0.0,"Federated Learning (FL) enables multiple machines to collaboratively train a
machine learning model without sharing of private training data. Yet,
especially for heterogeneous models, a key bottleneck remains the transfer of
knowledge gained from each client model with the server. One popular method,
FedDF, uses distillation to tackle this task with the use of a common, shared
dataset on which predictions are exchanged. However, in many contexts such a
dataset might be difficult to acquire due to privacy and the clients might not
allow for storage of a large shared dataset. To this end, in this paper, we
introduce a new method that improves this knowledge distillation method to only
rely on a single shared image between clients and server. In particular, we
propose a novel adaptive dataset pruning algorithm that selects the most
informative crops generated from only a single image. With this, we show that
federated learning with distillation under a limited shared dataset budget
works better by using a single image compared to multiple individual ones.
Finally, we extend our approach to allow for training heterogeneous client
architectures by incorporating a non-uniform distillation schedule and
client-model mirroring on the server side."
Benchmarks and Metrics for Evaluations of Code Generation - A Critical Review,https://arxiv.org/abs/2406.12655,2024-06-18,2024-06-19,0.0,0.0,"With the rapid development of Large Language Models (LLMs), a large number of
machine learning models have been developed to assist programming tasks
including the generation of program code from natural language input. However,
how to evaluate such LLMs for this task is still an open problem despite of the
great amount of research efforts that have been made and reported to evaluate
and compare them. This paper provides a critical review of the existing work on
the testing and evaluation of these tools with a focus on two key aspects: the
benchmarks and the metrics used in the evaluations. Based on the review,
further research directions are discussed."
Probabilistic Conceptual Explainers - Trustworthy Conceptual Explanations for Vision Foundation Models,https://arxiv.org/abs/2406.12649,2024-06-18,2024-06-19,0.0,0.0,"Vision transformers (ViTs) have emerged as a significant area of focus,
particularly for their capacity to be jointly trained with large language
models and to serve as robust vision foundation models. Yet, the development of
trustworthy explanation methods for ViTs has lagged, particularly in the
context of post-hoc interpretations of ViT predictions. Existing sub-image
selection approaches, such as feature-attribution and conceptual models, fall
short in this regard. This paper proposes five desiderata for explaining ViTs
-- faithfulness, stability, sparsity, multi-level structure, and parsimony --
and demonstrates the inadequacy of current methods in meeting these criteria
comprehensively. We introduce a variational Bayesian explanation framework,
dubbed ProbAbilistic Concept Explainers (PACE), which models the distributions
of patch embeddings to provide trustworthy post-hoc conceptual explanations.
Our qualitative analysis reveals the distributions of patch-level concepts,
elucidating the effectiveness of ViTs by modeling the joint distribution of
patch embeddings and ViT's predictions. Moreover, these patch-level
explanations bridge the gap between image-level and dataset-level explanations,
thus completing the multi-level structure of PACE. Through extensive
experiments on both synthetic and real-world datasets, we demonstrate that PACE
surpasses state-of-the-art methods in terms of the defined desiderata."
Evaluating Transparency of Machine Generated Fact Checking Explanations,https://arxiv.org/abs/2406.12645,2024-06-18,2024-06-19,0.0,0.0,"An important factor when it comes to generating fact-checking explanations is
the selection of evidence: intuitively, high-quality explanations can only be
generated given the right evidence. In this work, we investigate the impact of
human-curated vs. machine-selected evidence for explanation generation using
large language models. To assess the quality of explanations, we focus on
transparency (whether an explanation cites sources properly) and utility
(whether an explanation is helpful in clarifying a claim). Surprisingly, we
found that large language models generate similar or higher quality
explanations using machine-selected evidence, suggesting carefully curated
evidence (by humans) may not be necessary. That said, even with the best model,
the generated explanations are not always faithful to the sources, suggesting
further room for improvement in explanation generation for fact-checking."
Hierarchical Prompting Taxonomy - A Universal Evaluation Framework for Large Language Models,https://arxiv.org/abs/2406.12644,2024-06-18,2024-06-19,0.0,0.0,"Assessing the effectiveness of large language models (LLMs) in addressing
diverse tasks is essential for comprehending their strengths and weaknesses.
Conventional evaluation techniques typically apply a single prompting strategy
uniformly across datasets, not considering the varying degrees of task
complexity. We introduce the Hierarchical Prompting Taxonomy (HPT), a taxonomy
that employs a Hierarchical Prompt Framework (HPF) composed of five unique
prompting strategies, arranged from the simplest to the most complex, to assess
LLMs more precisely and to offer a clearer perspective. This taxonomy assigns a
score, called the Hierarchical Prompting Score (HP-Score), to datasets as well
as LLMs based on the rules of the taxonomy, providing a nuanced understanding
of their ability to solve diverse tasks and offering a universal measure of
task complexity. Additionally, we introduce the Adaptive Hierarchical Prompt
framework, which automates the selection of appropriate prompting strategies
for each task. This study compares manual and adaptive hierarchical prompt
frameworks using four instruction-tuned LLMs, namely Llama 3 8B, Phi 3 3.8B,
Mistral 7B, and Gemma 7B, across four datasets: BoolQ, CommonSenseQA (CSQA),
IWSLT-2017 en-fr (IWSLT), and SamSum. Experiments demonstrate the effectiveness
of HPT, providing a reliable way to compare different tasks and LLM
capabilities. This paper leads to the development of a universal evaluation
metric that can be used to evaluate both the complexity of the datasets and the
capabilities of LLMs. The implementation of both manual HPF and adaptive HPF is
publicly available."
DetectBench - Can Large Language Model Detect and Piece Together Implicit Evidence?,https://arxiv.org/abs/2406.12641,2024-06-18,2024-06-19,0.0,0.0,"Detecting evidence within the context is a key step in the process of
reasoning task. Evaluating and enhancing the capabilities of LLMs in evidence
detection will strengthen context-based reasoning performance. This paper
proposes a benchmark called DetectBench for verifying the ability to detect and
piece together implicit evidence within a long context. DetectBench contains
3,928 multiple-choice questions, with an average of 994 tokens per question.
Each question contains an average of 4.55 pieces of implicit evidence, and
solving the problem typically requires 7.62 logical jumps to find the correct
answer. To enhance the performance of LLMs in evidence detection, this paper
proposes Detective Reasoning Prompt and Finetune. Experiments demonstrate that
the existing LLMs' abilities to detect evidence in long contexts are far
inferior to humans. However, the Detective Reasoning Prompt effectively
enhances the capability of powerful LLMs in evidence detection, while the
Finetuning method shows significant effects in enhancing the performance of
weaker LLMs. Moreover, when the abilities of LLMs in evidence detection are
improved, their final reasoning performance is also enhanced accordingly."
Research and Implementation of Data Enhancement Techniques for Graph Neural Networks,https://arxiv.org/abs/2406.12640,2024-06-18,2024-06-19,0.0,0.0,"Data, algorithms, and arithmetic power are the three foundational conditions
for deep learning to be effective in the application domain. Data is the focus
for developing deep learning algorithms. In practical engineering applications,
some data are affected by the conditions under which more data cannot be
obtained or the cost of obtaining data is too high, resulting in smaller data
sets (generally several hundred to several thousand) and data sizes that are
far smaller than the size of large data sets (tens of thousands). The above two
methods are based on the original dataset to generate, in the case of
insufficient data volume of the original data may not reflect all the real
environment, such as the real environment of the light, silhouette and other
information, if the amount of data is not enough, it is difficult to use a
simple transformation or neural network generative model to generate the
required data. The research in this paper firstly analyses the key points of
the data enhancement technology of graph neural network, and at the same time
introduces the composition foundation of graph neural network in depth, on the
basis of which the data enhancement technology of graph neural network is
optimized and analysed."
Ask-before-Plan - Proactive Language Agents for Real-World Planning,https://arxiv.org/abs/2406.12639,2024-06-18,2024-06-19,0.0,0.0,"The evolution of large language models (LLMs) has enhanced the planning
capabilities of language agents in diverse real-world scenarios. Despite these
advancements, the potential of LLM-powered agents to comprehend ambiguous user
instructions for reasoning and decision-making is still under exploration. In
this work, we introduce a new task, Proactive Agent Planning, which requires
language agents to predict clarification needs based on user-agent conversation
and agent-environment interaction, invoke external tools to collect valid
information, and generate a plan to fulfill the user's demands. To study this
practical problem, we establish a new benchmark dataset, Ask-before-Plan. To
tackle the deficiency of LLMs in proactive planning, we propose a novel
multi-agent framework, Clarification-Execution-Planning (\texttt{CEP}), which
consists of three agents specialized in clarification, execution, and planning.
We introduce the trajectory tuning scheme for the clarification agent and
static execution agent, as well as the memory recollection mechanism for the
dynamic execution agent. Extensive evaluations and comprehensive analyses
conducted on the Ask-before-Plan dataset validate the effectiveness of our
proposed framework."
Efficient and Long-Tailed Generalization for Pre-trained Vision-Language Model,https://arxiv.org/abs/2406.12638,2024-06-18,2024-06-19,0.0,0.0,"Pre-trained vision-language models like CLIP have shown powerful zero-shot
inference ability via image-text matching and prove to be strong few-shot
learners in various downstream tasks. However, in real-world scenarios,
adapting CLIP to downstream tasks may encounter the following challenges: 1)
data may exhibit long-tailed data distributions and might not have abundant
samples for all the classes; 2) There might be emerging tasks with new classes
that contain no samples at all. To overcome them, we propose a novel framework
to achieve efficient and long-tailed generalization, which can be termed as
Candle. During the training process, we propose compensating logit-adjusted
loss to encourage large margins of prototypes and alleviate imbalance both
within the base classes and between the base and new classes. For efficient
adaptation, we treat the CLIP model as a black box and leverage the extracted
features to obtain visual and textual prototypes for prediction. To make full
use of multi-modal information, we also propose cross-modal attention to enrich
the features from both modalities. For effective generalization, we introduce
virtual prototypes for new classes to make up for their lack of training
images. Candle achieves state-of-the-art performance over extensive experiments
on 11 diverse datasets while substantially reducing the training time,
demonstrating the superiority of our approach. The source code is available at
https://github.com/shijxcs/Candle."
ScenEval - A Benchmark for Scenario-Based Evaluation of Code Generation,https://arxiv.org/abs/2406.12635,2024-06-18,2024-06-19,0.0,0.0,"In the scenario-based evaluation of machine learning models, a key problem is
how to construct test datasets that represent various scenarios. The
methodology proposed in this paper is to construct a benchmark and attach
metadata to each test case. Then a test system can be constructed with test
morphisms that filter the test cases based on metadata to form a dataset.
  The paper demonstrates this methodology with large language models for code
generation. A benchmark called ScenEval is constructed from problems in
textbooks, an online tutorial website and Stack Overflow. Filtering by scenario
is demonstrated and the test sets are used to evaluate ChatGPT for Java code
generation.
  Our experiments found that the performance of ChatGPT decreases with the
complexity of the coding task. It is weakest for advanced topics like
multi-threading, data structure algorithms and recursive methods. The Java code
generated by ChatGPT tends to be much shorter than reference solution in terms
of number of lines, while it is more likely to be more complex in both
cyclomatic and cognitive complexity metrics, if the generated code is correct.
However, the generated code is more likely to be less complex than the
reference solution if the code is incorrect."
News Without Borders - Domain Adaptation of Multilingual Sentence Embeddings for Cross-lingual News Recommendation,https://arxiv.org/abs/2406.12634,2024-06-18,2024-06-19,0.0,0.0,"Rapidly growing numbers of multilingual news consumers pose an increasing
challenge to news recommender systems in terms of providing customized
recommendations. First, existing neural news recommenders, even when powered by
multilingual language models (LMs), suffer substantial performance losses in
zero-shot cross-lingual transfer (ZS-XLT). Second, the current paradigm of
fine-tuning the backbone LM of a neural recommender on task-specific data is
computationally expensive and infeasible in few-shot recommendation and
cold-start setups, where data is scarce or completely unavailable. In this
work, we propose a news-adapted sentence encoder (NaSE), domain-specialized
from a pretrained massively multilingual sentence encoder (SE). To this end, we
construct and leverage PolyNews and PolyNewsParallel, two multilingual
news-specific corpora. With the news-adapted multilingual SE in place, we test
the effectiveness of (i.e., question the need for) supervised fine-tuning for
news recommendation, and propose a simple and strong baseline based on (i)
frozen NaSE embeddings and (ii) late click-behavior fusion. We show that NaSE
achieves state-of-the-art performance in ZS-XLT in true cold-start and few-shot
news recommendation."
SeTAR - Out-of-Distribution Detection with Selective Low-Rank Approximation,https://arxiv.org/abs/2406.12629,2024-06-18,2024-06-19,0.0,0.0,"Out-of-distribution (OOD) detection is crucial for the safe deployment of
neural networks. Existing CLIP-based approaches perform OOD detection by
devising novel scoring functions or sophisticated fine-tuning methods. In this
work, we propose SeTAR, a novel, training-free OOD detection method that
leverages selective low-rank approximation of weight matrices in
vision-language and vision-only models. SeTAR enhances OOD detection via
post-hoc modification of the model's weight matrices using a simple greedy
search algorithm. Based on SeTAR, we further propose SeTAR+FT, a fine-tuning
extension optimizing model performance for OOD detection tasks. Extensive
evaluations on ImageNet1K and Pascal-VOC benchmarks show SeTAR's superior
performance, reducing the false positive rate by up to 18.95% and 36.80%
compared to zero-shot and fine-tuning baselines. Ablation studies further
validate our approach's effectiveness, robustness, and generalizability across
different model backbones. Our work offers a scalable, efficient solution for
OOD detection, setting a new state-of-the-art in this area."
Judging the Judges - Evaluating Alignment and Vulnerabilities in LLMs-as-Judges,https://arxiv.org/abs/2406.12624,2024-06-18,2024-06-19,0.0,0.0,"Offering a promising solution to the scalability challenges associated with
human evaluation, the LLM-as-a-judge paradigm is rapidly gaining traction as an
approach to evaluating large language models (LLMs). However, there are still
many open questions about the strengths and weaknesses of this paradigm, and
what potential biases it may hold. In this paper, we present a comprehensive
study of the performance of various LLMs acting as judges. We leverage TriviaQA
as a benchmark for assessing objective knowledge reasoning of LLMs and evaluate
them alongside human annotations which we found to have a high inter-annotator
agreement. Our study includes 9 judge models and 9 exam taker models -- both
base and instruction-tuned. We assess the judge model's alignment across
different model sizes, families, and judge prompts. Among other results, our
research rediscovers the importance of using Cohen's kappa as a metric of
alignment as opposed to simple percent agreement, showing that judges with high
percent agreement can still assign vastly different scores. We find that both
Llama-3 70B and GPT-4 Turbo have an excellent alignment with humans, but in
terms of ranking exam taker models, they are outperformed by both JudgeLM-7B
and the lexical judge Contains, which have up to 34 points lower human
alignment. Through error analysis and various other studies, including the
effects of instruction length and leniency bias, we hope to provide valuable
lessons for using LLMs as judges in the future."
Growing Trees on Sounds - Assessing Strategies for End-to-End Dependency Parsing of Speech,https://arxiv.org/abs/2406.12621,2024-06-18,2024-06-19,0.0,0.0,"Direct dependency parsing of the speech signal -- as opposed to parsing
speech transcriptions -- has recently been proposed as a task (Pupier et al.
2022), as a way of incorporating prosodic information in the parsing system and
bypassing the limitations of a pipeline approach that would consist of using
first an Automatic Speech Recognition (ASR) system and then a syntactic parser.
In this article, we report on a set of experiments aiming at assessing the
performance of two parsing paradigms (graph-based parsing and sequence labeling
based parsing) on speech parsing. We perform this evaluation on a large
treebank of spoken French, featuring realistic spontaneous conversations. Our
findings show that (i) the graph based approach obtain better results across
the board (ii) parsing directly from speech outperforms a pipeline approach,
despite having 30% fewer parameters."
What makes two models think alike?,https://arxiv.org/abs/2406.12620,2024-06-18,2024-06-19,1.0,0.0,"Do architectural differences significantly affect the way models represent
and process language? We propose a new approach, based on metric-learning
encoding models (MLEMs), as a first step to answer this question. The approach
provides a feature-based comparison of how any two layers of any two models
represent linguistic information. We apply the method to BERT, GPT-2 and Mamba.
Unlike previous methods, MLEMs offer a transparent comparison, by identifying
the specific linguistic features responsible for similarities and differences.
More generally, the method uses formal, symbolic descriptions of a domain, and
use these to compare neural representations. As such, the approach can
straightforwardly be extended to other domains, such as speech and vision, and
to other neural systems, including human brains."
From Insights to Actions - The Impact of Interpretability and Analysis Research on NLP,https://arxiv.org/abs/2406.12618,2024-06-18,2024-06-19,1.0,0.0,"Interpretability and analysis (IA) research is a growing subfield within NLP
with the goal of developing a deeper understanding of the behavior or inner
workings of NLP systems and methods. Despite growing interest in the subfield,
a commonly voiced criticism is that it lacks actionable insights and therefore
has little impact on NLP. In this paper, we seek to quantify the impact of IA
research on the broader field of NLP. We approach this with a mixed-methods
analysis of: (1) a citation graph of 185K+ papers built from all papers
published at ACL and EMNLP conferences from 2018 to 2023, and (2) a survey of
138 members of the NLP community. Our quantitative results show that IA work is
well-cited outside of IA, and central in the NLP citation graph. Through
qualitative analysis of survey responses and manual annotation of 556 papers,
we find that NLP researchers build on findings from IA work and perceive it is
important for progress in NLP, multiple subfields, and rely on its findings and
terminology for their own work. Many novel methods are proposed based on IA
findings and highly influenced by them, but highly influential non-IA work
cites IA findings without being driven by them. We end by summarizing what is
missing in IA work today and provide a call to action, to pave the way for a
more impactful future of IA research."
Learning Diffusion at Lightspeed,https://arxiv.org/abs/2406.12616,2024-06-18,2024-06-19,0.0,0.0,"Diffusion regulates a phenomenal number of natural processes and the dynamics
of many successful generative models. Existing models to learn the diffusion
terms from observational data rely on complex bilevel optimization problems and
properly model only the drift of the system. We propose a new simple model,
JKOnet*, which bypasses altogether the complexity of existing architectures
while presenting significantly enhanced representational capacity: JKOnet*
recovers the potential, interaction, and internal energy components of the
underlying diffusion process. JKOnet* minimizes a simple quadratic loss, runs
at lightspeed, and drastically outperforms other baselines in practice.
Additionally, JKOnet* provides a closed-form optimal solution for linearly
parametrized functionals. Our methodology is based on the interpretation of
diffusion processes as energy-minimizing trajectories in the probability space
via the so-called JKO scheme, which we study via its first-order optimality
conditions, in light of few-weeks-old advancements in optimization in the
probability space."
When Are Bias-Free ReLU Networks Like Linear Networks?,https://arxiv.org/abs/2406.12615,2024-06-18,2024-06-19,0.0,0.0,"We investigate the expressivity and learning dynamics of bias-free ReLU
networks. We firstly show that two-layer bias-free ReLU networks have limited
expressivity: the only odd function two-layer bias-free ReLU networks can
express is a linear one. We then show that, under symmetry conditions on the
data, these networks have the same learning dynamics as linear networks. This
allows us to give closed-form time-course solutions to certain two-layer
bias-free ReLU networks, which has not been done for nonlinear networks outside
the lazy learning regime. While deep bias-free ReLU networks are more
expressive than their two-layer counterparts, they still share a number of
similarities with deep linear networks. These similarities enable us to
leverage insights from linear networks, leading to a novel understanding of
bias-free ReLU networks. Overall, our results show that some properties
established for bias-free ReLU networks arise due to equivalence to linear
networks, and suggest that including bias or considering asymmetric data are
avenues to engage with nonlinear behaviors."
EUvsDisinfo - a Dataset for Multilingual Detection of Pro-Kremlin Disinformation in News Articles,https://arxiv.org/abs/2406.12614,2024-06-18,2024-06-19,0.0,0.0,"This work introduces EUvsDisinfo, a multilingual dataset of disinformation
articles originating from pro-Kremlin outlets, along with trustworthy articles
from credible / less biased sources. It is sourced directly from the debunk
articles written by experts leading the EUvsDisinfo project. Our dataset is the
largest to-date resource in terms of the overall number of articles and
distinct languages. It also provides the largest topical and temporal coverage.
Using this dataset, we investigate the dissemination of pro-Kremlin
disinformation across different languages, uncovering language-specific
patterns targeting certain disinformation topics. We further analyse the
evolution of topic distribution over an eight-year period, noting a significant
surge in disinformation content before the full-scale invasion of Ukraine in
2022. Lastly, we demonstrate the dataset's applicability in training models to
effectively distinguish between disinformation and trustworthy content in
multilingual settings."
Rapid Language Adaptation for Multilingual E2E Speech Recognition Using Encoder Prompting,https://arxiv.org/abs/2406.12611,2024-06-18,2024-06-19,0.0,0.0,"End-to-end multilingual speech recognition models handle multiple languages
through a single model, often incorporating language identification to
automatically detect the language of incoming speech. Since the common scenario
is where the language is already known, these models can perform as
language-specific by using language information as prompts, which is
particularly beneficial for attention-based encoder-decoder architectures.
However, the Connectionist Temporal Classification (CTC) approach, which
enhances recognition via joint decoding and multi-task training, does not
normally incorporate language prompts due to its conditionally independent
output tokens. To overcome this, we introduce an encoder prompting technique
within the self-conditioned CTC framework, enabling language-specific
adaptation of the CTC model in a zero-shot manner. Our method has shown to
significantly reduce errors by 28% on average and by 41% on low-resource
languages."
Bridging Local Details and Global Context in Text-Attributed Graphs,https://arxiv.org/abs/2406.12608,2024-06-18,2024-06-19,0.0,0.0,"Representation learning on text-attributed graphs (TAGs) is vital for
real-world applications, as they combine semantic textual and contextual
structural information. Research in this field generally consist of two main
perspectives: local-level encoding and global-level aggregating, respectively
refer to textual node information unification (e.g., using Language Models) and
structure-augmented modeling (e.g., using Graph Neural Networks). Most existing
works focus on combining different information levels but overlook the
interconnections, i.e., the contextual textual information among nodes, which
provides semantic insights to bridge local and global levels. In this paper, we
propose GraphBridge, a multi-granularity integration framework that bridges
local and global perspectives by leveraging contextual textual information,
enhancing fine-grained understanding of TAGs. Besides, to tackle scalability
and efficiency challenges, we introduce a graphaware token reduction module.
Extensive experiments across various models and datasets show that our method
achieves state-of-theart performance, while our graph-aware token reduction
module significantly enhances efficiency and solves scalability issues."
Low-Redundant Optimization for Large Language Model Alignment,https://arxiv.org/abs/2406.12606,2024-06-18,2024-06-19,0.0,0.0,"Large language models (LLMs) are still struggling in aligning with human
preference in complex tasks and scenarios. They are prone to overfit into the
unexpected patterns or superficial styles in the training data. We conduct an
empirical study that only selects the top-10\% most updated parameters in LLMs
for alignment training, and see improvements in the convergence process and
final performance. It indicates the existence of redundant neurons in LLMs for
alignment training. To reduce its influence, we propose a low-redundant
alignment method named \textbf{ALLO}, focusing on optimizing the most related
neurons with the most useful supervised signals. Concretely, we first identify
the neurons that are related to the human preference data by a gradient-based
strategy, then identify the alignment-related key tokens by reward models for
computing loss. Besides, we also decompose the alignment process into the
forgetting and learning stages, where we first forget the tokens with unaligned
knowledge and then learn aligned knowledge, by updating different ratios of
neurons, respectively. Experimental results on 10 datasets have shown the
effectiveness of ALLO. Our code and data are available at
\url{https://github.com/RUCAIBox/ALLO}."
Attack and Defense of Deep Learning Models in the Field of Web Attack Detection,https://arxiv.org/abs/2406.12605,2024-06-18,2024-06-19,0.0,0.0,"The challenge of WAD (web attack detection) is growing as hackers
continuously refine their methods to evade traditional detection. Deep learning
models excel in handling complex unknown attacks due to their strong
generalization and adaptability. However, they are vulnerable to backdoor
attacks, where contextually irrelevant fragments are inserted into requests,
compromising model stability. While backdoor attacks are well studied in image
recognition, they are largely unexplored in WAD. This paper introduces backdoor
attacks in WAD, proposing five methods and corresponding defenses. Testing on
textCNN, biLSTM, and tinybert models shows an attack success rate over 87%,
reducible through fine-tuning. Future research should focus on backdoor
defenses in WAD. All the code and data of this paper can be obtained at
https://anonymous.4open.science/r/attackDefenceinDL-7E05"
Reinforcement-Learning based routing for packet-optical networks with hybrid telemetry,https://arxiv.org/abs/2406.12602,2024-06-18,2024-06-19,0.0,0.0,"This article provides a methodology and open-source implementation of
Reinforcement Learning algorithms for finding optimal routes in a
packet-optical network scenario. The algorithm uses measurements provided by
the physical layer (pre-FEC bit error rate and propagation delay) and the link
layer (link load) to configure a set of latency-based rewards and penalties
based on such measurements. Then, the algorithm executes Q-learning based on
this set of rewards for finding the optimal routing strategies. It is further
shown that the algorithm dynamically adapts to changing network conditions by
re-calculating optimal policies upon either link load changes or link
degradation as measured by pre-FEC BER."
Generalization bounds for mixing processes via delayed online-to-PAC conversions,https://arxiv.org/abs/2406.12600,2024-06-18,2024-06-19,0.0,0.0,"We study the generalization error of statistical learning algorithms in a
non-i.i.d. setting, where the training data is sampled from a stationary mixing
process. We develop an analytic framework for this scenario based on a
reduction to online learning with delayed feedback. In particular, we show that
the existence of an online learning algorithm with bounded regret (against a
fixed statistical learning algorithm in a specially constructed game of online
learning with delayed feedback) implies low generalization error of said
statistical learning method even if the data sequence is sampled from a mixing
time series. The rates demonstrate a trade-off between the amount of delay in
the online learning game and the degree of dependence between consecutive data
points, with near-optimal rates recovered in a number of well-studied settings
when the delay is tuned appropriately as a function of the mixing time of the
process."
PromptDSI - Prompt-based Rehearsal-free Instance-wise Incremental Learning for Document Retrieval,https://arxiv.org/abs/2406.12593,2024-06-18,2024-06-19,0.0,0.0,"Differentiable Search Index (DSI) utilizes Pre-trained Language Models (PLMs)
for efficient document retrieval without relying on external indexes. However,
DSIs need full re-training to handle updates in dynamic corpora, causing
significant computational inefficiencies. We introduce PromptDSI, a
rehearsal-free, prompt-based approach for instance-wise incremental learning in
document retrieval. PromptDSI attaches prompts to the frozen PLM's encoder of
DSI, leveraging its powerful representation to efficiently index new corpora
while maintaining a balance between stability and plasticity. We eliminate the
initial forward pass of prompt-based continual learning methods that doubles
training and inference time. Moreover, we propose a topic-aware prompt pool
that employs neural topic embeddings as fixed keys. This strategy ensures
diverse and effective prompt usage, addressing the challenge of parameter
underutilization caused by the collapse of the query-key matching mechanism.
Our empirical evaluations demonstrate that PromptDSI matches IncDSI in managing
forgetting while significantly enhancing recall by over 4% on new corpora."
Discovering Minimal Reinforcement Learning Environments,https://arxiv.org/abs/2406.12589,2024-06-18,2024-06-19,0.0,0.0,"Reinforcement learning (RL) agents are commonly trained and evaluated in the
same environment. In contrast, humans often train in a specialized environment
before being evaluated, such as studying a book before taking an exam. The
potential of such specialized training environments is still vastly
underexplored, despite their capacity to dramatically speed up training.
  The framework of synthetic environments takes a first step in this direction
by meta-learning neural network-based Markov decision processes (MDPs). The
initial approach was limited to toy problems and produced environments that did
not transfer to unseen RL algorithms. We extend this approach in three ways:
Firstly, we modify the meta-learning algorithm to discover environments
invariant towards hyperparameter configurations and learning algorithms.
Secondly, by leveraging hardware parallelism and introducing a curriculum on an
agent's evaluation episode horizon, we can achieve competitive results on
several challenging continuous control problems. Thirdly, we surprisingly find
that contextual bandits enable training RL agents that transfer well to their
evaluation environment, even if it is a complex MDP. Hence, we set up our
experiments to train synthetic contextual bandits, which perform on par with
synthetic MDPs, yield additional insights into the evaluation environment, and
can speed up downstream applications."
UIFV - Data Reconstruction Attack in Vertical Federated Learning,https://arxiv.org/abs/2406.12588,2024-06-18,2024-06-19,0.0,0.0,"Vertical Federated Learning (VFL) facilitates collaborative machine learning
without the need for participants to share raw private data. However, recent
studies have revealed privacy risks where adversaries might reconstruct
sensitive features through data leakage during the learning process. Although
data reconstruction methods based on gradient or model information are somewhat
effective, they reveal limitations in VFL application scenarios. This is
because these traditional methods heavily rely on specific model structures
and/or have strict limitations on application scenarios. To address this, our
study introduces the Unified InverNet Framework into VFL, which yields a novel
and flexible approach (dubbed UIFV) that leverages intermediate feature data to
reconstruct original data, instead of relying on gradients or model details.
The intermediate feature data is the feature exchanged by different
participants during the inference phase of VFL. Experiments on four datasets
demonstrate that our methods significantly outperform state-of-the-art
techniques in attack precision. Our work exposes severe privacy vulnerabilities
within VFL systems that pose real threats to practical VFL applications and
thus confirms the necessity of further enhancing privacy protection in the VFL
architecture."
Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling,https://arxiv.org/abs/2406.12585,2024-06-18,2024-06-19,1.0,0.0,"Ensembling multiple models has always been an effective approach to push the
limits of existing performance and is widely used in classification tasks by
simply averaging the classification probability vectors from multiple
classifiers to achieve better accuracy. However, in the thriving open-source
Large Language Model (LLM) community, ensembling methods are rare and typically
limited to ensembling the full-text outputs of LLMs, such as selecting the best
output using a ranker, which leads to underutilization of token-level
probability information. In this paper, we treat the Generation of each token
by LLMs as a Classification (GaC) for ensembling. This approach fully exploits
the probability information at each generation step and better prevents LLMs
from producing early incorrect tokens that lead to snowballing errors. In
experiments, we ensemble state-of-the-art LLMs on several benchmarks, including
exams, mathematics and reasoning, and observe that our method breaks the
existing community performance ceiling. Furthermore, we observed that most of
the tokens in the answer are simple and do not affect the correctness of the
final answer. Therefore, we also experimented with ensembling only key tokens,
and the results showed better performance with lower latency across benchmarks."
Training Diffusion Models with Federated Learning,https://arxiv.org/abs/2406.12575,2024-06-18,2024-06-19,0.0,0.0,"The training of diffusion-based models for image generation is predominantly
controlled by a select few Big Tech companies, raising concerns about privacy,
copyright, and data authority due to their lack of transparency regarding
training data. To ad-dress this issue, we propose a federated diffusion model
scheme that enables the independent and collaborative training of diffusion
models without exposing local data. Our approach adapts the Federated Averaging
(FedAvg) algorithm to train a Denoising Diffusion Model (DDPM). Through a novel
utilization of the underlying UNet backbone, we achieve a significant reduction
of up to 74% in the number of parameters exchanged during training,compared to
the naive FedAvg approach, whilst simultaneously maintaining image quality
comparable to the centralized setting, as evaluated by the FID score."
Mathador-LM - A Dynamic Benchmark for Mathematical Reasoning on Large Language Models,https://arxiv.org/abs/2406.12572,2024-06-18,2024-06-19,0.0,0.0,"We introduce Mathador-LM, a new benchmark for evaluating the mathematical
reasoning on large language models (LLMs), combining ruleset interpretation,
planning, and problem-solving. This benchmark is inspired by the Mathador game,
where the objective is to reach a target number using basic arithmetic
operations on a given set of base numbers, following a simple set of rules. We
show that, across leading LLMs, we obtain stable average performance while
generating benchmark instances dynamically, following a target difficulty
level. Thus, our benchmark alleviates concerns about test-set leakage into
training data, an issue that often undermines popular benchmarks. Additionally,
we conduct a comprehensive evaluation of both open and closed-source
state-of-the-art LLMs on Mathador-LM. Our findings reveal that contemporary
models struggle with Mathador-LM, scoring significantly lower than average 3rd
graders. This stands in stark contrast to their strong performance on popular
mathematical reasoning benchmarks."
Applying Ensemble Methods to Model-Agnostic Machine-Generated Text Detection,https://arxiv.org/abs/2406.12570,2024-06-18,2024-06-19,0.0,0.0,"In this paper, we study the problem of detecting machine-generated text when
the large language model (LLM) it is possibly derived from is unknown. We do so
by apply ensembling methods to the outputs from DetectGPT classifiers (Mitchell
et al. 2023), a zero-shot model for machine-generated text detection which is
highly accurate when the generative (or base) language model is the same as the
discriminative (or scoring) language model. We find that simple summary
statistics of DetectGPT sub-model outputs yield an AUROC of 0.73 (relative to
0.61) while retaining its zero-shot nature, and that supervised learning
methods sharply boost the accuracy to an AUROC of 0.94 but require a training
dataset. This suggests the possibility of further generalisation to create a
highly-accurate, model-agnostic machine-generated text detector."
MOYU - A Theoretical Study on Massive Over-activation Yielded Uplifts in LLMs,https://arxiv.org/abs/2406.12569,2024-06-18,2024-06-19,0.0,0.0,"Massive Over-activation Yielded Uplifts(MOYU) is an inherent property of
large language models, and dynamic activation(DA) based on the MOYU property is
a clever yet under-explored strategy designed to accelerate inference in these
models. Existing methods that utilize MOYU often face a significant 'Impossible
Trinity': struggling to simultaneously maintain model performance, enhance
inference speed, and extend applicability across various architectures. Due to
the theoretical ambiguities surrounding MOYU, this paper elucidates the root
cause of the MOYU property and outlines the mechanisms behind two primary
limitations encountered by current DA methods: 1) history-related activation
uncertainty, and 2) semantic-irrelevant activation inertia. Our analysis not
only underscores the limitations of current dynamic activation strategies
within large-scale LLaMA models but also proposes opportunities for refining
the design of future sparsity schemes."
RichRAG - Crafting Rich Responses for Multi-faceted Queries in Retrieval-Augmented Generation,https://arxiv.org/abs/2406.12566,2024-06-18,2024-06-19,0.0,0.0,"Retrieval-augmented generation (RAG) effectively addresses issues of static
knowledge and hallucination in large language models. Existing studies mostly
focus on question scenarios with clear user intents and concise answers.
However, it is prevalent that users issue broad, open-ended queries with
diverse sub-intents, for which they desire rich and long-form answers covering
multiple relevant aspects. To tackle this important yet underexplored problem,
we propose a novel RAG framework, namely RichRAG. It includes a sub-aspect
explorer to identify potential sub-aspects of input questions, a multi-faceted
retriever to build a candidate pool of diverse external documents related to
these sub-aspects, and a generative list-wise ranker, which is a key module to
provide the top-k most valuable documents for the final generator. These ranked
documents sufficiently cover various query aspects and are aware of the
generator's preferences, hence incentivizing it to produce rich and
comprehensive responses for users. The training of our ranker involves a
supervised fine-tuning stage to ensure the basic coverage of documents, and a
reinforcement learning stage to align downstream LLM's preferences to the
ranking of documents. Experimental results on two publicly available datasets
prove that our framework effectively and efficiently provides comprehensive and
satisfying responses to users."
Low-Resource Machine Translation through the Lens of Personalized Federated Learning,https://arxiv.org/abs/2406.12564,2024-06-18,2024-06-19,0.0,0.0,"We present a new approach based on the Personalized Federated Learning
algorithm MeritFed that can be applied to Natural Language Tasks with
heterogeneous data. We evaluate it on the Low-Resource Machine Translation
task, using the dataset from the Large-Scale Multilingual Machine Translation
Shared Task (Small Track #2) and the subset of Sami languages from the
multilingual benchmark for Finno-Ugric languages. In addition to its
effectiveness, MeritFed is also highly interpretable, as it can be applied to
track the impact of each language used for training. Our analysis reveals that
target dataset size affects weight distribution across auxiliary languages,
that unrelated languages do not interfere with the training, and auxiliary
optimizer parameters have minimal impact. Our approach is easy to apply with a
few lines of code, and we provide scripts for reproducing the experiments at
https://github.com/VityaVitalich/MeritFed"
A Super-human Vision-based Reinforcement Learning Agent for Autonomous Racing in Gran Turismo,https://arxiv.org/abs/2406.12563,2024-06-18,2024-06-19,0.0,0.0,"Racing autonomous cars faster than the best human drivers has been a
longstanding grand challenge for the fields of Artificial Intelligence and
robotics. Recently, an end-to-end deep reinforcement learning agent met this
challenge in a high-fidelity racing simulator, Gran Turismo. However, this
agent relied on global features that require instrumentation external to the
car. This paper introduces, to the best of our knowledge, the first super-human
car racing agent whose sensor input is purely local to the car, namely pixels
from an ego-centric camera view and quantities that can be sensed from on-board
the car, such as the car's velocity. By leveraging global features only at
training time, the learned agent is able to outperform the best human drivers
in time trial (one car on the track at a time) races using only local input
features. The resulting agent is evaluated in Gran Turismo 7 on multiple tracks
and cars. Detailed ablation experiments demonstrate the agent's strong reliance
on visual inputs, making it the first vision-based super-human car racing
agent."
Bayesian Data Selection,https://arxiv.org/abs/2406.12560,2024-06-18,2024-06-19,0.0,0.0,"A wide range of machine learning algorithms iteratively add data to the
training sample. Examples include semi-supervised learning, active learning,
multi-armed bandits, and Bayesian optimization. We embed this kind of data
addition into decision theory by framing data selection as a decision problem.
This paves the way for finding Bayes-optimal selections of data. For the
illustrative case of self-training in semi-supervised learning, we derive the
respective Bayes criterion. We further show that deploying this criterion
mitigates the issue of confirmation bias by empirically assessing our method
for generalized linear models, semi-parametric generalized additive models, and
Bayesian neural networks on simulated and real-world data."
Offline Imitation Learning with Model-based Reverse Augmentation,https://arxiv.org/abs/2406.12550,2024-06-18,2024-06-19,0.0,0.0,"In offline Imitation Learning (IL), one of the main challenges is the
\textit{covariate shift} between the expert observations and the actual
distribution encountered by the agent, because it is difficult to determine
what action an agent should take when outside the state distribution of the
expert demonstrations. Recently, the model-free solutions introduce the
supplementary data and identify the latent expert-similar samples to augment
the reliable samples during learning. Model-based solutions build forward
dynamic models with conservatism quantification and then generate additional
trajectories in the neighborhood of expert demonstrations. However, without
reward supervision, these methods are often over-conservative in the
out-of-expert-support regions, because only in states close to expert-observed
states can there be a preferred action enabling policy optimization. To
encourage more exploration on expert-unobserved states, we propose a novel
model-based framework, called offline Imitation Learning with Self-paced
Reverse Augmentation (SRA). Specifically, we build a reverse dynamic model from
the offline demonstrations, which can efficiently generate trajectories leading
to the expert-observed states in a self-paced style. Then, we use the
subsequent reinforcement learning method to learn from the augmented
trajectories and transit from expert-unobserved states to expert-observed
states. This framework not only explores the expert-unobserved states but also
guides maximizing long-term returns on these states, ultimately enabling
generalization beyond the expert data. Empirical results show that our proposal
could effectively mitigate the covariate shift and achieve the state-of-the-art
performance on the offline imitation learning benchmarks. Project website:
\url{https://www.lamda.nju.edu.cn/shaojj/KDD24_SRA/}."
MultiSocial - Multilingual Benchmark of Machine-Generated Text Detection of Social-Media Texts,https://arxiv.org/abs/2406.12549,2024-06-18,2024-06-19,0.0,0.0,"Recent LLMs are able to generate high-quality multilingual texts,
indistinguishable for humans from authentic human-written ones. Research in
machine-generated text detection is however mostly focused on the English
language and longer texts, such as news articles, scientific papers or student
essays. Social-media texts are usually much shorter and often feature informal
language, grammatical errors, or distinct linguistic items (e.g., emoticons,
hashtags). There is a gap in studying the ability of existing methods in
detection of such texts, reflected also in the lack of existing multilingual
benchmark datasets. To fill this gap we propose the first multilingual (22
languages) and multi-platform (5 social media platforms) dataset for
benchmarking machine-generated text detection in the social-media domain,
called MultiSocial. It contains 472,097 texts, of which about 58k are
human-written and approximately the same amount is generated by each of 7
multilingual LLMs. We use this benchmark to compare existing detection methods
in zero-shot as well as fine-tuned form. Our results indicate that the
fine-tuned detectors have no problem to be trained on social-media texts and
that the platform selection for training matters."
P-Tailor - Customizing Personality Traits for Language Models via Mixture of Specialized LoRA Experts,https://arxiv.org/abs/2406.12548,2024-06-18,2024-06-19,1.0,0.0,"Personalized large language models (LLMs) have attracted great attention in
many applications, such as intelligent education and emotional support. Most
work focuses on controlling the character settings based on the profile (e.g.,
age, skill, experience, and so on). Conversely, the psychological theory-based
personality traits with implicit expression and behavior are not well modeled,
limiting their potential application in more specialized fields such as the
psychological counseling agents. In this paper, we propose a mixture of experts
(MoE)-based personalized LLMs, named P-tailor, to model the Big Five
Personality Traits. Particularly, we learn specialized LoRA experts to
represent various traits, such as openness, conscientiousness, extraversion,
agreeableness and neuroticism. Then, we integrate P-Tailor with a personality
specialization loss, promoting experts to specialize in distinct personality
traits, thereby enhancing the efficiency of model parameter utilization. Due to
the lack of datasets, we also curate a high-quality personality crafting
dataset (PCD) to learn and develop the ability to exhibit different personality
traits across various topics. We conduct extensive experiments to verify the
great performance and effectiveness of P-Tailor in manipulation of the
fine-grained personality traits of LLMs."
The Heterophilic Snowflake Hypothesis - Training and Empowering GNNs for Heterophilic Graphs,https://arxiv.org/abs/2406.12539,2024-06-18,2024-06-19,0.0,0.0,"Graph Neural Networks (GNNs) have become pivotal tools for a range of
graph-based learning tasks. Notably, most current GNN architectures operate
under the assumption of homophily, whether explicitly or implicitly. While this
underlying assumption is frequently adopted, it is not universally applicable,
which can result in potential shortcomings in learning effectiveness. In this
paper, \textbf{for the first time}, we transfer the prevailing concept of ``one
node one receptive field"" to the heterophilic graph. By constructing a proxy
label predictor, we enable each node to possess a latent prediction
distribution, which assists connected nodes in determining whether they should
aggregate their associated neighbors. Ultimately, every node can have its own
unique aggregation hop and pattern, much like each snowflake is unique and
possesses its own characteristics. Based on observations, we innovatively
introduce the Heterophily Snowflake Hypothesis and provide an effective
solution to guide and facilitate research on heterophilic graphs and beyond. We
conduct comprehensive experiments including (1) main results on 10 graphs with
varying heterophily ratios across 10 backbones; (2) scalability on various deep
GNN backbones (SGC, JKNet, etc.) across various large number of layers
(2,4,6,8,16,32 layers); (3) comparison with conventional snowflake hypothesis;
(4) efficiency comparison with existing graph pruning algorithms. Our
observations show that our framework acts as a versatile operator for diverse
tasks. It can be integrated into various GNN frameworks, boosting performance
in-depth and offering an explainable approach to choosing the optimal network
depth. The source code is available at
\url{https://github.com/bingreeky/HeteroSnoH}."
Variational Distillation of Diffusion Policies into Mixture of Experts,https://arxiv.org/abs/2406.12538,2024-06-18,2024-06-19,0.0,0.0,"This work introduces Variational Diffusion Distillation (VDD), a novel method
that distills denoising diffusion policies into Mixtures of Experts (MoE)
through variational inference. Diffusion Models are the current
state-of-the-art in generative modeling due to their exceptional ability to
accurately learn and represent complex, multi-modal distributions. This ability
allows Diffusion Models to replicate the inherent diversity in human behavior,
making them the preferred models in behavior learning such as Learning from
Human Demonstrations (LfD). However, diffusion models come with some drawbacks,
including the intractability of likelihoods and long inference times due to
their iterative sampling process. The inference times, in particular, pose a
significant challenge to real-time applications such as robot control. In
contrast, MoEs effectively address the aforementioned issues while retaining
the ability to represent complex distributions but are notoriously difficult to
train. VDD is the first method that distills pre-trained diffusion models into
MoE models, and hence, combines the expressiveness of Diffusion Models with the
benefits of Mixture Models. Specifically, VDD leverages a decompositional upper
bound of the variational objective that allows the training of each expert
separately, resulting in a robust optimization scheme for MoEs. VDD
demonstrates across nine complex behavior learning tasks, that it is able to:
i) accurately distill complex distributions learned by the diffusion model, ii)
outperform existing state-of-the-art distillation methods, and iii) surpass
conventional methods for training MoE."
Unified Active Retrieval for Retrieval Augmented Generation,https://arxiv.org/abs/2406.12534,2024-06-18,2024-06-19,0.0,0.0,"In Retrieval-Augmented Generation (RAG), retrieval is not always helpful and
applying it to every instruction is sub-optimal. Therefore, determining whether
to retrieve is crucial for RAG, which is usually referred to as Active
Retrieval. However, existing active retrieval methods face two challenges: 1.
They usually rely on a single criterion, which struggles with handling various
types of instructions. 2. They depend on specialized and highly differentiated
procedures, and thus combining them makes the RAG system more complicated and
leads to higher response latency. To address these challenges, we propose
Unified Active Retrieval (UAR). UAR contains four orthogonal criteria and casts
them into plug-and-play classification tasks, which achieves multifaceted
retrieval timing judgements with negligible extra inference cost. We further
introduce the Unified Active Retrieval Criteria (UAR-Criteria), designed to
process diverse active retrieval scenarios through a standardized procedure.
Experiments on four representative types of user instructions show that UAR
significantly outperforms existing work on the retrieval timing judgement and
the performance of downstream tasks, which shows the effectiveness of UAR and
its helpfulness to downstream tasks."
TREE - Tree Regularization for Efficient Execution,https://arxiv.org/abs/2406.12531,2024-06-18,2024-06-19,0.0,0.0,"The rise of machine learning methods on heavily resource constrained devices
requires not only the choice of a suitable model architecture for the target
platform, but also the optimization of the chosen model with regard to
execution time consumption for inference in order to optimally utilize the
available resources. Random forests and decision trees are shown to be a
suitable model for such a scenario, since they are not only heavily tunable
towards the total model size, but also offer a high potential for optimizing
their executions according to the underlying memory architecture.
  In addition to the straightforward strategy of enforcing shorter paths
through decision trees and hence reducing the execution time for inference,
hardware-aware implementations can optimize the execution time in an orthogonal
manner. One particular hardware-aware optimization is to layout the memory of
decision trees in such a way, that higher probably paths are less likely to be
evicted from system caches. This works particularly well when splits within
tree nodes are uneven and have a high probability to visit one of the child
nodes.
  In this paper, we present a method to reduce path lengths by rewarding uneven
probability distributions during the training of decision trees at the cost of
a minimal accuracy degradation. Specifically, we regularize the impurity
computation of the CART algorithm in order to favor not only low impurity, but
also highly asymmetric distributions for the evaluation of split criteria and
hence offer a high optimization potential for a memory architecture-aware
implementation.
  We show that especially for binary classification data sets and data sets
with many samples, this form of regularization can lead to an reduction of up
to approximately four times in the execution time with a minimal accuracy
degradation."
LLM4MSR - An LLM-Enhanced Paradigm for Multi-Scenario Recommendation,https://arxiv.org/abs/2406.12529,2024-06-18,2024-06-19,0.0,0.0,"As the demand for more personalized recommendation grows and a dramatic boom
in commercial scenarios arises, the study on multi-scenario recommendation
(MSR) has attracted much attention, which uses the data from all scenarios to
simultaneously improve their recommendation performance. However, existing
methods tend to integrate insufficient scenario knowledge and neglect learning
personalized cross-scenario preferences, thus leading to suboptimal performance
and inadequate interpretability. Meanwhile, though large language model (LLM)
has shown great capability of reasoning and capturing semantic information, the
high inference latency and high computation cost of tuning hinder its
implementation in industrial recommender systems. To fill these gaps, we
propose an effective efficient interpretable LLM-enhanced paradigm LLM4MSR in
this work. Specifically, we first leverage LLM to uncover multi-level knowledge
including scenario correlations and users' cross-scenario interests from the
designed scenario- and user-level prompt without fine-tuning the LLM, then
adopt hierarchical meta networks to generate multi-level meta layers to
explicitly improves the scenario-aware and personalized recommendation
capability. Our experiments on KuaiSAR-small, KuaiSAR, and Amazon datasets
validate two significant advantages of LLM4MSR: (i) the effectiveness and
compatibility with different multi-scenario backbone models (achieving 1.5%,
1%, and 40% AUC improvement on three datasets), (ii) high efficiency and
deployability on industrial recommender systems, and (iii) improved
interpretability. The implemented code and data is available to ease
reproduction."
FuseGen - PLM Fusion for Data-generation based Zero-shot Learning,https://arxiv.org/abs/2406.12527,2024-06-18,2024-06-19,0.0,0.0,"Data generation-based zero-shot learning, although effective in training
Small Task-specific Models (STMs) via synthetic datasets generated by
Pre-trained Language Models (PLMs), is often limited by the low quality of such
synthetic datasets. Previous solutions have primarily focused on single PLM
settings, where synthetic datasets are typically restricted to specific
sub-spaces and often deviate from real-world distributions, leading to severe
distribution bias. To mitigate such bias, we propose FuseGen, a novel data
generation-based zero-shot learning framework that introduces a new criteria
for subset selection from synthetic datasets via utilizing multiple PLMs and
trained STMs. The chosen subset provides in-context feedback to each PLM,
enhancing dataset quality through iterative data generation. Trained STMs are
then used for sample re-weighting as well, further improving data quality.
Extensive experiments across diverse tasks demonstrate that FuseGen
substantially outperforms existing methods, highly effective in boosting STM
performance in a PLM-agnostic way. Code is provided in
https://github.com/LindaLydia/FuseGen."
On the Convergence of Ttonnement for Linear Fisher Markets,https://arxiv.org/abs/2406.12526,2024-06-18,2024-06-19,0.0,0.0,"T\^atonnement is a simple, intuitive market process where prices are
iteratively adjusted based on the difference between demand and supply. Many
variants under different market assumptions have been studied and shown to
converge to a market equilibrium, in some cases at a fast rate. However, the
classical case of linear Fisher markets have long eluded the analyses, and it
remains unclear whether t\^atonnement converges in this case. We show that, for
a sufficiently small step size, the prices given by the t\^atonnement process
are guaranteed to converge to equilibrium prices, up to a small approximation
radius that depends on the stepsize. To achieve this, we consider the dual
Eisenberg-Gale convex program in the price space, view t\^atonnement as
subgradient descent on this convex program, and utilize novel last-iterate
convergence results for subgradient descent under error bound conditions. In
doing so, we show that the convex program satisfies a particular error bound
condition, the quadratic growth condition, and that the price sequence
generated by t\^atonnement is bounded above and away from zero. We also show
that a similar convergence result holds for t\^atonnement in quasi-linear
Fisher markets. Numerical experiments are conducted to demonstrate that the
theoretical linear convergence aligns with empirical observations."
Update Selective Parameters - Federated Machine Unlearning Based on Model Explanation,https://arxiv.org/abs/2406.12516,2024-06-18,2024-06-19,0.0,0.0,"Federated learning is a promising privacy-preserving paradigm for distributed
machine learning. In this context, there is sometimes a need for a specialized
process called machine unlearning, which is required when the effect of some
specific training samples needs to be removed from a learning model due to
privacy, security, usability, and/or legislative factors. However, problems
arise when current centralized unlearning methods are applied to existing
federated learning, in which the server aims to remove all information about a
class from the global model. Centralized unlearning usually focuses on simple
models or is premised on the ability to access all training data at a central
node. However, training data cannot be accessed on the server under the
federated learning paradigm, conflicting with the requirements of the
centralized unlearning process. Additionally, there are high computation and
communication costs associated with accessing clients' data, especially in
scenarios involving numerous clients or complex global models. To address these
concerns, we propose a more effective and efficient federated unlearning scheme
based on the concept of model explanation. Model explanation involves
understanding deep networks and individual channel importance, so that this
understanding can be used to determine which model channels are critical for
classes that need to be unlearned. We select the most influential channels
within an already-trained model for the data that need to be unlearned and
fine-tune only influential channels to remove the contribution made by those
data. In this way, we can simultaneously avoid huge consumption costs and
ensure that the unlearned model maintains good performance. Experiments with
different training models on various datasets demonstrate the effectiveness of
the proposed approach."
Improving the Evaluation and Actionability of Explanation Methods for Multivariate Time Series Classification,https://arxiv.org/abs/2406.12507,2024-06-18,2024-06-19,0.0,0.0,"Explanation for Multivariate Time Series Classification (MTSC) is an
important topic that is under explored. There are very few quantitative
evaluation methodologies and even fewer examples of actionable explanation,
where the explanation methods are shown to objectively improve specific
computational tasks on time series data. In this paper we focus on analyzing
InterpretTime, a recent evaluation methodology for attribution methods applied
to MTSC. We showcase some significant weaknesses of the original methodology
and propose ideas to improve both its accuracy and efficiency. Unlike related
work, we go beyond evaluation and also showcase the actionability of the
produced explainer ranking, by using the best attribution methods for the task
of channel selection in MTSC. We find that perturbation-based methods such as
SHAP and Feature Ablation work well across a set of datasets, classifiers and
tasks and outperform gradient-based methods. We apply the best ranked
explainers to channel selection for MTSC and show significant data size
reduction and improved classifier accuracy."
Autonomous navigation of catheters and guidewires in mechanical thrombectomy using inverse reinforcement learning,https://arxiv.org/abs/2406.12499,2024-06-18,2024-06-19,0.0,0.0,"Purpose: Autonomous navigation of catheters and guidewires can enhance
endovascular surgery safety and efficacy, reducing procedure times and operator
radiation exposure. Integrating tele-operated robotics could widen access to
time-sensitive emergency procedures like mechanical thrombectomy (MT).
Reinforcement learning (RL) shows potential in endovascular navigation, yet its
application encounters challenges without a reward signal. This study explores
the viability of autonomous navigation in MT vasculature using inverse RL (IRL)
to leverage expert demonstrations. Methods: This study established a
simulation-based training and evaluation environment for MT navigation. We used
IRL to infer reward functions from expert behaviour when navigating a guidewire
and catheter. We utilized soft actor-critic to train models with various reward
functions and compared their performance in silico. Results: We demonstrated
feasibility of navigation using IRL. When evaluating single versus dual device
(i.e. guidewire versus catheter and guidewire) tracking, both methods achieved
high success rates of 95% and 96%, respectively. Dual-tracking, however,
utilized both devices mimicking an expert. A success rate of 100% and procedure
time of 22.6 s were obtained when training with a reward function obtained
through reward shaping. This outperformed a dense reward function (96%, 24.9 s)
and an IRL-derived reward function (48%, 59.2 s). Conclusions: We have
contributed to the advancement of autonomous endovascular intervention
navigation, particularly MT, by employing IRL. The results underscore the
potential of using reward shaping to train models, offering a promising avenue
for enhancing the accessibility and precision of MT. We envisage that future
research can extend our methodology to diverse anatomical structures to enhance
generalizability."
LightPAL - Lightweight Passage Retrieval for Open Domain Multi-Document Summarization,https://arxiv.org/abs/2406.12494,2024-06-18,2024-06-19,0.0,0.0,"Open-Domain Multi-Document Summarization (ODMDS) is crucial for addressing
diverse information needs, which aims to generate a summary as answer to user's
query, synthesizing relevant content from multiple documents in a large
collection. Existing approaches that first find relevant passages and then
generate a summary using a language model are inadequate for ODMDS. This is
because open-ended queries often require additional context for the retrieved
passages to cover the topic comprehensively, making it challenging to retrieve
all relevant passages initially. While iterative retrieval methods have been
explored for multi-hop question answering (MQA), they are impractical for ODMDS
due to high latency from repeated large language model (LLM) inference for
reasoning. To address this issue, we propose LightPAL, a lightweight passage
retrieval method for ODMDS that constructs a graph representing passage
relationships using an LLM during indexing and employs random walk instead of
iterative reasoning and retrieval at inference time. Experiments on ODMDS
benchmarks show that LightPAL outperforms baseline retrievers in summary
quality while being significantly more efficient than an iterative MQA
approach."
The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions,https://arxiv.org/abs/2406.12480,2024-06-18,2024-06-19,0.0,0.0,"Stance detection holds great potential for enhancing the quality of online
political discussions, as it has shown to be useful for summarizing
discussions, detecting misinformation, and evaluating opinion distributions.
Usually, transformer-based models are used directly for stance detection, which
require large amounts of data. However, the broad range of debate questions in
online political discussion creates a variety of possible scenarios that the
model is faced with and thus makes data acquisition for model training
difficult. In this work, we show how to leverage LLM-generated synthetic data
to train and improve stance detection agents for online political
discussions:(i) We generate synthetic data for specific debate questions by
prompting a Mistral-7B model and show that fine-tuning with the generated
synthetic data can substantially improve the performance of stance detection.
(ii) We examine the impact of combining synthetic data with the most
informative samples from an unlabelled dataset. First, we use the synthetic
data to select the most informative samples, second, we combine both these
samples and the synthetic data for fine-tuning. This approach reduces labelling
effort and consistently surpasses the performance of the baseline model that is
trained with fully labeled data. Overall, we show in comprehensive experiments
that LLM-generated data greatly improves stance detection performance for
online political discussions."
RS-GPT4V - A Unified Multimodal Instruction-Following Dataset for Remote Sensing Image Understanding,https://arxiv.org/abs/2406.12479,2024-06-18,2024-06-19,0.0,0.0,"The remote sensing image intelligence understanding model is undergoing a new
profound paradigm shift which has been promoted by multi-modal large language
model (MLLM), i.e. from the paradigm learning a domain model (LaDM) shifts to
paradigm learning a pre-trained general foundation model followed by an
adaptive domain model (LaGD). Under the new LaGD paradigm, the old datasets,
which have led to advances in RSI intelligence understanding in the last
decade, are no longer suitable for fire-new tasks. We argued that a new dataset
must be designed to lighten tasks with the following features: 1)
Generalization: training model to learn shared knowledge among tasks and to
adapt to different tasks; 2) Understanding complex scenes: training model to
understand the fine-grained attribute of the objects of interest, and to be
able to describe the scene with natural language; 3) Reasoning: training model
to be able to realize high-level visual reasoning. In this paper, we designed a
high-quality, diversified, and unified multimodal instruction-following dataset
for RSI understanding produced by GPT-4V and existing datasets, which we called
RS-GPT4V. To achieve generalization, we used a (Question, Answer) which was
deduced from GPT-4V via instruction-following to unify the tasks such as
captioning and localization; To achieve complex scene, we proposed a
hierarchical instruction description with local strategy in which the
fine-grained attributes of the objects and their spatial relationships are
described and global strategy in which all the local information are integrated
to yield detailed instruction descript; To achieve reasoning, we designed
multiple-turn QA pair to provide the reasoning ability for a model. The
empirical results show that the fine-tuned MLLMs by RS-GPT4V can describe
fine-grained information. The dataset is available at:
https://github.com/GeoX-Lab/RS-GPT4V."
Accelerating Depthwise Separable Convolutions on Ultra-Low-Power Devices,https://arxiv.org/abs/2406.12478,2024-06-18,2024-06-19,0.0,0.0,"Depthwise separable convolutions are a fundamental component in efficient
Deep Neural Networks, as they reduce the number of parameters and operations
compared to traditional convolutions while maintaining comparable accuracy.
However, their low data reuse opportunities make deploying them notoriously
difficult. In this work, we perform an extensive exploration of alternatives to
fuse the depthwise and pointwise kernels that constitute the separable
convolutional block. Our approach aims to minimize time-consuming memory
transfers by combining different data layouts. When targeting a commercial
ultra-low-power device with a three-level memory hierarchy, the GreenWaves GAP8
SoC, we reduce the latency of end-to-end network execution by up to 11.40%.
Furthermore, our kernels reduce activation data movements between L2 and L1
memories by up to 52.97%."
Adversarial Multi-dueling Bandits,https://arxiv.org/abs/2406.12475,2024-06-18,2024-06-19,0.0,0.0,"We introduce the problem of regret minimization in adversarial multi-dueling
bandits. While adversarial preferences have been studied in dueling bandits,
they have not been explored in multi-dueling bandits. In this setting, the
learner is required to select $m \geq 2$ arms at each round and observes as
feedback the identity of the most preferred arm which is based on an arbitrary
preference matrix chosen obliviously. We introduce a novel algorithm, MiDEX
(Multi Dueling EXP3), to learn from such preference feedback that is assumed to
be generated from a pairwise-subset choice model. We prove that the expected
cumulative $T$-round regret of MiDEX compared to a Borda-winner from a set of
$K$ arms is upper bounded by $O((K \log K)^{1/3} T^{2/3})$. Moreover, we prove
a lower bound of $\Omega(K^{1/3} T^{2/3})$ for the expected regret in this
setting which demonstrates that our proposed algorithm is near-optimal."
Exploring Intra and Inter-language Consistency in Embeddings with ICA,https://arxiv.org/abs/2406.12474,2024-06-18,2024-06-19,0.0,0.0,"Word embeddings represent words as multidimensional real vectors,
facilitating data analysis and processing, but are often challenging to
interpret. Independent Component Analysis (ICA) creates clearer semantic axes
by identifying independent key features. Previous research has shown ICA's
potential to reveal universal semantic axes across languages. However, it
lacked verification of the consistency of independent components within and
across languages. We investigated the consistency of semantic axes in two ways:
both within a single language and across multiple languages. We first probed
into intra-language consistency, focusing on the reproducibility of axes by
performing ICA multiple times and clustering the outcomes. Then, we
statistically examined inter-language consistency by verifying those axes'
correspondences using statistical tests. We newly applied statistical methods
to establish a robust framework that ensures the reliability and universality
of semantic axes."
Fighting Randomness with Randomness - Mitigating Optimisation Instability of Fine-Tuning using Delayed Ensemble and Noisy Interpolation,https://arxiv.org/abs/2406.12471,2024-06-18,2024-06-19,0.0,0.0,"While fine-tuning of pre-trained language models generally helps to overcome
the lack of labelled training samples, it also displays model performance
instability. This instability mainly originates from randomness in
initialisation or data shuffling. To address this, researchers either modify
the training process or augment the available samples, which typically results
in increased computational costs. We propose a new mitigation strategy, called
Delayed Ensemble with Noisy Interpolation (DENI), that leverages the strengths
of ensembling, noise regularisation and model interpolation, while retaining
computational efficiency. We compare DENI with 9 representative mitigation
strategies across 3 models, 4 tuning strategies and 7 text classification
datasets. We show that: 1) DENI outperforms the best performing mitigation
strategy (Ensemble), while using only a fraction of its cost; 2) the mitigation
strategies are beneficial for parameter-efficient fine-tuning (PEFT) methods,
outperforming full fine-tuning in specific cases; and 3) combining DENI with
data augmentation often leads to even more effective instability mitigation."
Adaptive Token Biaser - Knowledge Editing via Biasing Key Entities,https://arxiv.org/abs/2406.12468,2024-06-18,2024-06-19,1.0,0.0,"The parametric knowledge memorized by large language models (LLMs) becomes
outdated quickly. In-context editing (ICE) is currently the most effective
method for updating the knowledge of LLMs. Recent advancements involve
enhancing ICE by modifying the decoding strategy, obviating the need for
altering internal model structures or adjusting external prompts. However, this
enhancement operates across the entire sequence generation, encompassing a
plethora of non-critical tokens. In this work, we introduce $\textbf{A}$daptive
$\textbf{T}$oken $\textbf{Bias}$er ($\textbf{ATBias}$), a new decoding
technique designed to enhance ICE. It focuses on the tokens that are mostly
related to knowledge during decoding, biasing their logits by matching key
entities related to new and parametric knowledge. Experimental results show
that ATBias significantly enhances ICE performance, achieving up to a 32.3%
improvement over state-of-the-art ICE methods while incurring only half the
latency. ATBias not only improves the knowledge editing capabilities of ICE but
can also be widely applied to LLMs with negligible cost."
RIGL - A Unified Reciprocal Approach for Tracing the Independent and Group Learning Processes,https://arxiv.org/abs/2406.12465,2024-06-18,2024-06-19,0.0,0.0,"In the realm of education, both independent learning and group learning are
esteemed as the most classic paradigms. The former allows learners to
self-direct their studies, while the latter is typically characterized by
teacher-directed scenarios. Recent studies in the field of intelligent
education have leveraged deep temporal models to trace the learning process,
capturing the dynamics of students' knowledge states, and have achieved
remarkable performance. However, existing approaches have primarily focused on
modeling the independent learning process, with the group learning paradigm
receiving less attention. Moreover, the reciprocal effect between the two
learning processes, especially their combined potential to foster holistic
student development, remains inadequately explored. To this end, in this paper,
we propose RIGL, a unified Reciprocal model to trace knowledge states at both
the individual and group levels, drawing from the Independent and Group
Learning processes. Specifically, we first introduce a time frame-aware
reciprocal embedding module to concurrently model both student and group
response interactions across various time frames. Subsequently, we employ
reciprocal enhanced learning modeling to fully exploit the comprehensive and
complementary information between the two behaviors. Furthermore, we design a
relation-guided temporal attentive network, comprised of dynamic graph modeling
coupled with a temporal self-attention mechanism. It is used to delve into the
dynamic influence of individual and group interactions throughout the learning
processes. Conclusively, we introduce a bias-aware contrastive learning module
to bolster the stability of the model's training. Extensive experiments on four
real-world educational datasets clearly demonstrate the effectiveness of the
proposed RIGL model."
Insect Identification in the Wild - The AMI Dataset,https://arxiv.org/abs/2406.12452,2024-06-18,2024-06-19,0.0,0.0,"Insects represent half of all global biodiversity, yet many of the world's
insects are disappearing, with severe implications for ecosystems and
agriculture. Despite this crisis, data on insect diversity and abundance remain
woefully inadequate, due to the scarcity of human experts and the lack of
scalable tools for monitoring. Ecologists have started to adopt camera traps to
record and study insects, and have proposed computer vision algorithms as an
answer for scalable data processing. However, insect monitoring in the wild
poses unique challenges that have not yet been addressed within computer
vision, including the combination of long-tailed data, extremely similar
classes, and significant distribution shifts. We provide the first large-scale
machine learning benchmarks for fine-grained insect recognition, designed to
match real-world tasks faced by ecologists. Our contributions include a curated
dataset of images from citizen science platforms and museums, and an
expert-annotated dataset drawn from automated camera traps across multiple
continents, designed to test out-of-distribution generalization under field
conditions. We train and evaluate a variety of baseline algorithms and
introduce a combination of data augmentation techniques that enhance
generalization across geographies and hardware setups."
Retrieval-Augmented Generation for Generative Artificial Intelligence in Medicine,https://arxiv.org/abs/2406.12449,2024-06-18,2024-06-19,0.0,0.0,"Generative artificial intelligence (AI) has brought revolutionary innovations
in various fields, including medicine. However, it also exhibits limitations.
In response, retrieval-augmented generation (RAG) provides a potential
solution, enabling models to generate more accurate contents by leveraging the
retrieval of external knowledge. With the rapid advancement of generative AI,
RAG can pave the way for connecting this transformative technology with medical
applications and is expected to bring innovations in equity, reliability, and
personalization to health care."
Adaptive Mean Estimation in the Hidden Markov sub-Gaussian Mixture Model,https://arxiv.org/abs/2406.12446,2024-06-18,2024-06-19,0.0,0.0,"We investigate the problem of center estimation in the high dimensional
binary sub-Gaussian Mixture Model with Hidden Markov structure on the labels.
We first study the limitations of existing results in the high dimensional
setting and then propose a minimax optimal procedure for the problem of center
estimation. Among other findings, we show that our procedure reaches the
optimal rate that is of order $\sqrt{\delta d/n} + d/n$ instead of $\sqrt{d/n}
+ d/n$ where $\delta \in(0,1)$ is a dependence parameter between labels. Along
the way, we also develop an adaptive variant of our procedure that is globally
minimax optimal. In order to do so, we rely on a more refined and localized
analysis of the estimation risk. Overall, leveraging the hidden Markovian
dependence between the labels, we show that it is possible to get a strict
improvement of the rates adaptively at almost no cost."
Abstraction-of-Thought Makes Language Models Better Reasoners,https://arxiv.org/abs/2406.12442,2024-06-18,2024-06-19,1.0,0.0,"Abstract reasoning, the ability to reason from the abstract essence of a
problem, serves as a key to generalization in human reasoning. However,
eliciting language models to perform reasoning with abstraction remains
unexplored. This paper seeks to bridge this gap by introducing a novel
structured reasoning format called Abstraction-of-Thought (AoT). The uniqueness
of AoT lies in its explicit requirement for varying levels of abstraction
within the reasoning process. This approach could elicit language models to
first contemplate on the abstract level before incorporating concrete details,
which is overlooked by the prevailing step-by-step Chain-of-Thought (CoT)
method. To align models with the AoT format, we present AoT Collection, a
generic finetuning dataset consisting of 348k high-quality samples with AoT
reasoning processes, collected via an automated and scalable pipeline. We
finetune a wide range of language models with AoT Collection and conduct
extensive evaluations on 23 unseen tasks from the challenging benchmark
Big-Bench Hard. Experimental results indicate that models aligned to AoT
reasoning format substantially outperform those aligned to CoT in many
reasoning tasks."
A data-centric approach for assessing progress of Graph Neural Networks,https://arxiv.org/abs/2406.12439,2024-06-18,2024-06-19,0.0,0.0,"Graph Neural Networks (GNNs) have achieved state-of-the-art results in node
classification tasks. However, most improvements are in multi-class
classification, with less focus on the cases where each node could have
multiple labels. The first challenge in studying multi-label node
classification is the scarcity of publicly available datasets. To address this,
we collected and released three real-world biological datasets and developed a
multi-label graph generator with tunable properties. We also argue that
traditional notions of homophily and heterophily do not apply well to
multi-label scenarios. Therefore, we define homophily and Cross-Class
Neighborhood Similarity for multi-label classification and investigate $9$
collected multi-label datasets. Lastly, we conducted a large-scale comparative
study with $8$ methods across nine datasets to evaluate current progress in
multi-label node classification. We release our code at
\url{https://github.com/Tianqi-py/MLGNC}."
Federated Learning with Limited Node Labels,https://arxiv.org/abs/2406.12435,2024-06-18,2024-06-19,0.0,0.0,"Subgraph federated learning (SFL) is a research methodology that has gained
significant attention for its potential to handle distributed graph-structured
data. In SFL, the local model comprises graph neural networks (GNNs) with a
partial graph structure. However, some SFL models have overlooked the
significance of missing cross-subgraph edges, which can lead to local GNNs
being unable to message-pass global representations to other parties' GNNs.
Moreover, existing SFL models require substantial labeled data, which limits
their practical applications. To overcome these limitations, we present a novel
SFL framework called FedMpa that aims to learn cross-subgraph node
representations. FedMpa first trains a multilayer perceptron (MLP) model using
a small amount of data and then propagates the federated feature to the local
structures. To further improve the embedding representation of nodes with local
subgraphs, we introduce the FedMpae method, which reconstructs the local graph
structure with an innovation view that applies pooling operation to form
super-nodes. Our extensive experiments on six graph datasets demonstrate that
FedMpa is highly effective in node classification. Furthermore, our ablation
experiments verify the effectiveness of FedMpa."
Towards Audio Codec-based Speech Separation,https://arxiv.org/abs/2406.12434,2024-06-18,2024-06-19,0.0,0.0,"Recent improvements in neural audio codec (NAC) models have generated
interest in adopting pre-trained codecs for a variety of speech processing
applications to take advantage of the efficiencies gained from high
compression, but these have yet been applied to the speech separation (SS)
task. SS can benefit from high compression because the compute required for
traditional SS models makes them impractical for many edge computing use cases.
However, SS is a waveform-masking task where compression tends to introduce
distortions that severely impact performance. Here we propose a novel task of
Audio Codec-based SS, where SS is performed within the embedding space of a
NAC, and propose a new model, Codecformer, to address this task. At inference,
Codecformer achieves a 52x reduction in MAC while producing separation
performance comparable to a cloud deployment of Sepformer. This method charts a
new direction for performing efficient SS in practical scenarios."
Exploring Sensing Devices for Heart and Lung Sound Monitoring,https://arxiv.org/abs/2406.12432,2024-06-18,2024-06-19,0.0,0.0,"This paper presents a comprehensive review of cardiorespiratory auscultation
sensing devices which is useful for understanding the theoretical aspects of
sensing devices, as well as practical notes to design novel sensing devices.
One of the methods to design a stethoscope is using electret condenser
microphones (ECM). In this paper, we first introduce the acoustic properties of
the heart and lungs, as well as a brief history of stethoscope evolution. Then,
we discuss the basic concept of ECM sensors and a recent stethoscope based on
this technology. In response to the limitations of ECM-based systems, we
explore the potential of microelectromechanical systems (MEMS), particularly
focusing on piezoelectric transducer (PZT) sensors. This paper comprehensively
reviews sensing technologies, emphasizing innovative MEMS-based designs for
wearable cardiopulmonary auscultation in the past decade. To our knowledge,
this is the first paper to summarize ECM and MEMS applications for heart and
lung sound analysis. Keywords: Micro-electro-mechanical Systems (MEMS);
Electret Condenser Microphone (ECM); Wearable Sensing Devices;
Cardiorespiratory Auscultation; Phonocardiography (PCG); Heart Sound; Lung
Sound"
PlanRAG - A Plan-then-Retrieval Augmented Generation for Generative Large Language Models as Decision Makers,https://arxiv.org/abs/2406.12430,2024-06-18,2024-06-19,0.0,0.0,"In this paper, we conduct a study to utilize LLMs as a solution for decision
making that requires complex data analysis. We define Decision QA as the task
of answering the best decision, $d_{best}$, for a decision-making question $Q$,
business rules $R$ and a database $D$. Since there is no benchmark that can
examine Decision QA, we propose Decision QA benchmark, DQA. It has two
scenarios, Locating and Building, constructed from two video games (Europa
Universalis IV and Victoria 3) that have almost the same goal as Decision QA.
To address Decision QA effectively, we also propose a new RAG technique called
the iterative plan-then-retrieval augmented generation (PlanRAG). Our
PlanRAG-based LM generates the plan for decision making as the first step, and
the retriever generates the queries for data analysis as the second step. The
proposed method outperforms the state-of-the-art iterative RAG method by 15.8%
in the Locating scenario and by 7.4% in the Building scenario, respectively. We
release our code and benchmark at https://github.com/myeon9h/PlanRAG."
Adaptive Selection for Homogeneous Tools - An Instantiation in the RAG Scenario,https://arxiv.org/abs/2406.12429,2024-06-18,2024-06-19,0.0,0.0,"Current research on tool learning primarily focuses on selecting the most
effective tool from a wide array of options, often overlooking
cost-effectiveness, a crucial factor in human problem-solving. In this paper,
we address the selection of homogeneous tools by predicting both their
performance and the associated cost required to accomplish a given task. We
then assign queries to the optimal tools in a cost-effective manner. Our
experimental results demonstrate that our method achieves higher performance at
a lower cost compared to strong baseline approaches."
PSLM - Parallel Generation of Text and Speech with LLMs for Low-Latency Spoken Dialogue Systems,https://arxiv.org/abs/2406.12428,2024-06-18,2024-06-19,0.0,0.0,"Multimodal language models that process both text and speech have a potential
for applications in spoken dialogue systems. However, current models face two
major challenges in response generation latency: (1) generating a spoken
response requires the prior generation of a written response, and (2) speech
sequences are significantly longer than text sequences. This study addresses
these issues by extending the input and output sequences of the language model
to support the parallel generation of text and speech. Our experiments on
spoken question answering tasks demonstrate that our approach improves latency
while maintaining the quality of response content. Additionally, we show that
latency can be further reduced by generating speech in multiple sequences. Demo
samples are available at https://rinnakk.github.io/research/publications/PSLM."
Deep Temporal Deaggregation - Large-Scale Spatio-Temporal Generative Models,https://arxiv.org/abs/2406.12423,2024-06-18,2024-06-19,0.0,0.0,"Many of today's data is time-series data originating from various sources,
such as sensors, transaction systems, or production systems. Major challenges
with such data include privacy and business sensitivity. Generative time-series
models have the potential to overcome these problems, allowing representative
synthetic data, such as people's movement in cities, to be shared openly and be
used to the benefit of society at large. However, contemporary approaches are
limited to prohibitively short sequences and small scales. Aside from major
memory limitations, the models generate less accurate and less representative
samples the longer the sequences are. This issue is further exacerbated by the
lack of a comprehensive and accessible benchmark. Furthermore, a common need in
practical applications is what-if analysis and dynamic adaptation to data
distribution changes, for usage in decision making and to manage a changing
world: What if this road is temporarily blocked or another road is added? The
focus of this paper is on mobility data, such as people's movement in cities,
requiring all these issues to be addressed. To this end, we propose a
transformer-based diffusion model, TDDPM, for time-series which outperforms and
scales substantially better than state-of-the-art. This is evaluated in a new
comprehensive benchmark across several sequence lengths, standard datasets, and
evaluation measures. We also demonstrate how the model can be conditioned on a
prior over spatial occupancy frequency information, allowing the model to
generate mobility data for previously unseen environments and for hypothetical
scenarios where the underlying road network and its usage changes. This is
evaluated by training on mobility data from part of a city. Then, using only
aggregate spatial information as prior, we demonstrate out-of-distribution
generalization to the unobserved remainder of the city."
Open-Source Web Service with Morphological Dictionary-Supplemented Deep Learning for Morphosyntactic Analysis of Czech,https://arxiv.org/abs/2406.12422,2024-06-18,2024-06-19,0.0,0.0,"We present an open-source web service for Czech morphosyntactic analysis. The
system combines a deep learning model with rescoring by a high-precision
morphological dictionary at inference time. We show that our hybrid method
surpasses two competitive baselines: While the deep learning model ensures
generalization for out-of-vocabulary words and better disambiguation, an
improvement over an existing morphological analyser MorphoDiTa, at the same
time, the deep learning model benefits from inference-time guidance of a
manually curated morphological dictionary. We achieve 50% error reduction in
lemmatization and 58% error reduction in POS tagging over MorphoDiTa, while
also offering dependency parsing. The model is trained on one of the currently
largest Czech morphosyntactic corpora, the PDT-C 1.0, with the trained models
available at https://hdl.handle.net/11234/1-5293. We provide the tool as a web
service deployed at https://lindat.mff.cuni.cz/services/udpipe/. The source
code is available at GitHub (https://github.com/ufal/udpipe/tree/udpipe-2),
along with a Python client for a simple use. The documentation for the models
can be found at https://ufal.mff.cuni.cz/udpipe/2/models#czech_pdtc1.0_model."
MMUTF - Multimodal Multimedia Event Argument Extraction with Unified Template Filling,https://arxiv.org/abs/2406.12420,2024-06-18,2024-06-19,0.0,0.0,"With the advancement of multimedia technologies, news documents and
user-generated content are often represented as multiple modalities, making
Multimedia Event Extraction (MEE) an increasingly important challenge. However,
recent MEE methods employ weak alignment strategies and data augmentation with
simple classification models, which ignore the capabilities of natural
language-formulated event templates for the challenging Event Argument
Extraction (EAE) task. In this work, we focus on EAE and address this issue by
introducing a unified template filling model that connects the textual and
visual modalities via textual prompts. This approach enables the exploitation
of cross-ontology transfer and the incorporation of event-specific semantics.
Experiments on the M2E2 benchmark demonstrate the effectiveness of our
approach. Our system surpasses the current SOTA on textual EAE by +7% F1, and
performs generally better than the second-best systems for multimedia EAE."
AI-Assisted Human Evaluation of Machine Translation,https://arxiv.org/abs/2406.12419,2024-06-18,2024-06-19,0.0,0.0,"Annually, research teams spend large amounts of money to evaluate the quality
of machine translation systems (WMT, inter alia). This is expensive because it
requires a lot of expert human labor. The recently adopted annotation protocol,
Error Span Annotation (ESA), has annotators marking erroneous parts of the
translation and then assigning a final score. A lot of the annotator time is
spent on scanning the translation for possible errors. In our work, we help the
annotators by pre-filling the error annotations with recall-oriented automatic
quality estimation. With this AI assistance, we obtain annotations at the same
quality level while cutting down the time per span annotation by half
(71s/error span $\rightarrow$ 31s/error span). The biggest advantage of
ESA$^\mathrm{AI}$ protocol is an accurate priming of annotators (pre-filled
error spans) before they assign the final score. This also alleviates a
potential automation bias, which we confirm to be low. In addition, the
annotation budget can be reduced by almost 25\% with filtering of examples that
the AI deems to be very likely to be correct."
Beyond Under-Alignment - Atomic Preference Enhanced Factuality Tuning for Large Language Models,https://arxiv.org/abs/2406.12416,2024-06-18,2024-06-19,0.0,0.0,"Large language models (LLMs) have achieved remarkable success but still tend
to generate factually erroneous responses, a phenomenon known as hallucination.
A recent trend is to use preference learning to fine-tune models to align with
factuality. However, existing work primarily evaluates fine-tuned models on
in-domain (ID) datasets and the factuality on out-of-domain (OOD) datasets
remains underexplored. In this paper, we conduct a comprehensive evaluation of
the factuality of different models tuned by various preference learning
algorithms and demonstrate that their performance on OOD datasets either
increases minimally or decreases. Subsequently, we reveal that the main cause
of model's failure to uphold factuality under a distribution shift is
\textbf{under-alignment}, rather than \textbf{over-alignment}, by analyzing the
token distribution shift of the models before and after tuning. Finally, we
propose \textbf{APEFT} (\textbf{A}tomic \textbf{P}reference \textbf{E}nhanced
\textbf{F}actuality \textbf{T}uning), a framework that enhances model's
awareness of factuality at the granularity of individual facts. Extensive
experiments demonstrate that APEFT improves model performance by an average of
$\boldsymbol{3.45\%}$ on both ID and OOD datasets, which is highly effective."
Pushing the Frontier on Approximate EFX Allocations,https://arxiv.org/abs/2406.12413,2024-06-18,2024-06-19,0.0,0.0,"We study the problem of allocating a set of indivisible goods to a set of
agents with additive valuation functions, aiming to achieve approximate
envy-freeness up to any good ($\alpha$-EFX). The state-of-the-art results on
the problem include that (exact) EFX allocations exist when (a) there are at
most three agents, or (b) the agents' valuation functions can take at most two
values, or (c) the agents' valuation functions can be represented via a graph.
For $\alpha$-EFX, it is known that a $0.618$-EFX allocation exists for any
number of agents with additive valuation functions. In this paper, we show that
$2/3$-EFX allocations exist when (a) there are at most \emph{seven agents}, (b)
the agents' valuation functions can take at most \emph{three values}, or (c)
the agents' valuation functions can be represented via a \emph{multigraph}. Our
results can be interpreted in two ways. First, by relaxing the notion of EFX to
$2/3$-EFX, we obtain existence results for strict generalizations of the
settings for which exact EFX allocations are known to exist. Secondly, by
imposing restrictions on the setting, we manage to beat the barrier of $0.618$
and achieve an approximation guarantee of $2/3$. Therefore, our results push
the \emph{frontier} of existence and computation of approximate EFX
allocations, and provide insights into the challenges of settling the existence
of exact EFX allocations."
A Novel Algorithm for Community Detection in Networks using Rough Sets and Consensus Clustering,https://arxiv.org/abs/2406.12412,2024-06-18,2024-06-19,0.0,0.0,"Complex networks, such as those in social, biological, and technological
systems, often present challenges to the task of community detection. Our
research introduces a novel rough clustering based consensus community
framework (RC-CCD) for effective structure identification of network
communities. The RC-CCD method employs rough set theory to handle uncertainties
within data and utilizes a consensus clustering approach to aggregate multiple
clustering results, enhancing the reliability and accuracy of community
detection. This integration allows the RC-CCD to effectively manage overlapping
communities, which are often present in complex networks.
  This approach excels at detecting overlapping communities, offering a
detailed and accurate representation of network structures. Comprehensive
testing on benchmark networks generated by the Lancichinetti-Fortunato-Radicchi
method showcased the strength and adaptability of the new proposal to varying
node degrees and community sizes. Cross-comparisons of RC-CCD versus other well
known detection algorithms outcomes highlighted its stability and adaptability."
TADM - Temporally-Aware Diffusion Model for Neurodegenerative Progression on Brain MRI,https://arxiv.org/abs/2406.12411,2024-06-18,2024-06-19,0.0,0.0,"Generating realistic images to accurately predict changes in the structure of
brain MRI is a crucial tool for clinicians. Such applications help assess
patients' outcomes and analyze how diseases progress at the individual level.
However, existing methods for this task present some limitations. Some
approaches attempt to model the distribution of MRI scans directly by
conditioning the model on patients' ages, but they fail to explicitly capture
the relationship between structural changes in the brain and time intervals,
especially on age-unbalanced datasets. Other approaches simply rely on
interpolation between scans, which limits their clinical application as they do
not predict future MRIs. To address these challenges, we propose a
Temporally-Aware Diffusion Model (TADM), which introduces a novel approach to
accurately infer progression in brain MRIs. TADM learns the distribution of
structural changes in terms of intensity differences between scans and combines
the prediction of these changes with the initial baseline scans to generate
future MRIs. Furthermore, during training, we propose to leverage a pre-trained
Brain-Age Estimator (BAE) to refine the model's training process, enhancing its
ability to produce accurate MRIs that match the expected age gap between
baseline and generated scans. Our assessment, conducted on the OASIS-3 dataset,
uses similarity metrics and region sizes computed by comparing predicted and
real follow-up scans on 3 relevant brain regions. TADM achieves large
improvements over existing approaches, with an average decrease of 24% in
region size error and an improvement of 4% in similarity metrics. These
evaluations demonstrate the improvement of our model in mimicking temporal
brain neurodegenerative progression compared to existing methods. Our approach
will benefit applications, such as predicting patient outcomes or improving
treatments for patients."
Translation Equivariant Transformer Neural Processes,https://arxiv.org/abs/2406.12409,2024-06-18,2024-06-19,1.0,0.0,"The effectiveness of neural processes (NPs) in modelling posterior prediction
maps -- the mapping from data to posterior predictive distributions -- has
significantly improved since their inception. This improvement can be
attributed to two principal factors: (1) advancements in the architecture of
permutation invariant set functions, which are intrinsic to all NPs; and (2)
leveraging symmetries present in the true posterior predictive map, which are
problem dependent. Transformers are a notable development in permutation
invariant set functions, and their utility within NPs has been demonstrated
through the family of models we refer to as TNPs. Despite significant interest
in TNPs, little attention has been given to incorporating symmetries. Notably,
the posterior prediction maps for data that are stationary -- a common
assumption in spatio-temporal modelling -- exhibit translation equivariance. In
this paper, we introduce of a new family of translation equivariant TNPs that
incorporate translation equivariance. Through an extensive range of experiments
on synthetic and real-world spatio-temporal data, we demonstrate the
effectiveness of TE-TNPs relative to their non-translation-equivariant
counterparts and other NP baselines."
Fast Rates for Bandit PAC Multiclass Classification,https://arxiv.org/abs/2406.12406,2024-06-18,2024-06-19,0.0,0.0,"We study multiclass PAC learning with bandit feedback, where inputs are
classified into one of $K$ possible labels and feedback is limited to whether
or not the predicted labels are correct. Our main contribution is in designing
a novel learning algorithm for the agnostic $(\varepsilon,\delta)$-PAC version
of the problem, with sample complexity of $O\big( (\operatorname{poly}(K) + 1 /
\varepsilon^2) \log (|H| / \delta) \big)$ for any finite hypothesis class $H$.
In terms of the leading dependence on $\varepsilon$, this improves upon
existing bounds for the problem, that are of the form $O(K/\varepsilon^2)$. We
also provide an extension of this result to general classes and establish
similar sample complexity bounds in which $\log |H|$ is replaced by the
Natarajan dimension. This matches the optimal rate in the full-information
version of the problem and resolves an open question studied by Daniely,
Sabato, Ben-David, and Shalev-Shwartz (2011) who demonstrated that the
multiplicative price of bandit feedback in realizable PAC learning is
$\Theta(K)$. We complement this by revealing a stark contrast with the agnostic
case, where the price of bandit feedback is only $O(1)$ as $\varepsilon \to 0$.
Our algorithm utilizes a stochastic optimization technique to minimize a
log-barrier potential based on Frank-Wolfe updates for computing a low-variance
exploration distribution over the hypotheses, and is made computationally
efficient provided access to an ERM oracle over $H$."
PDSS - A Privacy-Preserving Framework for Step-by-Step Distillation of Large Language Models,https://arxiv.org/abs/2406.12403,2024-06-18,2024-06-19,0.0,0.0,"In the context of real-world applications, leveraging large language models
(LLMs) for domain-specific tasks often faces two major challenges:
domain-specific knowledge privacy and constrained resources. To address these
issues, we propose PDSS, a privacy-preserving framework for step-by-step
distillation of LLMs. PDSS works on a server-client architecture, wherein
client transmits perturbed prompts to the server's LLM for rationale
generation. The generated rationales are then decoded by the client and used to
enrich the training of task-specific small language model(SLM) within a
multi-task learning paradigm. PDSS introduces two privacy protection
strategies: the Exponential Mechanism Strategy and the Encoder-Decoder
Strategy, balancing prompt privacy and rationale usability. Experiments
demonstrate the effectiveness of PDSS in various text generation tasks,
enabling the training of task-specific SLM with enhanced performance while
prioritizing data privacy protection."
Flee the Flaw - Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling,https://arxiv.org/abs/2406.12402,2024-06-18,2024-06-19,0.0,0.0,"Prior research in computational argumentation has mainly focused on scoring
the quality of arguments, with less attention on explicating logical errors. In
this work, we introduce four sets of explainable templates for common informal
logical fallacies designed to explicate a fallacy's implicit logic. Using our
templates, we conduct an annotation study on top of 400 fallacious arguments
taken from LOGIC dataset and achieve a high agreement score (Krippendorf's
alpha of 0.54) and reasonable coverage (0.83). Finally, we conduct an
experiment for detecting the structure of fallacies and discover that
state-of-the-art language models struggle with detecting fallacy templates
(0.47 accuracy). To facilitate research on fallacies, we make our dataset and
guidelines publicly available."
QueerBench - Quantifying Discrimination in Language Models Toward Queer Identities,https://arxiv.org/abs/2406.12399,2024-06-18,2024-06-19,0.0,0.0,"With the increasing role of Natural Language Processing (NLP) in various
applications, challenges concerning bias and stereotype perpetuation are
accentuated, which often leads to hate speech and harm. Despite existing
studies on sexism and misogyny, issues like homophobia and transphobia remain
underexplored and often adopt binary perspectives, putting the safety of
LGBTQIA+ individuals at high risk in online spaces. In this paper, we assess
the potential harm caused by sentence completions generated by English large
language models (LLMs) concerning LGBTQIA+ individuals. This is achieved using
QueerBench, our new assessment framework, which employs a template-based
approach and a Masked Language Modeling (MLM) task. The analysis indicates that
large language models tend to exhibit discriminatory behaviour more frequently
towards individuals within the LGBTQIA+ community, reaching a difference gap of
7.2% in the QueerBench score of harmfulness."
Unveiling the Flaws - Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models,https://arxiv.org/abs/2406.12397,2024-06-18,2024-06-19,0.0,0.0,"Synthetic data has been proposed as a solution to address the issue of
high-quality data scarcity in the training of large language models (LLMs).
Studies have shown that synthetic data can effectively improve the performance
of LLMs on downstream benchmarks. However, despite its potential benefits, our
analysis suggests that there may be inherent flaws in synthetic data. The
uniform format of synthetic data can lead to pattern overfitting and cause
significant shifts in the output distribution, thereby reducing the model's
instruction-following capabilities. Our work delves into these specific flaws
associated with question-answer (Q-A) pairs, a prevalent type of synthetic
data, and presents a method based on unlearning techniques to mitigate these
flaws. The empirical results demonstrate the effectiveness of our approach,
which can reverse the instruction-following issues caused by pattern
overfitting without compromising performance on benchmarks at relatively low
cost. Our work has yielded key insights into the effective use of synthetic
data, aiming to promote more robust and efficient LLM training."
EMO-KNOW - A Large Scale Dataset on Emotion and Emotion-cause,https://arxiv.org/abs/2406.12389,2024-06-18,2024-06-19,0.0,0.0,"Emotion-Cause analysis has attracted the attention of researchers in recent
years. However, most existing datasets are limited in size and number of
emotion categories. They often focus on extracting parts of the document that
contain the emotion cause and fail to provide more abstractive, generalizable
root cause. To bridge this gap, we introduce a large-scale dataset of emotion
causes, derived from 9.8 million cleaned tweets over 15 years. We describe our
curation process, which includes a comprehensive pipeline for data gathering,
cleaning, labeling, and validation, ensuring the dataset's reliability and
richness. We extract emotion labels and provide abstractive summarization of
the events causing emotions. The final dataset comprises over 700,000 tweets
with corresponding emotion-cause pairs spanning 48 emotion classes, validated
by human evaluators. The novelty of our dataset stems from its broad spectrum
of emotion classes and the abstractive emotion cause that facilitates the
development of an emotion-cause knowledge graph for nuanced reasoning. Our
dataset will enable the design of emotion-aware systems that account for the
diverse emotional responses of different people for the same event."
Performant ASR Models for Medical Entities in Accented Speech,https://arxiv.org/abs/2406.12387,2024-06-18,2024-06-19,0.0,0.0,"Recent strides in automatic speech recognition (ASR) have accelerated their
application in the medical domain where their performance on accented medical
named entities (NE) such as drug names, diagnoses, and lab results, is largely
unknown. We rigorously evaluate multiple ASR models on a clinical English
dataset of 93 African accents. Our analysis reveals that despite some models
achieving low overall word error rates (WER), errors in clinical entities are
higher, potentially posing substantial risks to patient safety. To empirically
demonstrate this, we extract clinical entities from transcripts, develop a
novel algorithm to align ASR predictions with these entities, and compute
medical NE Recall, medical WER, and character error rate. Our results show that
fine-tuning on accented clinical speech improves medical WER by a wide margin
(25-34 % relative), improving their practical applicability in healthcare
environments."
From Instance Training to Instruction Learning - Task Adapters Generation from Instructions,https://arxiv.org/abs/2406.12382,2024-06-18,2024-06-19,0.0,0.0,"Large language models (LLMs) have acquired the ability to solve general tasks
by utilizing instruction finetuning (IFT). However, IFT still relies heavily on
instance training of extensive task data, which greatly limits the adaptability
of LLMs to real-world scenarios where labeled task instances are scarce and
broader task generalization becomes paramount. Contrary to LLMs, humans acquire
skills and complete tasks not merely through repeated practice but also by
understanding and following instructional guidelines. This paper is dedicated
to simulating human learning to address the shortcomings of instance training,
focusing on instruction learning to enhance cross-task generalization. Within
this context, we introduce Task Adapters Generation from Instructions (TAGI),
which automatically constructs the task-specific model in a parameter
generation manner based on the given task instructions without retraining for
unseen tasks. Specifically, we utilize knowledge distillation to enhance the
consistency between TAGI developed through Learning with Instruction and
task-specific models developed through Training with Instance, by aligning the
labels, output logits, and adapter parameters between them. TAGI is endowed
with cross-task generalization capabilities through a two-stage training
process that includes hypernetwork pretraining and finetuning. We evaluate TAGI
on the Super-Natural Instructions and P3 datasets. The experimental results
demonstrate that TAGI can match or even outperform traditional meta-trained
models and other hypernetwork models, while significantly reducing
computational requirements."
QOG -Question and Options Generation based on Language Model,https://arxiv.org/abs/2406.12381,2024-06-18,2024-06-19,0.0,0.0,"Question-Options Generation (QOG) is a task that involves generating a set of
question-options pairs given context. This task has various applications,
including fine-tuning large models, information retrieval, and automated
multiple-choice question generation for education. In this paper, we develop
QOG models using three different methods based on fine-tuning
sequence-to-sequence language models (LMs). Experiments demonstrate that the
end-to-end QOG model is computationally efficient and stable during both
training and inference, outperforming other methods. Furthermore, our analysis
indicates that our QOG models are competitive on the QOG task compared to the
large language model Llama 3-8B."
Efficient mapping of phase diagrams with conditional normalizing flows,https://arxiv.org/abs/2406.12378,2024-06-18,2024-06-19,0.0,0.0,"The accurate prediction of phase diagrams is of central importance for both
the fundamental understanding of materials as well as for technological
applications in material sciences. However, the computational prediction of the
relative stability between phases based on their free energy is a daunting
task, as traditional free energy estimators require a large amount of
simulation data to obtain uncorrelated equilibrium samples over a grid of
thermodynamic states. In this work, we develop deep generative machine learning
models based on the Boltzmann Generator approach for entire phase diagrams,
employing normalizing flows conditioned on the thermodynamic states, e.g.,
temperature and pressure, that they map to. By training a single normalizing
flow to transform the equilibrium distribution sampled at only one reference
thermodynamic state to a wide range of target temperatures and pressures, we
can efficiently generate equilibrium samples across the entire phase diagram.
Using a permutation-equivariant architecture allows us, thereby, to treat solid
and liquid phases on the same footing. We demonstrate our approach by
predicting the solid-liquid coexistence line for a Lennard-Jones system in
excellent agreement with state-of-the-art free energy methods while
significantly reducing the number of energy evaluations needed."
GW-MoE - Resolving Uncertainty in MoE Router with Global Workspace Theory,https://arxiv.org/abs/2406.12375,2024-06-18,2024-06-19,0.0,0.0,"Mixture-of-Experts (MoE) has been demonstrated as an efficient method to
scale up models. By dynamically and sparsely selecting activated experts, MoE
can effectively reduce computational costs. Despite the success, we observe
that many tokens in the MoE models have uncertain routing results. These tokens
have nearly equal scores for choosing each expert, and we demonstrate that this
uncertainty can lead to incorrect selections. Inspired by the Global Workspace
Theory (GWT), we propose a new fine-tuning method, GW-MoE, to address this
issue. The core idea is to broadcast the uncertain tokens across experts during
fine-tuning. Therefore, these tokens can acquire the necessary knowledge from
any expert during inference and become less sensitive to the choice. GW-MoE
does not introduce additional inference overhead. We validate that GW can
mitigate the uncertain problem and consistently improve in different tasks
(text classification, question answering, summarization, code generation, and
mathematical problem solving) and model sizes (650M and 8B parameters)."
Problem-Solving in Language Model Networks,https://arxiv.org/abs/2406.12374,2024-06-18,2024-06-19,0.0,0.0,"To improve the reasoning and question-answering capabilities of Large
Language Models (LLMs), several multi-agent approaches have been introduced.
While these methods enhance performance, the application of collective
intelligence-based approaches to complex network structures and the dynamics of
agent interactions remain underexplored. This work extends the concept of
multi-agent debate to more general network topologies, measuring the
question-answering accuracy, influence, consensus, and the effects of bias on
the collective. The results show that random networks perform similarly to
fully connected networks despite using significantly fewer tokens. Furthermore,
a strong consensus among agents correlates with correct answers, whereas
divided responses typically indicate incorrect answers. Analysing the influence
of the agents reveals a balance between self-reflection and interconnectedness;
self-reflection aids when local interactions are incorrect, and local
interactions aid when the agent itself is incorrect. Additionally, bias plays a
strong role in system performance with correctly biased hub nodes boosting
performance. These insights suggest that using random networks or scale-free
networks with knowledgeable agents placed in central positions can enhance the
overall question-answering performance of multi-agent systems."
WebCanvas - Benchmarking Web Agents in Online Environments,https://arxiv.org/abs/2406.12373,2024-06-18,2024-06-19,0.0,0.0,"For web agents to be practically useful, they must adapt to the continuously
evolving web environment characterized by frequent updates to user interfaces
and content. However, most existing benchmarks only capture the static aspects
of the web. To bridge this gap, we introduce WebCanvas, an innovative online
evaluation framework for web agents that effectively addresses the dynamic
nature of web interactions. WebCanvas contains three main components to
facilitate realistic assessments: (1) A novel evaluation metric which reliably
capture critical intermediate actions or states necessary for task completions
while disregarding noise caused by insignificant events or changed
web-elements. (2) A benchmark dataset called Mind2Web-Live, a refined version
of original Mind2Web static dataset containing 542 tasks with 2439 intermediate
evaluation states; (3) Lightweight and generalizable annotation tools and
testing pipelines that enables the community to collect and maintain the
high-quality, up-to-date dataset. Building on WebCanvas, we open-source an
agent framework with extensible modules for reasoning, providing a foundation
for the community to conduct online inference and evaluations. Our
best-performing agent achieves a task success rate of 23.1% and a task
completion rate of 48.8% on the Mind2Web-Live test set. Additionally, we
analyze the performance discrepancies across various websites, domains, and
experimental environments. We encourage the community to contribute further
insights on online agent evaluation, thereby advancing this field of research."
A Comparative Study of Continuous Sign Language Recognition Techniques,https://arxiv.org/abs/2406.12369,2024-06-18,2024-06-19,0.0,0.0,"Continuous Sign Language Recognition (CSLR) focuses on the interpretation of
a sequence of sign language gestures performed continually without pauses. In
this study, we conduct an empirical evaluation of recent deep learning CSLR
techniques and assess their performance across various datasets and sign
languages. The models selected for analysis implement a range of approaches for
extracting meaningful features and employ distinct training strategies. To
determine their efficacy in modeling different sign languages, these models
were evaluated using multiple datasets, specifically RWTH-PHOENIX-Weather-2014,
ArabSign, and GrSL, each representing a unique sign language. The performance
of the models was further tested with unseen signers and sentences. The
conducted experiments establish new benchmarks on the selected datasets and
provide valuable insights into the robustness and generalization of the
evaluated techniques under challenging scenarios."
Competitive Learning for Achieving Content-specific Filters in Video Coding for Machines,https://arxiv.org/abs/2406.12367,2024-06-18,2024-06-19,0.0,0.0,"This paper investigates the efficacy of jointly optimizing content-specific
post-processing filters to adapt a human oriented video/image codec into a
codec suitable for machine vision tasks. By observing that artifacts produced
by video/image codecs are content-dependent, we propose a novel training
strategy based on competitive learning principles. This strategy assigns
training samples to filters dynamically, in a fuzzy manner, which further
optimizes the winning filter on the given sample. Inspired by simulated
annealing optimization techniques, we employ a softmax function with a
temperature variable as the weight allocation function to mitigate the effects
of random initialization. Our evaluation, conducted on a system utilizing
multiple post-processing filters within a Versatile Video Coding (VVC) codec
framework, demonstrates the superiority of content-specific filters trained
with our proposed strategies, specifically, when images are processed in
blocks. Using VVC reference software VTM 12.0 as the anchor, experiments on the
OpenImages dataset show an improvement in the BD-rate reduction from -41.3% and
-44.6% to -42.3% and -44.7% for object detection and instance segmentation
tasks, respectively, compared to independently trained filters. The statistics
of the filter usage align with our hypothesis and underscore the importance of
jointly optimizing filters for both content and reconstruction quality. Our
findings pave the way for further improving the performance of video/image
codecs."
Structured Prediction in Online Learning,https://arxiv.org/abs/2406.12366,2024-06-18,2024-06-19,0.0,0.0,"We study a theoretical and algorithmic framework for structured prediction in
the online learning setting. The problem of structured prediction, i.e.
estimating function where the output space lacks a vectorial structure, is well
studied in the literature of supervised statistical learning. We show that our
algorithm is a generalisation of optimal algorithms from the supervised
learning setting, and achieves the same excess risk upper bound also when data
are not i.i.d. Moreover, we consider a second algorithm designed especially for
non-stationary data distributions, including adversarial data. We bound its
stochastic regret in function of the variation of the data distributions."
UrbanLLM - Autonomous Urban Activity Planning and Management with Large Language Models,https://arxiv.org/abs/2406.12360,2024-06-18,2024-06-19,0.0,0.0,"Location-based services play an critical role in improving the quality of our
daily lives. Despite the proliferation of numerous specialized AI models within
spatio-temporal context of location-based services, these models struggle to
autonomously tackle problems regarding complex urban planing and management. To
bridge this gap, we introduce UrbanLLM, a fine-tuned large language model (LLM)
designed to tackle diverse problems in urban scenarios. UrbanLLM functions as a
problem-solver by decomposing urban-related queries into manageable sub-tasks,
identifying suitable spatio-temporal AI models for each sub-task, and
generating comprehensive responses to the given queries. Our experimental
results indicate that UrbanLLM significantly outperforms other established
LLMs, such as Llama and the GPT series, in handling problems concerning complex
urban activity planning and management. UrbanLLM exhibits considerable
potential in enhancing the effectiveness of solving problems in urban
scenarios, reducing the workload and reliance for human experts."
Memory Sequence Length of Data Sampling Impacts the Adaptation of Meta-Reinforcement Learning Agents,https://arxiv.org/abs/2406.12359,2024-06-18,2024-06-19,0.0,0.0,"Fast adaptation to new tasks is extremely important for embodied agents in
the real world. Meta-reinforcement learning (meta-RL) has emerged as an
effective method to enable fast adaptation in unknown environments. Compared to
on-policy meta-RL algorithms, off-policy algorithms rely heavily on efficient
data sampling strategies to extract and represent the historical trajectories.
However, little is known about how different data sampling methods impact the
ability of meta-RL agents to represent unknown environments. Here, we
investigate the impact of data sampling strategies on the exploration and
adaptability of meta-RL agents. Specifically, we conducted experiments with two
types of off-policy meta-RL algorithms based on Thompson sampling and
Bayes-optimality theories in continuous control tasks within the MuJoCo
environment and sparse reward navigation tasks. Our analysis revealed the
long-memory and short-memory sequence sampling strategies affect the
representation and adaptive capabilities of meta-RL agents. We found that the
algorithm based on Bayes-optimality theory exhibited more robust and better
adaptability than the algorithm based on Thompson sampling, highlighting the
importance of appropriate data sampling strategies for the agent's
representation of an unknown environment, especially in the case of sparse
rewards."
Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models,https://arxiv.org/abs/2406.12354,2024-06-18,2024-06-19,0.0,0.0,"Pretrained language models memorize vast amounts of information, including
private and copyrighted data, raising significant safety concerns. Retraining
these models after excluding sensitive data is prohibitively expensive, making
machine unlearning a viable, cost-effective alternative. Previous research has
focused on machine unlearning for monolingual models, but we find that
unlearning in one language does not necessarily transfer to others. This
vulnerability makes models susceptible to low-resource language attacks, where
sensitive information remains accessible in less dominant languages. This paper
presents a pioneering approach to machine unlearning for multilingual language
models, selectively erasing information across different languages while
maintaining overall performance. Specifically, our method employs an adaptive
unlearning scheme that assigns language-dependent weights to address different
language performances of multilingual language models. Empirical results
demonstrate the effectiveness of our framework compared to existing unlearning
baselines, setting a new standard for secure and adaptable multilingual
language models."
Top-Down Bayesian Posterior Sampling for Sum-Product Networks,https://arxiv.org/abs/2406.12353,2024-06-18,2024-06-19,0.0,0.0,"Sum-product networks (SPNs) are probabilistic models characterized by exact
and fast evaluation of fundamental probabilistic operations. Its superior
computational tractability has led to applications in many fields, such as
machine learning with time constraints or accuracy requirements and real-time
systems. The structural constraints of SPNs supporting fast inference, however,
lead to increased learning-time complexity and can be an obstacle to building
highly expressive SPNs. This study aimed to develop a Bayesian learning
approach that can be efficiently implemented on large-scale SPNs. We derived a
new full conditional probability of Gibbs sampling by marginalizing multiple
random variables to expeditiously obtain the posterior distribution. The
complexity analysis revealed that our sampling algorithm works efficiently even
for the largest possible SPN. Furthermore, we proposed a hyperparameter tuning
method that balances the diversity of the prior distribution and optimization
efficiency in large-scale SPNs. Our method has improved learning-time
complexity and demonstrated computational speed tens to more than one hundred
times faster and superior predictive performance in numerical experiments on
more than 20 datasets."
Effective Generation of Feasible Solutions for Integer Programming via Guided Diffusion,https://arxiv.org/abs/2406.12349,2024-06-18,2024-06-19,0.0,0.0,"Feasible solutions are crucial for Integer Programming (IP) since they can
substantially speed up the solving process. In many applications, similar IP
instances often exhibit similar structures and shared solution distributions,
which can be potentially modeled by deep learning methods. Unfortunately,
existing deep-learning-based algorithms, such as Neural Diving and
Predict-and-search framework, are limited to generating only partial feasible
solutions, and they must rely on solvers like SCIP and Gurobi to complete the
solutions for a given IP problem. In this paper, we propose a novel framework
that generates complete feasible solutions end-to-end. Our framework leverages
contrastive learning to characterize the relationship between IP instances and
solutions, and learns latent embeddings for both IP instances and their
solutions. Further, the framework employs diffusion models to learn the
distribution of solution embeddings conditioned on IP representations, with a
dedicated guided sampling strategy that accounts for both constraints and
objectives. We empirically evaluate our framework on four typical datasets of
IP problems, and show that it effectively generates complete feasible solutions
with a high probability (> 89.7 \%) without the reliance of Solvers and the
quality of solutions is comparable to the best heuristic solutions from Gurobi.
Furthermore, by integrating our method's sampled partial solutions with the
CompleteSol heuristic from SCIP, the resulting feasible solutions outperform
those from state-of-the-art methods across all datasets, exhibiting a 3.7 to
33.7\% improvement in the gap to optimal values, and maintaining a feasible
ratio of over 99.7\% for all datasets."
Navigating Knowledge Management Implementation Success in Government Organizations - A type-2 fuzzy approach,https://arxiv.org/abs/2406.12345,2024-06-18,2024-06-19,0.0,0.0,"Optimal information and knowledge management is crucial for organizations to
achieve their objectives efficiently. As a rare and valuable resource,
effective knowledge management provides a strategic advantage and has become a
key determinant of organizational success. The study aims to identify critical
success and failure factors for implementing knowledge management systems in
government organizations. This research employs a descriptive survey
methodology, collecting data through random interviews and questionnaires. The
study highlights the critical success factors for knowledge management systems
in government organizations, including cooperation, an open atmosphere, staff
training, creativity and innovation, removal of organizational constraints,
reward policies, role modeling, and focus. Conversely, failure to consider
formality, staff participation, collaboration technologies, network and
hardware infrastructure, complexity, IT staff, and trust can pose significant
obstacles to successful implementation."
PARAFAC2-based Coupled Matrix and Tensor Factorizations with Constraints,https://arxiv.org/abs/2406.12338,2024-06-18,2024-06-19,0.0,0.0,"Data fusion models based on Coupled Matrix and Tensor Factorizations (CMTF)
have been effective tools for joint analysis of data from multiple sources.
While the vast majority of CMTF models are based on the strictly multilinear
CANDECOMP/PARAFAC (CP) tensor model, recently also the more flexible PARAFAC2
model has been integrated into CMTF models. PARAFAC2 tensor models can handle
irregular/ragged tensors and have shown to be especially useful for modelling
dynamic data with unaligned or irregular time profiles. However, existing
PARAFAC2-based CMTF models have limitations in terms of possible
regularizations on the factors and/or types of coupling between datasets. To
address these limitations, in this paper we introduce a flexible algorithmic
framework that fits PARAFAC2-based CMTF models using Alternating Optimization
(AO) and the Alternating Direction Method of Multipliers (ADMM). The proposed
framework allows to impose various constraints on all modes and linear
couplings to other matrix-, CP- or PARAFAC2-models. Experiments on various
simulated and a real dataset demonstrate the utility and versatility of the
proposed framework as well as its benefits in terms of accuracy and efficiency
in comparison with state-of-the-art methods."
A Compass for Navigating the World of Sentence Embeddings for the Telecom Domain,https://arxiv.org/abs/2406.12336,2024-06-18,2024-06-19,0.0,0.0,"A plethora of sentence embedding models makes it challenging to choose one,
especially for domains such as telecom, rich with specialized vocabulary. We
evaluate multiple embeddings obtained from publicly available models and their
domain-adapted variants, on both point retrieval accuracies as well as their
(95\%) confidence intervals. We establish a systematic method to obtain
thresholds for similarity scores for different embeddings. We observe that
fine-tuning improves mean bootstrapped accuracies as well as tightens
confidence intervals. The pre-training combined with fine-tuning makes
confidence intervals even tighter. To understand these variations, we analyse
and report significant correlations between the distributional overlap between
top-$K$, correct and random sentence similarities with retrieval accuracies and
similarity thresholds. Following current literature, we analyze if retrieval
accuracy variations can be attributed to isotropy of embeddings. Our
conclusions are that isotropy of embeddings (as measured by two independent
state-of-the-art isotropy metric definitions) cannot be attributed to better
retrieval performance. However, domain adaptation which improves retrieval
accuracies also improves isotropy. We establish that domain adaptation moves
domain specific embeddings further away from general domain embeddings."
Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction - Value Also Matters,https://arxiv.org/abs/2406.12335,2024-06-18,2024-06-19,1.0,0.0,"Scaling the context size of large language models (LLMs) enables them to
perform various new tasks, e.g., book summarization. However, the memory cost
of the Key and Value (KV) cache in attention significantly limits the practical
applications of LLMs. Recent works have explored token pruning for KV cache
reduction in LLMs, relying solely on attention scores as a token importance
indicator. However, our investigation into value vector norms revealed a
notably non-uniform pattern questioning their reliance only on attention
scores. Inspired by this, we propose a new method: Value-Aware Token Pruning
(VATP) which uses both attention scores and the $ \ell_{1} $ norm of value
vectors to evaluate token importance. Extensive experiments on LLaMA2-7B-chat
and Vicuna-v1.5-7B across 16 LongBench tasks demonstrate that VATP outperforms
attention-score-only baselines in over 12 tasks, confirming the effectiveness
of incorporating value vector norms into token importance evaluation of LLMs."
What Did I Do Wrong? Quantifying LLMs' Sensitivity and Consistency to Prompt Engineering,https://arxiv.org/abs/2406.12334,2024-06-18,2024-06-19,0.0,0.0,"Large Language Models (LLMs) changed the way we design and interact with
software systems. Their ability to process and extract information from text
has drastically improved productivity in a number of routine tasks. Developers
that want to include these models in their software stack, however, face a
dreadful challenge: debugging LLMs' inconsistent behavior across minor
variations of the prompt. We therefore introduce two metrics for classification
tasks, namely sensitivity and consistency, which are complementary to task
performance. First, sensitivity measures changes of predictions across
rephrasings of the prompt, and does not require access to ground truth labels.
Instead, consistency measures how predictions vary across rephrasings for
elements of the same class. We perform an empirical comparison of these metrics
on text classification tasks, using them as guideline for understanding failure
modes of the LLM. Our hope is that sensitivity and consistency will be helpful
to guide prompt engineering and obtain LLMs that balance robustness with
performance."
Retrieval Meets Reasoning - Dynamic In-Context Editing for Long-Text Understanding,https://arxiv.org/abs/2406.12331,2024-06-18,2024-06-19,0.0,0.0,"Current Large Language Models (LLMs) face inherent limitations due to their
pre-defined context lengths, which impede their capacity for multi-hop
reasoning within extensive textual contexts. While existing techniques like
Retrieval-Augmented Generation (RAG) have attempted to bridge this gap by
sourcing external information, they fall short when direct answers are not
readily available. We introduce a novel approach that re-imagines information
retrieval through dynamic in-context editing, inspired by recent breakthroughs
in knowledge editing. By treating lengthy contexts as malleable external
knowledge, our method interactively gathers and integrates relevant
information, thereby enabling LLMs to perform sophisticated reasoning steps.
Experimental results demonstrate that our method effectively empowers
context-limited LLMs, such as Llama2, to engage in multi-hop reasoning with
improved performance, which outperforms state-of-the-art context window
extrapolation methods and even compares favorably to more advanced commercial
long-context models. Our interactive method not only enhances reasoning
capabilities but also mitigates the associated training and computational
costs, making it a pragmatic solution for enhancing LLMs' reasoning within
expansive contexts."
Security and Privacy of 6G Federated Learning-enabled Dynamic Spectrum Sharing,https://arxiv.org/abs/2406.12330,2024-06-18,2024-06-19,0.0,0.0,"Spectrum sharing is increasingly vital in 6G wireless communication,
facilitating dynamic access to unused spectrum holes. Recently, there has been
a significant shift towards employing machine learning (ML) techniques for
sensing spectrum holes. In this context, federated learning (FL)-enabled
spectrum sensing technology has garnered wide attention, allowing for the
construction of an aggregated ML model without disclosing the private spectrum
sensing information of wireless user devices. However, the integrity of
collaborative training and the privacy of spectrum information from local users
have remained largely unexplored. This article first examines the latest
developments in FL-enabled spectrum sharing for prospective 6G scenarios. It
then identifies practical attack vectors in 6G to illustrate potential
AI-powered security and privacy threats in these contexts. Finally, the study
outlines future directions, including practical defense challenges and
guidelines."
SNAP - Unlearning Selective Knowledge in Large Language Models with Negative Instructions,https://arxiv.org/abs/2406.12329,2024-06-18,2024-06-19,0.0,0.0,"Instruction-following large language models (LLMs), such as ChatGPT, have
become increasingly popular with the general audience, many of whom are
incorporating them into their daily routines. However, these LLMs inadvertently
disclose personal or copyrighted information, which calls for a machine
unlearning method to remove selective knowledge. Previous attempts sought to
forget the link between the target information and its associated entities, but
it rather led to generating undesirable responses about the target,
compromising the end-user experience. In this work, we propose SNAP, an
innovative framework designed to selectively unlearn information by 1) training
an LLM with negative instructions to generate obliterated responses, 2)
augmenting hard positives to retain the original LLM performance, and 3)
applying the novel Wasserstein regularization to ensure adequate deviation from
the initial weights of the LLM. We evaluate our framework on various NLP
benchmarks and demonstrate that our approach retains the original LLM
capabilities, while successfully unlearning the specified information."
Toward Exploring the Code Understanding Capabilities of Pre-trained Code Generation Models,https://arxiv.org/abs/2406.12326,2024-06-18,2024-06-19,0.0,0.0,"Recently, large code generation models trained in a self-supervised manner on
extensive unlabeled programming language data have achieved remarkable success.
While these models acquire vast amounts of code knowledge, they perform poorly
on code understanding tasks, such as code search and clone detection, as they
are specifically trained for generation. Pre-training a larger encoder-only
architecture model from scratch on massive code data can improve understanding
performance. However, this approach is costly and time-consuming, making it
suboptimal. In this paper, we pioneer the transfer of knowledge from
pre-trained code generation models to code understanding tasks, significantly
reducing training costs. We examine effective strategies for enabling
decoder-only models to acquire robust code representations. Furthermore, we
introduce CL4D, a contrastive learning method designed to enhance the
representation capabilities of decoder-only models. Comprehensive experiments
demonstrate that our approach achieves state-of-the-art performance in
understanding tasks such as code search and clone detection. Our analysis shows
that our method effectively reduces the distance between semantically identical
samples in the representation space. These findings suggest the potential for
unifying code understanding and generation tasks using a decoder-only
structured model."
PRePair - Pointwise Reasoning Enhance Pairwise Evaluating for Robust Instruction-Following Assessments,https://arxiv.org/abs/2406.12319,2024-06-18,2024-06-19,0.0,0.0,"Pairwise evaluation using large language models (LLMs) is widely used for
evaluating natural language generation (NLG) tasks. However, the reliability of
LLMs is often compromised by biases, such as favoring verbosity and
authoritative tone. In the study, we focus on the comparison of two LLM-based
evaluation approaches, pointwise and pairwise. Our findings demonstrate that
pointwise evaluators exhibit more robustness against undesirable preferences.
Further analysis reveals that pairwise evaluators can accurately identify the
shortcomings of low-quality outputs even when their judgment is incorrect.
These results indicate that LLMs are more severely influenced by their bias in
a pairwise evaluation setup. To mitigate this, we propose a hybrid method that
integrates pointwise reasoning into pairwise evaluation. Experimental results
show that our method enhances the robustness of pairwise evaluators against
adversarial samples while preserving accuracy on normal samples."
Finding Task-specific Subnetworks in Multi-task Spoken Language Understanding Model,https://arxiv.org/abs/2406.12317,2024-06-18,2024-06-19,0.0,0.0,"Recently, multi-task spoken language understanding (SLU) models have emerged,
designed to address various speech processing tasks. However, these models
often rely on a large number of parameters. Also, they often encounter
difficulties in adapting to new data for a specific task without experiencing
catastrophic forgetting of previously trained tasks. In this study, we propose
finding task-specific subnetworks within a multi-task SLU model via neural
network pruning. In addition to model compression, we expect that the
forgetting of previously trained tasks can be mitigated by updating only a
task-specific subnetwork. We conduct experiments on top of the state-of-the-art
multi-task SLU model ``UniverSLU'', trained for several tasks such as emotion
recognition (ER), intent classification (IC), and automatic speech recognition
(ASR). We show that pruned models were successful in adapting to additional ASR
or IC data with minimal performance degradation on previously trained tasks."
Enhancing Visible-Infrared Person Re-identification with Modality- and Instance-aware Visual Prompt Learning,https://arxiv.org/abs/2406.12316,2024-06-18,2024-06-19,0.0,0.0,"The Visible-Infrared Person Re-identification (VI ReID) aims to match visible
and infrared images of the same pedestrians across non-overlapped camera views.
These two input modalities contain both invariant information, such as shape,
and modality-specific details, such as color. An ideal model should utilize
valuable information from both modalities during training for enhanced
representational capability. However, the gap caused by modality-specific
information poses substantial challenges for the VI ReID model to handle
distinct modality inputs simultaneously. To address this, we introduce the
Modality-aware and Instance-aware Visual Prompts (MIP) network in our work,
designed to effectively utilize both invariant and specific information for
identification. Specifically, our MIP model is built on the transformer
architecture. In this model, we have designed a series of modality-specific
prompts, which could enable our model to adapt to and make use of the specific
information inherent in different modality inputs, thereby reducing the
interference caused by the modality gap and achieving better identification.
Besides, we also employ each pedestrian feature to construct a group of
instance-specific prompts. These customized prompts are responsible for guiding
our model to adapt to each pedestrian instance dynamically, thereby capturing
identity-level discriminative clues for identification. Through extensive
experiments on SYSU-MM01 and RegDB datasets, the effectiveness of both our
designed modules is evaluated. Additionally, our proposed MIP performs better
than most state-of-the-art methods."
PruningBench - A Comprehensive Benchmark of Structural Pruning,https://arxiv.org/abs/2406.12315,2024-06-18,2024-06-19,0.0,0.0,"Structural pruning has emerged as a promising approach for producing more
efficient models. Nevertheless, the community suffers from a lack of
standardized benchmarks and metrics, leaving the progress in this area not
fully comprehended. To fill this gap, we present the first comprehensive
benchmark, termed \textit{PruningBench}, for structural pruning. PruningBench
showcases the following three characteristics: 1) PruningBench employs a
unified and consistent framework for evaluating the effectiveness of diverse
structural pruning techniques; 2) PruningBench systematically evaluates 16
existing pruning methods, encompassing a wide array of models (e.g., CNNs and
ViTs) and tasks (e.g., classification and detection); 3) PruningBench provides
easily implementable interfaces to facilitate the implementation of future
pruning methods, and enables the subsequent researchers to incorporate their
work into our leaderboards. We provide an online pruning platform
http://pruning.vipazoo.cn for customizing pruning tasks and reproducing all
results in this paper. Codes will be made publicly on
https://github.com/HollyLee2000/PruningBench."
Mixture of Scales - Memory-Efficient Token-Adaptive Binarization for Large Language Models,https://arxiv.org/abs/2406.12311,2024-06-18,2024-06-19,1.0,0.0,"Binarization, which converts weight parameters to binary values, has emerged
as an effective strategy to reduce the size of large language models (LLMs).
However, typical binarization techniques significantly diminish linguistic
effectiveness of LLMs. To address this issue, we introduce a novel binarization
technique called Mixture of Scales (BinaryMoS). Unlike conventional methods,
BinaryMoS employs multiple scaling experts for binary weights, dynamically
merging these experts for each token to adaptively generate scaling factors.
This token-adaptive approach boosts the representational power of binarized
LLMs by enabling contextual adjustments to the values of binary weights.
Moreover, because this adaptive process only involves the scaling factors
rather than the entire weight matrix, BinaryMoS maintains compression
efficiency similar to traditional static binarization methods. Our experimental
results reveal that BinaryMoS surpasses conventional binarization techniques in
various natural language processing tasks and even outperforms 2-bit
quantization methods, all while maintaining similar model size to static
binarization techniques."
Can Tool-augmented Large Language Models be Aware of Incomplete Conditions?,https://arxiv.org/abs/2406.12307,2024-06-18,2024-06-19,0.0,0.0,"Recent advancements in integrating large language models (LLMs) with tools
have allowed the models to interact with real-world environments. However,
these \textit{tool-augmented LLMs} often encounter incomplete scenarios when
users provide partial information or the necessary tools are unavailable.
Recognizing and managing such scenarios is crucial for LLMs to ensure their
reliability, but this exploration remains understudied. This study examines
whether LLMs can identify incomplete conditions and appropriately determine
when to refrain from using tools. To this end, we address a dataset by
manipulating instances from two datasets by removing necessary tools or
essential information for tool invocation. We confirm that most LLMs are
challenged to identify the additional information required to utilize specific
tools and the absence of appropriate tools. We further analyze model behaviors
in different environments and compare their performance against humans. Our
research can contribute to advancing reliable LLMs by addressing scenarios that
commonly arise during interactions between humans and LLMs."
COT - A Generative Approach for Hate Speech Counter-Narratives via Contrastive Optimal Transport,https://arxiv.org/abs/2406.12304,2024-06-18,2024-06-19,0.0,0.0,"Counter-narratives, which are direct responses consisting of non-aggressive
fact-based arguments, have emerged as a highly effective approach to combat the
proliferation of hate speech. Previous methodologies have primarily focused on
fine-tuning and post-editing techniques to ensure the fluency of generated
contents, while overlooking the critical aspects of individualization and
relevance concerning the specific hatred targets, such as LGBT groups,
immigrants, etc. This research paper introduces a novel framework based on
contrastive optimal transport, which effectively addresses the challenges of
maintaining target interaction and promoting diversification in generating
counter-narratives. Firstly, an Optimal Transport Kernel (OTK) module is
leveraged to incorporate hatred target information in the token
representations, in which the comparison pairs are extracted between original
and transported features. Secondly, a self-contrastive learning module is
employed to address the issue of model degeneration. This module achieves this
by generating an anisotropic distribution of token representations. Finally, a
target-oriented search method is integrated as an improved decoding strategy to
explicitly promote domain relevance and diversification in the inference
process. This strategy modifies the model's confidence score by considering
both token similarity and target relevance. Quantitative and qualitative
experiments have been evaluated on two benchmark datasets, which demonstrate
that our proposed model significantly outperforms current methods evaluated by
metrics from multiple aspects."
A Step Towards a Universal Method for Modeling and Implementing Cross-Organizational Business Processes,https://arxiv.org/abs/2406.12302,2024-06-18,2024-06-19,0.0,0.0,"The widely adopted Business Process Model and Notation (BPMN) is a
cornerstone of industry standards for business process modeling. However, its
ambiguous execution semantics often result in inconsistent interpretations,
depending on the software used for implementation. In response, the Process
Specification Language (PASS) provides formally defined semantics to overcome
these interpretational challenges. Despite its clear advantages, PASS has not
reached the same level of industry penetration as BPMN.
  This feasibility study proposes using PASS as an intermediary framework to
translate and execute BPMN models. It describes the development of a prototype
translator that converts specific BPMN elements into a format compatible with
PASS. These models are then transformed into source code and executed in a
bespoke workflow environment, marking a departure from traditional BPMN
implementations.
  Our findings suggest that integrating PASS enhances compatibility across
different modeling and execution tools and offers a more robust methodology for
implementing business processes across organizations. This study lays the
groundwork for more accurate and unified business process model executions,
potentially transforming industry standards for process modeling and execution."
Research on Dangerous Flight Weather Prediction based on Machine Learning,https://arxiv.org/abs/2406.12298,2024-06-18,2024-06-19,0.0,0.0,"With the continuous expansion of the scale of air transport, the demand for
aviation meteorological support also continues to grow. The impact of hazardous
weather on flight safety is critical. How to effectively use meteorological
data to improve the early warning capability of flight dangerous weather and
ensure the safe flight of aircraft is the primary task of aviation
meteorological services. In this work, support vector machine (SVM) models are
used to predict hazardous flight weather, especially for meteorological
conditions with high uncertainty such as storms and turbulence. SVM is a
supervised learning method that distinguishes between different classes of data
by finding optimal decision boundaries in a high-dimensional space. In order to
meet the needs of this study, we chose the radial basis function (RBF) as the
kernel function, which helps to deal with nonlinear problems and enables the
model to better capture complex meteorological data structures. During the
model training phase, we used historical meteorological observations from
multiple weather stations, including temperature, humidity, wind speed, wind
direction, and other meteorological indicators closely related to flight
safety. From this data, the SVM model learns how to distinguish between normal
and dangerous flight weather conditions."
Faithful Density-Peaks Clustering via Matrix Computations on MPI Parallelization System,https://arxiv.org/abs/2406.12297,2024-06-18,2024-06-19,0.0,0.0,"Density peaks clustering (DP) has the ability of detecting clusters of
arbitrary shape and clustering non-Euclidean space data, but its quadratic
complexity in both computing and storage makes it difficult to scale for big
data. Various approaches have been proposed in this regard, including MapReduce
based distribution computing, multi-core parallelism, presentation
transformation (e.g., kd-tree, Z-value), granular computing, and so forth.
However, most of these existing methods face two limitations. One is their
target datasets are mostly constrained to be in Euclidian space, the other is
they emphasize only on local neighbors while ignoring global data distribution
due to restriction to cut-off kernel when computing density. To address the two
issues, we present a faithful and parallel DP method that makes use of two
types of vector-like distance matrices and an inverse leading-node-finding
policy. The method is implemented on a message passing interface (MPI) system.
Extensive experiments showed that our method is capable of clustering
non-Euclidean data such as in community detection, while outperforming the
state-of-the-art counterpart methods in accuracy when clustering large
Euclidean data. Our code is publicly available at
https://github.com/alanxuji/FaithPDP."
Fast and Slow Generating - An Empirical Study on Large and Small Language Models Collaborative Decoding,https://arxiv.org/abs/2406.12295,2024-06-18,2024-06-19,0.0,0.0,"Large Language Models (LLMs) demonstrate impressive performance in diverse
applications, yet they face significant drawbacks, including high inference
latency, expensive training cost, and generation of hallucination.
Collaborative decoding between large and small language models (SLMs) offers a
novel approach to address these challenges. Inspired by dual-process cognitive
theory, we integrate these methods into a unified framework termed Fast and
Slow Generating (FS-GEN). This paper explores several techniques within the
FS-GEN framework, including speculative decoding, contrastive decoding, and
emulator or proxy fine-tuning. We provide a comprehensive analysis of these
methodologies, offering insights into their similarities and differences under
this framework. Our study delves into the differential knowledge capabilities
of LLMs versus SLMs through the FS-GEN lens, revealing that fewer than 20% of
collaborative interactions are required across various methods. These
interactions adhere to a scaling law relative to the parameter ratios, thereby
facilitating predictable collaboration. Furthermore, we investigate the
specific positions where collaboration is most effective from an uncertainty
perspective, yielding novel insights that could refine FS-GEN methods. Our
findings reveal that the essential difference between models of different sizes
lies in the uncertainty of the next token prediction, where interventions by
larger models are most needed to assist the smaller ones. Code for
Reproduction: https://github.com/TsinghuaC3I/FS-GEN"
JEN-1 DreamStyler - Customized Musical Concept Learning via Pivotal Parameters Tuning,https://arxiv.org/abs/2406.12292,2024-06-18,2024-06-19,0.0,0.0,"Large models for text-to-music generation have achieved significant progress,
facilitating the creation of high-quality and varied musical compositions from
provided text prompts. However, input text prompts may not precisely capture
user requirements, particularly when the objective is to generate music that
embodies a specific concept derived from a designated reference collection. In
this paper, we propose a novel method for customized text-to-music generation,
which can capture the concept from a two-minute reference music and generate a
new piece of music conforming to the concept. We achieve this by fine-tuning a
pretrained text-to-music model using the reference music. However, directly
fine-tuning all parameters leads to overfitting issues. To address this
problem, we propose a Pivotal Parameters Tuning method that enables the model
to assimilate the new concept while preserving its original generative
capabilities. Additionally, we identify a potential concept conflict when
introducing multiple concepts into the pretrained model. We present a concept
enhancement strategy to distinguish multiple concepts, enabling the fine-tuned
model to generate music incorporating either individual or multiple concepts
simultaneously. Since we are the first to work on the customized music
generation task, we also introduce a new dataset and evaluation protocol for
the new task. Our proposed Jen1-DreamStyler outperforms several baselines in
both qualitative and quantitative evaluations. Demos will be available at
https://www.jenmusic.ai/research#DreamStyler."
Stability of Data-Dependent Ridge-Regularization for Inverse Problems,https://arxiv.org/abs/2406.12289,2024-06-18,2024-06-19,0.0,0.0,"Theoretical guarantees for the robust solution of inverse problems have
important implications for applications. To achieve both guarantees and high
reconstruction quality, we propose to learn a pixel-based ridge regularizer
with a data-dependent and spatially-varying regularization strength. For this
architecture, we establish the existence of solutions to the associated
variational problem and the stability of its solution operator. Further, we
prove that the reconstruction forms a maximum-a-posteriori approach.
Simulations for biomedical imaging and material sciences demonstrate that the
approach yields high-quality reconstructions even if only a small
instance-specific training set is available."
An Investigation of Neuron Activation as a Unified Lens to Explain Chain-of-Thought Eliciting Arithmetic Reasoning of LLMs,https://arxiv.org/abs/2406.12288,2024-06-18,2024-06-19,0.0,0.0,"Large language models (LLMs) have shown strong arithmetic reasoning
capabilities when prompted with Chain-of-Thought (CoT) prompts. However, we
have only a limited understanding of how they are processed by LLMs. To
demystify it, prior work has primarily focused on ablating different components
in the CoT prompt and empirically observing their resulting LLM performance
change. Yet, the reason why these components are important to LLM reasoning is
not explored. To fill this gap, in this work, we investigate ``neuron
activation'' as a lens to provide a unified explanation to observations made by
prior work. Specifically, we look into neurons within the feed-forward layers
of LLMs that may have activated their arithmetic reasoning capabilities, using
Llama2 as an example. To facilitate this investigation, we also propose an
approach based on GPT-4 to automatically identify neurons that imply arithmetic
reasoning. Our analyses revealed that the activation of reasoning neurons in
the feed-forward layers of an LLM can explain the importance of various
components in a CoT prompt, and future research can extend it for a more
complete understanding."
VIRL - Volume-Informed Representation Learning towards Few-shot Manufacturability Estimation,https://arxiv.org/abs/2406.12286,2024-06-18,2024-06-19,0.0,0.0,"Designing for manufacturing poses significant challenges in part due to the
computation bottleneck of Computer-Aided Manufacturing (CAM) simulations.
Although deep learning as an alternative offers fast inference, its performance
is dependently bounded by the need for abundant training data. Representation
learning, particularly through pre-training, offers promise for few-shot
learning, aiding in manufacturability tasks where data can be limited. This
work introduces VIRL, a Volume-Informed Representation Learning approach to
pre-train a 3D geometric encoder. The pretrained model is evaluated across four
manufacturability indicators obtained from CAM simulations: subtractive
machining (SM) time, additive manufacturing (AM) time, residual von Mises
stress, and blade collisions during Laser Power Bed Fusion process. Across all
case studies, the model pre-trained by VIRL shows substantial enhancements on
demonstrating improved generalizability with limited data and superior
performance with larger datasets. Regarding deployment strategy, case-specific
phenomenon exists where finetuning VIRL-pretrained models adversely affects AM
tasks with limited data but benefits SM time prediction. Moreover, the efficacy
of Low-rank adaptation (LoRA), which balances between probing and finetuning,
is explored. LoRA shows stable performance akin to probing with limited data,
while achieving a higher upper bound than probing as data size increases,
without the computational costs of finetuning. Furthermore, static
normalization of manufacturing indicators consistently performs well across
tasks, while dynamic normalization enhances performance when a reliable task
dependent input is available."
DASSF - Dynamic-Attention Scale-Sequence Fusion for Aerial Object Detection,https://arxiv.org/abs/2406.12285,2024-06-18,2024-06-19,0.0,0.0,"The detection of small objects in aerial images is a fundamental task in the
field of computer vision. Moving objects in aerial photography have problems
such as different shapes and sizes, dense overlap, occlusion by the background,
and object blur, however, the original YOLO algorithm has low overall detection
accuracy due to its weak ability to perceive targets of different scales. In
order to improve the detection accuracy of densely overlapping small targets
and fuzzy targets, this paper proposes a dynamic-attention scale-sequence
fusion algorithm (DASSF) for small target detection in aerial images. First, we
propose a dynamic scale sequence feature fusion (DSSFF) module that improves
the up-sampling mechanism and reduces computational load. Secondly, a x-small
object detection head is specially added to enhance the detection capability of
small targets. Finally, in order to improve the expressive ability of targets
of different types and sizes, we use the dynamic head (DyHead). The model we
proposed solves the problem of small target detection in aerial images and can
be applied to multiple different versions of the YOLO algorithm, which is
universal. Experimental results show that when the DASSF method is applied to
YOLOv8, compared to YOLOv8n, on the VisDrone-2019 and DIOR datasets, the model
shows an increase of 9.2% and 2.4% in the mean average precision (mAP),
respectively, and outperforms the current mainstream methods."
Demystifying the Recency Heuristic in Temporal-Difference Learning,https://arxiv.org/abs/2406.12284,2024-06-18,2024-06-19,0.0,0.0,"The recency heuristic in reinforcement learning is the assumption that
stimuli that occurred closer in time to an acquired reward should be more
heavily reinforced. The recency heuristic is one of the key assumptions made by
TD($\lambda$), which reinforces recent experiences according to an
exponentially decaying weighting. In fact, all other widely used return
estimators for TD learning, such as $n$-step returns, satisfy a weaker (i.e.,
non-monotonic) recency heuristic. Why is the recency heuristic effective for
temporal credit assignment? What happens when credit is assigned in a way that
violates this heuristic? In this paper, we analyze the specific mathematical
implications of adopting the recency heuristic in TD learning. We prove that
any return estimator satisfying this heuristic: 1) is guaranteed to converge to
the correct value function, 2) has a relatively fast contraction rate, and 3)
has a long window of effective credit assignment, yet bounded worst-case
variance. We also give a counterexample where on-policy, tabular TD methods
violating the recency heuristic diverge. Our results offer some of the first
theoretical evidence that credit assignment based on the recency heuristic
facilitates learning."
SAGDFN - A Scalable Adaptive Graph Diffusion Forecasting Network for Multivariate Time Series Forecasting,https://arxiv.org/abs/2406.12282,2024-06-18,2024-06-19,0.0,0.0,"Time series forecasting is essential for our daily activities and precise
modeling of the complex correlations and shared patterns among multiple time
series is essential for improving forecasting performance. Spatial-Temporal
Graph Neural Networks (STGNNs) are widely used in multivariate time series
forecasting tasks and have achieved promising performance on multiple
real-world datasets for their ability to model the underlying complex spatial
and temporal dependencies. However, existing studies have mainly focused on
datasets comprising only a few hundred sensors due to the heavy computational
cost and memory cost of spatial-temporal GNNs. When applied to larger datasets,
these methods fail to capture the underlying complex spatial dependencies and
exhibit limited scalability and performance. To this end, we present a Scalable
Adaptive Graph Diffusion Forecasting Network (SAGDFN) to capture complex
spatial-temporal correlation for large-scale multivariate time series and
thereby, leading to exceptional performance in multivariate time series
forecasting tasks. The proposed SAGDFN is scalable to datasets of thousands of
nodes without the need of prior knowledge of spatial correlation. Extensive
experiments demonstrate that SAGDFN achieves comparable performance with
state-of-the-art baselines on one real-world dataset of 207 nodes and
outperforms all state-of-the-art baselines by a significant margin on three
real-world datasets of 2000 nodes."
What Matters in Learning Facts in Language Models? Multifaceted Knowledge Probing with Diverse Multi-Prompt Datasets,https://arxiv.org/abs/2406.12277,2024-06-18,2024-06-19,0.0,0.0,"Large language models (LLMs) face issues in handling factual knowledge,
making it vital to evaluate their true ability to understand facts. In this
study, we introduce knowledge probing frameworks, BELIEF(-ICL), to evaluate the
knowledge understanding ability of not only encoder-based PLMs but also
decoder-based PLMs from diverse perspectives. BELIEFs utilize a multi-prompt
dataset to evaluate PLM's accuracy, consistency, and reliability in factual
knowledge understanding. To provide a more reliable evaluation with BELIEFs, we
semi-automatically create MyriadLAMA, which has more diverse prompts than
existing datasets. We validate the effectiveness of BELIEFs in correctly and
comprehensively evaluating PLM's factual understanding ability through
extensive evaluations. We further investigate key factors in learning facts in
LLMs, and reveal the limitation of the prompt-based knowledge probing. The
dataset is anonymously publicized."
CodeNav - Beyond tool-use to using real-world codebases with LLM agents,https://arxiv.org/abs/2406.12276,2024-06-18,2024-06-19,0.0,0.0,"We present CodeNav, an LLM agent that navigates and leverages previously
unseen code repositories to solve user queries. In contrast to tool-use LLM
agents that require ``registration'' of all relevant tools via manual
descriptions within the LLM context, CodeNav automatically indexes and searches
over code blocks in the target codebase, finds relevant code snippets, imports
them, and uses them to iteratively generate a solution with execution feedback.
To highlight the core-capabilities of CodeNav, we first showcase three case
studies where we use CodeNav for solving complex user queries using three
diverse codebases. Next, on three benchmarks, we quantitatively compare the
effectiveness of code-use (which only has access to the target codebase) to
tool-use (which has privileged access to all tool names and descriptions).
Finally, we study the effect of varying kinds of tool and library descriptions
on code-use performance, as well as investigate the advantage of the agent
seeing source code as opposed to natural descriptions of code. All code will be
made open source under a permissive license."
SafeInfer - Context Adaptive Decoding Time Safety Alignment for Large Language Models,https://arxiv.org/abs/2406.12274,2024-06-18,2024-06-19,0.0,0.0,"Safety-aligned language models often exhibit fragile and imbalanced safety
mechanisms, increasing the likelihood of generating unsafe content. In
addition, incorporating new knowledge through editing techniques to language
models can further compromise safety. To address these issues, we propose
SafeInfer, a context-adaptive, decoding-time safety alignment strategy for
generating safe responses to user queries. SafeInfer comprises two phases: the
safety amplification phase, which employs safe demonstration examples to adjust
the model's hidden states and increase the likelihood of safer outputs, and the
safety-guided decoding phase, which influences token selection based on
safety-optimized distributions, ensuring the generated content complies with
ethical guidelines. Further, we present HarmEval, a novel benchmark for
extensive safety evaluations, designed to address potential misuse scenarios in
accordance with the policies of leading AI tech giants."
Slot State Space Models,https://arxiv.org/abs/2406.12272,2024-06-18,2024-06-19,0.0,0.0,"Recent State Space Models (SSMs) such as S4, S5, and Mamba have shown
remarkable computational benefits in long-range temporal dependency modeling.
However, in many sequence modeling problems, the underlying process is
inherently modular and it is of interest to have inductive biases that mimic
this modular structure. In this paper, we introduce SlotSSMs, a novel framework
for incorporating independent mechanisms into SSMs to preserve or encourage
separation of information. Unlike conventional SSMs that maintain a monolithic
state vector, SlotSSMs maintains the state as a collection of multiple vectors
called slots. Crucially, the state transitions are performed independently per
slot with sparse interactions across slots implemented via the bottleneck of
self-attention. In experiments, we evaluate our model in object-centric video
understanding, 3D visual reasoning, and video prediction tasks, which involve
modeling multiple objects and their long-range temporal dependencies. We find
that our proposed design offers substantial performance gains over existing
sequence modeling methods. Project page is available at
https://slotssms.github.io/"
Unveiling Implicit Table Knowledge with Question-Then-Pinpoint Reasoner for Insightful Table Summarization,https://arxiv.org/abs/2406.12269,2024-06-18,2024-06-19,0.0,0.0,"Implicit knowledge hidden within the explicit table cells, such as data
insights, is the key to generating a high-quality table summary. However,
unveiling such implicit knowledge is a non-trivial task. Due to the complex
nature of structured tables, it is challenging even for large language models
(LLMs) to mine the implicit knowledge in an insightful and faithful manner. To
address this challenge, we propose a novel table reasoning framework
Question-then-Pinpoint. Our work focuses on building a plug-and-play table
reasoner that can self-question the insightful knowledge and answer it by
faithfully pinpointing evidence on the table to provide explainable guidance
for the summarizer. To train a reliable reasoner, we collect table knowledge by
guiding a teacher LLM to follow the coarse-to-fine reasoning paths and refine
it through two quality enhancement strategies to selectively distill the
high-quality knowledge to the reasoner. Extensive experiments on two table
summarization datasets, including our newly proposed InsTaSumm, validate the
general effectiveness of our framework."
Towards a Client-Centered Assessment of LLM Therapists by Client Simulation,https://arxiv.org/abs/2406.12266,2024-06-18,2024-06-19,0.0,0.0,"Although there is a growing belief that LLMs can be used as therapists,
exploring LLMs' capabilities and inefficacy, particularly from the client's
perspective, is limited. This work focuses on a client-centered assessment of
LLM therapists with the involvement of simulated clients, a standard approach
in clinical medical education. However, there are two challenges when applying
the approach to assess LLM therapists at scale. Ethically, asking humans to
frequently mimic clients and exposing them to potentially harmful LLM outputs
can be risky and unsafe. Technically, it can be difficult to consistently
compare the performances of different LLM therapists interacting with the same
client. To this end, we adopt LLMs to simulate clients and propose ClientCAST,
a client-centered approach to assessing LLM therapists by client simulation.
Specifically, the simulated client is utilized to interact with LLM therapists
and complete questionnaires related to the interaction. Based on the
questionnaire results, we assess LLM therapists from three client-centered
aspects: session outcome, therapeutic alliance, and self-reported feelings. We
conduct experiments to examine the reliability of ClientCAST and use it to
evaluate LLMs therapists implemented by Claude-3, GPT-3.5, LLaMA3-70B, and
Mixtral 8*7B. Codes are released at https://github.com/wangjs9/ClientCAST."
Projection Methods for Operator Learning and Universal Approximation,https://arxiv.org/abs/2406.12264,2024-06-18,2024-06-19,0.0,0.0,"We obtain a new universal approximation theorem for continuous operators on
arbitrary Banach spaces using the Leray-Schauder mapping. Moreover, we
introduce and study a method for operator learning in Banach spaces $L^p$ of
functions with multiple variables, based on orthogonal projections on
polynomial bases. We derive a universal approximation result for operators
where we learn a linear projection and a finite dimensional mapping under some
additional assumptions. For the case of $p=2$, we give some sufficient
conditions for the approximation results to hold. This article serves as the
theoretical framework for a deep learning methodology whose implementation will
be provided in subsequent work."
Defending Against Social Engineering Attacks in the Age of LLMs,https://arxiv.org/abs/2406.12263,2024-06-18,2024-06-19,0.0,0.0,"The proliferation of Large Language Models (LLMs) poses challenges in
detecting and mitigating digital deception, as these models can emulate human
conversational patterns and facilitate chat-based social engineering (CSE)
attacks. This study investigates the dual capabilities of LLMs as both
facilitators and defenders against CSE threats. We develop a novel dataset,
SEConvo, simulating CSE scenarios in academic and recruitment contexts, and
designed to examine how LLMs can be exploited in these situations. Our findings
reveal that, while off-the-shelf LLMs generate high-quality CSE content, their
detection capabilities are suboptimal, leading to increased operational costs
for defense. In response, we propose ConvoSentinel, a modular defense pipeline
that improves detection at both the message and the conversation levels,
offering enhanced adaptability and cost-effectiveness. The retrieval-augmented
module in ConvoSentinel identifies malicious intent by comparing messages to a
database of similar conversations, enhancing CSE detection at all stages. Our
study highlights the need for advanced strategies to leverage LLMs in
cybersecurity."
Investigating Data Usage for Inductive Conformal Predictors,https://arxiv.org/abs/2406.12262,2024-06-18,2024-06-19,0.0,0.0,"Inductive conformal predictors (ICPs) are algorithms that are able to
generate prediction sets, instead of point predictions, which are valid at a
user-defined confidence level, only assuming exchangeability. These algorithms
are useful for reliable machine learning and are increasing in popularity. The
ICP development process involves dividing development data into three parts:
training, calibration and test. With access to limited or expensive development
data, it is an open question regarding the most efficient way to divide the
data. This study provides several experiments to explore this question and
consider the case for allowing overlap of examples between training and
calibration sets. Conclusions are drawn that will be of value to academics and
practitioners planning to use ICPs."
Self-Supervised Time-Series Anomaly Detection Using Learnable Data Augmentation,https://arxiv.org/abs/2406.12260,2024-06-18,2024-06-19,0.0,0.0,"Continuous efforts are being made to advance anomaly detection in various
manufacturing processes to increase the productivity and safety of industrial
sites. Deep learning replaced rule-based methods and recently emerged as a
promising method for anomaly detection in diverse industries. However, in the
real world, the scarcity of abnormal data and difficulties in obtaining labeled
data create limitations in the training of detection models. In this study, we
addressed these shortcomings by proposing a learnable data augmentation-based
time-series anomaly detection (LATAD) technique that is trained in a
self-supervised manner. LATAD extracts discriminative features from time-series
data through contrastive learning. At the same time, learnable data
augmentation produces challenging negative samples to enhance learning
efficiency. We measured anomaly scores of the proposed technique based on
latent feature similarities. As per the results, LATAD exhibited comparable or
improved performance to the state-of-the-art anomaly detection assessments on
several benchmark datasets and provided a gradient-based diagnosis technique to
help identify root causes."
Adversarial Attacks on Large Language Models in Medicine,https://arxiv.org/abs/2406.12259,2024-06-18,2024-06-19,0.0,0.0,"The integration of Large Language Models (LLMs) into healthcare applications
offers promising advancements in medical diagnostics, treatment
recommendations, and patient care. However, the susceptibility of LLMs to
adversarial attacks poses a significant threat, potentially leading to harmful
outcomes in delicate medical contexts. This study investigates the
vulnerability of LLMs to two types of adversarial attacks in three medical
tasks. Utilizing real-world patient data, we demonstrate that both open-source
and proprietary LLMs are susceptible to manipulation across multiple tasks.
This research further reveals that domain-specific tasks demand more
adversarial data in model fine-tuning than general domain tasks for effective
attack execution, especially for more capable models. We discover that while
integrating adversarial data does not markedly degrade overall model
performance on medical benchmarks, it does lead to noticeable shifts in
fine-tuned model weights, suggesting a potential pathway for detecting and
countering model attacks. This research highlights the urgent need for robust
security measures and the development of defensive mechanisms to safeguard LLMs
in medical applications, to ensure their safe and effective deployment in
healthcare settings."
CleanGen - Mitigating Backdoor Attacks for Generation Tasks in Large Language Models,https://arxiv.org/abs/2406.12257,2024-06-18,2024-06-19,0.0,0.0,"The remarkable performance of large language models (LLMs) in generation
tasks has enabled practitioners to leverage publicly available models to power
custom applications, such as chatbots and virtual assistants. However, the data
used to train or fine-tune these LLMs is often undisclosed, allowing an
attacker to compromise the data and inject backdoors into the models. In this
paper, we develop a novel inference time defense, named CleanGen, to mitigate
backdoor attacks for generation tasks in LLMs. CleanGenis a lightweight and
effective decoding strategy that is compatible with the state-of-the-art (SOTA)
LLMs. Our insight behind CleanGen is that compared to other LLMs, backdoored
LLMs assign significantly higher probabilities to tokens representing the
attacker-desired contents. These discrepancies in token probabilities enable
CleanGen to identify suspicious tokens favored by the attacker and replace them
with tokens generated by another LLM that is not compromised by the same
attacker, thereby avoiding generation of attacker-desired content. We evaluate
CleanGen against five SOTA backdoor attacks. Our results show that CleanGen
achieves lower attack success rates (ASR) compared to five SOTA baseline
defenses for all five backdoor attacks. Moreover, LLMs deploying CleanGen
maintain helpfulness in their responses when serving benign user queries with
minimal added computational overhead."
A Hopfieldian View-based Interpretation for Chain-of-Thought Reasoning,https://arxiv.org/abs/2406.12255,2024-06-18,2024-06-19,0.0,0.0,"Chain-of-Thought (CoT) holds a significant place in augmenting the reasoning
performance for large language models (LLMs). While some studies focus on
improving CoT accuracy through methods like retrieval enhancement, yet a
rigorous explanation for why CoT achieves such success remains unclear. In this
paper, we analyze CoT methods under two different settings by asking the
following questions: (1) For zero-shot CoT, why does prompting the model with
""let's think step by step"" significantly impact its outputs? (2) For few-shot
CoT, why does providing examples before questioning the model could
substantially improve its reasoning ability? To answer these questions, we
conduct a top-down explainable analysis from the Hopfieldian view and propose a
Read-and-Control approach for controlling the accuracy of CoT. Through
extensive experiments on seven datasets for three different tasks, we
demonstrate that our framework can decipher the inner workings of CoT, provide
reasoning error localization, and control to come up with the correct reasoning
path."
Language and Multimodal Models in Sports - A Survey of Datasets and Applications,https://arxiv.org/abs/2406.12252,2024-06-18,2024-06-19,0.0,0.0,"Recent integration of Natural Language Processing (NLP) and multimodal models
has advanced the field of sports analytics. This survey presents a
comprehensive review of the datasets and applications driving these innovations
post-2020. We overviewed and categorized datasets into three primary types:
language-based, multimodal, and convertible datasets. Language-based and
multimodal datasets are for tasks involving text or multimodality (e.g., text,
video, audio), respectively. Convertible datasets, initially single-modal
(video), can be enriched with additional annotations, such as explanations of
actions and video descriptions, to become multimodal, offering future potential
for richer and more diverse applications. Our study highlights the
contributions of these datasets to various applications, from improving fan
experiences to supporting tactical analysis and medical diagnostics. We also
discuss the challenges and future directions in dataset development,
emphasizing the need for diverse, high-quality data to support real-time
processing and personalized user experiences. This survey provides a
foundational resource for researchers and practitioners aiming to leverage NLP
and multimodal models in sports, offering insights into current trends and
future opportunities in the field."
Mitigate Negative Transfer with Similarity Heuristic Lifelong Prompt Tuning,https://arxiv.org/abs/2406.12251,2024-06-18,2024-06-19,0.0,0.0,"Lifelong prompt tuning has significantly advanced parameter-efficient
lifelong learning with its efficiency and minimal storage demands on various
tasks. Our empirical studies, however, highlights certain transferability
constraints in the current methodologies: a universal algorithm that guarantees
consistent positive transfer across all tasks is currently unattainable,
especially when dealing dissimilar tasks that may engender negative transfer.
Identifying the misalignment between algorithm selection and task specificity
as the primary cause of negative transfer, we present the Similarity Heuristic
Lifelong Prompt Tuning (SHLPT) framework. This innovative strategy partitions
tasks into two distinct subsets by harnessing a learnable similarity metric,
thereby facilitating fruitful transfer from tasks regardless of their
similarity or dissimilarity. Additionally, SHLPT incorporates a parameter pool
to combat catastrophic forgetting effectively. Our experiments shows that SHLPT
outperforms state-of-the-art techniques in lifelong learning benchmarks and
demonstrates robustness against negative transfer in diverse task sequences."
TroL - Traversal of Layers for Large Language and Vision Models,https://arxiv.org/abs/2406.12246,2024-06-18,2024-06-19,0.0,0.0,"Large language and vision models (LLVMs) have been driven by the
generalization power of large language models (LLMs) and the advent of visual
instruction tuning. Along with scaling them up directly, these models enable
LLVMs to showcase powerful vision language (VL) performances by covering
diverse tasks via natural language instructions. However, existing open-source
LLVMs that perform comparably to closed-source LLVMs such as GPT-4V are often
considered too large (e.g., 26B, 34B, and 110B parameters), having a larger
number of layers. These large models demand costly, high-end resources for both
training and inference. To address this issue, we present a new efficient LLVM
family with 1.8B, 3.8B, and 7B LLM model sizes, Traversal of Layers (TroL),
which enables the reuse of layers in a token-wise manner. This layer traversing
technique simulates the effect of looking back and retracing the answering
stream while increasing the number of forward propagation layers without
physically adding more layers. We demonstrate that TroL employs a simple layer
traversing approach yet efficiently outperforms the open-source LLVMs with
larger model sizes and rivals the performances of the closed-source LLVMs with
substantial sizes."
CherryRec - Enhancing News Recommendation Quality via LLM-driven Framework,https://arxiv.org/abs/2406.12243,2024-06-18,2024-06-19,0.0,0.0,"Large Language Models (LLMs) have achieved remarkable progress in language
understanding and generation. Custom LLMs leveraging textual features have been
applied to recommendation systems, demonstrating improvements across various
recommendation scenarios. However, most existing methods perform untrained
recommendation based on pre-trained knowledge (e.g., movie recommendation), and
the auto-regressive generation of LLMs leads to slow inference speeds, making
them less effective in real-time recommendations.To address this, we propose a
framework for news recommendation using LLMs, named \textit{CherryRec}, which
ensures the quality of recommendations while accelerating the recommendation
process. Specifically, we employ a Knowledge-aware News Rapid Selector to
retrieve candidate options based on the user's interaction history. The history
and retrieved items are then input as text into a fine-tuned LLM, the
Content-aware News Llm Evaluator, designed to enhance news recommendation
capabilities. Finally, the Value-aware News Scorer integrates the scores to
compute the CherryRec Score, which serves as the basis for the final
recommendation.We validate the effectiveness of the proposed framework by
comparing it with state-of-the-art baseline methods on benchmark datasets. Our
experimental results consistently show that CherryRec outperforms the baselines
in both recommendation performance and efficiency.The project resource can be
accessed at: \url{https://github.com/xxxxxx}"
GMP-AR - Granularity Message Passing and Adaptive Reconciliation for Temporal Hierarchy Forecasting,https://arxiv.org/abs/2406.12242,2024-06-18,2024-06-19,0.0,0.0,"Time series forecasts of different temporal granularity are widely used in
real-world applications, e.g., sales prediction in days and weeks for making
different inventory plans. However, these tasks are usually solved separately
without ensuring coherence, which is crucial for aligning downstream decisions.
Previous works mainly focus on ensuring coherence with some straightforward
methods, e.g., aggregation from the forecasts of fine granularity to the coarse
ones, and allocation from the coarse granularity to the fine ones. These
methods merely take the temporal hierarchical structure to maintain coherence
without improving the forecasting accuracy. In this paper, we propose a novel
granularity message-passing mechanism (GMP) that leverages temporal hierarchy
information to improve forecasting performance and also utilizes an adaptive
reconciliation (AR) strategy to maintain coherence without performance loss.
Furthermore, we introduce an optimization module to achieve task-based targets
while adhering to more real-world constraints. Experiments on real-world
datasets demonstrate that our framework (GMP-AR) achieves superior performances
on temporal hierarchical forecasting tasks compared to state-of-the-art
methods. In addition, our framework has been successfully applied to a
real-world task of payment traffic management in Alipay by integrating with the
task-based optimization module."
More Efficient Randomized Exploration for Reinforcement Learning via Approximate Sampling,https://arxiv.org/abs/2406.12241,2024-06-18,2024-06-19,0.0,0.0,"Thompson sampling (TS) is one of the most popular exploration techniques in
reinforcement learning (RL). However, most TS algorithms with theoretical
guarantees are difficult to implement and not generalizable to Deep RL. While
the emerging approximate sampling-based exploration schemes are promising, most
existing algorithms are specific to linear Markov Decision Processes (MDP) with
suboptimal regret bounds, or only use the most basic samplers such as Langevin
Monte Carlo. In this work, we propose an algorithmic framework that
incorporates different approximate sampling methods with the recently proposed
Feel-Good Thompson Sampling (FGTS) approach (Zhang, 2022; Dann et al., 2021),
which was previously known to be computationally intractable in general. When
applied to linear MDPs, our regret analysis yields the best known dependency of
regret on dimensionality, surpassing existing randomized algorithms.
Additionally, we provide explicit sampling complexity for each employed
sampler. Empirically, we show that in tasks where deep exploration is
necessary, our proposed algorithms that combine FGTS and approximate sampling
perform significantly better compared to other strong baselines. On several
challenging games from the Atari 57 suite, our algorithms achieve performance
that is either better than or on par with other strong baselines from the deep
RL literature."
PFID - Privacy First Inference Delegation Framework for LLMs,https://arxiv.org/abs/2406.12238,2024-06-18,2024-06-19,0.0,0.0,"This paper introduces a novel privacy-preservation framework named PFID for
LLMs that addresses critical privacy concerns by localizing user data through
model sharding and singular value decomposition. When users are interacting
with LLM systems, their prompts could be subject to being exposed to
eavesdroppers within or outside LLM system providers who are interested in
collecting users' input. In this work, we proposed a framework to camouflage
user input, so as to alleviate privacy issues. Our framework proposes to place
model shards on the client and the public server, we sent compressed hidden
states instead of prompts to and from servers. Clients have held back
information that can re-privatized the hidden states so that overall system
performance is comparable to traditional LLMs services. Our framework was
designed to be communication efficient, computation can be delegated to the
local client so that the server's computation burden can be lightened. We
conduct extensive experiments on machine translation tasks to verify our
framework's performance."
SyncVSR - Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization,https://arxiv.org/abs/2406.12233,2024-06-18,2024-06-19,0.0,0.0,"Visual Speech Recognition (VSR) stands at the intersection of computer vision
and speech recognition, aiming to interpret spoken content from visual cues. A
prominent challenge in VSR is the presence of homophenes-visually similar lip
gestures that represent different phonemes. Prior approaches have sought to
distinguish fine-grained visemes by aligning visual and auditory semantics, but
often fell short of full synchronization. To address this, we present SyncVSR,
an end-to-end learning framework that leverages quantized audio for frame-level
crossmodal supervision. By integrating a projection layer that synchronizes
visual representation with acoustic data, our encoder learns to generate
discrete audio tokens from a video sequence in a non-autoregressive manner.
SyncVSR shows versatility across tasks, languages, and modalities at the cost
of a forward pass. Our empirical evaluations show that it not only achieves
state-of-the-art results but also reduces data usage by up to ninefold."
MCSD - An Efficient Language Model with Diverse Fusion,https://arxiv.org/abs/2406.12230,2024-06-18,2024-06-19,0.0,0.0,"Transformers excel in Natural Language Processing (NLP) due to their prowess
in capturing long-term dependencies but suffer from exponential resource
consumption with increasing sequence lengths. To address these challenges, we
propose MCSD model, an efficient language model with linear scaling and fast
inference speed. MCSD model leverages diverse feature fusion, primarily through
the multi-channel slope and decay (MCSD) block, to robustly represent features.
This block comprises slope and decay sections that extract features across
diverse temporal receptive fields, facilitating capture of both local and
global information. In addition, MCSD block conducts element-wise fusion of
diverse features to further enhance the delicate feature extraction capability.
For inference, we formulate the inference process into a recurrent
representation, slashing space complexity to $O(1)$ and time complexity to
$O(N)$ respectively. Our experiments show that MCSD attains higher throughput
and lower GPU memory consumption compared to Transformers, while maintaining
comparable performance to larger-scale language learning models on benchmark
tests. These attributes position MCSD as a promising base for edge deployment
and embodied intelligence."
Spatially Resolved Gene Expression Prediction from Histology via Multi-view Graph Contrastive Learning with HSIC-bottleneck Regularization,https://arxiv.org/abs/2406.12229,2024-06-18,2024-06-19,0.0,0.0,"The rapid development of spatial transcriptomics(ST) enables the measurement
of gene expression at spatial resolution, making it possible to simultaneously
profile the gene expression, spatial locations of spots, and the matched
histopathological images. However, the cost for collecting ST data is much
higher than acquiring histopathological images, and thus several studies
attempt to predict the gene expression on ST by leveraging their corresponding
histopathological images. Most of the existing image-based gene prediction
models treat the prediction task on each spot of ST data independently, which
ignores the spatial dependency among spots. In addition, while the histology
images share phenotypic characteristics with the ST data, it is still challenge
to extract such common information to help align paired image and expression
representations. To address the above issues, we propose a Multi-view Graph
Contrastive Learning framework with HSIC-bottleneck Regularization(ST-GCHB)
aiming at learning shared representation to help impute the gene expression of
the queried imagingspots by considering their spatial dependency."
Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector,https://arxiv.org/abs/2406.12227,2024-06-18,2024-06-19,0.0,0.0,"Fine-tuning large language models (LLMs) can cause them to lose their general
capabilities. However, the intrinsic mechanisms behind such forgetting remain
unexplored. In this paper, we begin by examining this phenomenon by focusing on
knowledge understanding and instruction following, with the latter identified
as the main contributor to forgetting during fine-tuning. Consequently, we
propose the Instruction Vector (IV) framework to capture model representations
highly related to specific instruction-following capabilities, thereby making
it possible to understand model-intrinsic forgetting. Through the analysis of
IV dynamics pre and post-training, we suggest that fine-tuning mostly adds
specialized reasoning patterns instead of erasing previous skills, which may
appear as forgetting. Building on this insight, we develop IV-guided training,
which aims to preserve original computation graph, thereby mitigating
catastrophic forgetting. Empirical tests on three benchmarks confirm the
efficacy of this new approach, supporting the relationship between IVs and
forgetting. Our code will be made available soon."
ToxiCloakCN - Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations,https://arxiv.org/abs/2406.12223,2024-06-18,2024-06-19,0.0,0.0,"Detecting hate speech and offensive language is essential for maintaining a
safe and respectful digital environment. This study examines the limitations of
state-of-the-art large language models (LLMs) in identifying offensive content
within systematically perturbed data, with a focus on Chinese, a language
particularly susceptible to such perturbations. We introduce
\textsf{ToxiCloakCN}, an enhanced dataset derived from ToxiCN, augmented with
homophonic substitutions and emoji transformations, to test the robustness of
LLMs against these cloaking perturbations. Our findings reveal that existing
models significantly underperform in detecting offensive content when these
perturbations are applied. We provide an in-depth analysis of how different
types of offensive content are affected by these perturbations and explore the
alignment between human and model explanations of offensiveness. Our work
highlights the urgent need for more advanced techniques in offensive language
detection to combat the evolving tactics used to evade detection mechanisms."
BadSampler - Harnessing the Power of Catastrophic Forgetting to Poison Byzantine-robust Federated Learning,https://arxiv.org/abs/2406.12222,2024-06-18,2024-06-19,0.0,0.0,"Federated Learning (FL) is susceptible to poisoning attacks, wherein
compromised clients manipulate the global model by modifying local datasets or
sending manipulated model updates. Experienced defenders can readily detect and
mitigate the poisoning effects of malicious behaviors using Byzantine-robust
aggregation rules. However, the exploration of poisoning attacks in scenarios
where such behaviors are absent remains largely unexplored for Byzantine-robust
FL. This paper addresses the challenging problem of poisoning Byzantine-robust
FL by introducing catastrophic forgetting. To fill this gap, we first formally
define generalization error and establish its connection to catastrophic
forgetting, paving the way for the development of a clean-label data poisoning
attack named BadSampler. This attack leverages only clean-label data (i.e.,
without poisoned data) to poison Byzantine-robust FL and requires the adversary
to selectively sample training data with high loss to feed model training and
maximize the model's generalization error. We formulate the attack as an
optimization problem and present two elegant adversarial sampling strategies,
Top-$\kappa$ sampling, and meta-sampling, to approximately solve it.
Additionally, our formal error upper bound and time complexity analysis
demonstrate that our design can preserve attack utility with high efficiency.
Extensive evaluations on two real-world datasets illustrate the effectiveness
and performance of our proposed attacks."
On-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation,https://arxiv.org/abs/2406.12221,2024-06-18,2024-06-19,0.0,0.0,"Hallucination occurs when large language models (LLMs) exhibit behavior that
deviates from the boundaries of their knowledge during the response generation
process. Previous learning-based methods focus on detecting knowledge
boundaries and finetuning models with instance-level feedback, but they suffer
from inaccurate signals due to off-policy data sampling and coarse-grained
feedback. In this paper, we introduce \textit{\b{R}einforcement \b{L}earning
\b{f}or \b{H}allucination} (RLFH), a fine-grained feedback-based online
reinforcement learning method for hallucination mitigation. Unlike previous
learning-based methods, RLFH enables LLMs to explore the boundaries of their
internal knowledge and provide on-policy, fine-grained feedback on these
explorations. To construct fine-grained feedback for learning reliable
generation behavior, RLFH decomposes the outcomes of large models into atomic
facts, provides statement-level evaluation signals, and traces back the signals
to the tokens of the original responses. Finally, RLFH adopts the online
reinforcement algorithm with these token-level rewards to adjust model behavior
for hallucination mitigation. For effective on-policy optimization, RLFH also
introduces an LLM-based fact assessment framework to verify the truthfulness
and helpfulness of atomic facts without human intervention. Experiments on
HotpotQA, SQuADv2, and Biography benchmarks demonstrate that RLFH can balance
their usage of internal knowledge during the generation process to eliminate
the hallucination behavior of LLMs."
"Hierarchical Associative Memory, Parallelized MLP-Mixer, and Symmetry Breaking",https://arxiv.org/abs/2406.12220,2024-06-18,2024-06-19,0.0,0.0,"Transformers have established themselves as the leading neural network model
in natural language processing and are increasingly foundational in various
domains. In vision, the MLP-Mixer model has demonstrated competitive
performance, suggesting that attention mechanisms might not be indispensable.
Inspired by this, recent research has explored replacing attention modules with
other mechanisms, including those described by MetaFormers. However, the
theoretical framework for these models remains underdeveloped. This paper
proposes a novel perspective by integrating Krotov's hierarchical associative
memory with MetaFormers, enabling a comprehensive representation of the entire
Transformer block, encompassing token-/channel-mixing modules, layer
normalization, and skip connections, as a single Hopfield network. This
approach yields a parallelized MLP-Mixer derived from a three-layer Hopfield
network, which naturally incorporates symmetric token-/channel-mixing modules
and layer normalization. Empirical studies reveal that symmetric interaction
matrices in the model hinder performance in image recognition tasks.
Introducing symmetry-breaking effects transitions the performance of the
symmetric parallelized MLP-Mixer to that of the vanilla MLP-Mixer. This
indicates that during standard training, weight matrices of the vanilla
MLP-Mixer spontaneously acquire a symmetry-breaking configuration, enhancing
their effectiveness. These findings offer insights into the intrinsic
properties of Transformers and MLP-Mixers and their theoretical underpinnings,
providing a robust framework for future model design and optimization."
Is persona enough for personality? Using ChatGPT to reconstruct an agent's latent personality from simple descriptions,https://arxiv.org/abs/2406.12216,2024-06-18,2024-06-19,1.0,0.0,"Personality, a fundamental aspect of human cognition, contains a range of
traits that influence behaviors, thoughts, and emotions. This paper explores
the capabilities of large language models (LLMs) in reconstructing these
complex cognitive attributes based only on simple descriptions containing
socio-demographic and personality type information. Utilizing the HEXACO
personality framework, our study examines the consistency of LLMs in recovering
and predicting underlying (latent) personality dimensions from simple
descriptions. Our experiments reveal a significant degree of consistency in
personality reconstruction, although some inconsistencies and biases, such as a
tendency to default to positive traits in the absence of explicit information,
are also observed. Additionally, socio-demographic factors like age and number
of children were found to influence the reconstructed personality dimensions.
These findings have implications for building sophisticated agent-based
simulacra using LLMs and highlight the need for further research on robust
personality generation in LLMs."
LLM-Oracle Machines,https://arxiv.org/abs/2406.12213,2024-06-18,2024-06-19,0.0,0.0,"Contemporary AI applications leverage large language models (LLMs) to harness
their knowledge and reasoning abilities for natural language processing tasks.
This approach shares similarities with the concept of oracle Turing machines
(OTMs). To capture the broader potential of these computations, including those
not yet realized, we propose an extension to OTMs: the LLM-oracle machine
(LLM-OM), by employing a cluster of LLMs as the oracle. Each LLM acts as a
black box, capable of answering queries within its expertise, albeit with a
delay. We introduce four variants of the LLM-OM: basic, augmented,
fault-avoidance, and $\epsilon$-fault. The first two are commonly observed in
existing AI applications. The latter two are specifically designed to address
the challenges of LLM hallucinations, biases, and inconsistencies, aiming to
ensure reliable outcomes."
Interface Design for Self-Supervised Speech Models,https://arxiv.org/abs/2406.12209,2024-06-18,2024-06-19,0.0,0.0,"Self-supervised speech (SSL) models have recently become widely adopted for
many downstream speech processing tasks. The general usage pattern is to employ
SSL models as feature extractors, and then train a downstream prediction head
to solve a specific task. However, different layers of SSL models have been
shown to capture different types of information, and the methods of combining
them are not well studied. To this end, we extend the general framework for SSL
model utilization by proposing the interface that connects the upstream and
downstream. Under this view, the dominant technique of combining features via a
layerwise weighted sum can be regarded as a specific interface. We propose
several alternative interface designs and demonstrate that the weighted sum
interface is suboptimal for many tasks. In particular, we show that a
convolutional interface whose depth scales logarithmically with the depth of
the upstream model consistently outperforms many other interface designs."
Knowledge Fusion By Evolving Weights of Language Models,https://arxiv.org/abs/2406.12208,2024-06-18,2024-06-19,0.0,0.0,"Fine-tuning pre-trained language models, particularly large language models,
demands extensive computing resources and can result in varying performance
outcomes across different domains and datasets. This paper examines the
approach of integrating multiple models from diverse training scenarios into a
unified model. This unified model excels across various data domains and
exhibits the ability to generalize well on out-of-domain data. We propose a
knowledge fusion method named Evolver, inspired by evolutionary algorithms,
which does not need further training or additional training data. Specifically,
our method involves aggregating the weights of different language models into a
population and subsequently generating offspring models through mutation and
crossover operations. These offspring models are then evaluated against their
parents, allowing for the preservation of those models that show enhanced
performance on development datasets. Importantly, our model evolving strategy
can be seamlessly integrated with existing model merging frameworks, offering a
versatile tool for model enhancement. Experimental results on mainstream
language models (i.e., encoder-only, decoder-only, encoder-decoder) reveal that
Evolver outperforms previous state-of-the-art models by large margins. The code
is publicly available at {https://github.com/duguodong7/model-evolution}."
Order-Optimal Instance-Dependent Bounds for Offline Reinforcement Learning with Preference Feedback,https://arxiv.org/abs/2406.12205,2024-06-18,2024-06-19,0.0,0.0,"We consider offline reinforcement learning (RL) with preference feedback in
which the implicit reward is a linear function of an unknown parameter. Given
an offline dataset, our objective consists in ascertaining the optimal action
for each state, with the ultimate goal of minimizing the {\em simple regret}.
We propose an algorithm, \underline{RL} with \underline{L}ocally
\underline{O}ptimal \underline{W}eights or {\sc RL-LOW}, which yields a simple
regret of $\exp ( - \Omega(n/H) )$ where $n$ is the number of data samples and
$H$ denotes an instance-dependent hardness quantity that depends explicitly on
the suboptimality gap of each action. Furthermore, we derive a
first-of-its-kind instance-dependent lower bound in offline RL with preference
feedback. Interestingly, we observe that the lower and upper bounds on the
simple regret match order-wise in the exponent, demonstrating order-wise
optimality of {\sc RL-LOW}. In view of privacy considerations in practical
applications, we also extend {\sc RL-LOW} to the setting of
$(\varepsilon,\delta)$-differential privacy and show, somewhat surprisingly,
that the hardness parameter $H$ is unchanged in the asymptotic regime as $n$
tends to infinity; this underscores the inherent efficiency of {\sc RL-LOW} in
terms of preserving the privacy of the observed rewards. Given our focus on
establishing instance-dependent bounds, our work stands in stark contrast to
previous works that focus on establishing worst-case regrets for offline RL
with preference feedback."
An Optimal Transport Approach for Network Regression,https://arxiv.org/abs/2406.12204,2024-06-18,2024-06-19,0.0,0.0,"We study the problem of network regression, where one is interested in how
the topology of a network changes as a function of Euclidean covariates. We
build upon recent developments in generalized regression models on metric
spaces based on Fr\'echet means and propose a network regression method using
the Wasserstein metric. We show that when representing graphs as multivariate
Gaussian distributions, the network regression problem requires the computation
of a Riemannian center of mass (i.e., Fr\'echet means). Fr\'echet means with
non-negative weights translates into a barycenter problem and can be
efficiently computed using fixed point iterations. Although the convergence
guarantees of fixed-point iterations for the computation of Wasserstein affine
averages remain an open problem, we provide evidence of convergence in a large
number of synthetic and real-data scenarios. Extensive numerical results show
that the proposed approach improves existing procedures by accurately
accounting for graph size, topology, and sparsity in synthetic experiments.
Additionally, real-world experiments using the proposed approach result in
higher Coefficient of Determination ($R^{2}$) values and lower mean squared
prediction error (MSPE), cementing improved prediction capabilities in
practice."
InterIntent - Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context,https://arxiv.org/abs/2406.12203,2024-06-18,2024-06-19,0.0,0.0,"Large language models (LLMs) have demonstrated the potential to mimic human
social intelligence. However, most studies focus on simplistic and static
self-report or performance-based tests, which limits the depth and validity of
the analysis. In this paper, we developed a novel framework, InterIntent, to
assess LLMs' social intelligence by mapping their ability to understand and
manage intentions in a game setting. We focus on four dimensions of social
intelligence: situational awareness, self-regulation, self-awareness, and
theory of mind. Each dimension is linked to a specific game task: intention
selection, intention following, intention summarization, and intention
guessing. Our findings indicate that while LLMs exhibit high proficiency in
selecting intentions, achieving an accuracy of 88\%, their ability to infer the
intentions of others is significantly weaker, trailing human performance by
20\%. Additionally, game performance correlates with intention understanding,
highlighting the importance of the four components towards success in this
game. These findings underline the crucial role of intention understanding in
evaluating LLMs' social intelligence and highlight the potential of using
social deduction games as a complex testbed to enhance LLM evaluation.
InterIntent contributes a structured approach to bridging the evaluation gap in
social intelligence within multiplayer games."
SFedCA - Credit Assignment-Based Active Client Selection Strategy for Spiking Federated Learning,https://arxiv.org/abs/2406.12200,2024-06-18,2024-06-19,0.0,0.0,"Spiking federated learning is an emerging distributed learning paradigm that
allows resource-constrained devices to train collaboratively at low power
consumption without exchanging local data. It takes advantage of both the
privacy computation property in federated learning (FL) and the energy
efficiency in spiking neural networks (SNN). Thus, it is highly promising to
revolutionize the efficient processing of multimedia data. However, existing
spiking federated learning methods employ a random selection approach for
client aggregation, assuming unbiased client participation. This neglect of
statistical heterogeneity affects the convergence and accuracy of the global
model significantly. In our work, we propose a credit assignment-based active
client selection strategy, the SFedCA, to judiciously aggregate clients that
contribute to the global sample distribution balance. Specifically, the client
credits are assigned by the firing intensity state before and after local model
training, which reflects the local data distribution difference from the global
model. Comprehensive experiments are conducted on various non-identical and
independent distribution (non-IID) scenarios. The experimental results
demonstrate that the SFedCA outperforms the existing state-of-the-art spiking
federated learning methods, and requires fewer communication rounds."
Time Series Modeling for Heart Rate Prediction - From ARIMA to Transformers,https://arxiv.org/abs/2406.12199,2024-06-18,2024-06-19,1.0,0.0,"Cardiovascular disease (CVD) is a leading cause of death globally,
necessitating precise forecasting models for monitoring vital signs like heart
rate, blood pressure, and ECG. Traditional models, such as ARIMA and Prophet,
are limited by their need for manual parameter tuning and challenges in
handling noisy, sparse, and highly variable medical data. This study
investigates advanced deep learning models, including LSTM, and
transformer-based architectures, for predicting heart rate time series from the
MIT-BIH Database. Results demonstrate that deep learning models, particularly
PatchTST, significantly outperform traditional models across multiple metrics,
capturing complex patterns and dependencies more effectively. This research
underscores the potential of deep learning to enhance patient monitoring and
CVD management, suggesting substantial clinical benefits. Future work should
extend these findings to larger, more diverse datasets and real-world clinical
applications to further validate and optimize model performance."
Debate as Optimization - Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction,https://arxiv.org/abs/2406.12197,2024-06-18,2024-06-19,0.0,0.0,"We propose a multi-agent debate as optimization (DAO) system for event
extraction, where the primary objective is to iteratively refine the large
language models (LLMs) outputs through debating without parameter tuning. In
DAO, we introduce two novel modules: the Diverse-RAG (DRAG) module and the
Adaptive Conformal Prediction (AdaCP) module. DRAG systematically retrieves
supporting information that best fits the debate discussion, while AdaCP
enhances the accuracy and reliability of event extraction by effectively
rejecting less promising answers. Experimental results demonstrate a
significant reduction in the performance gap between supervised approaches and
tuning-free LLM-based methods by 18.1% and 17.8% on ACE05 and 17.9% and 15.2%
on CASIE for event detection and argument extraction respectively."
Quantum Compiling with Reinforcement Learning on a Superconducting Processor,https://arxiv.org/abs/2406.12195,2024-06-18,2024-06-19,0.0,0.0,"To effectively implement quantum algorithms on noisy intermediate-scale
quantum (NISQ) processors is a central task in modern quantum technology. NISQ
processors feature tens to a few hundreds of noisy qubits with limited
coherence times and gate operations with errors, so NISQ algorithms naturally
require employing circuits of short lengths via quantum compilation. Here, we
develop a reinforcement learning (RL)-based quantum compiler for a
superconducting processor and demonstrate its capability of discovering novel
and hardware-amenable circuits with short lengths. We show that for the
three-qubit quantum Fourier transformation, a compiled circuit using only seven
CZ gates with unity circuit fidelity can be achieved. The compiler is also able
to find optimal circuits under device topological constraints, with lengths
considerably shorter than those by the conventional method. Our study
exemplifies the codesign of the software with hardware for efficient quantum
compilation, offering valuable insights for the advancement of RL-based
compilers."
Adaptive Collaborative Correlation Learning-based Semi-Supervised Multi-Label Feature Selection,https://arxiv.org/abs/2406.12193,2024-06-18,2024-06-19,0.0,0.0,"Semi-supervised multi-label feature selection has recently been developed to
solve the curse of dimensionality problem in high-dimensional multi-label data
with certain samples missing labels. Although many efforts have been made, most
existing methods use a predefined graph approach to capture the sample
similarity or the label correlation. In this manner, the presence of noise and
outliers within the original feature space can undermine the reliability of the
resulting sample similarity graph. It also fails to precisely depict the label
correlation due to the existence of unknown labels. Besides, these methods only
consider the discriminative power of selected features, while neglecting their
redundancy. In this paper, we propose an Adaptive Collaborative Correlation
lEarning-based Semi-Supervised Multi-label Feature Selection (Access-MFS)
method to address these issues. Specifically, a generalized regression model
equipped with an extended uncorrelated constraint is introduced to select
discriminative yet irrelevant features and maintain consistency between
predicted and ground-truth labels in labeled data, simultaneously. Then, the
instance correlation and label correlation are integrated into the proposed
regression model to adaptively learn both the sample similarity graph and the
label similarity graph, which mutually enhance feature selection performance.
Extensive experimental results demonstrate the superiority of the proposed
Access-MFS over other state-of-the-art methods."
Aqulia-Med LLM - Pioneering Full-Process Open-Source Medical Language Models,https://arxiv.org/abs/2406.12182,2024-06-18,2024-06-19,0.0,0.0,"Recently, both closed-source LLMs and open-source communities have made
significant strides, outperforming humans in various general domains. However,
their performance in specific professional fields such as medicine, especially
within the open-source community, remains suboptimal due to the complexity of
medical knowledge. We propose Aquila-Med, a bilingual medical LLM based on
Aquila, addressing these challenges through continue pre-training, supervised
fine-tuning (SFT), and reinforcement learning from human feedback (RLHF). We
construct a large-scale Chinese and English medical dataset for continue
pre-training and a high-quality SFT dataset, covering extensive medical
specialties. Additionally, we develop a high-quality Direct Preference
Optimization (DPO) dataset for further alignment. Aquila-Med achieves notable
results across single-turn, multi-turn dialogues, and medical multiple-choice
questions, demonstrating the effectiveness of our approach. We open-source the
datasets and the entire training process, contributing valuable resources to
the research community. Our models and datasets will released at
https://huggingface.co/BAAI/AquilaMed-RL."
Navigating the Labyrinth - Evaluating and Enhancing LLMs' Ability to Reason About Search Problems,https://arxiv.org/abs/2406.12172,2024-06-18,2024-06-19,0.0,0.0,"Recently, Large Language Models (LLMs) attained impressive performance in
math and reasoning benchmarks. However, they still often struggle with logic
problems and puzzles that are relatively easy for humans. To further
investigate this, we introduce a new benchmark, SearchBench, containing 11
unique search problem types, each equipped with automated pipelines to generate
an arbitrary number of instances and analyze the feasibility, correctness, and
optimality of LLM-generated solutions. We show that even the most advanced LLMs
fail to solve these problems end-to-end in text, e.g. GPT4 solves only 1.4%.
SearchBench problems require considering multiple pathways to the solution as
well as backtracking, posing a significant challenge to auto-regressive models.
Instructing LLMs to generate code that solves the problem helps, but only
slightly, e.g., GPT4's performance rises to 11.7%. In this work, we show that
in-context learning with A* algorithm implementations enhances performance. The
full potential of this promoting approach emerges when combined with our
proposed Multi-Stage-Multi-Try method, which breaks down the algorithm
implementation into two stages and verifies the first stage against unit tests,
raising GPT-4's performance above 57%."
BPO - Supercharging Online Preference Learning by Adhering to the Proximity of Behavior LLM,https://arxiv.org/abs/2406.12168,2024-06-18,2024-06-19,0.0,0.0,"Direct alignment from preferences (DAP) has emerged as a promising paradigm
for aligning large language models (LLMs) to human desiderata from
pre-collected, offline preference datasets. While recent studies indicate that
existing offline DAP methods can directly benefit from online training samples,
we highlight the need to develop specific online DAP algorithms to fully
harness the power of online training. Specifically, we identify that the
learned LLM should adhere to the proximity of the behavior LLM, which collects
the training samples. To this end, we propose online Preference Optimization in
proximity to the Behavior LLM (BPO), emphasizing the importance of constructing
a proper trust region for LLM alignment.
  We conduct extensive experiments to validate the effectiveness and
applicability of our approach by integrating it with various DAP methods,
resulting in significant performance improvements across a wide range of tasks
when training with the same amount of preference data. Even when only
introducing one additional data collection phase, our online BPO improves its
offline DAP baseline from 72.0% to 80.2% on TL;DR and from 82.2% to 89.1% on
Anthropic Helpfulness in terms of win rate against human reference text."
A Mel Spectrogram Enhancement Paradigm Based on CWT in Speech Synthesis,https://arxiv.org/abs/2406.12164,2024-06-18,2024-06-19,0.0,0.0,"Acoustic features play an important role in improving the quality of the
synthesised speech. Currently, the Mel spectrogram is a widely employed
acoustic feature in most acoustic models. However, due to the fine-grained loss
caused by its Fourier transform process, the clarity of speech synthesised by
Mel spectrogram is compromised in mutant signals. In order to obtain a more
detailed Mel spectrogram, we propose a Mel spectrogram enhancement paradigm
based on the continuous wavelet transform (CWT). This paradigm introduces an
additional task: a more detailed wavelet spectrogram, which like the
post-processing network takes as input the Mel spectrogram output by the
decoder. We choose Tacotron2 and Fastspeech2 for experimental validation in
order to test autoregressive (AR) and non-autoregressive (NAR) speech systems,
respectively. The experimental results demonstrate that the speech synthesised
using the model with the Mel spectrogram enhancement paradigm exhibits higher
MOS, with an improvement of 0.14 and 0.09 compared to the baseline model,
respectively. These findings provide some validation for the universality of
the enhancement paradigm, as they demonstrate the success of the paradigm in
different architectures."
Discussion Graph Semantics of First-Order Logic with Equality for Reasoning about Discussion and Argumentation,https://arxiv.org/abs/2406.12163,2024-06-18,2024-06-19,0.0,0.0,"We formulate discussion graph semantics of first-order logic with equality
for reasoning about discussion and argumentation as naturally as we would
reason about sentences. While there are a few existing proposals to use a
formal logic for reasoning about argumentation, they are constructed bottom-up
and specialised to the argumentation model by Dung. There is indeed a
conspicuous lack of a formal reasoning framework for handling general
discussion and argumentation models. We achieve the generality through a
top-down formulation of the semantics of first-order logic (with equality)
formulas, addressing the current shortage."
Exploring the Impact of a Transformer's Latent Space Geometry on Downstream Task Performance,https://arxiv.org/abs/2406.12159,2024-06-18,2024-06-19,0.0,0.0,"It is generally thought that transformer-based large language models benefit
from pre-training by learning generic linguistic knowledge that can be focused
on a specific task during fine-tuning. However, we propose that much of the
benefit from pre-training may be captured by geometric characteristics of the
latent space representations, divorced from any specific linguistic knowledge.
In this work we explore the relationship between GLUE benchmarking task
performance and a variety of measures applied to the latent space resulting
from BERT-type contextual language models. We find that there is a strong
linear relationship between a measure of quantized cell density and average
GLUE performance and that these measures may be predictive of otherwise
surprising GLUE performance for several non-standard BERT-type models from the
literature. These results may be suggestive of a strategy for decreasing
pre-training requirements, wherein model initialization can be informed by the
geometric characteristics of the model's latent space."
LLMs Are Prone to Fallacies in Causal Inference,https://arxiv.org/abs/2406.12158,2024-06-18,2024-06-19,1.0,0.0,"Recent work shows that causal facts can be effectively extracted from LLMs
through prompting, facilitating the creation of causal graphs for causal
inference tasks. However, it is unclear if this success is limited to
explicitly-mentioned causal facts in the pretraining data which the model can
memorize. Thus, this work investigates: Can LLMs infer causal relations from
other relational data in text? To disentangle the role of memorized causal
facts vs inferred causal relations, we finetune LLMs on synthetic data
containing temporal, spatial and counterfactual relations, and measure whether
the LLM can then infer causal relations. We find that: (a) LLMs are susceptible
to inferring causal relations from the order of two entity mentions in text
(e.g. X mentioned before Y implies X causes Y); (b) if the order is randomized,
LLMs still suffer from the post hoc fallacy, i.e. X occurs before Y (temporal
relation) implies X causes Y. We also find that while LLMs can correctly deduce
the absence of causal relations from temporal and spatial relations, they have
difficulty inferring causal relations from counterfactuals, questioning their
understanding of causality."
ChaosMining - A Benchmark to Evaluate Post-Hoc Local Attribution Methods in Low SNR Environments,https://arxiv.org/abs/2406.12150,2024-06-17,2024-06-19,0.0,0.0,"In this study, we examine the efficacy of post-hoc local attribution methods
in identifying features with predictive power from irrelevant ones in domains
characterized by a low signal-to-noise ratio (SNR), a common scenario in
real-world machine learning applications. We developed synthetic datasets
encompassing symbolic functional, image, and audio data, incorporating a
benchmark on the {\it (Model \(\times\) Attribution\(\times\) Noise Condition)}
triplet. By rigorously testing various classic models trained from scratch, we
gained valuable insights into the performance of these attribution methods in
multiple conditions. Based on these findings, we introduce a novel extension to
the notable recursive feature elimination (RFE) algorithm, enhancing its
applicability for neural networks. Our experiments highlight its strengths in
prediction and feature selection, alongside limitations in scalability. Further
details and additional minor findings are included in the appendix, with
extensive discussions. The codes and resources are available at
\href{https://github.com/geshijoker/ChaosMining/}{URL}."
Metacognitive AI - Framework and the Case for a Neurosymbolic Approach,https://arxiv.org/abs/2406.12147,2024-06-17,2024-06-19,0.0,0.0,"Metacognition is the concept of reasoning about an agent's own internal
processes and was originally introduced in the field of developmental
psychology. In this position paper, we examine the concept of applying
metacognition to artificial intelligence. We introduce a framework for
understanding metacognitive artificial intelligence (AI) that we call TRAP:
transparency, reasoning, adaptation, and perception. We discuss each of these
aspects in-turn and explore how neurosymbolic AI (NSAI) can be leveraged to
address challenges of metacognition."
Should AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers,https://arxiv.org/abs/2406.12146,2024-06-17,2024-06-19,0.0,0.0,"In the contemporary landscape of computer architecture, the demand for
efficient parallel programming persists, needing robust optimization
techniques. Traditional optimizing compilers have historically been pivotal in
this endeavor, adapting to the evolving complexities of modern software
systems. The emergence of Large Language Models (LLMs) raises intriguing
questions about the potential for AI-driven approaches to revolutionize code
optimization methodologies.
  This paper presents a comparative analysis between two state-of-the-art Large
Language Models, GPT-4.0 and CodeLlama-70B, and traditional optimizing
compilers, assessing their respective abilities and limitations in optimizing
code for maximum efficiency. Additionally, we introduce a benchmark suite of
challenging optimization patterns and an automatic mechanism for evaluating
performance and correctness of the code generated by such tools. We used two
different prompting methodologies to assess the performance of the LLMs --
Chain of Thought (CoT) and Instruction Prompting (IP). We then compared these
results with three traditional optimizing compilers, CETUS, PLUTO and ROSE,
across a range of real-world use cases.
  A key finding is that while LLMs have the potential to outperform current
optimizing compilers, they often generate incorrect code on large code sizes,
calling for automated verification methods. Our extensive evaluation across 3
different benchmarks suites shows CodeLlama-70B as the superior optimizer among
the two LLMs, capable of achieving speedups of up to 2.1x. Additionally, CETUS
is the best among the optimizing compilers, achieving a maximum speedup of
1.9x. We also found no significant difference between the two prompting
methods: Chain of Thought (Cot) and Instructing prompting (IP)."
Minimax Linear Regression under the Quantile Risk,https://arxiv.org/abs/2406.12145,2024-06-17,2024-06-19,0.0,0.0,"We study the problem of designing minimax procedures in linear regression
under the quantile risk. We start by considering the realizable setting with
independent Gaussian noise, where for any given noise level and distribution of
inputs, we obtain the exact minimax quantile risk for a rich family of error
functions and establish the minimaxity of OLS. This improves on the known lower
bounds for the special case of square error, and provides us with a lower bound
on the minimax quantile risk over larger sets of distributions. Under the
square error and a fourth moment assumption on the distribution of inputs, we
show that this lower bound is tight over a larger class of problems.
Specifically, we prove a matching upper bound on the worst-case quantile risk
of a variant of the recently proposed min-max regression procedure, thereby
establishing its minimaxity, up to absolute constants. We illustrate the
usefulness of our approach by extending this result to all $p$-th power error
functions for $p \in (2, \infty)$. Along the way, we develop a generic analogue
to the classical Bayesian method for lower bounding the minimax risk when
working with the quantile risk, as well as a tight characterization of the
quantiles of the smallest eigenvalue of the sample covariance matrix."
Slicing Through Bias - Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods,https://arxiv.org/abs/2406.12142,2024-06-17,2024-06-19,0.0,0.0,"Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses."
A dual task learning approach to fine-tune a multilingual semantic speech encoder for Spoken Language Understanding,https://arxiv.org/abs/2406.12141,2024-06-17,2024-06-19,0.0,0.0,"Self-Supervised Learning is vastly used to efficiently represent speech for
Spoken Language Understanding, gradually replacing conventional approaches.
Meanwhile, textual SSL models are proposed to encode language-agnostic
semantics. SAMU-XLSR framework employed this semantic information to enrich
multilingual speech representations. A recent study investigated SAMU-XLSR
in-domain semantic enrichment by specializing it on downstream transcriptions,
leading to state-of-the-art results on a challenging SLU task. This study's
interest lies in the loss of multilingual performances and lack of
specific-semantics training induced by such specialization in close languages
without any SLU implication. We also consider SAMU-XLSR's loss of initial
cross-lingual abilities due to a separate SLU fine-tuning. Therefore, this
paper proposes a dual task learning approach to improve SAMU-XLSR semantic
enrichment while considering distant languages for multilingual and language
portability experiments."
COT Flow - Learning Optimal-Transport Image Sampling and Editing by Contrastive Pairs,https://arxiv.org/abs/2406.12140,2024-06-17,2024-06-19,0.0,0.0,"Diffusion models have demonstrated strong performance in sampling and editing
multi-modal data with high generation quality, yet they suffer from the
iterative generation process which is computationally expensive and slow. In
addition, most methods are constrained to generate data from Gaussian noise,
which limits their sampling and editing flexibility. To overcome both
disadvantages, we present Contrastive Optimal Transport Flow (COT Flow), a new
method that achieves fast and high-quality generation with improved zero-shot
editing flexibility compared to previous diffusion models. Benefiting from
optimal transport (OT), our method has no limitation on the prior distribution,
enabling unpaired image-to-image (I2I) translation and doubling the editable
space (at both the start and end of the trajectory) compared to other zero-shot
editing methods. In terms of quality, COT Flow can generate competitive results
in merely one step compared to previous state-of-the-art unpaired
image-to-image (I2I) translation methods. To highlight the advantages of COT
Flow through the introduction of OT, we introduce the COT Editor to perform
user-guided editing with excellent flexibility and quality. The code will be
released at https://github.com/zuxinrui/cot_flow."
IDs for AI Systems,https://arxiv.org/abs/2406.12137,2024-06-17,2024-06-19,0.0,0.0,"AI systems are increasingly pervasive, yet information needed to decide
whether and how to engage with them may not exist or be accessible. A user may
not be able to verify whether a system has certain safety certifications. An
investigator may not know whom to investigate when a system causes an incident.
It may not be clear whom to contact to shut down a malfunctioning system.
Across a number of domains, IDs address analogous problems by identifying
particular entities (e.g., a particular Boeing 747) and providing information
about other entities of the same class (e.g., some or all Boeing 747s). We
propose a framework in which IDs are ascribed to instances of AI systems (e.g.,
a particular chat session with Claude 3), and associated information is
accessible to parties seeking to interact with that system. We characterize IDs
for AI systems, provide concrete examples where IDs could be useful, argue that
there could be significant demand for IDs from key actors, analyze how those
actors could incentivize ID adoption, explore a potential implementation of our
framework for deployers of AI systems, and highlight limitations and risks. IDs
seem most warranted in settings where AI systems could have a large impact upon
the world, such as in making financial transactions or contacting real humans.
With further study, IDs could help to manage a world where AI systems pervade
society."
Gram2Vec - An Interpretable Document Vectorizer,https://arxiv.org/abs/2406.12131,2024-06-17,2024-06-19,0.0,0.0,"We present Gram2Vec, a grammatical style embedding algorithm that embeds
documents into a higher dimensional space by extracting the normalized relative
frequencies of grammatical features present in the text. Compared to neural
approaches, Gram2Vec offers inherent interpretability based on how the feature
vectors are generated. In our demo, we present a way to visualize a mapping of
authors to documents based on their Gram2Vec vectors and highlight the ability
to drop or add features to view which authors make certain linguistic choices.
Next, we use authorship attribution as an application to show how Gram2Vec can
explain why a document is attributed to a certain author, using cosine
similarities between the Gram2Vec feature vectors to calculate the distances
between candidate documents and a query document."
"AI ""News"" Content Farms Are Easy to Make and Hard to Detect - A Case Study in Italian",https://arxiv.org/abs/2406.12128,2024-06-17,2024-06-19,0.0,0.0,"Large Language Models (LLMs) are increasingly used as ""content farm"" models
(CFMs), to generate synthetic text that could pass for real news articles. This
is already happening even for languages that do not have high-quality
monolingual LLMs. We show that fine-tuning Llama (v1), mostly trained on
English, on as little as 40K Italian news articles, is sufficient for producing
news-like texts that native speakers of Italian struggle to identify as
synthetic.
  We investigate three LLMs and three methods of detecting synthetic texts
(log-likelihood, DetectGPT, and supervised classification), finding that they
all perform better than human raters, but they are all impractical in the real
world (requiring either access to token likelihood information or a large
dataset of CFM texts). We also explore the possibility of creating a proxy CFM:
an LLM fine-tuned on a similar dataset to one used by the real ""content farm"".
We find that even a small amount of fine-tuning data suffices for creating a
successful detector, but we need to know which base LLM is used, which is a
major challenge.
  Our results suggest that there are currently no practical methods for
detecting synthetic news-like texts 'in the wild', while generating them is too
easy. We highlight the urgency of more NLP research on this problem."
Efficient Sequential Decision Making with Large Language Models,https://arxiv.org/abs/2406.12125,2024-06-17,2024-06-19,0.0,0.0,"This paper focuses on extending the success of large language models (LLMs)
to sequential decision making. Existing efforts either (i) re-train or finetune
LLMs for decision making, or (ii) design prompts for pretrained LLMs. The
former approach suffers from the computational burden of gradient updates, and
the latter approach does not show promising results. In this paper, we propose
a new approach that leverages online model selection algorithms to efficiently
incorporate LLMs agents into sequential decision making. Statistically, our
approach significantly outperforms both traditional decision making algorithms
and vanilla LLM agents. Computationally, our approach avoids the need for
expensive gradient updates of LLMs, and throughout the decision making process,
it requires only a small number of LLM calls. We conduct extensive experiments
to verify the effectiveness of our proposed approach. As an example, on a
large-scale Amazon dataset, our approach achieves more than a $6$x performance
gain over baselines while calling LLMs in only $1.5$\% of the time steps."
Adding Conditional Control to Diffusion Models with Reinforcement Learning,https://arxiv.org/abs/2406.12120,2024-06-17,2024-06-19,0.0,0.0,"Diffusion models are powerful generative models that allow for precise
control over the characteristics of the generated samples. While these
diffusion models trained on large datasets have achieved success, there is
often a need to introduce additional controls in downstream fine-tuning
processes, treating these powerful models as pre-trained diffusion models. This
work presents a novel method based on reinforcement learning (RL) to add
additional controls, leveraging an offline dataset comprising inputs and
corresponding labels. We formulate this task as an RL problem, with the
classifier learned from the offline dataset and the KL divergence against
pre-trained models serving as the reward functions. We introduce our method,
$\textbf{CTRL}$ ($\textbf{C}$onditioning pre-$\textbf{T}$rained diffusion
models with $\textbf{R}$einforcement $\textbf{L}$earning), which produces
soft-optimal policies that maximize the abovementioned reward functions. We
formally demonstrate that our method enables sampling from the conditional
distribution conditioned on additional controls during inference. Our RL-based
approach offers several advantages over existing methods. Compared to commonly
used classifier-free guidance, our approach improves sample efficiency, and can
greatly simplify offline dataset construction by exploiting conditional
independence between the inputs and additional controls. Furthermore, unlike
classifier guidance, we avoid the need to train classifiers from intermediate
states to additional controls."
Decoding the Narratives - Analyzing Personal Drug Experiences Shared on Reddit,https://arxiv.org/abs/2406.12117,2024-06-17,2024-06-19,0.0,0.0,"Online communities such as drug-related subreddits serve as safe spaces for
people who use drugs (PWUD), fostering discussions on substance use
experiences, harm reduction, and addiction recovery. Users' shared narratives
on these forums provide insights into the likelihood of developing a substance
use disorder (SUD) and recovery potential. Our study aims to develop a
multi-level, multi-label classification model to analyze online user-generated
texts about substance use experiences. For this purpose, we first introduce a
novel taxonomy to assess the nature of posts, including their intended
connections (Inquisition or Disclosure), subjects (e.g., Recovery, Dependency),
and specific objectives (e.g., Relapse, Quality, Safety). Using various
multi-label classification algorithms on a set of annotated data, we show that
GPT-4, when prompted with instructions, definitions, and examples, outperformed
all other models. We apply this model to label an additional 1,000 posts and
analyze the categories of linguistic expression used within posts in each
class. Our analysis shows that topics such as Safety, Combination of
Substances, and Mental Health see more disclosure, while discussions about
physiological Effects focus on harm reduction. Our work enriches the
understanding of PWUD's experiences and informs the broader knowledge base on
SUD and drug use."
Thermodynamic Transferability in Coarse-Grained Force Fields using Graph Neural Networks,https://arxiv.org/abs/2406.12112,2024-06-17,2024-06-19,0.0,0.0,"Coarse-graining is a molecular modeling technique in which an atomistic
system is represented in a simplified fashion that retains the most significant
system features that contribute to a target output, while removing the degrees
of freedom that are less relevant. This reduction in model complexity allows
coarse-grained molecular simulations to reach increased spatial and temporal
scales compared to corresponding all-atom models. A core challenge in
coarse-graining is to construct a force field that represents the interactions
in the new representation in a way that preserves the atomistic-level
properties. Many approaches to building coarse-grained force fields have
limited transferability between different thermodynamic conditions as a result
of averaging over internal fluctuations at a specific thermodynamic state
point. Here, we use a graph-convolutional neural network architecture, the
Hierarchically Interacting Particle Neural Network with Tensor Sensitivity
(HIP-NN-TS), to develop a highly automated training pipeline for coarse grained
force fields which allows for studying the transferability of coarse-grained
models based on the force-matching approach. We show that this approach not
only yields highly accurate force fields, but also that these force fields are
more transferable through a variety of thermodynamic conditions. These results
illustrate the potential of machine learning techniques such as graph neural
networks to improve the construction of transferable coarse-grained force
fields."
Can LLMs Learn Macroeconomic Narratives from Social Media?,https://arxiv.org/abs/2406.12109,2024-06-17,2024-06-19,0.0,0.0,"This study empirically tests the $\textit{Narrative Economics}$ hypothesis,
which posits that narratives (ideas that are spread virally and affect public
beliefs) can influence economic fluctuations. We introduce two curated datasets
containing posts from X (formerly Twitter) which capture economy-related
narratives (Data will be shared upon paper acceptance). Employing Natural
Language Processing (NLP) methods, we extract and summarize narratives from the
tweets. We test their predictive power for $\textit{macroeconomic}$ forecasting
by incorporating the tweets' or the extracted narratives' representations in
downstream financial prediction tasks. Our work highlights the challenges in
improving macroeconomic models with narrative data, paving the way for the
research community to realistically address this important challenge. From a
scientific perspective, our investigation offers valuable insights and NLP
tools for narrative extraction and summarization using Large Language Models
(LLMs), contributing to future research on the role of narratives in economics."
Computing in the Life Sciences - From Early Algorithms to Modern AI,https://arxiv.org/abs/2406.12108,2024-06-17,2024-06-19,0.0,0.0,"Computing in the life sciences has undergone a transformative evolution, from
early computational models in the 1950s to the applications of artificial
intelligence (AI) and machine learning (ML) seen today. This paper highlights
key milestones and technological advancements through the historical
development of computing in the life sciences. The discussion includes the
inception of computational models for biological processes, the advent of
bioinformatics tools, and the integration of AI/ML in modern life sciences
research. Attention is given to AI-enabled tools used in the life sciences,
such as scientific large language models and bio-AI tools, examining their
capabilities, limitations, and impact to biological risk. This paper seeks to
clarify and establish essential terminology and concepts to ensure informed
decision-making and effective communication across disciplines."
End-to-end Text-to-SQL Generation within an Analytics Insight Engine,https://arxiv.org/abs/2406.12104,2024-06-17,2024-06-19,0.0,0.0,"Recent advancements in Text-to-SQL have pushed database management systems
towards greater democratization of data access. Today's language models are at
the core of these advancements. They enable impressive Text-to-SQL generation
as experienced in the development of Distyl AI's Analytics Insight Engine. Its
early deployment with enterprise customers has highlighted three core
challenges. First, data analysts expect support with authoring SQL queries of
very high complexity. Second, requests are ad-hoc and, as such, require low
latency. Finally, generation requires an understanding of domain-specific
terminology and practices.
  The design and implementation of our Text-to-SQL generation pipeline, powered
by large language models, tackles these challenges. The core tenants of our
approach rely on external knowledge that we extract in a pre-processing phase,
on retrieving the appropriate external knowledge at query generation time, and
on decomposing SQL query generation following a hierarchical CTE-based
structure. Finally, an adaptation framework leverages feedback to update the
external knowledge, in turn improving query generation over time. We give an
overview of our end-to-end approach and highlight the operators generating SQL
during inference."
DistillNeRF - Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features,https://arxiv.org/abs/2406.12095,2024-06-17,2024-06-19,0.0,0.0,"We propose DistillNeRF, a self-supervised learning framework addressing the
challenge of understanding 3D environments from limited 2D observations in
autonomous driving. Our method is a generalizable feedforward model that
predicts a rich neural scene representation from sparse, single-frame
multi-view camera inputs, and is trained self-supervised with differentiable
rendering to reconstruct RGB, depth, or feature images. Our first insight is to
exploit per-scene optimized Neural Radiance Fields (NeRFs) by generating dense
depth and virtual camera targets for training, thereby helping our model to
learn 3D geometry from sparse non-overlapping image inputs. Second, to learn a
semantically rich 3D representation, we propose distilling features from
pre-trained 2D foundation models, such as CLIP or DINOv2, thereby enabling
various downstream tasks without the need for costly 3D human annotations. To
leverage these two insights, we introduce a novel model architecture with a
two-stage lift-splat-shoot encoder and a parameterized sparse hierarchical
voxel representation. Experimental results on the NuScenes dataset demonstrate
that DistillNeRF significantly outperforms existing comparable self-supervised
methods for scene reconstruction, novel view synthesis, and depth estimation;
and it allows for competitive zero-shot 3D semantic occupancy prediction, as
well as open-world scene understanding through distilled foundation model
features. Demos and code will be available at https://distillnerf.github.io/."
Who's asking? User personas and the mechanics of latent misalignment,https://arxiv.org/abs/2406.12094,2024-06-17,2024-06-19,0.0,0.0,"Despite investments in improving model safety, studies show that misaligned
capabilities remain latent in safety-tuned models. In this work, we shed light
on the mechanics of this phenomenon. First, we show that even when model
generations are safe, harmful content can persist in hidden representations and
can be extracted by decoding from earlier layers. Then, we show that whether
the model divulges such content depends significantly on its perception of who
it is talking to, which we refer to as user persona. In fact, we find
manipulating user persona to be even more effective for eliciting harmful
content than direct attempts to control model refusal. We study both natural
language prompting and activation steering as control methods and show that
activation steering is significantly more effective at bypassing safety
filters. We investigate why certain personas break model safeguards and find
that they enable the model to form more charitable interpretations of otherwise
dangerous queries. Finally, we show we can predict a persona's effect on
refusal given only the geometry of its steering vector."
Is poisoning a real threat to LLM alignment? Maybe more so than you think,https://arxiv.org/abs/2406.12091,2024-06-17,2024-06-19,0.0,0.0,"Recent advancements in Reinforcement Learning with Human Feedback (RLHF) have
significantly impacted the alignment of Large Language Models (LLMs). The
sensitivity of reinforcement learning algorithms such as Proximal Policy
Optimization (PPO) has led to new line work on Direct Policy Optimization
(DPO), which treats RLHF in a supervised learning framework. The increased
practical use of these RLHF methods warrants an analysis of their
vulnerabilities. In this work, we investigate the vulnerabilities of DPO to
poisoning attacks under different scenarios and compare the effectiveness of
preference poisoning, a first of its kind. We comprehensively analyze DPO's
vulnerabilities under different types of attacks, i.e., backdoor and
non-backdoor attacks, and different poisoning methods across a wide array of
language models, i.e., LLama 7B, Mistral 7B, and Gemma 7B. We find that unlike
PPO-based methods, which, when it comes to backdoor attacks, require at least
4\% of the data to be poisoned to elicit harmful behavior, we exploit the true
vulnerabilities of DPO more simply so we can poison the model with only as much
as 0.5\% of the data. We further investigate the potential reasons behind the
vulnerability and how well this vulnerability translates into backdoor vs
non-backdoor attacks."
When Reasoning Meets Information Aggregation - A Case Study with Sports Narratives,https://arxiv.org/abs/2406.12084,2024-06-17,2024-06-19,0.0,0.0,"Reasoning is most powerful when an LLM accurately aggregates relevant
information. We examine the critical role of information aggregation in
reasoning by requiring the LLM to analyze sports narratives. To succeed at this
task, an LLM must infer points from actions, identify related entities,
attribute points accurately to players and teams, and compile key statistics to
draw conclusions. We conduct comprehensive experiments with real NBA basketball
data and present SportsGen, a new method to synthesize game narratives. By
synthesizing data, we can rigorously evaluate LLMs' reasoning capabilities
under complex scenarios with varying narrative lengths and density of
information. Our findings show that most models, including GPT-4o, often fail
to accurately aggregate basketball scores due to frequent scoring patterns.
Open-source models like Llama-3 further suffer from significant score
hallucinations. Finally, the effectiveness of reasoning is influenced by
narrative complexity, information density, and domain-specific terms,
highlighting the challenges in analytical reasoning tasks."
Uncertainty modeling for fine-tuned implicit functions,https://arxiv.org/abs/2406.12082,2024-06-17,2024-06-19,0.0,0.0,"Implicit functions such as Neural Radiance Fields (NeRFs), occupancy
networks, and signed distance functions (SDFs) have become pivotal in computer
vision for reconstructing detailed object shapes from sparse views. Achieving
optimal performance with these models can be challenging due to the extreme
sparsity of inputs and distribution shifts induced by data corruptions. To this
end, large, noise-free synthetic datasets can serve as shape priors to help
models fill in gaps, but the resulting reconstructions must be approached with
caution. Uncertainty estimation is crucial for assessing the quality of these
reconstructions, particularly in identifying areas where the model is uncertain
about the parts it has inferred from the prior. In this paper, we introduce
Dropsembles, a novel method for uncertainty estimation in tuned implicit
functions. We demonstrate the efficacy of our approach through a series of
experiments, starting with toy examples and progressing to a real-world
scenario. Specifically, we train a Convolutional Occupancy Network on synthetic
anatomical data and test it on low-resolution MRI segmentations of the lumbar
spine. Our results show that Dropsembles achieve the accuracy and calibration
levels of deep ensembles but with significantly less computational cost."
"Multi-Dimensional Pruning - Joint Channel, Layer and Block Pruning with Latency Constraint",https://arxiv.org/abs/2406.12079,2024-06-17,2024-06-19,0.0,0.0,"As we push the boundaries of performance in various vision tasks, the models
grow in size correspondingly. To keep up with this growth, we need very
aggressive pruning techniques for efficient inference and deployment on edge
devices. Existing pruning approaches are limited to channel pruning and
struggle with aggressive parameter reductions. In this paper, we propose a
novel multi-dimensional pruning framework that jointly optimizes pruning across
channels, layers, and blocks while adhering to latency constraints. We develop
a latency modeling technique that accurately captures model-wide latency
variations during pruning, which is crucial for achieving an optimal
latency-accuracy trade-offs at high pruning ratio. We reformulate pruning as a
Mixed-Integer Nonlinear Program (MINLP) to efficiently determine the optimal
pruned structure with only a single pass. Our extensive results demonstrate
substantial improvements over previous methods, particularly at large pruning
ratios. In classification, our method significantly outperforms prior art HALP
with a Top-1 accuracy of 70.0(v.s. 68.6) and an FPS of 5262 im/s(v.s. 4101
im/s). In 3D object detection, we establish a new state-of-the-art by pruning
StreamPETR at a 45% pruning ratio, achieving higher FPS (37.3 vs. 31.7) and mAP
(0.451 vs. 0.449) than the dense baseline."
Conformance Checking of Fuzzy Logs against Declarative Temporal Specifications,https://arxiv.org/abs/2406.12078,2024-06-17,2024-06-19,0.0,0.0,"Traditional conformance checking tasks assume that event data provide a
faithful and complete representation of the actual process executions. This
assumption has been recently questioned: more and more often events are not
traced explicitly, but are instead indirectly obtained as the result of event
recognition pipelines, and thus inherently come with uncertainty. In this work,
differently from the typical probabilistic interpretation of uncertainty, we
consider the relevant case where uncertainty refers to which activity is
actually conducted, under a fuzzy semantics. In this novel setting, we consider
the problem of checking whether fuzzy event data conform with declarative
temporal rules specified as Declare patterns or, more generally, as formulae of
linear temporal logic over finite traces (LTLf). This requires to relax the
assumption that at each instant only one activity is executed, and to
correspondingly redefine boolean operators of the logic with a fuzzy semantics.
Specifically, we provide a threefold contribution. First, we define a fuzzy
counterpart of LTLf tailored to our purpose. Second, we cast conformance
checking over fuzzy logs as a verification problem in this logic. Third, we
provide a proof-of-concept, efficient implementation based on the PyTorch
Python library, suited to check conformance of multiple fuzzy traces at once."
COMMUNITY-CROSS-INSTRUCT - Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities,https://arxiv.org/abs/2406.12074,2024-06-17,2024-06-19,0.0,0.0,"Social scientists use surveys to probe the opinions and beliefs of
populations, but these methods are slow, costly, and prone to biases. Recent
advances in large language models (LLMs) enable creating computational
representations or ""digital twins"" of populations that generate human-like
responses mimicking the population's language, styles, and attitudes. We
introduce Community-Cross-Instruct, an unsupervised framework for aligning LLMs
to online communities to elicit their beliefs. Given a corpus of a community's
online discussions, Community-Cross-Instruct automatically generates
instruction-output pairs by an advanced LLM to (1) finetune an foundational LLM
to faithfully represent that community, and (2) evaluate the alignment of the
finetuned model to the community. We demonstrate the method's utility in
accurately representing political and fitness communities on Reddit. Unlike
prior methods requiring human-authored instructions, Community-Cross-Instruct
generates instructions in a fully unsupervised manner, enhancing scalability
and generalization across domains. This work enables cost-effective and
automated surveying of diverse online communities."
DTGB - A Comprehensive Benchmark for Dynamic Text-Attributed Graphs,https://arxiv.org/abs/2406.12072,2024-06-17,2024-06-19,0.0,0.0,"Dynamic text-attributed graphs (DyTAGs) are prevalent in various real-world
scenarios, where each node and edge are associated with text descriptions, and
both the graph structure and text descriptions evolve over time. Despite their
broad applicability, there is a notable scarcity of benchmark datasets tailored
to DyTAGs, which hinders the potential advancement in many research fields. To
address this gap, we introduce Dynamic Text-attributed Graph Benchmark (DTGB),
a collection of large-scale, time-evolving graphs from diverse domains, with
nodes and edges enriched by dynamically changing text attributes and
categories. To facilitate the use of DTGB, we design standardized evaluation
procedures based on four real-world use cases: future link prediction,
destination node retrieval, edge classification, and textual relation
generation. These tasks require models to understand both dynamic graph
structures and natural language, highlighting the unique challenges posed by
DyTAGs. Moreover, we conduct extensive benchmark experiments on DTGB,
evaluating 7 popular dynamic graph learning algorithms and their variants of
adapting to text attributes with LLM embeddings, along with 6 powerful large
language models (LLMs). Our results show the limitations of existing models in
handling DyTAGs. Our analysis also demonstrates the utility of DTGB in
investigating the incorporation of structural and textual dynamics. The
proposed DTGB fosters research on DyTAGs and their broad applications. It
offers a comprehensive benchmark for evaluating and advancing models to handle
the interplay between dynamic graph structures and natural language. The
dataset and source code are available at https://github.com/zjs123/DTGB."
Satyrn - A Platform for Analytics Augmented Generation,https://arxiv.org/abs/2406.12069,2024-06-17,2024-06-19,0.0,0.0,"Large language models (LLMs) are capable of producing documents, and
retrieval augmented generation (RAG) has shown itself to be a powerful method
for improving accuracy without sacrificing fluency. However, not all
information can be retrieved from text. We propose an approach that uses the
analysis of structured data to generate fact sets that are used to guide
generation in much the same way that retrieved documents are used in RAG. This
analytics augmented generation (AAG) approach supports the ability to utilize
standard analytic techniques to generate facts that are then converted to text
and passed to an LLM. We present a neurosymbolic platform, Satyrn that
leverages AAG to produce accurate, fluent, and coherent reports grounded in
large scale databases. In our experiments, we find that Satyrn generates
reports in which over 86% accurate claims while maintaining high levels of
fluency and coherence, even when using smaller language models such as
Mistral-7B, as compared to GPT-4 Code Interpreter in which just 57% of claims
are accurate."
Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks,https://arxiv.org/abs/2406.12066,2024-06-17,2024-06-19,0.0,0.0,"Medical knowledge is context-dependent and requires consistent reasoning
across various natural language expressions of semantically equivalent phrases.
This is particularly crucial for drug names, where patients often use brand
names like Advil or Tylenol instead of their generic equivalents. To study
this, we create a new robustness dataset, RABBITS, to evaluate performance
differences on medical benchmarks after swapping brand and generic drug names
using physician expert annotations.
  We assess both open-source and API-based LLMs on MedQA and MedMCQA, revealing
a consistent performance drop ranging from 1-10\%. Furthermore, we identify a
potential source of this fragility as the contamination of test data in widely
used pre-training datasets. All code is accessible at
https://github.com/BittermanLab/RABBITS, and a HuggingFace leaderboard is
available at https://huggingface.co/spaces/AIM-Harvard/rabbits-leaderboard."
STNAGNN - Spatiotemporal Node Attention Graph Neural Network for Task-based fMRI Analysis,https://arxiv.org/abs/2406.12065,2024-06-17,2024-06-19,0.0,0.0,"Task-based fMRI uses actions or stimuli to trigger task-specific brain
responses and measures them using BOLD contrast. Despite the significant
task-induced spatiotemporal brain activation fluctuations, most studies on
task-based fMRI ignore the task context information aligned with fMRI and
consider task-based fMRI a coherent sequence. In this paper, we show that using
the task structures as data-driven guidance is effective for spatiotemporal
analysis. We propose STNAGNN, a GNN-based spatiotemporal architecture, and
validate its performance in an autism classification task. The trained model is
also interpreted for identifying autism-related spatiotemporal brain
biomarkers."
Entropic Regression DMD (ERDMD) Discovers Informative Sparse and Nonuniformly Time Delayed Models,https://arxiv.org/abs/2406.12062,2024-06-17,2024-06-19,0.0,0.0,"In this work, we present a method which determines optimal multi-step dynamic
mode decomposition (DMD) models via entropic regression, which is a nonlinear
information flow detection algorithm. Motivated by the higher-order DMD (HODMD)
method of \cite{clainche}, and the entropic regression (ER) technique for
network detection and model construction found in \cite{bollt, bollt2}, we
develop a method that we call ERDMD that produces high fidelity time-delay DMD
models that allow for nonuniform time space, and the time spacing is discovered
by consider most informativity based on ER. These models are shown to be highly
efficient and robust. We test our method over several data sets generated by
chaotic attractors and show that we are able to build excellent reconstructions
using relatively minimal models. We likewise are able to better identify
multiscale features via our models which enhances the utility of dynamic mode
decomposition."
Not Eliminate but Aggregate - Post-Hoc Control over Mixture-of-Experts to Address Shortcut Shifts in Natural Language Understanding,https://arxiv.org/abs/2406.12060,2024-06-17,2024-06-19,0.0,0.0,"Recent models for natural language understanding are inclined to exploit
simple patterns in datasets, commonly known as shortcuts. These shortcuts hinge
on spurious correlations between labels and latent features existing in the
training data. At inference time, shortcut-dependent models are likely to
generate erroneous predictions under distribution shifts, particularly when
some latent features are no longer correlated with the labels. To avoid this,
previous studies have trained models to eliminate the reliance on shortcuts. In
this study, we explore a different direction: pessimistically aggregating the
predictions of a mixture-of-experts, assuming each expert captures relatively
different latent features. The experimental results demonstrate that our
post-hoc control over the experts significantly enhances the model's robustness
to the distribution shift in shortcuts. Besides, we show that our approach has
some practical advantages. We also analyze our model and provide results to
support the assumption."
A Scalable and Effective Alternative to Graph Transformers,https://arxiv.org/abs/2406.12059,2024-06-17,2024-06-19,0.0,0.0,"Graph Neural Networks (GNNs) have shown impressive performance in graph
representation learning, but they face challenges in capturing long-range
dependencies due to their limited expressive power. To address this, Graph
Transformers (GTs) were introduced, utilizing self-attention mechanism to
effectively model pairwise node relationships. Despite their advantages, GTs
suffer from quadratic complexity w.r.t. the number of nodes in the graph,
hindering their applicability to large graphs. In this work, we present
Graph-Enhanced Contextual Operator (GECO), a scalable and effective alternative
to GTs that leverages neighborhood propagation and global convolutions to
effectively capture local and global dependencies in quasilinear time. Our
study on synthetic datasets reveals that GECO reaches 169x speedup on a graph
with 2M nodes w.r.t. optimized attention. Further evaluations on diverse range
of benchmarks showcase that GECO scales to large graphs where traditional GTs
often face memory and time limitations. Notably, GECO consistently achieves
comparable or superior quality compared to baselines, improving the SOTA up to
4.5%, and offering a scalable and effective solution for large-scale graph
learning."
WellDunn - On the Robustness and Explainability of Language Models and Large Language Models in Identifying Wellness Dimensions,https://arxiv.org/abs/2406.12058,2024-06-17,2024-06-19,0.0,0.0,"Language Models (LMs) are being proposed for mental health applications where
the heightened risk of adverse outcomes means predictive performance may not be
a sufficient litmus test of a model's utility in clinical practice. A model
that can be trusted for practice should have a correspondence between
explanation and clinical determination, yet no prior research has examined the
attention fidelity of these models and their effect on ground truth
explanations. We introduce an evaluation design that focuses on the robustness
and explainability of LMs in identifying Wellness Dimensions (WD). We focus on
two mental health and well-being datasets: (a) Multi-label Classification-based
MultiWD, and (b) WellXplain for evaluating attention mechanism veracity against
expert-labeled explanations. The labels are based on Halbert Dunn's theory of
wellness, which gives grounding to our evaluation. We reveal four surprising
results about LMs/LLMs: (1) Despite their human-like capabilities, GPT-3.5/4
lag behind RoBERTa, and MedAlpaca, a fine-tuned LLM fails to deliver any
remarkable improvements in performance or explanations. (2) Re-examining LMs'
predictions based on a confidence-oriented loss function reveals a significant
performance drop. (3) Across all LMs/LLMs, the alignment between attention and
explanations remains low, with LLMs scoring a dismal 0.0. (4) Most mental
health-specific LMs/LLMs overlook domain-specific knowledge and undervalue
explanations, causing these discrepancies. This study highlights the need for
further research into their consistency and explanations in mental health and
well-being."
Learning Molecular Representation in a Cell,https://arxiv.org/abs/2406.12056,2024-06-17,2024-06-19,0.0,0.0,"Predicting drug efficacy and safety in vivo requires information on
biological responses (e.g., cell morphology and gene expression) to small
molecule perturbations. However, current molecular representation learning
methods do not provide a comprehensive view of cell states under these
perturbations and struggle to remove noise, hindering model generalization. We
introduce the Information Alignment (InfoAlign) approach to learn molecular
representations through the information bottleneck method in cells. We
integrate molecules and cellular response data as nodes into a context graph,
connecting them with weighted edges based on chemical, biological, and
computational criteria. For each molecule in a training batch, InfoAlign
optimizes the encoder's latent representation with a minimality objective to
discard redundant structural information. A sufficiency objective decodes the
representation to align with different feature spaces from the molecule's
neighborhood in the context graph. We demonstrate that the proposed sufficiency
objective for alignment is tighter than existing encoder-based contrastive
methods. Empirically, we validate representations from InfoAlign in two
downstream tasks: molecular property prediction against up to 19 baseline
methods across four datasets, plus zero-shot molecule-morphology matching."
FAWN - Floor-And-Walls Normal Regularization for Direct Neural TSDF Reconstruction,https://arxiv.org/abs/2406.12054,2024-06-17,2024-06-19,0.0,0.0,"Leveraging 3D semantics for direct 3D reconstruction has a great potential
yet unleashed. For instance, by assuming that walls are vertical, and a floor
is planar and horizontal, we can correct distorted room shapes and eliminate
local artifacts such as holes, pits, and hills. In this paper, we propose FAWN,
a modification of truncated signed distance function (TSDF) reconstruction
methods, which considers scene structure by detecting walls and floor in a
scene, and penalizing the corresponding surface normals for deviating from the
horizontal and vertical directions. Implemented as a 3D sparse convolutional
module, FAWN can be incorporated into any trainable pipeline that predicts
TSDF. Since FAWN requires 3D semantics only for training, no additional
limitations on further use are imposed. We demonstrate, that FAWN-modified
methods use semantics more effectively, than existing semantic-based
approaches. Besides, we apply our modification to state-of-the-art TSDF
reconstruction methods, and demonstrate a quality gain in SCANNET, ICL-NUIM,
TUM RGB-D, and 7SCENES benchmarks."
InternalInspector $I^2$ - Robust Confidence Estimation in LLMs through Internal States,https://arxiv.org/abs/2406.12053,2024-06-17,2024-06-19,0.0,0.0,"Despite their vast capabilities, Large Language Models (LLMs) often struggle
with generating reliable outputs, frequently producing high-confidence
inaccuracies known as hallucinations. Addressing this challenge, our research
introduces InternalInspector, a novel framework designed to enhance confidence
estimation in LLMs by leveraging contrastive learning on internal states
including attention states, feed-forward states, and activation states of all
layers. Unlike existing methods that primarily focus on the final activation
state, InternalInspector conducts a comprehensive analysis across all internal
states of every layer to accurately identify both correct and incorrect
prediction processes. By benchmarking InternalInspector against existing
confidence estimation methods across various natural language understanding and
generation tasks, including factual question answering, commonsense reasoning,
and reading comprehension, InternalInspector achieves significantly higher
accuracy in aligning the estimated confidence scores with the correctness of
the LLM's predictions and lower calibration error. Furthermore,
InternalInspector excels at HaluEval, a hallucination detection benchmark,
outperforming other internal-based confidence estimation methods in this task."
UniGLM - Training One Unified Language Model for Text-Attributed Graphs,https://arxiv.org/abs/2406.12052,2024-06-17,2024-06-19,0.0,0.0,"Representation learning on text-attributed graphs (TAGs), where nodes are
represented by textual descriptions, is crucial for textual and relational
knowledge systems and recommendation systems. Currently, state-of-the-art
embedding methods for TAGs primarily focus on fine-tuning language models
(e.g., BERT) using structure-aware training signals. While effective, these
methods are tailored for individual TAG and cannot generalize across various
graph scenarios. Given the shared textual space, leveraging multiple TAGs for
joint fine-tuning, aligning text and graph structure from different aspects,
would be more beneficial. Motivated by this, we introduce a novel Unified Graph
Language Model (UniGLM) framework, the first graph embedding model that
generalizes well to both in-domain and cross-domain TAGs. Specifically, UniGLM
is trained over multiple TAGs with different domains and scales using
self-supervised contrastive learning. UniGLM includes an adaptive positive
sample selection technique for identifying structurally similar nodes and a
lazy contrastive module that is devised to accelerate training by minimizing
repetitive encoding calculations. Extensive empirical results across 9
benchmark TAGs demonstrate UniGLM's efficacy against leading embedding
baselines in terms of generalization (various downstream tasks and backbones)
and transfer learning (in and out of domain scenarios). The code is available
at https://github.com/NYUSHCS/UniGLM."
MEDeA - Multi-view Efficient Depth Adjustment,https://arxiv.org/abs/2406.12048,2024-06-17,2024-06-19,0.0,0.0,"The majority of modern single-view depth estimation methods predict relative
depth and thus cannot be directly applied in many real-world scenarios, despite
impressive performance in the benchmarks. Moreover, single-view approaches
cannot guarantee consistency across a sequence of frames. Consistency is
typically addressed with test-time optimization of discrepancy across views;
however, it takes hours to process a single scene. In this paper, we present
MEDeA, an efficient multi-view test-time depth adjustment method, that is an
order of magnitude faster than existing test-time approaches. Given RGB frames
with camera parameters, MEDeA predicts initial depth maps, adjusts them by
optimizing local scaling coefficients, and outputs temporally-consistent depth
maps. Contrary to test-time methods requiring normals, optical flow, or
semantics estimation, MEDeA produces high-quality predictions with a depth
estimation network solely. Our method sets a new state-of-the-art on TUM RGB-D,
7Scenes, and ScanNet benchmarks and successfully handles smartphone-captured
data from ARKitScenes dataset."
$$-bench - A Benchmark for Tool-Agent-User Interaction in Real-World Domains,https://arxiv.org/abs/2406.12045,2024-06-17,2024-06-19,0.0,0.0,"Existing benchmarks do not test language agents on their interaction with
human users or ability to follow domain-specific rules, both of which are vital
for deploying them in real world applications. We propose $\tau$-bench, a
benchmark emulating dynamic conversations between a user (simulated by language
models) and a language agent provided with domain-specific API tools and policy
guidelines. We employ an efficient and faithful evaluation process that
compares the database state at the end of a conversation with the annotated
goal state. We also propose a new metric (pass^k) to evaluate the reliability
of agent behavior over multiple trials. Our experiments show that even
state-of-the-art function calling agents (like gpt-4o) succeed on <50% of the
tasks, and are quite inconsistent (pass^8 <25% in retail). Our findings point
to the need for methods that can improve the ability of agents to act
consistently and follow rules reliably."
Grade Score - Quantifying LLM Performance in Option Selection,https://arxiv.org/abs/2406.12043,2024-06-17,2024-06-19,0.0,0.0,"This study introduces the ""Grade Score"", a novel metric designed to evaluate
the consistency and fairness of Large Language Models (LLMs) when used as
multiple-choice judges with respect to order bias and choice consistency. The
Grade Score combines Entropy, which measures order bias, and Mode Frequency,
which assesses choice stability, offering insights into LLMs' reliability and
impartiality. The study explores techniques such as prompt engineering and
option sampling strategies to optimize the Grade Score, demonstrating their
effectiveness in enhancing LLMs' performance. Results showcase varying
performances among LLMs with respect to prompts and highlight the positive
impact of including irrelevant options. The study also identifies an emergent
behavior in instruction-following models, where they adapt to instructions
targeting specific biases, demonstrating their adaptability. The Grade Score
facilitates comparisons between LLMs and encourages ongoing research towards
optimizing their decision-making processes, with potential implications for
improving their reliability and fairness in various applications. All code is
available on GitHub https://github.com/IoDmitri/GradeLab"
Not All Prompts Are Made Equal - Prompt-based Pruning of Text-to-Image Diffusion Models,https://arxiv.org/abs/2406.12042,2024-06-17,2024-06-19,0.0,0.0,"Text-to-image (T2I) diffusion models have demonstrated impressive image
generation capabilities. Still, their computational intensity prohibits
resource-constrained organizations from deploying T2I models after fine-tuning
them on their internal target data. While pruning techniques offer a potential
solution to reduce the computational burden of T2I models, static pruning
methods use the same pruned model for all input prompts, overlooking the
varying capacity requirements of different prompts. Dynamic pruning addresses
this issue by utilizing a separate sub-network for each prompt, but it prevents
batch parallelism on GPUs. To overcome these limitations, we introduce Adaptive
Prompt-Tailored Pruning (APTP), a novel prompt-based pruning method designed
for T2I diffusion models. Central to our approach is a prompt router model,
which learns to determine the required capacity for an input text prompt and
routes it to an architecture code, given a total desired compute budget for
prompts. Each architecture code represents a specialized model tailored to the
prompts assigned to it, and the number of codes is a hyperparameter. We train
the prompt router and architecture codes using contrastive learning, ensuring
that similar prompts are mapped to nearby codes. Further, we employ optimal
transport to prevent the codes from collapsing into a single one. We
demonstrate APTP's effectiveness by pruning Stable Diffusion (SD) V2.1 using
CC3M and COCO as target datasets. APTP outperforms the single-model pruning
baselines in terms of FID, CLIP, and CMMD scores. Our analysis of the clusters
learned by APTP reveals they are semantically meaningful. We also show that
APTP can automatically discover previously empirically found challenging
prompts for SD, e.g., prompts for generating text images, assigning them to
higher capacity codes."
Soft Prompting for Unlearning in Large Language Models,https://arxiv.org/abs/2406.12038,2024-06-17,2024-06-19,0.0,0.0,"The widespread popularity of Large Language Models (LLMs), partly due to
their unique ability to perform in-context learning, has also brought to light
the importance of ethical and safety considerations when deploying these
pre-trained models. In this work, we focus on investigating machine unlearning
for LLMs motivated by data protection regulations. In contrast to the growing
literature on fine-tuning methods to achieve unlearning, we focus on a
comparatively lightweight alternative called soft prompting to realize the
unlearning of a subset of training data. With losses designed to enforce
forgetting as well as utility preservation, our framework \textbf{S}oft
\textbf{P}rompting for \textbf{U}n\textbf{l}earning (SPUL) learns prompt tokens
that can be appended to an arbitrary query to induce unlearning of specific
examples at inference time without updating LLM parameters. We conduct a
rigorous evaluation of the proposed method and our results indicate that SPUL
can significantly improve the trade-off between utility and forgetting in the
context of text classification and question answering with LLMs. We further
validate our method using multiple LLMs to highlight the scalability of our
framework and provide detailed insights into the choice of hyperparameters and
the influence of the size of unlearning data. Our implementation is available
at \url{https://github.com/karuna-bhaila/llm_unlearning}."
MedCalc-Bench - Evaluating Large Language Models for Medical Calculations,https://arxiv.org/abs/2406.12036,2024-06-17,2024-06-19,0.0,0.0,"As opposed to evaluating computation and logic-based reasoning, current
benchmarks for evaluating large language models (LLMs) in medicine are
primarily focused on question-answering involving domain knowledge and
descriptive reasoning. While such qualitative capabilities are vital to medical
diagnosis, in real-world scenarios, doctors frequently use clinical calculators
that follow quantitative equations and rule-based reasoning paradigms for
evidence-based decision support. To this end, we propose MedCalc-Bench, a
first-of-its-kind dataset focused on evaluating the medical calculation
capability of LLMs. MedCalc-Bench contains an evaluation set of over 1000
manually reviewed instances from 55 different medical calculation tasks. Each
instance in MedCalc-Bench consists of a patient note, a question requesting to
compute a specific medical value, a ground truth answer, and a step-by-step
explanation showing how the answer is obtained. While our evaluation results
show the potential of LLMs in this area, none of them are effective enough for
clinical settings. Common issues include extracting the incorrect entities, not
using the correct equation or rules for a calculation task, or incorrectly
performing the arithmetic for the computation. We hope our study highlights the
quantitative knowledge and reasoning gaps in LLMs within medical settings,
encouraging future improvements of LLMs for various clinical calculation tasks."
Socially Interactive Agents for Robotic Neurorehabilitation Training - Conceptualization and Proof-of-concept Study,https://arxiv.org/abs/2406.12035,2024-06-17,2024-06-19,0.0,0.0,"Individuals with diverse motor abilities often benefit from intensive and
specialized rehabilitation therapies aimed at enhancing their functional
recovery. Nevertheless, the challenge lies in the restricted availability of
neurorehabilitation professionals, hindering the effective delivery of the
necessary level of care. Robotic devices hold great potential in reducing the
dependence on medical personnel during therapy but, at the same time, they
generally lack the crucial human interaction and motivation that traditional
in-person sessions provide. To bridge this gap, we introduce an AI-based system
aimed at delivering personalized, out-of-hospital assistance during
neurorehabilitation training. This system includes a rehabilitation training
device, affective signal classification models, training exercises, and a
socially interactive agent as the user interface. With the assistance of a
professional, the envisioned system is designed to be tailored to accommodate
the unique rehabilitation requirements of an individual patient. Conceptually,
after a preliminary setup and instruction phase, the patient is equipped to
continue their rehabilitation regimen autonomously in the comfort of their
home, facilitated by a socially interactive agent functioning as a virtual
coaching assistant. Our approach involves the integration of an interactive
socially-aware virtual agent into a neurorehabilitation robotic framework, with
the primary objective of recreating the social aspects inherent to in-person
rehabilitation sessions. We also conducted a feasibility study to test the
framework with healthy patients. The results of our preliminary investigation
indicate that participants demonstrated a propensity to adapt to the system.
Notably, the presence of the interactive agent during the proposed exercises
did not act as a source of distraction; instead, it positively impacted users'
engagement."
Large Scale Transfer Learning for Tabular Data via Language Modeling,https://arxiv.org/abs/2406.12031,2024-06-17,2024-06-19,0.0,0.0,"Tabular data -- structured, heterogeneous, spreadsheet-style data with rows
and columns -- is widely used in practice across many domains. However, while
recent foundation models have reduced the need for developing task-specific
datasets and predictors in domains such as language modeling and computer
vision, this transfer learning paradigm has not had similar impact in the
tabular domain. In this work, we seek to narrow this gap and present TabuLa-8B,
a language model for tabular prediction. We define a process for extracting a
large, high-quality training dataset from the TabLib corpus, proposing methods
for tabular data filtering and quality control. Using the resulting dataset,
which comprises over 1.6B rows from 3.1M unique tables, we fine-tune a Llama
3-8B large language model (LLM) for tabular data prediction (classification and
binned regression) using a novel packing and attention scheme for tabular
prediction. Through evaluation across a test suite of 329 datasets, we find
that TabuLa-8B has zero-shot accuracy on unseen tables that is over 15
percentage points (pp) higher than random guessing, a feat that is not possible
with existing state-of-the-art tabular prediction models (e.g. XGBoost,
TabPFN). In the few-shot setting (1-32 shots), without any fine-tuning on the
target datasets, TabuLa-8B is 5-15 pp more accurate than XGBoost and TabPFN
models that are explicitly trained on equal, or even up to 16x more data. We
release our model, code, and data along with the publication of this paper."
SPA-VL - A Comprehensive Safety Preference Alignment Dataset for Vision Language Model,https://arxiv.org/abs/2406.12030,2024-06-17,2024-06-19,0.0,0.0,"The emergence of Vision Language Models (VLMs) has brought unprecedented
advances in understanding multimodal information. The combination of textual
and visual semantics in VLMs is highly complex and diverse, making the safety
alignment of these models challenging. Furthermore, due to the limited study on
the safety alignment of VLMs, there is a lack of large-scale, high-quality
datasets. To address these limitations, we propose a Safety Preference
Alignment dataset for Vision Language Models named SPA-VL. In terms of breadth,
SPA-VL covers 6 harmfulness domains, 13 categories, and 53 subcategories, and
contains 100,788 samples of the quadruple (question, image, chosen response,
rejected response). In terms of depth, the responses are collected from 12
open- (e.g., QwenVL) and closed-source (e.g., Gemini) VLMs to ensure diversity.
The experimental results indicate that models trained with alignment techniques
on the SPA-VL dataset exhibit substantial improvements in harmlessness and
helpfulness while maintaining core capabilities. SPA-VL, as a large-scale,
high-quality, and diverse dataset, represents a significant milestone in
ensuring that VLMs achieve both harmlessness and helpfulness. We have made our
code https://github.com/EchoseChen/SPA-VL-RLHF and SPA-VL dataset url
https://huggingface.co/datasets/sqrti/SPA-VL publicly available."
LiLiuM - eBay's Large Language Models for e-commerce,https://arxiv.org/abs/2406.12023,2024-06-17,2024-06-19,0.0,0.0,"We introduce the LiLiuM series of large language models (LLMs): 1B, 7B, and
13B parameter models developed 100% in-house to fit eBay's specific needs in
the e-commerce domain. This gives eBay full control over all aspects of the
models including license, data, vocabulary, and architecture. We expect these
models to be used as a foundation for fine-tuning and instruction-tuning,
eliminating dependencies to external models.
  The LiLiuM LLMs have been trained on 3 trillion tokens of multilingual text
from general and e-commerce domain. They perform similar to the popular LLaMA-2
models on English natural language understanding (NLU) benchmarks. At the same
time, we outperform LLaMA-2 on non-English NLU tasks, machine translation and
on e-commerce specific downstream tasks.
  As part of our data mixture, we utilize the newly released RedPajama-V2
dataset for training and share our insights regarding data filtering and
deduplication. We also discuss in detail how to serialize structured data for
use in autoregressive language modeling. We provide insights on the effects of
including code and parallel machine translation data in pre-training.
Furthermore, we develop our own tokenizer and model vocabulary, customized
towards e-commerce. This way, we can achieve up to 34% speed-up in text
generation on eBay-specific downstream tasks compared to LLaMA-2.
  Finally, in relation to LLM pretraining, we show that checkpoint averaging
can further improve over the best individual model checkpoint."
Constructing Ancestral Recombination Graphs through Reinforcement Learning,https://arxiv.org/abs/2406.12022,2024-06-17,2024-06-19,0.0,0.0,"Over the years, many approaches have been proposed to build ancestral
recombination graphs (ARGs), graphs used to represent the genetic relationship
between individuals. Among these methods, many rely on the assumption that the
most likely graph is among the shortest ones. In this paper, we propose a new
approach to build short ARGs: Reinforcement Learning (RL). We exploit the
similarities between finding the shortest path between a set of genetic
sequences and their most recent common ancestor and finding the shortest path
between the entrance and exit of a maze, a classic RL problem. In the maze
problem, the learner, called the agent, must learn the directions to take in
order to escape as quickly as possible, whereas in our problem, the agent must
learn the actions to take between coalescence, mutation, and recombination in
order to reach the most recent common ancestor as quickly as possible. Our
results show that RL can be used to build ARGs as short as those built with a
heuristic algorithm optimized to build short ARGs, and sometimes even shorter.
Moreover, our method allows to build a distribution of short ARGs for a given
sample, and can also generalize learning to new samples not used during the
learning process."
When Box Meets Graph Neural Network in Tag-aware Recommendation,https://arxiv.org/abs/2406.12020,2024-06-17,2024-06-19,0.0,0.0,"Last year has witnessed the re-flourishment of tag-aware recommender systems
supported by the LLM-enriched tags. Unfortunately, though large efforts have
been made, current solutions may fail to describe the diversity and uncertainty
inherent in user preferences with only tag-driven profiles. Recently, with the
development of geometry-based techniques, e.g., box embedding, diversity of
user preferences now could be fully modeled as the range within a box in high
dimension space. However, defect still exists as these approaches are incapable
of capturing high-order neighbor signals, i.e., semantic-rich multi-hop
relations within the user-tag-item tripartite graph, which severely limits the
effectiveness of user modeling. To deal with this challenge, in this paper, we
propose a novel algorithm, called BoxGNN, to perform the message aggregation
via combination of logical operations, thereby incorporating high-order
signals. Specifically, we first embed users, items, and tags as hyper-boxes
rather than simple points in the representation space, and define two logical
operations to facilitate the subsequent process. Next, we perform the message
aggregation mechanism via the combination of logical operations, to obtain the
corresponding high-order box representations. Finally, we adopt a volume-based
learning objective with Gumbel smoothing techniques to refine the
representation of boxes. Extensive experiments on two publicly available
datasets and one LLM-enhanced e-commerce dataset have validated the superiority
of BoxGNN compared with various state-of-the-art baselines. The code is
released online"
CItruS - Chunked Instruction-aware State Eviction for Long Sequence Modeling,https://arxiv.org/abs/2406.12018,2024-06-17,2024-06-19,0.0,0.0,"Long sequence modeling has gained broad interest as large language models
(LLMs) continue to advance. Recent research has identified that a large portion
of hidden states within the key-value caches of Transformer models can be
discarded (also termed evicted) without affecting the perplexity performance in
generating long sequences. However, we show that these methods, despite
preserving perplexity performance, often drop information that is important for
solving downstream tasks, a problem which we call information neglect. To
address this issue, we introduce Chunked Instruction-aware State Eviction
(CItruS), a novel modeling technique that integrates the attention preferences
useful for a downstream task into the eviction process of hidden states. In
addition, we design a method for chunked sequence processing to further improve
efficiency. Our training-free method exhibits superior performance on long
sequence comprehension and retrieval tasks over several strong baselines under
the same memory budget, while preserving language modeling perplexity."
Sparsity-Constraint Optimization via Splicing Iteration,https://arxiv.org/abs/2406.12017,2024-06-17,2024-06-19,0.0,0.0,"Sparsity-constraint optimization has wide applicability in signal processing,
statistics, and machine learning. Existing fast algorithms must burdensomely
tune parameters, such as the step size or the implementation of precise stop
criteria, which may be challenging to determine in practice. To address this
issue, we develop an algorithm named Sparsity-Constraint Optimization via
sPlicing itEration (SCOPE) to optimize nonlinear differential objective
functions with strong convexity and smoothness in low dimensional subspaces.
Algorithmically, the SCOPE algorithm converges effectively without tuning
parameters. Theoretically, SCOPE has a linear convergence rate and converges to
a solution that recovers the true support set when it correctly specifies the
sparsity. We also develop parallel theoretical results without
restricted-isometry-property-type conditions. We apply SCOPE's versatility and
power to solve sparse quadratic optimization, learn sparse classifiers, and
recover sparse Markov networks for binary variables. The numerical results on
these specific tasks reveal that SCOPE perfectly identifies the true support
set with a 10--1000 speedup over the standard exact solver, confirming SCOPE's
algorithmic and theoretical merits. Our open-source Python package skscope
based on C++ implementation is publicly available on GitHub, reaching a
ten-fold speedup on the competing convex relaxation methods implemented by the
cvxpy library."
Prefixing Attention Sinks can Mitigate Activation Outliers for Large Language Model Quantization,https://arxiv.org/abs/2406.12016,2024-06-17,2024-06-19,0.0,0.0,"Despite recent advances in LLM quantization, activation quantization remains
to be challenging due to the activation outliers. Conventional remedies, e.g.,
mixing precisions for different channels, introduce extra overhead and reduce
the speedup. In this work, we develop a simple yet effective strategy to
facilitate per-tensor activation quantization by preventing the generation of
problematic tokens. Precisely, we propose a method to find a set of key-value
cache, coined CushionCache, which mitigates outliers in subsequent tokens when
inserted as a prefix. CushionCache works in two steps: First, we greedily
search for a prompt token sequence that minimizes the maximum activation values
in subsequent tokens. Then, we further tune the token cache to regularize the
activations of subsequent tokens to be more quantization-friendly. The proposed
method successfully addresses activation outliers of LLMs, providing a
substantial performance boost for per-tensor activation quantization methods.
We thoroughly evaluate our method over a wide range of models and benchmarks
and find that it significantly surpasses the established baseline of per-tensor
W8A8 quantization and can be seamlessly integrated with the recent activation
quantization method."
The Benefits and Risks of Transductive Approaches for AI Fairness,https://arxiv.org/abs/2406.12011,2024-06-17,2024-06-19,0.0,0.0,"Recently, transductive learning methods, which leverage holdout sets during
training, have gained popularity for their potential to improve speed,
accuracy, and fairness in machine learning models. Despite this, the
composition of the holdout set itself, particularly the balance of sensitive
sub-groups, has been largely overlooked. Our experiments on CIFAR and CelebA
datasets show that compositional changes in the holdout set can substantially
influence fairness metrics. Imbalanced holdout sets exacerbate existing
disparities, while balanced holdouts can mitigate issues introduced by
imbalanced training data. These findings underline the necessity of
constructing holdout sets that are both diverse and representative."
FinTruthQA - A Benchmark Dataset for Evaluating the Quality of Financial Information Disclosure,https://arxiv.org/abs/2406.12009,2024-06-17,2024-06-19,0.0,0.0,"Accurate and transparent financial information disclosure is crucial in the
fields of accounting and finance, ensuring market efficiency and investor
confidence. Among many information disclosure platforms, the Chinese stock
exchanges' investor interactive platform provides a novel and interactive way
for listed firms to disclose information of interest to investors through an
online question-and-answer (Q&A) format. However, it is common for listed firms
to respond to questions with limited or no substantive information, and
automatically evaluating the quality of financial information disclosure on
large amounts of Q&A pairs is challenging. This paper builds a benchmark
FinTruthQA, that can evaluate advanced natural language processing (NLP)
techniques for the automatic quality assessment of information disclosure in
financial Q&A data. FinTruthQA comprises 6,000 real-world financial Q&A entries
and each Q&A was manually annotated based on four conceptual dimensions of
accounting. We benchmarked various NLP techniques on FinTruthQA, including
statistical machine learning models, pre-trained language model and their
fine-tuned versions, as well as the large language model GPT-4. Experiments
showed that existing NLP models have strong predictive ability for real
question identification and question relevance tasks, but are suboptimal for
answer relevance and answer readability tasks. By establishing this benchmark,
we provide a robust foundation for the automatic evaluation of information
disclosure, significantly enhancing the transparency and quality of financial
reporting. FinTruthQA can be used by auditors, regulators, and financial
analysts for real-time monitoring and data-driven decision-making, as well as
by researchers for advanced studies in accounting and finance, ultimately
fostering greater trust and efficiency in the financial markets."
QC-Forest - a Classical-Quantum Algorithm to Provably Speedup Retraining of Random Forest,https://arxiv.org/abs/2406.12008,2024-06-17,2024-06-19,0.0,0.0,"Random Forest (RF) is a popular tree-ensemble method for supervised learning,
prized for its ease of use and flexibility. Online RF models require to account
for new training data to maintain model accuracy. This is particularly
important in applications where data is periodically and sequentially generated
over time in data streams, such as auto-driving systems, and credit card
payments. In this setting, performing periodic model retraining with the old
and new data accumulated is beneficial as it fully captures possible drifts in
the data distribution over time. However, this is unpractical with
state-of-the-art classical algorithms for RF as they scale linearly with the
accumulated number of samples. We propose QC-Forest, a classical-quantum
algorithm designed to time-efficiently retrain RF models in the streaming
setting for multi-class classification and regression, achieving a runtime
poly-logarithmic in the total number of accumulated samples. QC-Forest
leverages Des-q, a quantum algorithm for single tree construction and
retraining proposed by Kumar et al. by expanding to multi-class classification,
as the original proposal was limited to binary classes, and introducing an
exact classical method to replace an underlying quantum subroutine incurring a
finite error, while maintaining the same poly-logarithmic dependence. Finally,
we showcase that QC-Forest achieves competitive accuracy in comparison to
state-of-the-art RF methods on widely used benchmark datasets with up to 80,000
samples, while significantly speeding up the model retrain."
"Modeling, Inference, and Prediction in Mobility-Based Compartmental Models for Epidemiology",https://arxiv.org/abs/2406.12002,2024-06-17,2024-06-19,0.0,0.0,"Classical compartmental models in epidemiology often assume a homogeneous
population for simplicity, which neglects the inherent heterogeneity among
individuals. This assumption frequently leads to inaccurate predictions when
applied to real-world data. For example, evidence has shown that classical
models overestimate the final pandemic size in the H1N1-2009 and COVID-19
outbreaks. To address this issue, we introduce individual mobility as a key
factor in disease transmission and control. We characterize disease dynamics
using mobility distribution functions for each compartment and propose a
mobility-based compartmental model that incorporates population heterogeneity.
Our results demonstrate that, for the same basic reproduction number, our
mobility-based model predicts a smaller final pandemic size compared to the
classical models, effectively addressing the common overestimation problem.
Additionally, we infer mobility distributions from the time series of the
infected population. We provide sufficient conditions for uniquely identifying
the mobility distribution from a dataset and propose a machine-learning-based
approach to learn mobility from both synthesized and real-world data."
Look Further Ahead - Testing the Limits of GPT-4 in Path Planning,https://arxiv.org/abs/2406.12000,2024-06-17,2024-06-19,0.0,0.0,"Large Language Models (LLMs) have shown impressive capabilities across a wide
variety of tasks. However, they still face challenges with long-horizon
planning. To study this, we propose path planning tasks as a platform to
evaluate LLMs' ability to navigate long trajectories under geometric
constraints. Our proposed benchmark systematically tests path-planning skills
in complex settings. Using this, we examined GPT-4's planning abilities using
various task representations and prompting approaches. We found that framing
prompts as Python code and decomposing long trajectory tasks improve GPT-4's
path planning effectiveness. However, while these approaches show some promise
toward improving the planning ability of the model, they do not obtain optimal
paths and fail at generalizing over extended horizons."
Online Pareto-Optimal Decision-Making for Complex Tasks using Active Inference,https://arxiv.org/abs/2406.11984,2024-06-17,2024-06-19,0.0,0.0,"When a robot autonomously performs a complex task, it frequently must balance
competing objectives while maintaining safety. This becomes more difficult in
uncertain environments with stochastic outcomes. Enhancing transparency in the
robot's behavior and aligning with user preferences are also crucial. This
paper introduces a novel framework for multi-objective reinforcement learning
that ensures safe task execution, optimizes trade-offs between objectives, and
adheres to user preferences. The framework has two main layers: a
multi-objective task planner and a high-level selector. The planning layer
generates a set of optimal trade-off plans that guarantee satisfaction of a
temporal logic task. The selector uses active inference to decide which
generated plan best complies with user preferences and aids learning. Operating
iteratively, the framework updates a parameterized learning model based on
collected data. Case studies and benchmarks on both manipulation and mobile
robots show that our framework outperforms other methods and (i) learns
multiple optimal trade-offs, (ii) adheres to a user preference, and (iii)
allows the user to adjust the balance between (i) and (ii)."
Prompt Design Matters for Computational Social Science Tasks but in Unpredictable Ways,https://arxiv.org/abs/2406.11980,2024-06-17,2024-06-19,0.0,0.0,"Manually annotating data for computational social science tasks can be
costly, time-consuming, and emotionally draining. While recent work suggests
that LLMs can perform such annotation tasks in zero-shot settings, little is
known about how prompt design impacts LLMs' compliance and accuracy. We conduct
a large-scale multi-prompt experiment to test how model selection (ChatGPT,
PaLM2, and Falcon7b) and prompt design features (definition inclusion, output
type, explanation, and prompt length) impact the compliance and accuracy of
LLM-generated annotations on four CSS tasks (toxicity, sentiment, rumor stance,
and news frames). Our results show that LLM compliance and accuracy are highly
prompt-dependent. For instance, prompting for numerical scores instead of
labels reduces all LLMs' compliance and accuracy. The overall best prompting
setup is task-dependent, and minor prompt changes can cause large changes in
the distribution of generated labels. By showing that prompt design
significantly impacts the quality and distribution of LLM-generated
annotations, this work serves as both a warning and practical guide for
researchers and practitioners."
Dialogue Action Tokens - Steering Language Models in Goal-Directed Dialogue with a Multi-Turn Planner,https://arxiv.org/abs/2406.11978,2024-06-17,2024-06-19,0.0,0.0,"We present an approach called Dialogue Action Tokens (DAT) that adapts
language model agents to plan goal-directed dialogues. The core idea is to
treat each utterance as an action, thereby converting dialogues into games
where existing approaches such as reinforcement learning can be applied.
Specifically, we freeze a pretrained language model and train a small planner
model that predicts a continuous action vector, used for controlled generation
in each round. This design avoids the problem of language degradation under
reward optimization. When evaluated on the Sotopia platform for social
simulations, the DAT-steered LLaMA model surpasses GPT-4's performance. We also
apply DAT to steer an attacker language model in a novel multi-turn red-teaming
setting, revealing a potential new attack surface."
Reframing linguistic bootstrapping as joint inference using visually-grounded grammar induction models,https://arxiv.org/abs/2406.11977,2024-06-17,2024-06-19,0.0,0.0,"Semantic and syntactic bootstrapping posit that children use their prior
knowledge of one linguistic domain, say syntactic relations, to help later
acquire another, such as the meanings of new words. Empirical results
supporting both theories may tempt us to believe that these are different
learning strategies, where one may precede the other. Here, we argue that they
are instead both contingent on a more general learning strategy for language
acquisition: joint learning. Using a series of neural visually-grounded grammar
induction models, we demonstrate that both syntactic and semantic bootstrapping
effects are strongest when syntax and semantics are learnt simultaneously.
Joint learning results in better grammar induction, realistic lexical category
learning, and better interpretations of novel sentence and verb meanings. Joint
learning makes language acquisition easier for learners by mutually
constraining the hypotheses spaces for both syntax and semantics. Studying the
dynamics of joint inference over many input sources and modalities represents
an important new direction for language modeling and learning research in both
cognitive sciences and AI, as it may help us explain how language can be
acquired in more constrained learning settings."
mDPO - Conditional Preference Optimization for Multimodal Large Language Models,https://arxiv.org/abs/2406.11839,2024-06-17,2024-06-19,0.0,0.0,"Direct preference optimization (DPO) has shown to be an effective method for
large language model (LLM) alignment. Recent works have attempted to apply DPO
to multimodal scenarios but have found it challenging to achieve consistent
improvement. Through a comparative experiment, we identify the unconditional
preference problem in multimodal preference optimization, where the model
overlooks the image condition. To address this problem, we propose mDPO, a
multimodal DPO objective that prevents the over-prioritization of language-only
preferences by also optimizing image preference. Moreover, we introduce a
reward anchor that forces the reward to be positive for chosen responses,
thereby avoiding the decrease in their likelihood -- an intrinsic problem of
relative preference optimization. Experiments on two multimodal LLMs of
different sizes and three widely used benchmarks demonstrate that mDPO
effectively addresses the unconditional preference problem in multimodal
preference optimization and significantly improves model performance,
particularly in reducing hallucination."
MMDU - A Multi-Turn Multi-Image Dialog Understanding Benchmark and Instruction-Tuning Dataset for LVLMs,https://arxiv.org/abs/2406.11833,2024-06-17,2024-06-19,0.0,0.0,"Generating natural and meaningful responses to communicate with multi-modal
human inputs is a fundamental capability of Large Vision-Language
Models(LVLMs). While current open-source LVLMs demonstrate promising
performance in simplified scenarios such as single-turn single-image input,
they fall short in real-world conversation scenarios such as following
instructions in a long context history with multi-turn and multi-images.
Existing LVLM benchmarks primarily focus on single-choice questions or
short-form responses, which do not adequately assess the capabilities of LVLMs
in real-world human-AI interaction applications. Therefore, we introduce MMDU,
a comprehensive benchmark, and MMDU-45k, a large-scale instruction tuning
dataset, designed to evaluate and improve LVLMs' abilities in multi-turn and
multi-image conversations. We employ the clustering algorithm to ffnd the
relevant images and textual descriptions from the open-source Wikipedia and
construct the question-answer pairs by human annotators with the assistance of
the GPT-4o model. MMDU has a maximum of 18k image+text tokens, 20 images, and
27 turns, which is at least 5x longer than previous benchmarks and poses
challenges to current LVLMs. Our in-depth analysis of 15 representative LVLMs
using MMDU reveals that open-source LVLMs lag behind closed-source counterparts
due to limited conversational instruction tuning data. We demonstrate that
ffne-tuning open-source LVLMs on MMDU-45k signiffcantly address this gap,
generating longer and more accurate conversations, and improving scores on MMDU
and existing benchmarks (MMStar: +1.1%, MathVista: +1.5%, ChartQA:+1.2%). Our
contributions pave the way for bridging the gap between current LVLM models and
real-world application demands. This project is available at
https://github.com/Liuziyu77/MMDU."
Language Modeling with Editable External Knowledge,https://arxiv.org/abs/2406.11830,2024-06-17,2024-06-19,0.0,0.0,"When the world changes, so does the text that humans write about it. How do
we build language models that can be easily updated to reflect these changes?
One popular approach is retrieval-augmented generation, in which new documents
are inserted into a knowledge base and retrieved during prediction for
downstream tasks. Most prior work on these systems have focused on improving
behavior during prediction through better retrieval or reasoning. This paper
introduces ERASE, which instead improves model behavior when new documents are
acquired, by incrementally deleting or rewriting other entries in the knowledge
base each time a document is added. In two new benchmark datasets evaluating
models' ability to answer questions about a stream of news articles or
conversations, ERASE improves accuracy relative to conventional
retrieval-augmented generation by 7-13% (Mixtral-8x7B) and 6-10% (Llama-3-8B)
absolute. Code and data are available at https://github.com/belindal/ERASE"
Learning sum of diverse features - computational hardness and efficient gradient-based training for ridge combinations,https://arxiv.org/abs/2406.11828,2024-06-17,2024-06-19,0.0,0.0,"We study the computational and sample complexity of learning a target
function $f_*:\mathbb{R}^d\to\mathbb{R}$ with additive structure, that is,
$f_*(x) = \frac{1}{\sqrt{M}}\sum_{m=1}^M f_m(\langle x, v_m\rangle)$, where
$f_1,f_2,...,f_M:\mathbb{R}\to\mathbb{R}$ are nonlinear link functions of
single-index models (ridge functions) with diverse and near-orthogonal index
features $\{v_m\}_{m=1}^M$, and the number of additive tasks $M$ grows with the
dimensionality $M\asymp d^\gamma$ for $\gamma\ge 0$. This problem setting is
motivated by the classical additive model literature, the recent representation
learning theory of two-layer neural network, and large-scale pretraining where
the model simultaneously acquires a large number of ""skills"" that are often
localized in distinct parts of the trained network. We prove that a large
subset of polynomial $f_*$ can be efficiently learned by gradient descent
training of a two-layer neural network, with a polynomial statistical and
computational complexity that depends on the number of tasks $M$ and the
information exponent of $f_m$, despite the unknown link function and $M$
growing with the dimensionality. We complement this learnability guarantee with
computational hardness result by establishing statistical query (SQ) lower
bounds for both the correlational SQ and full SQ algorithms."
WPO - Enhancing RLHF with Weighted Preference Optimization,https://arxiv.org/abs/2406.11827,2024-06-17,2024-06-19,0.0,0.0,"Reinforcement learning from human feedback (RLHF) is a promising solution to
align large language models (LLMs) more closely with human values. Off-policy
preference optimization, where the preference data is obtained from other
models, is widely adopted due to its cost efficiency and scalability. However,
off-policy preference optimization often suffers from a distributional gap
between the policy used for data collection and the target policy, leading to
suboptimal optimization. In this paper, we propose a novel strategy to mitigate
this problem by simulating on-policy learning with off-policy preference data.
Our Weighted Preference Optimization (WPO) method adapts off-policy data to
resemble on-policy data more closely by reweighting preference pairs according
to their probability under the current policy. This method not only addresses
the distributional gap problem but also enhances the optimization process
without incurring additional costs. We validate our method on instruction
following benchmarks including Alpaca Eval 2 and MT-bench. WPO not only
outperforms Direct Preference Optimization (DPO) by up to 5.6% on Alpaca Eval 2
but also establishes a remarkable length-controlled winning rate against
GPT-4-turbo of 48.6% based on Llama-3-8B-Instruct, making it the strongest 8B
model on the leaderboard. We will release the code and models at
https://github.com/wzhouad/WPO."
Spectral Introspection Identifies Group Training Dynamics in Deep Neural Networks for Neuroimaging,https://arxiv.org/abs/2406.11825,2024-06-17,2024-06-19,0.0,0.0,"Neural networks, whice have had a profound effect on how researchers study
complex phenomena, do so through a complex, nonlinear mathematical structure
which can be difficult for human researchers to interpret. This obstacle can be
especially salient when researchers want to better understand the emergence of
particular model behaviors such as bias, overfitting, overparametrization, and
more. In Neuroimaging, the understanding of how such phenomena emerge is
fundamental to preventing and informing users of the potential risks involved
in practice. In this work, we present a novel introspection framework for Deep
Learning on Neuroimaging data, which exploits the natural structure of gradient
computations via the singular value decomposition of gradient components during
reverse-mode auto-differentiation. Unlike post-hoc introspection techniques,
which require fully-trained models for evaluation, our method allows for the
study of training dynamics on the fly, and even more interestingly, allow for
the decomposition of gradients based on which samples belong to particular
groups of interest. We demonstrate how the gradient spectra for several common
deep learning models differ between schizophrenia and control participants from
the COBRE study, and illustrate how these trajectories may reveal specific
training dynamics helpful for further analysis."
On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding - What Matters in Reading and Reasoning,https://arxiv.org/abs/2406.11823,2024-06-17,2024-06-19,0.0,0.0,"Recent advancements in language and vision assistants have showcased
impressive capabilities but suffer from a lack of transparency, limiting
broader research and reproducibility. While open-source models handle general
image tasks effectively, they face challenges with the high computational
demands of complex visually-situated text understanding. Such tasks often
require increased token inputs and large vision modules to harness
high-resolution information. Striking a balance between model size and data
importance remains an open question. This study aims to redefine the design of
vision-language models by identifying key components and creating efficient
models with constrained inference costs. By strategically formulating datasets,
optimizing vision modules, and enhancing supervision techniques, we achieve
significant improvements in inference throughput while maintaining high
performance. Extensive experiments across models ranging from 160M to 13B
parameters offer insights into model optimization. We will fully open-source
our codebase, models, and datasets at https://github.com/naver-ai/elva ."
Embodied Instruction Following in Unknown Environments,https://arxiv.org/abs/2406.11818,2024-06-17,2024-06-19,0.0,0.0,"Enabling embodied agents to complete complex human instructions from natural
language is crucial to autonomous systems in household services. Conventional
methods can only accomplish human instructions in the known environment where
all interactive objects are provided to the embodied agent, and directly
deploying the existing approaches for the unknown environment usually generates
infeasible plans that manipulate non-existing objects. On the contrary, we
propose an embodied instruction following (EIF) method for complex tasks in the
unknown environment, where the agent efficiently explores the unknown
environment to generate feasible plans with existing objects to accomplish
abstract instructions. Specifically, we build a hierarchical embodied
instruction following framework including the high-level task planner and the
low-level exploration controller with multimodal large language models. We then
construct a semantic representation map of the scene with dynamic region
attention to demonstrate the known visual clues, where the goal of task
planning and scene exploration is aligned for human instruction. For the task
planner, we generate the feasible step-by-step plans for human goal
accomplishment according to the task completion process and the known visual
clues. For the exploration controller, the optimal navigation or object
interaction policy is predicted based on the generated step-wise plans and the
known visual clues. The experimental results demonstrate that our method can
achieve 45.09% success rate in 204 complex human instructions such as making
breakfast and tidying rooms in large house-level scenes."
Iterative Length-Regularized Direct Preference Optimization - A Case Study on Improving 7B Language Models to GPT-4 Level,https://arxiv.org/abs/2406.11817,2024-06-17,2024-06-19,0.0,0.0,"Direct Preference Optimization (DPO), a standard method for aligning language
models with human preferences, is traditionally applied to offline preferences.
Recent studies show that DPO benefits from iterative training with online
preferences labeled by a trained reward model. In this work, we identify a
pitfall of vanilla iterative DPO - improved response quality can lead to
increased verbosity. To address this, we introduce iterative length-regularized
DPO (iLR-DPO) to penalize response length. Our empirical results show that
iLR-DPO can enhance a 7B model to perform on par with GPT-4 without increasing
verbosity. Specifically, our 7B model achieves a $50.5\%$ length-controlled win
rate against $\texttt{GPT-4 Preview}$ on AlpacaEval 2.0, and excels across
standard benchmarks including MT-Bench, Arena-Hard and OpenLLM Leaderboard.
These results demonstrate the effectiveness of iterative DPO in aligning
language models with human feedback."
LLARVA - Vision-Action Instruction Tuning Enhances Robot Learning,https://arxiv.org/abs/2406.11815,2024-06-17,2024-06-19,0.0,0.0,"In recent years, instruction-tuned Large Multimodal Models (LMMs) have been
successful at several tasks, including image captioning and visual question
answering; yet leveraging these models remains an open question for robotics.
Prior LMMs for robotics applications have been extensively trained on language
and action data, but their ability to generalize in different settings has
often been less than desired. To address this, we introduce LLARVA, a model
trained with a novel instruction tuning method that leverages structured
prompts to unify a range of robotic learning tasks, scenarios, and
environments. Additionally, we show that predicting intermediate 2-D
representations, which we refer to as ""visual traces"", can help further align
vision and action spaces for robot learning. We generate 8.5M image-visual
trace pairs from the Open X-Embodiment dataset in order to pre-train our model,
and we evaluate on 12 different tasks in the RLBench simulator as well as a
physical Franka Emika Panda 7-DoF robot. Our experiments yield strong
performance, demonstrating that LLARVA - using 2-D and language representations
- performs well compared to several contemporary baselines, and can generalize
across various robot environments and configurations."
Stochastic Neural Network Symmetrisation in Markov Categories,https://arxiv.org/abs/2406.11814,2024-06-17,2024-06-19,0.0,0.0,"We consider the problem of symmetrising a neural network along a group
homomorphism: given a homomorphism $\varphi : H \to G$, we would like a
procedure that converts $H$-equivariant neural networks into $G$-equivariant
ones. We formulate this in terms of Markov categories, which allows us to
consider neural networks whose outputs may be stochastic, but with
measure-theoretic details abstracted away. We obtain a flexible, compositional,
and generic framework for symmetrisation that relies on minimal assumptions
about the structure of the group and the underlying neural network
architecture. Our approach recovers existing methods for deterministic
symmetrisation as special cases, and extends directly to provide a novel
methodology for stochastic symmetrisation also. Beyond this, we believe our
findings also demonstrate the utility of Markov categories for addressing
problems in machine learning in a conceptual yet mathematically rigorous way."
How Do Large Language Models Acquire Factual Knowledge During Pretraining?,https://arxiv.org/abs/2406.11813,2024-06-17,2024-06-19,0.0,0.0,"Despite the recent observation that large language models (LLMs) can store
substantial factual knowledge, there is a limited understanding of the
mechanisms of how they acquire factual knowledge through pretraining. This work
addresses this gap by studying how LLMs acquire factual knowledge during
pretraining. The findings reveal several important insights into the dynamics
of factual knowledge acquisition during pretraining. First, counterintuitively,
we observe that pretraining on more data shows no significant improvement in
the model's capability to acquire and maintain factual knowledge. Next, there
is a power-law relationship between training steps and forgetting of
memorization and generalization of factual knowledge, and LLMs trained with
duplicated training data exhibit faster forgetting. Third, training LLMs with
larger batch sizes can enhance the models' robustness to forgetting. Overall,
our observations suggest that factual knowledge acquisition in LLM pretraining
occurs by progressively increasing the probability of factual knowledge
presented in the pretraining data at each step. However, this increase is
diluted by subsequent forgetting. Based on this interpretation, we demonstrate
that we can provide plausible explanations for recently observed behaviors of
LLMs, such as the poor performance of LLMs on long-tail knowledge and the
benefits of deduplicating the pretraining corpus."
RepLiQA - A Question-Answering Dataset for Benchmarking LLMs on Unseen Reference Content,https://arxiv.org/abs/2406.11811,2024-06-17,2024-06-19,0.0,0.0,"Large Language Models (LLMs) are trained on vast amounts of data, most of
which is automatically scraped from the internet. This data includes
encyclopedic documents that harbor a vast amount of general knowledge (e.g.,
Wikipedia) but also potentially overlap with benchmark datasets used for
evaluating LLMs. Consequently, evaluating models on test splits that might have
leaked into the training set is prone to misleading conclusions. To foster
sound evaluation of language models, we introduce a new test dataset named
RepLiQA, suited for question-answering and topic retrieval tasks. RepLiQA is a
collection of five splits of test sets, four of which have not been released to
the internet or exposed to LLM APIs prior to this publication. Each sample in
RepLiQA comprises (1) a reference document crafted by a human annotator and
depicting an imaginary scenario (e.g., a news article) absent from the
internet; (2) a question about the document's topic; (3) a ground-truth answer
derived directly from the information in the document; and (4) the paragraph
extracted from the reference document containing the answer. As such, accurate
answers can only be generated if a model can find relevant content within the
provided document. We run a large-scale benchmark comprising several
state-of-the-art LLMs to uncover differences in performance across models of
various types and sizes in a context-conditional language modeling setting.
Released splits of RepLiQA can be found here:
https://huggingface.co/datasets/ServiceNow/repliqa."
Computationally Efficient RL under Linear Bellman Completeness for Deterministic Dynamics,https://arxiv.org/abs/2406.11810,2024-06-17,2024-06-19,0.0,0.0,"We study computationally and statistically efficient Reinforcement Learning
algorithms for the linear Bellman Complete setting, a setting that uses linear
function approximation to capture value functions and unifies existing models
like linear Markov Decision Processes (MDP) and Linear Quadratic Regulators
(LQR). While it is known from the prior works that this setting is
statistically tractable, it remained open whether a computationally efficient
algorithm exists. Our work provides a computationally efficient algorithm for
the linear Bellman complete setting that works for MDPs with large action
spaces, random initial states, and random rewards but relies on the underlying
dynamics to be deterministic. Our approach is based on randomization: we inject
random noise into least square regression problems to perform optimistic value
iteration. Our key technical contribution is to carefully design the noise to
only act in the null space of the training data to ensure optimism while
circumventing a subtle error amplification issue."
Physics-Constrained Learning for PDE Systems with Uncertainty Quantified Port-Hamiltonian Models,https://arxiv.org/abs/2406.11809,2024-06-17,2024-06-19,0.0,0.0,"Modeling the dynamics of flexible objects has become an emerging topic in the
community as these objects become more present in many applications, e.g., soft
robotics. Due to the properties of flexible materials, the movements of soft
objects are often highly nonlinear and, thus, complex to predict. Data-driven
approaches seem promising for modeling those complex dynamics but often neglect
basic physical principles, which consequently makes them untrustworthy and
limits generalization. To address this problem, we propose a
physics-constrained learning method that combines powerful learning tools and
reliable physical models. Our method leverages the data collected from
observations by sending them into a Gaussian process that is physically
constrained by a distributed Port-Hamiltonian model. Based on the Bayesian
nature of the Gaussian process, we not only learn the dynamics of the system,
but also enable uncertainty quantification. Furthermore, the proposed approach
preserves the compositional nature of Port-Hamiltonian systems."
Efficient Discovery of Significant Patterns with Few-Shot Resampling,https://arxiv.org/abs/2406.11803,2024-06-17,2024-06-19,0.0,0.0,"Significant pattern mining is a fundamental task in mining transactional
data, requiring to identify patterns significantly associated with the value of
a given feature, the target. In several applications, such as biomedicine,
basket market analysis, and social networks, the goal is to discover patterns
whose association with the target is defined with respect to an underlying
population, or process, of which the dataset represents only a collection of
observations, or samples. A natural way to capture the association of a pattern
with the target is to consider its statistical significance, assessing its
deviation from the (null) hypothesis of independence between the pattern and
the target. While several algorithms have been proposed to find statistically
significant patterns, it remains a computationally demanding task, and for
complex patterns such as subgroups, no efficient solution exists.
  We present FSR, an efficient algorithm to identify statistically significant
patterns with rigorous guarantees on the probability of false discoveries. FSR
builds on a novel general framework for mining significant patterns that
captures some of the most commonly considered patterns, including itemsets,
sequential patterns, and subgroups. FSR uses a small number of resampled
datasets, obtained by assigning i.i.d. labels to each transaction, to
rigorously bound the supremum deviation of a quality statistic measuring the
significance of patterns. FSR builds on novel tight bounds on the supremum
deviation that require to mine a small number of resampled datasets, while
providing a high effectiveness in discovering significant patterns. As a test
case, we consider significant subgroup mining, and our evaluation on several
real datasets shows that FSR is effective in discovering significant subgroups,
while requiring a small number of resampled datasets."
GAugLLM - Improving Graph Contrastive Learning for Text-Attributed Graphs with Large Language Models,https://arxiv.org/abs/2406.11945,2024-06-17,2024-06-19,0.0,0.0,"This work studies self-supervised graph learning for text-attributed graphs
(TAGs) where nodes are represented by textual attributes. Unlike traditional
graph contrastive methods that perturb the numerical feature space and alter
the graph's topological structure, we aim to improve view generation through
language supervision. This is driven by the prevalence of textual attributes in
real applications, which complement graph structures with rich semantic
information. However, this presents challenges because of two major reasons.
First, text attributes often vary in length and quality, making it difficulty
to perturb raw text descriptions without altering their original semantic
meanings. Second, although text attributes complement graph structures, they
are not inherently well-aligned. To bridge the gap, we introduce GAugLLM, a
novel framework for augmenting TAGs. It leverages advanced large language
models like Mistral to enhance self-supervised graph learning. Specifically, we
introduce a mixture-of-prompt-expert technique to generate augmented node
features. This approach adaptively maps multiple prompt experts, each of which
modifies raw text attributes using prompt engineering, into numerical feature
space. Additionally, we devise a collaborative edge modifier to leverage
structural and textual commonalities, enhancing edge augmentation by examining
or building connections between nodes. Empirical results across five benchmark
datasets spanning various domains underscore our framework's ability to enhance
the performance of leading contrastive methods as a plug-in tool. Notably, we
observe that the augmented features and graph structure can also enhance the
performance of standard generative methods, as well as popular graph neural
networks. The open-sourced implementation of our GAugLLM is available at
Github."
Transcoders Find Interpretable LLM Feature Circuits,https://arxiv.org/abs/2406.11944,2024-06-17,2024-06-19,0.0,0.0,"A key goal in mechanistic interpretability is circuit analysis: finding
sparse subgraphs of models corresponding to specific behaviors or capabilities.
However, MLP sublayers make fine-grained circuit analysis on transformer-based
language models difficult. In particular, interpretable features -- such as
those found by sparse autoencoders (SAEs) -- are typically linear combinations
of extremely many neurons, each with its own nonlinearity to account for.
Circuit analysis in this setting thus either yields intractably large circuits
or fails to disentangle local and global behavior. To address this we explore
transcoders, which seek to faithfully approximate a densely activating MLP
layer with a wider, sparsely-activating MLP layer. We successfully train
transcoders on language models with 120M, 410M, and 1.4B parameters, and find
them to perform at least on par with SAEs in terms of sparsity, faithfulness,
and human-interpretability. We then introduce a novel method for using
transcoders to perform weights-based circuit analysis through MLP sublayers.
The resulting circuits neatly factorize into input-dependent and
input-invariant terms. Finally, we apply transcoders to reverse-engineer
unknown circuits in the model, and we obtain novel insights regarding the
greater-than circuit in GPT2-small. Our results suggest that transcoders can
prove effective in decomposing model computations involving MLPs into
interpretable circuits. Code is available at
https://github.com/jacobdunefsky/transcoder_circuits."
Safety Arithmetic - A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations,https://arxiv.org/abs/2406.11801,2024-06-17,2024-06-19,0.0,0.0,"Ensuring the safe alignment of large language models (LLMs) with human values
is critical as they become integral to applications like translation and
question answering. Current alignment methods struggle with dynamic user
intentions and complex objectives, making models vulnerable to generating
harmful content. We propose Safety Arithmetic, a training-free framework
enhancing LLM safety across different scenarios: Base models, Supervised
fine-tuned models (SFT), and Edited models. Safety Arithmetic involves Harm
Direction Removal to avoid harmful content and Safety Alignment to promote safe
responses. Additionally, we present NoIntentEdit, a dataset highlighting edit
instances that could compromise model safety if used unintentionally. Our
experiments show that Safety Arithmetic significantly improves safety measures,
reduces over-safety, and maintains model utility, outperforming existing
methods in ensuring safe content generation."
Personalized Federated Knowledge Graph Embedding with Client-Wise Relation Graph,https://arxiv.org/abs/2406.11943,2024-06-17,2024-06-19,0.0,0.0,"Federated Knowledge Graph Embedding (FKGE) has recently garnered considerable
interest due to its capacity to extract expressive representations from
distributed knowledge graphs, while concurrently safeguarding the privacy of
individual clients. Existing FKGE methods typically harness the arithmetic mean
of entity embeddings from all clients as the global supplementary knowledge,
and learn a replica of global consensus entities embeddings for each client.
However, these methods usually neglect the inherent semantic disparities among
distinct clients. This oversight not only results in the globally shared
complementary knowledge being inundated with too much noise when tailored to a
specific client, but also instigates a discrepancy between local and global
optimization objectives. Consequently, the quality of the learned embeddings is
compromised. To address this, we propose Personalized Federated knowledge graph
Embedding with client-wise relation Graph (PFedEG), a novel approach that
employs a client-wise relation graph to learn personalized embeddings by
discerning the semantic relevance of embeddings from other clients.
Specifically, PFedEG learns personalized supplementary knowledge for each
client by amalgamating entity embedding from its neighboring clients based on
their ""affinity"" on the client-wise relation graph. Each client then conducts
personalized embedding learning based on its local triples and personalized
supplementary knowledge. We conduct extensive experiments on four benchmark
datasets to evaluate our method against state-of-the-art models and results
demonstrate the superiority of our method."
DataComp-LM - In search of the next generation of training sets for language models,https://arxiv.org/abs/2406.11794,2024-06-17,2024-06-19,0.0,0.0,"We introduce DataComp for Language Models (DCLM), a testbed for controlled
dataset experiments with the goal of improving language models. As part of
DCLM, we provide a standardized corpus of 240T tokens extracted from Common
Crawl, effective pretraining recipes based on the OpenLM framework, and a broad
suite of 53 downstream evaluations. Participants in the DCLM benchmark can
experiment with data curation strategies such as deduplication, filtering, and
data mixing at model scales ranging from 412M to 7B parameters. As a baseline
for DCLM, we conduct extensive experiments and find that model-based filtering
is key to assembling a high-quality training set. The resulting dataset,
DCLM-Baseline enables training a 7B parameter language model from scratch to
64% 5-shot accuracy on MMLU with 2.6T training tokens. Compared to MAP-Neo, the
previous state-of-the-art in open-data language models, DCLM-Baseline
represents a 6.6 percentage point improvement on MMLU while being trained with
40% less compute. Our baseline model is also comparable to Mistral-7B-v0.3 and
Llama 3 8B on MMLU (63% & 66%), and performs similarly on an average of 53
natural language understanding tasks while being trained with 6.6x less compute
than Llama 3 8B. Our results highlight the importance of dataset design for
training language models and offer a starting point for further research on
data curation."
CELL your Model - Contrastive Explanation Methods for Large Language Models,https://arxiv.org/abs/2406.11785,2024-06-17,2024-06-19,0.0,0.0,"The advent of black-box deep neural network classification models has sparked
the need to explain their decisions. However, in the case of generative AI such
as large language models (LLMs), there is no class prediction to explain.
Rather, one can ask why an LLM output a particular response to a given prompt.
In this paper, we answer this question by proposing, to the best of our
knowledge, the first contrastive explanation methods requiring simply
black-box/query access. Our explanations suggest that an LLM outputs a reply to
a given prompt because if the prompt was slightly modified, the LLM would have
given a different response that is either less preferable or contradicts the
original response. The key insight is that contrastive explanations simply
require a distance function that has meaning to the user and not necessarily a
real valued representation of a specific response (viz. class label). We offer
two algorithms for finding contrastive explanations: i) A myopic algorithm,
which although effective in creating contrasts, requires many model calls and
ii) A budgeted algorithm, our main algorithmic contribution, which
intelligently creates contrasts adhering to a query budget, necessary for
longer contexts. We show the efficacy of these methods on diverse natural
language tasks such as open-text generation, automated red teaming, and
explaining conversational degradation."
MDCR - A Dataset for Multi-Document Conditional Reasoning,https://arxiv.org/abs/2406.11784,2024-06-17,2024-06-19,0.0,0.0,"The same real-life questions posed to different individuals may lead to
different answers based on their unique situations. For instance, whether a
student is eligible for a scholarship depends on eligibility conditions, such
as major or degree required. ConditionalQA was proposed to evaluate models'
capability of reading a document and answering eligibility questions,
considering unmentioned conditions. However, it is limited to questions on
single documents, neglecting harder cases that may require cross-document
reasoning and optimization, for example, ""What is the maximum number of
scholarships attainable?"" Such questions over multiple documents are not only
more challenging due to more context having to understand, but also because the
model has to (1) explore all possible combinations of unmentioned conditions
and (2) understand the relationship between conditions across documents, to
reason about the optimal outcome. To evaluate models' capability of answering
such questions, we propose a new dataset MDCR, which can reflect real-world
challenges and serve as a new test bed for complex conditional reasoning that
requires optimization. We evaluate this dataset using the most recent LLMs and
demonstrate their limitations in solving this task. We believe this dataset
will facilitate future research in answering optimization questions with
unknown conditions."
"Split, Unlearn, Merge - Leveraging Data Attributes for More Effective Unlearning in LLMs",https://arxiv.org/abs/2406.11780,2024-06-17,2024-06-19,0.0,0.0,"Large language models (LLMs) have shown to pose social and ethical risks such
as generating toxic language or facilitating malicious use of hazardous
knowledge. Machine unlearning is a promising approach to improve LLM safety by
directly removing harmful behaviors and knowledge. In this paper, we propose
""SPlit, UNlearn, MerGE"" (SPUNGE), a framework that can be used with any
unlearning method to amplify its effectiveness. SPUNGE leverages data
attributes during unlearning by splitting unlearning data into subsets based on
specific attribute values, unlearning each subset separately, and merging the
unlearned models. We empirically demonstrate that SPUNGE significantly improves
the performance of two recent unlearning methods on state-of-the-art LLMs while
maintaining their general capabilities on standard academic benchmarks."
Provable Guarantees for Model Performance via Mechanistic Interpretability,https://arxiv.org/abs/2406.11779,2024-06-17,2024-06-19,0.0,0.0,"We propose using mechanistic interpretability -- techniques for reverse
engineering model weights into human-interpretable algorithms -- to derive and
compactly prove formal guarantees on model performance. We prototype this
approach by formally proving lower bounds on the accuracy of 151 small
transformers trained on a Max-of-$K$ task. We create 102 different
computer-assisted proof strategies and assess their length and tightness of
bound on each of our models. Using quantitative metrics, we find that shorter
proofs seem to require and provide more mechanistic understanding. Moreover, we
find that more faithful mechanistic understanding leads to tighter performance
bounds. We confirm these connections by qualitatively examining a subset of our
proofs. Finally, we identify compounding structureless noise as a key challenge
for using mechanistic interpretability to generate compact proofs on model
performance."
Improving Multi-Agent Debate with Sparse Communication Topology,https://arxiv.org/abs/2406.11776,2024-06-17,2024-06-19,0.0,0.0,"Multi-agent debate has proven effective in improving large language models
quality for reasoning and factuality tasks. While various role-playing
strategies in multi-agent debates have been explored, in terms of the
communication among agents, existing approaches adopt a brute force algorithm
-- each agent can communicate with all other agents. In this paper, we
systematically investigate the effect of communication connectivity in
multi-agent systems. Our experiments on GPT and Mistral models reveal that
multi-agent debates leveraging sparse communication topology can achieve
comparable or superior performance while significantly reducing computational
costs. Furthermore, we extend the multi-agent debate framework to multimodal
reasoning and alignment labeling tasks, showcasing its broad applicability and
effectiveness. Our findings underscore the importance of communication
connectivity on enhancing the efficiency and effectiveness of the ""society of
minds"" approach."
Task Me Anything,https://arxiv.org/abs/2406.11775,2024-06-17,2024-06-19,0.0,0.0,"Benchmarks for large multimodal language models (MLMs) now serve to
simultaneously assess the general capabilities of models instead of evaluating
for a specific capability. As a result, when a developer wants to identify
which models to use for their application, they are overwhelmed by the number
of benchmarks and remain uncertain about which benchmark's results are most
reflective of their specific use case. This paper introduces Task-Me-Anything,
a benchmark generation engine which produces a benchmark tailored to a user's
needs. Task-Me-Anything maintains an extendable taxonomy of visual assets and
can programmatically generate a vast number of task instances. Additionally, it
algorithmically addresses user queries regarding MLM performance efficiently
within a computational budget. It contains 113K images, 10K videos, 2K 3D
object assets, over 365 object categories, 655 attributes, and 335
relationships. It can generate 750M image/video question-answering pairs, which
focus on evaluating MLM perceptual capabilities. Task-Me-Anything reveals
critical insights: open-source MLMs excel in object and attribute recognition
but lack spatial and temporal understanding; each model exhibits unique
strengths and weaknesses; larger models generally perform better, though
exceptions exist; and GPT4o demonstrates challenges in recognizing
rotating/moving objects and distinguishing colors."
Optimal Transport-Assisted Risk-Sensitive Q-Learning,https://arxiv.org/abs/2406.11774,2024-06-17,2024-06-19,0.0,0.0,"The primary goal of reinforcement learning is to develop decision-making
policies that prioritize optimal performance without considering risk or
safety. In contrast, safe reinforcement learning aims to mitigate or avoid
unsafe states. This paper presents a risk-sensitive Q-learning algorithm that
leverages optimal transport theory to enhance the agent safety. By integrating
optimal transport into the Q-learning framework, our approach seeks to optimize
the policy's expected return while minimizing the Wasserstein distance between
the policy's stationary distribution and a predefined risk distribution, which
encapsulates safety preferences from domain experts. We validate the proposed
algorithm in a Gridworld environment. The results indicate that our method
significantly reduces the frequency of visits to risky states and achieves
faster convergence to a stable policy compared to the traditional Q-learning
algorithm."
Deep Learning methodology for the identification of wood species using high-resolution macroscopic images,https://arxiv.org/abs/2406.11772,2024-06-17,2024-06-19,0.0,0.0,"Significant advancements in the field of wood species identification are
needed worldwide to support sustainable timber trade. In this work we
contribute to automate the identification of wood species via high-resolution
macroscopic images of timber. The main challenge of this problem is that
fine-grained patterns in timber are crucial in order to accurately identify
wood species, and these patterns are not properly learned by traditional
convolutional neural networks (CNNs) trained on low/medium resolution images.
  We propose a Timber Deep Learning Identification with Patch-based Inference
Voting methodology, abbreviated TDLI-PIV methodology. Our proposal exploits the
concept of patching and the availability of high-resolution macroscopic images
of timber in order to overcome the inherent challenges that CNNs face in timber
identification. The TDLI-PIV methodology is able to capture fine-grained
patterns in timber and, moreover, boosts robustness and prediction accuracy via
a collaborative voting inference process.
  In this work we also introduce a new data set of marcroscopic images of
timber, called GOIMAI-Phase-I, which has been obtained using optical
magnification in order to capture fine-grained details, which contrasts to the
other datasets that are publicly available. More concretely, images in
GOIMAI-Phase-I are taken with a smartphone with a 24x magnifying lens attached
to the camera. Our data set contains 2120 images of timber and covers 37
legally protected wood species.
  Our experiments have assessed the performance of the TDLI-PIV methodology,
involving the comparison with other methodologies available in the literature,
exploration of data augmentation methods and the effect that the dataset size
has on the accuracy of TDLI-PIV."
GAMA - A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities,https://arxiv.org/abs/2406.11768,2024-06-17,2024-06-19,0.0,0.0,"Perceiving and understanding non-speech sounds and non-verbal speech is
essential to making decisions that help us interact with our surroundings. In
this paper, we propose GAMA, a novel General-purpose Large Audio-Language Model
(LALM) with Advanced Audio Understanding and Complex Reasoning Abilities. We
build GAMA by integrating an LLM with multiple types of audio representations,
including features from a custom Audio Q-Former, a multi-layer aggregator that
aggregates features from multiple layers of an audio encoder. We fine-tune GAMA
on a large-scale audio-language dataset, which augments it with audio
understanding capabilities. Next, we propose CompA-R (Instruction-Tuning for
Complex Audio Reasoning), a synthetically generated instruction-tuning (IT)
dataset with instructions that require the model to perform complex reasoning
on the input audio. We instruction-tune GAMA with CompA-R to endow it with
complex reasoning abilities, where we further add a soft prompt as input with
high-level semantic evidence by leveraging event tags of the input audio.
Finally, we also propose CompA-R-test, a human-labeled evaluation dataset for
evaluating the capabilities of LALMs on open-ended audio question-answering
that requires complex reasoning. Through automated and expert human
evaluations, we show that GAMA outperforms all other LALMs in literature on
diverse audio understanding tasks by margins of 1%-84%. Further, GAMA IT-ed on
CompA-R proves to be superior in its complex reasoning and instruction
following capabilities."
Model-Based Inference and Experimental Design for Interference Using Partial Network Data,https://arxiv.org/abs/2406.11940,2024-06-17,2024-06-19,0.0,0.0,"The stable unit treatment value assumption states that the outcome of an
individual is not affected by the treatment statuses of others, however in many
real world applications, treatments can have an effect on many others beyond
the immediately treated. Interference can generically be thought of as mediated
through some network structure. In many empirically relevant situations
however, complete network data (required to adjust for these spillover effects)
are too costly or logistically infeasible to collect. Partially or indirectly
observed network data (e.g., subsamples, aggregated relational data (ARD),
egocentric sampling, or respondent-driven sampling) reduce the logistical and
financial burden of collecting network data, but the statistical properties of
treatment effect adjustments from these design strategies are only beginning to
be explored. In this paper, we present a framework for the estimation and
inference of treatment effect adjustments using partial network data through
the lens of structural causal models. We also illustrate procedures to assign
treatments using only partial network data, with the goal of either minimizing
estimator variance or optimally seeding. We derive single network asymptotic
results applicable to a variety of choices for an underlying graph model. We
validate our approach using simulated experiments on observed graphs with
applications to information diffusion in India and Malawi."
Joint Linked Component Analysis for Multiview Data,https://arxiv.org/abs/2406.11761,2024-06-17,2024-06-19,0.0,0.0,"In this work, we propose the joint linked component analysis (joint\_LCA) for
multiview data. Unlike classic methods which extract the shared components in a
sequential manner, the objective of joint\_LCA is to identify the view-specific
loading matrices and the rank of the common latent subspace simultaneously. We
formulate a matrix decomposition model where a joint structure and an
individual structure are present in each data view, which enables us to arrive
at a clean svd representation for the cross covariance between any pair of data
views. An objective function with a novel penalty term is then proposed to
achieve simultaneous estimation and rank selection. In addition, a refitting
procedure is employed as a remedy to reduce the shrinkage bias caused by the
penalization."
Tracking the perspectives of interacting language models,https://arxiv.org/abs/2406.11938,2024-06-17,2024-06-19,0.0,0.0,"Large language models (LLMs) are capable of producing high quality
information at unprecedented rates. As these models continue to entrench
themselves in society, the content they produce will become increasingly
pervasive in databases that are, in turn, incorporated into the pre-training
data, fine-tuning data, retrieval data, etc. of other language models. In this
paper we formalize the idea of a communication network of LLMs and introduce a
method for representing the perspective of individual models within a
collection of LLMs. Given these tools we systematically study information
diffusion in the communication network of LLMs in various simulated settings."
STAR - SocioTechnical Approach to Red Teaming Language Models,https://arxiv.org/abs/2406.11757,2024-06-17,2024-06-19,0.0,0.0,"This research introduces STAR, a sociotechnical framework that improves on
current best practices for red teaming safety of large language models. STAR
makes two key contributions: it enhances steerability by generating
parameterised instructions for human red teamers, leading to improved coverage
of the risk surface. Parameterised instructions also provide more detailed
insights into model failures at no increased cost. Second, STAR improves signal
quality by matching demographics to assess harms for specific groups, resulting
in more sensitive annotations. STAR further employs a novel step of arbitration
to leverage diverse viewpoints and improve label reliability, treating
disagreement not as noise but as a valuable contribution to signal quality."
DustNet - skillful neural network predictions of Saharan dust,https://arxiv.org/abs/2406.11754,2024-06-17,2024-06-19,0.0,0.0,"Suspended in the atmosphere are millions of tonnes of mineral dust which
interacts with weather and climate. Accurate representation of mineral dust in
weather models is vital, yet remains challenging. Large scale weather models
use high power supercomputers and take hours to complete the forecast. Such
computational burden allows them to only include monthly climatological means
of mineral dust as input states inhibiting their forecasting accuracy. Here, we
introduce DustNet a simple, accurate and super fast forecasting model for
24-hours ahead predictions of aerosol optical depth AOD. DustNet trains in less
than 8 minutes and creates predictions in 2 seconds on a desktop computer.
Created by DustNet predictions outperform the state-of-the-art physics-based
model on coarse 1 x 1 degree resolution at 95% of grid locations when compared
to ground truth satellite data. Our results show DustNet has a potential for
fast and accurate AOD forecasting which could transform our understanding of
dust impacts on weather patterns."
A Semantic-based Layer Freezing Approach to Efficient Fine-Tuning of Language Models,https://arxiv.org/abs/2406.11753,2024-06-17,2024-06-19,0.0,0.0,"Finetuning language models (LMs) is crucial for adapting the models to
downstream data and tasks. However, full finetuning is usually costly. Existing
work, such as parameter-efficient finetuning (PEFT), often focuses on
\textit{how to finetune} but neglects the issue of \textit{where to finetune}.
As a pioneering work on answering where to finetune (at the layer level), we
conduct a semantic analysis of the LM inference process. We first propose a
virtual transition of the latent representation and then trace its factual
transition. Based on the deviation in transitions, we estimate the gain of
finetuning each model layer, and further, narrow down the scope for finetuning.
We perform extensive experiments across well-known LMs and datasets. The
results show that our approach is effective and efficient, and outperforms the
existing baselines. Our approach is orthogonal to existing efficient
techniques, such as PEFT methods, offering practical values on LM finetuning."
Multi-Layer Ranking with Large Language Models for News Source Recommendation,https://arxiv.org/abs/2406.11745,2024-06-17,2024-06-19,0.0,0.0,"To seek reliable information sources for news events, we introduce a novel
task of expert recommendation, which aims to identify trustworthy sources based
on their previously quoted statements. To achieve this, we built a novel
dataset, called NewsQuote, consisting of 23,571 quote-speaker pairs sourced
from a collection of news articles. We formulate the recommendation task as the
retrieval of experts based on their likelihood of being associated with a given
query. We also propose a multi-layer ranking framework employing Large Language
Models to improve the recommendation performance. Our results show that
employing an in-context learning based LLM ranker and a multi-layer
ranking-based filter significantly improve both the predictive quality and
behavioural quality of the recommender system."
Transcendence - Generative Models Can Outperform The Experts That Train Them,https://arxiv.org/abs/2406.11741,2024-06-17,2024-06-19,0.0,0.0,"Generative models are trained with the simple objective of imitating the
conditional probability distribution induced by the data they are trained on.
Therefore, when trained on data generated by humans, we may not expect the
artificial model to outperform the humans on their original objectives. In this
work, we study the phenomenon of transcendence: when a generative model
achieves capabilities that surpass the abilities of the experts generating its
data. We demonstrate transcendence by training an autoregressive transformer to
play chess from game transcripts, and show that the trained model can sometimes
achieve better performance than all players in the dataset. We theoretically
prove that transcendence can be enabled by low-temperature sampling, and
rigorously assess this claim experimentally. Finally, we discuss other sources
of transcendence, laying the groundwork for future investigation of this
phenomenon in a broader setting."
Imagination Policy - Using Generative Point Cloud Models for Learning Manipulation Policies,https://arxiv.org/abs/2406.11740,2024-06-17,2024-06-19,0.0,0.0,"Humans can imagine goal states during planning and perform actions to match
those goals. In this work, we propose Imagination Policy, a novel multi-task
key-frame policy network for solving high-precision pick and place tasks.
Instead of learning actions directly, Imagination Policy generates point clouds
to imagine desired states which are then translated to actions using rigid
action estimation. This transforms action inference into a local generative
task. We leverage pick and place symmetries underlying the tasks in the
generation process and achieve extremely high sample efficiency and
generalizability to unseen configurations. Finally, we demonstrate
state-of-the-art performance across various tasks on the RLbench benchmark
compared with several strong baselines."
Interactive Evolution - A Neural-Symbolic Self-Training Framework For Large Language Models,https://arxiv.org/abs/2406.11736,2024-06-17,2024-06-19,0.0,0.0,"One of the primary driving forces contributing to the superior performance of
Large Language Models (LLMs) is the extensive availability of human-annotated
natural language data, which is used for alignment fine-tuning. This inspired
researchers to investigate self-training methods to mitigate the extensive
reliance on human annotations. However, the current success of self-training
has been primarily observed in natural language scenarios, rather than in the
increasingly important neural-symbolic scenarios. To this end, we propose an
environment-guided neural-symbolic self-training framework named ENVISIONS. It
aims to overcome two main challenges: (1) the scarcity of symbolic data, and
(2) the limited proficiency of LLMs in processing symbolic language. Extensive
evaluations conducted on three distinct domains demonstrate the effectiveness
of our approach. Additionally, we have conducted a comprehensive analysis to
uncover the factors contributing to ENVISIONS's success, thereby offering
valuable insights for future research in this area. Code will be available at
\url{https://github.com/xufangzhi/ENVISIONS}."
A Clipped Trip - the Dynamics of SGD with Gradient Clipping in High-Dimensions,https://arxiv.org/abs/2406.11733,2024-06-17,2024-06-19,0.0,0.0,"The success of modern machine learning is due in part to the adaptive
optimization methods that have been developed to deal with the difficulties of
training large models over complex datasets. One such method is gradient
clipping: a practical procedure with limited theoretical underpinnings. In this
work, we study clipping in a least squares problem under streaming SGD. We
develop a theoretical analysis of the learning dynamics in the limit of large
intrinsic dimension-a model and dataset dependent notion of dimensionality. In
this limit we find a deterministic equation that describes the evolution of the
loss. We show that with Gaussian noise clipping cannot improve SGD performance.
Yet, in other noisy settings, clipping can provide benefits with tuning of the
clipping threshold. In these cases, clipping biases updates in a way beneficial
to training which cannot be recovered by SGD under any schedule. We conclude
with a discussion about the links between high-dimensional clipping and neural
network training."
CHG Shapley - Efficient Data Valuation and Selection towards Trustworthy Machine Learning,https://arxiv.org/abs/2406.11730,2024-06-17,2024-06-19,0.0,0.0,"Understanding the decision-making process of machine learning models is
crucial for ensuring trustworthy machine learning. Data Shapley, a landmark
study on data valuation, advances this understanding by assessing the
contribution of each datum to model accuracy. However, the resource-intensive
and time-consuming nature of multiple model retraining poses challenges for
applying Data Shapley to large datasets. To address this, we propose the CHG
(Conduct of Hardness and Gradient) score, which approximates the utility of
each data subset on model accuracy during a single model training. By deriving
the closed-form expression of the Shapley value for each data point under the
CHG score utility function, we reduce the computational complexity to the
equivalent of a single model retraining, an exponential improvement over
existing methods. Additionally, we employ CHG Shapley for real-time data
selection, demonstrating its effectiveness in identifying high-value and noisy
data. CHG Shapley facilitates trustworthy model training through efficient data
valuation, introducing a novel data-centric perspective on trustworthy machine
learning."
1000 African Voices - Advancing inclusive multi-speaker multi-accent speech synthesis,https://arxiv.org/abs/2406.11727,2024-06-17,2024-06-19,0.0,0.0,"Recent advances in speech synthesis have enabled many useful applications
like audio directions in Google Maps, screen readers, and automated content
generation on platforms like TikTok. However, these systems are mostly
dominated by voices sourced from data-rich geographies with personas
representative of their source data. Although 3000 of the world's languages are
domiciled in Africa, African voices and personas are under-represented in these
systems. As speech synthesis becomes increasingly democratized, it is desirable
to increase the representation of African English accents. We present Afro-TTS,
the first pan-African accented English speech synthesis system able to generate
speech in 86 African accents, with 1000 personas representing the rich
phonological diversity across the continent for downstream application in
Education, Public Health, and Automated Content Creation. Speaker interpolation
retains naturalness and accentedness, enabling the creation of new voices."
Zero-Shot Generalization during Instruction Tuning - Insights from Similarity and Granularity,https://arxiv.org/abs/2406.11721,2024-06-17,2024-06-19,0.0,0.0,"Understanding alignment techniques begins with comprehending zero-shot
generalization brought by instruction tuning, but little of the mechanism has
been understood. Existing work has largely been confined to the task level,
without considering that tasks are artificially defined and, to LLMs, merely
consist of tokens and representations. This line of research has been limited
to examining transfer between tasks from a task-pair perspective, with few
studies focusing on understanding zero-shot generalization from the perspective
of the data itself. To bridge this gap, we first demonstrate through multiple
metrics that zero-shot generalization during instruction tuning happens very
early. Next, we investigate the facilitation of zero-shot generalization from
both data similarity and granularity perspectives, confirming that encountering
highly similar and fine-grained training data earlier during instruction
tuning, without the constraints of defined ""tasks"", enables better
generalization. Finally, we propose a more grounded training data arrangement
method, Test-centric Multi-turn Arrangement, and show its effectiveness in
promoting continual learning and further loss reduction. For the first time, we
show that zero-shot generalization during instruction tuning is a form of
similarity-based generalization between training and test data at the instance
level. We hope our analysis will advance the understanding of zero-shot
generalization during instruction tuning and contribute to the development of
more aligned LLMs. Our code is released at
https://github.com/HBX-hbx/dynamics_of_zero-shot_generalization."
Measuring memorization in RLHF for code completion,https://arxiv.org/abs/2406.11715,2024-06-17,2024-06-19,0.0,0.0,"Reinforcement learning with human feedback (RLHF) has become the dominant
method to align large models to user preferences. Unlike fine-tuning, for which
there are many studies regarding training data memorization, it is not clear
how memorization is affected by or introduced in the RLHF alignment process.
Understanding this relationship is important as real user data may be collected
and used to align large models; if user data is memorized during RLHF and later
regurgitated, this could raise privacy concerns. In this work, we analyze how
training data memorization can surface and propagate through each phase of
RLHF. We focus our study on code completion models, as code completion is one
of the most popular use cases for large language models. We find that RLHF
significantly decreases the chance that data used for reward modeling and
reinforcement learning is memorized, in comparison to aligning via directly
fine-tuning on this data, but that examples already memorized during the
fine-tuning stage of RLHF, will, in the majority of cases, remain memorized
after RLHF."
Scalable Expressiveness through Preprocessed Graph Perturbations,https://arxiv.org/abs/2406.11714,2024-06-17,2024-06-19,0.0,0.0,"Graph Neural Networks (GNNs) have emerged as the predominant method for
analyzing graph-structured data. However, canonical GNNs have limited
expressive power and generalization capability, thus triggering the development
of more expressive yet computationally intensive methods. One such approach is
to create a series of perturbed versions of input graphs and then repeatedly
conduct multiple message-passing operations on all variations during training.
Despite their expressive power, this approach does not scale well on larger
graphs. To address this scalability issue, we introduce Scalable Expressiveness
through Preprocessed Graph Perturbation (SE2P). This model offers a flexible,
configurable balance between scalability and generalizability with four
distinct configuration classes. At one extreme, the configuration prioritizes
scalability through minimal learnable feature extraction and extensive
preprocessing; at the other extreme, it enhances generalizability with more
learnable feature extractions, though this increases scalability costs. We
conduct extensive experiments on real-world datasets to evaluate the
generalizability and scalability of SE2P variants compared to various
state-of-the-art benchmarks. Our results indicate that, depending on the chosen
SE2P configuration, the model can enhance generalizability compared to
benchmarks while achieving significant speed improvements of up to 8-fold."
"Instruct, Not Assist - LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging",https://arxiv.org/abs/2406.11709,2024-06-17,2024-06-19,0.0,0.0,"Socratic questioning is an effective teaching strategy, encouraging critical
thinking and problem-solving. The conversational capabilities of large language
models (LLMs) show great potential for providing scalable, real-time student
guidance. However, current LLMs often give away solutions directly, making them
ineffective instructors. We tackle this issue in the code debugging domain with
TreeInstruct, an Instructor agent guided by a novel state space-based planning
algorithm. TreeInstruct asks probing questions to help students independently
identify and resolve errors. It estimates a student's conceptual and
syntactical knowledge to dynamically construct a question tree based on their
responses and current knowledge state, effectively addressing both independent
and dependent mistakes concurrently in a multi-turn interaction setting. In
addition to using an existing single-bug debugging benchmark, we construct a
more challenging multi-bug dataset of 150 coding problems, incorrect solutions,
and bug fixes -- all carefully constructed and annotated by experts. Extensive
evaluation shows TreeInstruct's state-of-the-art performance on both datasets,
proving it to be a more effective instructor than baselines. Furthermore, a
real-world case study with five students of varying skill levels further
demonstrates TreeInstruct's ability to guide students to debug their code
efficiently with minimal turns and highly Socratic questioning. We provide our
code and datasets at http://github.com/agarwalishika/TreeInstruct ."
Tackling the Curse of Dimensionality in Fractional and Tempered Fractional PDEs with Physics-Informed Neural Networks,https://arxiv.org/abs/2406.11708,2024-06-17,2024-06-19,0.0,0.0,"Fractional and tempered fractional partial differential equations (PDEs) are
effective models of long-range interactions, anomalous diffusion, and non-local
effects. Traditional numerical methods for these problems are mesh-based, thus
struggling with the curse of dimensionality (CoD). Physics-informed neural
networks (PINNs) offer a promising solution due to their universal
approximation, generalization ability, and mesh-free training. In principle,
Monte Carlo fractional PINN (MC-fPINN) estimates fractional derivatives using
Monte Carlo methods and thus could lift CoD. However, this may cause
significant variance and errors, hence affecting convergence; in addition,
MC-fPINN is sensitive to hyperparameters. In general, numerical methods and
specifically PINNs for tempered fractional PDEs are under-developed. Herein, we
extend MC-fPINN to tempered fractional PDEs to address these issues, resulting
in the Monte Carlo tempered fractional PINN (MC-tfPINN). To reduce possible
high variance and errors from Monte Carlo sampling, we replace the
one-dimensional (1D) Monte Carlo with 1D Gaussian quadrature, applicable to
both MC-fPINN and MC-tfPINN. We validate our methods on various forward and
inverse problems of fractional and tempered fractional PDEs, scaling up to
100,000 dimensions. Our improved MC-fPINN/MC-tfPINN using quadrature
consistently outperforms the original versions in accuracy and convergence
speed in very high dimensions."
Prompts as Auto-Optimized Training Hyperparameters - Training Best-in-Class IR Models from Scratch with 10 Gold Labels,https://arxiv.org/abs/2406.11706,2024-06-17,2024-06-19,0.0,0.0,"We develop a method for training small-scale (under 100M parameter) neural
information retrieval models with as few as 10 gold relevance labels. The
method depends on generating synthetic queries for documents using a language
model (LM), and the key step is that we automatically optimize the LM prompt
that is used to generate these queries based on training quality. In
experiments with the BIRCO benchmark, we find that models trained with our
method outperform RankZephyr and are competitive with RankLLama, both of which
are 7B parameter models trained on over 100K labels. These findings point to
the power of automatic prompt optimization for synthetic dataset generation."
Nemotron-4 340B Technical Report,https://arxiv.org/abs/2406.11704,2024-06-17,2024-06-19,0.0,0.0,"We release the Nemotron-4 340B model family, including Nemotron-4-340B-Base,
Nemotron-4-340B-Instruct, and Nemotron-4-340B-Reward. Our models are open
access under the NVIDIA Open Model License Agreement, a permissive model
license that allows distribution, modification, and use of the models and its
outputs. These models perform competitively to open access models on a wide
range of evaluation benchmarks, and were sized to fit on a single DGX H100 with
8 GPUs when deployed in FP8 precision. We believe that the community can
benefit from these models in various research studies and commercial
applications, especially for generating synthetic data to train smaller
language models. Notably, over 98% of data used in our model alignment process
is synthetically generated, showcasing the effectiveness of these models in
generating synthetic data. To further support open research and facilitate
model development, we are also open-sourcing the synthetic data generation
pipeline used in our model alignment process."
"Multiple Descents in Unsupervised Learning - The Role of Noise, Domain Shift and Anomalies",https://arxiv.org/abs/2406.11703,2024-06-17,2024-06-19,0.0,0.0,"The phenomenon of double descent has recently gained attention in supervised
learning. It challenges the conventional wisdom of the bias-variance trade-off
by showcasing a surprising behavior. As the complexity of the model increases,
the test error initially decreases until reaching a certain point where the
model starts to overfit the train set, causing the test error to rise. However,
deviating from classical theory, the error exhibits another decline when
exceeding a certain degree of over-parameterization. We study the presence of
double descent in unsupervised learning, an area that has received little
attention and is not yet fully understood. We conduct extensive experiments
using under-complete auto-encoders (AEs) for various applications, such as
dealing with noisy data, domain shifts, and anomalies. We use synthetic and
real data and identify model-wise, epoch-wise, and sample-wise double descent
for all the aforementioned applications. Finally, we assessed the usability of
the AEs for detecting anomalies and mitigating the domain shift between
datasets. Our findings indicate that over-parameterized models can improve
performance not only in terms of reconstruction, but also in enhancing
capabilities for the downstream task."
Meta Reasoning for Large Language Models,https://arxiv.org/abs/2406.11698,2024-06-17,2024-06-19,0.0,0.0,"We introduce Meta-Reasoning Prompting (MRP), a novel and efficient system
prompting method for large language models (LLMs) inspired by human
meta-reasoning. Traditional in-context learning-based reasoning techniques,
such as Tree-of-Thoughts, show promise but lack consistent state-of-the-art
performance across diverse tasks due to their specialized nature. MRP addresses
this limitation by guiding LLMs to dynamically select and apply different
reasoning methods based on the specific requirements of each task, optimizing
both performance and computational efficiency. With MRP, LLM reasoning operates
in two phases. Initially, the LLM identifies the most appropriate reasoning
method using task input cues and objective descriptions of available methods.
Subsequently, it applies the chosen method to complete the task. This dynamic
strategy mirrors human meta-reasoning, allowing the model to excel in a wide
range of problem domains. We evaluate the effectiveness of MRP through
comprehensive benchmarks. The results demonstrate that MRP achieves or
approaches state-of-the-art performance across diverse tasks. MRP represents a
significant advancement in enabling LLMs to identify cognitive challenges
across problems and leverage benefits across different reasoning approaches,
enhancing their ability to handle diverse and complex problem domains
efficiently. Every LLM deserves a Meta-Reasoning Prompting to unlock its full
potential and ensure adaptability in an ever-evolving landscape of challenges
and applications."
Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs,https://arxiv.org/abs/2406.11695,2024-06-17,2024-06-19,0.0,0.0,"Language Model Programs, i.e. sophisticated pipelines of modular language
model (LM) calls, are increasingly advancing NLP tasks, but they require
crafting prompts that are jointly effective for all modules. We study prompt
optimization for LM programs, i.e. how to update these prompts to maximize a
downstream metric without access to module-level labels or gradients. To make
this tractable, we factorize our problem into optimizing the free-form
instructions and few-shot demonstrations of every module and introduce several
strategies to craft task-grounded instructions and navigate credit assignment
across modules. Our strategies include (i) program- and data-aware techniques
for proposing effective instructions, (ii) a stochastic mini-batch evaluation
function for learning a surrogate model of our objective, and (iii) a
meta-optimization procedure in which we refine how LMs construct proposals over
time. Using these insights we develop MIPRO, a novel optimizer that outperforms
baselines on five of six diverse LM programs using a best-in-class open-source
model (Llama-3-8B), by as high as 12.9% accuracy. We will release our new
optimizers and benchmark in DSPy at https://github.com/stanfordnlp/dspy"
Iterative or Innovative? A Problem-Oriented Perspective for Code Optimization,https://arxiv.org/abs/2406.11935,2024-06-17,2024-06-19,0.0,0.0,"Large language models (LLMs) have demonstrated strong capabilities in solving
a wide range of programming tasks. However, LLMs have rarely been explored for
code optimization. In this paper, we explore code optimization with a focus on
performance enhancement, specifically aiming to optimize code for minimal
execution time. The recently proposed first PIE dataset for performance
optimization constructs program optimization pairs based on iterative
submissions from the same programmer for the same problem. However, this
approach restricts LLMs to local performance improvements, neglecting global
algorithmic innovation. Therefore, we adopt a completely different perspective
by reconstructing the optimization pairs into a problem-oriented approach. This
allows for the integration of various ingenious ideas from different
programmers tackling the same problem. Experimental results demonstrate that
adapting LLMs to problem-oriented optimization pairs significantly enhances
their optimization capabilities. Meanwhile, we identified performance
bottlenecks within the problem-oriented perspective. By employing model merge,
we further overcame bottlenecks and ultimately elevated the program
optimization ratio ($51.76\%\rightarrow76.65\%$) and speedup
($2.65\times\rightarrow5.09\times$) to new levels."
Tokenization Falling Short - The Curse of Tokenization,https://arxiv.org/abs/2406.11687,2024-06-17,2024-06-19,0.0,0.0,"Language models typically tokenize raw text into sequences of subword
identifiers from a predefined vocabulary, a process inherently sensitive to
typographical errors, length variations, and largely oblivious to the internal
structure of tokens-issues we term the curse of tokenization. In this study, we
delve into these drawbacks and demonstrate that large language models (LLMs)
remain susceptible to these problems. This study systematically investigates
these challenges and their impact on LLMs through three critical research
questions: (1) complex problem solving, (2) token structure probing, and (3)
resilience to typographical variation. Our findings reveal that scaling model
parameters can mitigate the issue of tokenization; however, LLMs still suffer
from biases induced by typos and other text format variations. Our experiments
show that subword regularization such as BPE-dropout can mitigate this issue.
We will release our code and data to facilitate further research."
The Role of Inherent Bellman Error in Offline Reinforcement Learning with Linear Function Approximation,https://arxiv.org/abs/2406.11686,2024-06-17,2024-06-19,0.0,0.0,"In this paper, we study the offline RL problem with linear function
approximation. Our main structural assumption is that the MDP has low inherent
Bellman error, which stipulates that linear value functions have linear Bellman
backups with respect to the greedy policy. This assumption is natural in that
it is essentially the minimal assumption required for value iteration to
succeed. We give a computationally efficient algorithm which succeeds under a
single-policy coverage condition on the dataset, namely which outputs a policy
whose value is at least that of any policy which is well-covered by the
dataset. Even in the setting when the inherent Bellman error is 0 (termed
linear Bellman completeness), our algorithm yields the first known guarantee
under single-policy coverage.
  In the setting of positive inherent Bellman error
${\varepsilon_{\mathrm{BE}}} > 0$, we show that the suboptimality error of our
algorithm scales with $\sqrt{\varepsilon_{\mathrm{BE}}}$. Furthermore, we prove
that the scaling of the suboptimality with $\sqrt{\varepsilon_{\mathrm{BE}}}$
cannot be improved for any algorithm. Our lower bound stands in contrast to
many other settings in reinforcement learning with misspecification, where one
can typically obtain performance that degrades linearly with the
misspecification error."
Bridging Design Gaps - A Parametric Data Completion Approach With Graph Guided Diffusion Models,https://arxiv.org/abs/2406.11934,2024-06-17,2024-06-19,0.0,0.0,"This study introduces a generative imputation model leveraging graph
attention networks and tabular diffusion models for completing missing
parametric data in engineering designs. This model functions as an AI design
co-pilot, providing multiple design options for incomplete designs, which we
demonstrate using the bicycle design CAD dataset. Through comparative
evaluations, we demonstrate that our model significantly outperforms existing
classical methods, such as MissForest, hotDeck, PPCA, and tabular generative
method TabCSDI in both the accuracy and diversity of imputation options.
Generative modeling also enables a broader exploration of design possibilities,
thereby enhancing design decision-making by allowing engineers to explore a
variety of design completions. The graph model combines GNNs with the
structural information contained in assembly graphs, enabling the model to
understand and predict the complex interdependencies between different design
parameters. The graph model helps accurately capture and impute complex
parametric interdependencies from an assembly graph, which is key for design
problems. By learning from an existing dataset of designs, the imputation
capability allows the model to act as an intelligent assistant that
autocompletes CAD designs based on user-defined partial parametric design,
effectively bridging the gap between ideation and realization. The proposed
work provides a pathway to not only facilitate informed design decisions but
also promote creative exploration in design."
Edge Classification on Graphs - New Directions in Topological Imbalance,https://arxiv.org/abs/2406.11685,2024-06-17,2024-06-19,0.0,0.0,"Recent years have witnessed the remarkable success of applying Graph machine
learning (GML) to node/graph classification and link prediction. However, edge
classification task that enjoys numerous real-world applications such as social
network analysis and cybersecurity, has not seen significant advancement. To
address this gap, our study pioneers a comprehensive approach to edge
classification. We identify a novel `Topological Imbalance Issue', which arises
from the skewed distribution of edges across different classes, affecting the
local subgraph of each edge and harming the performance of edge
classifications. Inspired by the recent studies in node classification that the
performance discrepancy exists with varying local structural patterns, we aim
to investigate if the performance discrepancy in topological imbalanced edge
classification can also be mitigated by characterizing the local class
distribution variance. To overcome this challenge, we introduce Topological
Entropy (TE), a novel topological-based metric that measures the topological
imbalance for each edge. Our empirical studies confirm that TE effectively
measures local class distribution variance, and indicate that prioritizing
edges with high TE values can help address the issue of topological imbalance.
Based on this, we develop two strategies - Topological Reweighting and TE
Wedge-based Mixup - to focus training on (synthetic) edges based on their TEs.
While topological reweighting directly manipulates training edge weights
according to TE, our wedge-based mixup interpolates synthetic edges between
high TE wedges. Ultimately, we integrate these strategies into a novel
topological imbalance strategy for edge classification: TopoEdge. Through
extensive experiments, we demonstrate the efficacy of our proposed strategies
on newly curated datasets and thus establish a new benchmark for (imbalanced)
edge classification."
HoLLMwood - Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing,https://arxiv.org/abs/2406.11683,2024-06-17,2024-06-19,0.0,0.0,"Generative AI has demonstrated unprecedented creativity in the field of
computer vision, yet such phenomena have not been observed in natural language
processing. In particular, large language models (LLMs) can hardly produce
written works at the level of human experts due to the extremely high
complexity of literature writing. In this paper, we present HoLLMwood, an
automated framework for unleashing the creativity of LLMs and exploring their
potential in screenwriting, which is a highly demanding task. Mimicking the
human creative process, we assign LLMs to different roles involved in the
real-world scenario. In addition to the common practice of treating LLMs as
${Writer}$, we also apply LLMs as ${Editor}$, who is responsible for providing
feedback and revision advice to ${Writer}$. Besides, to enrich the characters
and deepen the plots, we introduce a role-playing mechanism and adopt LLMs as
${Actors}$ that can communicate and interact with each other. Evaluations on
automatically generated screenplays show that HoLLMwood substantially
outperforms strong baselines in terms of coherence, relevance, interestingness
and overall quality."
Knowledge-to-Jailbreak - One Knowledge Point Worth One Attack,https://arxiv.org/abs/2406.11682,2024-06-17,2024-06-19,0.0,0.0,"Large language models (LLMs) have been increasingly applied to various
domains, which triggers increasing concerns about LLMs' safety on specialized
domains, e.g. medicine. However, testing the domain-specific safety of LLMs is
challenging due to the lack of domain knowledge-driven attacks in existing
benchmarks. To bridge this gap, we propose a new task, knowledge-to-jailbreak,
which aims to generate jailbreaks from domain knowledge to evaluate the safety
of LLMs when applied to those domains. We collect a large-scale dataset with
12,974 knowledge-jailbreak pairs and fine-tune a large language model as
jailbreak-generator, to produce domain knowledge-specific jailbreaks.
Experiments on 13 domains and 8 target LLMs demonstrate the effectiveness of
jailbreak-generator in generating jailbreaks that are both relevant to the
given knowledge and harmful to the target LLMs. We also apply our method to an
out-of-domain knowledge base, showing that jailbreak-generator can generate
jailbreaks that are comparable in harmfulness to those crafted by human
experts. Data and code: https://github.com/THU-KEG/Knowledge-to-Jailbreak/."
R-Eval - A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models,https://arxiv.org/abs/2406.11681,2024-06-17,2024-06-19,0.0,0.0,"Large language models have achieved remarkable success on general NLP tasks,
but they may fall short for domain-specific problems. Recently, various
Retrieval-Augmented Large Language Models (RALLMs) are proposed to address this
shortcoming. However, existing evaluation tools only provide a few baselines
and evaluate them on various domains without mining the depth of domain
knowledge. In this paper, we address the challenges of evaluating RALLMs by
introducing the R-Eval toolkit, a Python toolkit designed to streamline the
evaluation of different RAG workflows in conjunction with LLMs. Our toolkit,
which supports popular built-in RAG workflows and allows for the incorporation
of customized testing data on the specific domain, is designed to be
user-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMs
across three task levels and two representative domains, revealing significant
variations in the effectiveness of RALLMs across different tasks and domains.
Our analysis emphasizes the importance of considering both task and domain
requirements when choosing a RAG workflow and LLM combination. We are committed
to continuously maintaining our platform at https://github.com/THU-KEG/R-Eval
to facilitate both the industry and the researchers."
TourRank - Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy,https://arxiv.org/abs/2406.11678,2024-06-17,2024-06-19,0.0,0.0,"Large Language Models (LLMs) are increasingly employed in zero-shot documents
ranking, yielding commendable results. However, several significant challenges
still persist in LLMs for ranking: (1) LLMs are constrained by limited input
length, precluding them from processing a large number of documents
simultaneously; (2) The output document sequence is influenced by the input
order of documents, resulting in inconsistent ranking outcomes; (3) Achieving a
balance between cost and ranking performance is quite challenging. To tackle
these issues, we introduce a novel documents ranking method called TourRank,
which is inspired by the tournament mechanism. This approach alleviates the
impact of LLM's limited input length through intelligent grouping, while the
tournament-like points system ensures robust ranking, mitigating the influence
of the document input sequence. We test TourRank with different LLMs on the
TREC DL datasets and the BEIR benchmark. Experimental results show that
TourRank achieves state-of-the-art performance at a reasonable cost."
BLoB - Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models,https://arxiv.org/abs/2406.11675,2024-06-17,2024-06-19,0.0,0.0,"Large Language Models (LLMs) often suffer from overconfidence during
inference, particularly when adapted to downstream domain-specific tasks with
limited data. Previous work addresses this issue by employing approximate
Bayesian estimation after the LLMs are trained, enabling them to quantify
uncertainty. However, such post-training approaches' performance is severely
limited by the parameters learned during training. In this paper, we go beyond
post-training Bayesianization and propose Bayesian Low-Rank Adaptation by
Backpropagation (BLoB), an algorithm that continuously and jointly adjusts both
the mean and covariance of LLM parameters throughout the whole fine-tuning
process. Our empirical results verify the effectiveness of BLoB in terms of
generalization and uncertainty estimation, when evaluated on both
in-distribution and out-of-distribution data."
Endor - Hardware-Friendly Sparse Format for Offloaded LLM Inference,https://arxiv.org/abs/2406.11674,2024-06-17,2024-06-19,0.0,0.0,"The increasing size of large language models (LLMs) challenges their usage on
resource-constrained platforms. For example, memory on modern GPUs is
insufficient to hold LLMs that are hundreds of Gigabytes in size. Offloading is
a popular method to escape this constraint by storing weights of an LLM model
to host CPU memory and SSD, then loading each weight to GPU before every use.
In our case study of offloaded inference, we found that due to the low
bandwidth between storage devices and GPU, the latency of transferring large
model weights from its offloaded location to GPU memory becomes the critical
bottleneck with actual compute taking nearly 0% of runtime. To effectively
reduce the weight transfer latency, we propose a novel sparse format that
compresses the unstructured sparse pattern of pruned LLM weights to non-zero
values with high compression ratio and low decompression overhead. Endor
achieves this by expressing the positions of non-zero elements with a bitmap.
Compared to offloaded inference using the popular Huggingface Accelerate,
applying Endor accelerates OPT-66B by 1.70x and Llama2-70B by 1.78x. When
direct weight transfer from SSD to GPU is leveraged, Endor achieves 2.25x
speedup on OPT-66B and 2.37x speedup on Llama2-70B."
Benchmarking of LLM Detection - Comparing Two Competing Approaches,https://arxiv.org/abs/2406.11670,2024-06-17,2024-06-19,0.0,0.0,"This article gives an overview of the field of LLM text recognition.
Different approaches and implemented detectors for the recognition of
LLM-generated text are presented. In addition to discussing the
implementations, the article focuses on benchmarking the detectors. Although
there are numerous software products for the recognition of LLM-generated text,
with a focus on ChatGPT-like LLMs, the quality of the recognition (recognition
rate) is not clear. Furthermore, while it can be seen that scientific
contributions presenting their novel approaches strive for some kind of
comparison with other approaches, the construction and independence of the
evaluation dataset is often not comprehensible. As a result, discrepancies in
the performance evaluation of LLM detectors are often visible due to the
different benchmarking datasets. This article describes the creation of an
evaluation dataset and uses this dataset to investigate the different
detectors. The selected detectors are benchmarked against each other."
"""Not Aligned"" is Not ""Malicious"" - Being Careful about Hallucinations of Large Language Models' Jailbreak",https://arxiv.org/abs/2406.11668,2024-06-17,2024-06-19,0.0,0.0,"""Jailbreak"" is a major safety concern of Large Language Models (LLMs), which
occurs when malicious prompts lead LLMs to produce harmful outputs, raising
issues about the reliability and safety of LLMs. Therefore, an effective
evaluation of jailbreaks is very crucial to develop its mitigation strategies.
However, our research reveals that many jailbreaks identified by current
evaluations may actually be hallucinations-erroneous outputs that are mistaken
for genuine safety breaches. This finding suggests that some perceived
vulnerabilities might not represent actual threats, indicating a need for more
precise red teaming benchmarks. To address this problem, we propose the
$\textbf{B}$enchmark for reli$\textbf{AB}$ilit$\textbf{Y}$ and
jail$\textbf{B}$reak ha$\textbf{L}$l$\textbf{U}$cination $\textbf{E}$valuation
(BabyBLUE). BabyBLUE introduces a specialized validation framework including
various evaluators to enhance existing jailbreak benchmarks, ensuring outputs
are useful malicious instructions. Additionally, BabyBLUE presents a new
dataset as an augmentation to the existing red teaming benchmarks, specifically
addressing hallucinations in jailbreaks, aiming to evaluate the true potential
of jailbroken LLM outputs to cause harm to human society."
Is Efficient PAC Learning Possible with an Oracle That Responds 'Yes' or 'No'?,https://arxiv.org/abs/2406.11667,2024-06-17,2024-06-19,0.0,0.0,"The empirical risk minimization (ERM) principle has been highly impactful in
machine learning, leading both to near-optimal theoretical guarantees for
ERM-based learning algorithms as well as driving many of the recent empirical
successes in deep learning. In this paper, we investigate the question of
whether the ability to perform ERM, which computes a hypothesis minimizing
empirical risk on a given dataset, is necessary for efficient learning: in
particular, is there a weaker oracle than ERM which can nevertheless enable
learnability? We answer this question affirmatively, showing that in the
realizable setting of PAC learning for binary classification, a concept class
can be learned using an oracle which only returns a single bit indicating
whether a given dataset is realizable by some concept in the class. The sample
complexity and oracle complexity of our algorithm depend polynomially on the VC
dimension of the hypothesis class, thus showing that there is only a polynomial
price to pay for use of our weaker oracle. Our results extend to the agnostic
learning setting with a slight strengthening of the oracle, as well as to the
partial concept, multiclass and real-valued learning settings. In the setting
of partial concept classes, prior to our work no oracle-efficient algorithms
were known, even with a standard ERM oracle. Thus, our results address a
question of Alon et al. (2021) who asked whether there are algorithmic
principles which enable efficient learnability in this setting."
ROTI-GCV - Generalized Cross-Validation for right-ROTationally Invariant Data,https://arxiv.org/abs/2406.11666,2024-06-17,2024-06-19,0.0,0.0,"Two key tasks in high-dimensional regularized regression are tuning the
regularization strength for good predictions and estimating the out-of-sample
risk. It is known that the standard approach -- $k$-fold cross-validation -- is
inconsistent in modern high-dimensional settings. While leave-one-out and
generalized cross-validation remain consistent in some high-dimensional cases,
they become inconsistent when samples are dependent or contain heavy-tailed
covariates. To model structured sample dependence and heavy tails, we use
right-rotationally invariant covariate distributions - a crucial concept from
compressed sensing. In the common modern proportional asymptotics regime where
the number of features and samples grow comparably, we introduce a new
framework, ROTI-GCV, for reliably performing cross-validation. Along the way,
we propose new estimators for the signal-to-noise ratio and noise variance
under these challenging conditions. We conduct extensive experiments that
demonstrate the power of our approach and its superiority over existing
methods."
See It from My Perspective - Diagnosing the Western Cultural Bias of Large Vision-Language Models in Image Understanding,https://arxiv.org/abs/2406.11665,2024-06-17,2024-06-19,0.0,0.0,"Vision-language models (VLMs) can respond to queries about images in many
languages. However, beyond language, culture affects how we see things. For
example, individuals from Western cultures focus more on the central figure in
an image while individuals from Eastern cultures attend more to scene context.
In this work, we present a novel investigation that demonstrates and localizes
VLMs' Western bias in image understanding. We evaluate large VLMs across
subjective and objective visual tasks with culturally diverse images and
annotations. We find that VLMs perform better on the Western subset than the
Eastern subset of each task. Controlled experimentation tracing the source of
this bias highlights the importance of a diverse language mix in text-only
pre-training for building equitable VLMs, even when inference is performed in
English. Moreover, while prompting in the language of a target culture can lead
to reductions in bias, it is not a substitute for building AI more
representative of the world's languages."
Diffusion Generative Modelling for Divide-and-Conquer MCMC,https://arxiv.org/abs/2406.11664,2024-06-17,2024-06-19,0.0,0.0,"Divide-and-conquer MCMC is a strategy for parallelising Markov Chain Monte
Carlo sampling by running independent samplers on disjoint subsets of a dataset
and merging their output. An ongoing challenge in the literature is to
efficiently perform this merging without imposing distributional assumptions on
the posteriors. We propose using diffusion generative modelling to fit density
approximations to the subposterior distributions. This approach outperforms
existing methods on challenging merging problems, while its computational cost
scales more efficiently to high dimensional problems than existing density
estimation approaches."
Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting,https://arxiv.org/abs/2406.11661,2024-06-17,2024-06-19,0.0,0.0,"Socio-demographic prompting is a commonly employed approach to study cultural
biases in LLMs as well as for aligning models to certain cultures. In this
paper, we systematically probe four LLMs (Llama 3, Mistral v0.2, GPT-3.5 Turbo
and GPT-4) with prompts that are conditioned on culturally sensitive and
non-sensitive cues, on datasets that are supposed to be culturally sensitive
(EtiCor and CALI) or neutral (MMLU and ETHICS). We observe that all models
except GPT-4 show significant variations in their responses on both kinds of
datasets for both kinds of prompts, casting doubt on the robustness of the
culturally-conditioned prompting as a method for eliciting cultural bias in
models or as an alignment strategy. The work also calls rethinking the control
experiment design to tease apart the cultural conditioning of responses from
""placebo effect"", i.e., random perturbations of model responses due to
arbitrary tokens in the prompt."
Can LLM be a Personalized Judge?,https://arxiv.org/abs/2406.11657,2024-06-17,2024-06-19,0.0,0.0,"Ensuring that large language models (LLMs) reflect diverse user values and
preferences is crucial as their user bases expand globally. It is therefore
encouraging to see the growing interest in LLM personalization within the
research community. However, current works often rely on the LLM-as-a-Judge
approach for evaluation without thoroughly examining its validity. In this
paper, we investigate the reliability of LLM-as-a-Personalized-Judge, asking
LLMs to judge user preferences based on personas. Our findings suggest that
directly applying LLM-as-a-Personalized-Judge is less reliable than previously
assumed, showing low and inconsistent agreement with human ground truth. The
personas typically used are often overly simplistic, resulting in low
predictive power. To address these issues, we introduce verbal uncertainty
estimation into the LLM-as-a-Personalized-Judge pipeline, allowing the model to
express low confidence on uncertain judgments. This adjustment leads to much
higher agreement (above 80%) on high-certainty samples for binary tasks.
Through human evaluation, we find that the LLM-as-a-Personalized-Judge achieves
comparable performance to third-party humans evaluation and even surpasses
human performance on high-certainty samples. Our work indicates that
certainty-enhanced LLM-as-a-Personalized-Judge offers a promising direction for
developing more reliable and scalable methods for evaluating LLM
personalization."
Ruby Teaming - Improving Quality Diversity Search with Memory for Automated Red Teaming,https://arxiv.org/abs/2406.11654,2024-06-17,2024-06-19,0.0,0.0,"We propose Ruby Teaming, a method that improves on Rainbow Teaming by
including a memory cache as its third dimension. The memory dimension provides
cues to the mutator to yield better-quality prompts, both in terms of attack
success rate (ASR) and quality diversity. The prompt archive generated by Ruby
Teaming has an ASR of 74%, which is 20% higher than the baseline. In terms of
quality diversity, Ruby Teaming outperforms Rainbow Teaming by 6% and 3% on
Shannon's Evenness Index (SEI) and Simpson's Diversity Index (SDI),
respectively."
A Two-dimensional Zero-shot Dialogue State Tracking Evaluation Method using GPT-4,https://arxiv.org/abs/2406.11651,2024-06-17,2024-06-19,0.0,0.0,"Dialogue state tracking (DST) is evaluated by exact matching methods, which
rely on large amounts of labeled data and ignore semantic consistency, leading
to over-evaluation. Currently, leveraging large language models (LLM) in
evaluating natural language processing tasks has achieved promising results.
However, using LLM for DST evaluation is still under explored. In this paper,
we propose a two-dimensional zero-shot evaluation method for DST using GPT-4,
which divides the evaluation into two dimensions: accuracy and completeness.
Furthermore, we also design two manual reasoning paths in prompting to further
improve the accuracy of evaluation. Experimental results show that our method
achieves better performance compared to the baselines, and is consistent with
traditional exact matching based methods."
Multimodal Learning To Improve Segmentation With Intraoperative CBCT & Preoperative CT,https://arxiv.org/abs/2406.11650,2024-06-17,2024-06-19,0.0,0.0,"Cone-beam computed tomography (CBCT) is an important tool facilitating
computer aided interventions, despite often suffering from artifacts that pose
challenges for accurate interpretation. While the degraded image quality can
affect downstream segmentation, the availability of high quality, preoperative
scans represents potential for improvements. Here we consider a setting where
preoperative CT and intraoperative CBCT scans are available, however, the
alignment (registration) between the scans is imperfect. We propose a
multimodal learning method that fuses roughly aligned CBCT and CT scans and
investigate the effect of CBCT quality and misalignment on the final
segmentation performance. For that purpose, we make use of a synthetically
generated data set containing real CT and synthetic CBCT volumes. As an
application scenario, we focus on liver and liver tumor segmentation. We show
that the fusion of preoperative CT and simulated, intraoperative CBCT mostly
improves segmentation performance (compared to using intraoperative CBCT only)
and that even clearly misaligned preoperative data has the potential to improve
segmentation performance."
Making Old Things New - A Unified Algorithm for Differentially Private Clustering,https://arxiv.org/abs/2406.11649,2024-06-17,2024-06-19,0.0,0.0,"As a staple of data analysis and unsupervised learning, the problem of
private clustering has been widely studied under various privacy models.
Centralized differential privacy is the first of them, and the problem has also
been studied for the local and the shuffle variation. In each case, the goal is
to design an algorithm that computes privately a clustering, with the smallest
possible error. The study of each variation gave rise to new algorithms: the
landscape of private clustering algorithms is therefore quite intricate.
  In this paper, we show that a 20-year-old algorithm can be slightly modified
to work for any of these models. This provides a unified picture: while
matching almost all previously known results, it allows us to improve some of
them and extend it to a new privacy model, the continual observation setting,
where the input is changing over time and the algorithm must output a new
solution at each time step."
Linear Bellman Completeness Suffices for Efficient Online Reinforcement Learning with Few Actions,https://arxiv.org/abs/2406.11640,2024-06-17,2024-06-19,0.0,0.0,"One of the most natural approaches to reinforcement learning (RL) with
function approximation is value iteration, which inductively generates
approximations to the optimal value function by solving a sequence of
regression problems. To ensure the success of value iteration, it is typically
assumed that Bellman completeness holds, which ensures that these regression
problems are well-specified. We study the problem of learning an optimal policy
under Bellman completeness in the online model of RL with linear function
approximation. In the linear setting, while statistically efficient algorithms
are known under Bellman completeness (e.g., Jiang et al. (2017); Zanette et al.
(2020)), these algorithms all rely on the principle of global optimism which
requires solving a nonconvex optimization problem. In particular, it has
remained open as to whether computationally efficient algorithms exist. In this
paper we give the first polynomial-time algorithm for RL under linear Bellman
completeness when the number of actions is any constant."
MASAI - Modular Architecture for Software-engineering AI Agents,https://arxiv.org/abs/2406.11638,2024-06-17,2024-06-19,0.0,0.0,"A common method to solve complex problems in software engineering, is to
divide the problem into multiple sub-problems. Inspired by this, we propose a
Modular Architecture for Software-engineering AI (MASAI) agents, where
different LLM-powered sub-agents are instantiated with well-defined objectives
and strategies tuned to achieve those objectives. Our modular architecture
offers several advantages: (1) employing and tuning different problem-solving
strategies across sub-agents, (2) enabling sub-agents to gather information
from different sources scattered throughout a repository, and (3) avoiding
unnecessarily long trajectories which inflate costs and add extraneous context.
MASAI enabled us to achieve the highest performance (28.33% resolution rate) on
the popular and highly challenging SWE-bench Lite dataset consisting of 300
GitHub issues from 11 Python repositories. We conduct a comprehensive
evaluation of MASAI relative to other agentic methods and analyze the effects
of our design decisions and their contribution to the success of MASAI."
Feasibility of Federated Learning from Client Databases with Different Brain Diseases and MRI Modalities,https://arxiv.org/abs/2406.11636,2024-06-17,2024-06-19,0.0,0.0,"Segmentation models for brain lesions in MRI are commonly developed for a
specific disease and trained on data with a predefined set of MRI modalities.
Each such model cannot segment the disease using data with a different set of
MRI modalities, nor can it segment any other type of disease. Moreover, this
training paradigm does not allow a model to benefit from learning from
heterogeneous databases that may contain scans and segmentation labels for
different types of brain pathologies and diverse sets of MRI modalities.
Additionally, the sensitivity of patient data often prevents centrally
aggregating data, necessitating a decentralized approach. Is it feasible to use
Federated Learning (FL) to train a single model on client databases that
contain scans and labels of different brain pathologies and diverse sets of MRI
modalities? We demonstrate promising results by combining appropriate, simple,
and practical modifications to the model and training strategy: Designing a
model with input channels that cover the whole set of modalities available
across clients, training with random modality drop, and exploring the effects
of feature normalization methods. Evaluation on 7 brain MRI databases with 5
different diseases shows that such FL framework can train a single model that
is shown to be very promising in segmenting all disease types seen during
training. Importantly, it is able to segment these diseases in new databases
that contain sets of modalities different from those in training clients. These
results demonstrate, for the first time, the feasibility and effectiveness of
using Federated Learning to train a single 3D segmentation model on
decentralised data with diverse brain diseases and MRI modalities, a necessary
step towards leveraging heterogeneous real-world databases. Code will be made
available at: https://github.com/FelixWag/FL-MultiDisease-MRI"
The Base-Rate Effect on LLM Benchmark Performance - Disambiguating Test-Taking Strategies from Benchmark Performance,https://arxiv.org/abs/2406.11634,2024-06-17,2024-06-19,0.0,0.0,"Cloze testing is a common method for measuring the behavior of large language
models on a number of benchmark tasks. Using the MMLU dataset, we show that the
base-rate probability (BRP) differences across answer tokens are significant
and affect task performance ie. guess A if uncertain. We find that
counterfactual prompting does sufficiently mitigate the BRP effect. The BRP
effect is found to have a similar effect to test taking strategies employed by
humans leading to the conflation of task performance and test-taking ability.
We propose the Nvr-X-MMLU task, a variation of MMLU, which helps to
disambiguate test-taking ability from task performance and reports the latter."
Unveiling the Power of Source - Source-based Minimum Bayes Risk Decoding for Neural Machine Translation,https://arxiv.org/abs/2406.11632,2024-06-17,2024-06-19,0.0,0.0,"Maximum a posteriori decoding, a commonly used method for neural machine
translation (NMT), aims to maximize the estimated posterior probability.
However, high estimated probability does not always lead to high translation
quality. Minimum Bayes Risk (MBR) decoding offers an alternative by seeking
hypotheses with the highest expected utility.
  In this work, we show that Quality Estimation (QE) reranking, which uses a QE
model as a reranker, can be viewed as a variant of MBR. Inspired by this, we
propose source-based MBR (sMBR) decoding, a novel approach that utilizes
synthetic sources generated by backward translation as ``support hypotheses''
and a reference-free quality estimation metric as the utility function, marking
the first work to solely use sources in MBR decoding. Experiments show that
sMBR significantly outperforms QE reranking and is competitive with standard
MBR decoding. Furthermore, sMBR calls the utility function fewer times compared
to MBR. Our findings suggest that sMBR is a promising approach for high-quality
NMT decoding."
The Liouville Generator for Producing Integrable Expressions,https://arxiv.org/abs/2406.11631,2024-06-17,2024-06-19,0.0,0.0,"There has been a growing need to devise processes that can create
comprehensive datasets in the world of Computer Algebra, both for accurate
benchmarking and for new intersections with machine learning technology. We
present here a method to generate integrands that are guaranteed to be
integrable, dubbed the LIOUVILLE method. It is based on Liouville's theorem and
the Parallel Risch Algorithm for symbolic integration.
  We show that this data generation method retains the best qualities of
previous data generation methods, while overcoming some of the issues built
into that prior work. The LIOUVILLE generator is able to generate sufficiently
complex and realistic integrands, and could be used for benchmarking or machine
learning training tasks related to symbolic integration."
"Can Many-Shot In-Context Learning Help Long-Context LLM Judges? See More, Judge Better!",https://arxiv.org/abs/2406.11629,2024-06-17,2024-06-19,0.0,0.0,"Utilizing Large Language Models (LLMs) as evaluators for evaluating the
performance of LLMs has recently garnered attention. However, this kind of
evaluation approach is affected by potential biases in LLMs, raising concerns
about the accuracy and reliability of the evaluation results. To mitigate this
issue, we propose and study two many-shot ICL prompts, which rely on two
versions of many-shot ICL prompt templates for helping LLM evaluators to
mitigate the potential biases in LLMs, \textbf{M}any-\textbf{S}hot
\textbf{w}ith \textbf{R}eference (\textbf{MSwR}) and
\textbf{M}any-\textbf{S}hot with\textbf{o}ut \textbf{R}eference
(\textbf{MSoR}). Concretely, the former utilizes in-context examples with
model-generated rationales as guidance, and the latter without. Based on the
designed prompts, we investigate the impact of scaling the number of in-context
examples on the consistency and quality of the evaluation results. Experimental
results show that advanced LLMs, such as GPT-4o, perform better in the
many-shot regime than in the zero-shot regime. Furthermore, we reveal the
symbol bias hidden in the selection bias of LLMs and propose a simple yet
effective approach to mitigate the bias. Experimental results further verify
the effectiveness of the symbol bias mitigation approach."
Words in Motion - Representation Engineering for Motion Forecasting,https://arxiv.org/abs/2406.11624,2024-06-17,2024-06-19,0.0,0.0,"Motion forecasting transforms sequences of past movements and environment
context into future motion. Recent methods rely on learned representations,
resulting in hidden states that are difficult to interpret. In this work, we
use natural language to quantize motion features in a human-interpretable way,
and measure the degree to which they are embedded in hidden states. Our
experiments reveal that hidden states of motion sequences are arranged with
respect to our discrete sets of motion features. Following these insights, we
fit control vectors to motion features, which allow for controlling motion
forecasts at inference. Consequently, our method enables controlling
transformer-based motion forecasting models with textual inputs, providing a
unique interface to interact with and understand these models. Our
implementation is available at https://github.com/kit-mrt/future-motion"
Building Knowledge-Guided Lexica to Model Cultural Variation,https://arxiv.org/abs/2406.11622,2024-06-17,2024-06-19,0.0,0.0,"Cultural variation exists between nations (e.g., the United States vs.
China), but also within regions (e.g., California vs. Texas, Los Angeles vs.
San Francisco). Measuring this regional cultural variation can illuminate how
and why people think and behave differently. Historically, it has been
difficult to computationally model cultural variation due to a lack of training
data and scalability constraints. In this work, we introduce a new research
problem for the NLP community: How do we measure variation in cultural
constructs across regions using language? We then provide a scalable solution:
building knowledge-guided lexica to model cultural variation, encouraging
future work at the intersection of NLP and cultural understanding. We also
highlight modern LLMs' failure to measure cultural variation or generate
culturally varied language."
AV-CrossNet - an Audiovisual Complex Spectral Mapping Network for Speech Separation By Leveraging Narrow- and Cross-Band Modeling,https://arxiv.org/abs/2406.11619,2024-06-17,2024-06-19,0.0,0.0,"Adding visual cues to audio-based speech separation can improve separation
performance. This paper introduces AV-CrossNet, an audiovisual (AV) system for
speech enhancement, target speaker extraction, and multi-talker speaker
separation. AV-CrossNet is extended from the CrossNet architecture, which is a
recently proposed network that performs complex spectral mapping for speech
separation by leveraging global attention and positional encoding. To
effectively utilize visual cues, the proposed system incorporates pre-extracted
visual embeddings and employs a visual encoder comprising temporal
convolutional layers. Audio and visual features are fused in an early fusion
layer before feeding to AV-CrossNet blocks. We evaluate AV-CrossNet on multiple
datasets, including LRS, VoxCeleb, and COG-MHEAR challenge. Evaluation results
demonstrate that AV-CrossNet advances the state-of-the-art performance in all
audiovisual tasks, even on untrained and mismatched datasets."
DELLA-Merging - Reducing Interference in Model Merging through Magnitude-Based Sampling,https://arxiv.org/abs/2406.11617,2024-06-17,2024-06-19,0.0,0.0,"With the proliferation of domain-specific models, model merging has emerged
as a set of techniques that combine the capabilities of multiple models into
one that can multitask without the cost of additional training. In this paper,
we propose a new model merging technique, Drop and rEscaLe via sampLing with
mAgnitude (DELLA-Merging), that employs a novel pruning technique, MAGPRUNE,
which shows significant advantages over DARE and TIES. MAGPRUNE first ranks the
parameters in order of their magnitude and assigns higher dropout probabilities
(p) to parameters with lower ranks corresponding to lower magnitudes. To
approximate the original embeddings, MAGPRUNE employs a rescaling operation on
the parameters that survive the random dropping by 1/(1 - p). On three
different expert models considered for merging (LM, Math, Code) and
corresponding benchmark datasets (AlpacaEval, GSM8K, MBPP), DELLA shows an
average improvement of 2.4 points over baseline methods employing delta
parameter pruning (an improvement of 3.6 points over TIES, 1.2 points over
DARE), and 11.1 points over the no-pruning baseline (TA). We release the source
code at: https://github.com/declare-lab/della."
Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces,https://arxiv.org/abs/2406.11614,2024-06-17,2024-06-19,0.0,0.0,"The task of ""unlearning"" certain concepts in large language models (LLMs) has
attracted immense attention recently, due to its importance for mitigating
undesirable model behaviours, such as the generation of harmful, private, or
incorrect information. Current protocols to evaluate unlearning methods largely
rely on behavioral tests, without monitoring the presence of unlearned
knowledge within the model's parameters. This residual knowledge can be
adversarially exploited to recover the erased information post-unlearning. We
argue that unlearning should also be evaluated internally, by considering
changes in the parametric knowledge traces of the unlearned concepts. To this
end, we propose a general methodology for eliciting directions in the parameter
space (termed ""concept vectors"") that encode concrete concepts, and construct
ConceptVectors, a benchmark dataset containing hundreds of common concepts and
their parametric knowledge traces within two open-source LLMs. Evaluation on
ConceptVectors shows that existing unlearning methods minimally impact concept
vectors, while directly ablating these vectors demonstrably removes the
associated knowledge from the LLMs and significantly reduces their
susceptibility to adversarial manipulation. Our results highlight limitations
in behavioral-based unlearning evaluations and call for future work to include
parametric-based evaluations. To support this, we release our code and
benchmark at https://github.com/yihuaihong/ConceptVectors."
Long Code Arena - a Set of Benchmarks for Long-Context Code Models,https://arxiv.org/abs/2406.11612,2024-06-17,2024-06-19,0.0,0.0,"Nowadays, the fields of code and natural language processing are evolving
rapidly. In particular, models become better at processing long context windows
- supported context sizes have increased by orders of magnitude over the last
few years. However, there is a shortage of benchmarks for code processing that
go beyond a single file of context, while the most popular ones are limited to
a single method. With this work, we aim to close this gap by introducing Long
Code Arena, a suite of six benchmarks for code processing tasks that require
project-wide context. These tasks cover different aspects of code processing:
library-based code generation, CI builds repair, project-level code completion,
commit message generation, bug localization, and module summarization. For each
task, we provide a manually verified dataset for testing, an evaluation suite,
and open-source baseline solutions based on popular LLMs to showcase the usage
of the dataset and to simplify adoption by other researchers. We publish the
benchmark page on HuggingFace Spaces with the leaderboard, links to HuggingFace
Hub for all the datasets, and link to the GitHub repository with baselines:
https://huggingface.co/spaces/JetBrains-Research/long-code-arena."
Standardizing Structural Causal Models,https://arxiv.org/abs/2406.11601,2024-06-17,2024-06-19,0.0,0.0,"Synthetic datasets generated by structural causal models (SCMs) are commonly
used for benchmarking causal structure learning algorithms. However, the
variances and pairwise correlations in SCM data tend to increase along the
causal ordering. Several popular algorithms exploit these artifacts, possibly
leading to conclusions that do not generalize to real-world settings. Existing
metrics like $\operatorname{Var}$-sortability and
$\operatorname{R^2}$-sortability quantify these patterns, but they do not
provide tools to remedy them. To address this, we propose
internally-standardized structural causal models (iSCMs), a modification of
SCMs that introduces a standardization operation at each variable during the
generative process. By construction, iSCMs are not
$\operatorname{Var}$-sortable, and as we show experimentally, not
$\operatorname{R^2}$-sortable either for commonly-used graph families.
Moreover, contrary to the post-hoc standardization of data generated by
standard SCMs, we prove that linear iSCMs are less identifiable from prior
knowledge on the weights and do not collapse to deterministic relationships in
large systems, which may make iSCMs a useful model in causal inference beyond
the benchmarking problem studied here."
"Understanding ""Democratization"" in NLP and ML Research",https://arxiv.org/abs/2406.11598,2024-06-17,2024-06-19,0.0,0.0,"Recent improvements in natural language processing (NLP) and machine learning
(ML) and increased mainstream adoption have led to researchers frequently
discussing the ""democratization"" of artificial intelligence. In this paper, we
seek to clarify how democratization is understood in NLP and ML publications,
through large-scale mixed-methods analyses of papers using the keyword
""democra*"" published in NLP and adjacent venues. We find that democratization
is most frequently used to convey (ease of) access to or use of technologies,
without meaningfully engaging with theories of democratization, while research
using other invocations of ""democra*"" tends to be grounded in theories of
deliberation and debate. Based on our findings, we call for researchers to
enrich their use of the term democratization with appropriate theory, towards
democratic technologies beyond superficial access."
On GNN explanability with activation rules,https://arxiv.org/abs/2406.11594,2024-06-17,2024-06-19,0.0,0.0,"GNNs are powerful models based on node representation learning that perform
particularly well in many machine learning problems related to graphs. The
major obstacle to the deployment of GNNs is mostly a problem of societal
acceptability and trustworthiness, properties which require making explicit the
internal functioning of such models. Here, we propose to mine activation rules
in the hidden layers to understand how the GNNs perceive the world. The problem
is not to discover activation rules that are individually highly discriminating
for an output of the model. Instead, the challenge is to provide a small set of
rules that cover all input graphs. To this end, we introduce the subjective
activation pattern domain. We define an effective and principled algorithm to
enumerate activations rules in each hidden layer. The proposed approach for
quantifying the interest of these rules is rooted in information theory and is
able to account for background knowledge on the input graph data. The
activation rules can then be redescribed thanks to pattern languages involving
interpretable features. We show that the activation rules provide insights on
the characteristics used by the GNN to classify the graphs. Especially, this
allows to identify the hidden features built by the GNN through its different
layers. Also, these rules can subsequently be used for explaining GNN
decisions. Experiments on both synthetic and real-life datasets show highly
competitive performance, with up to 200% improvement in fidelity on explaining
graph classification over the SOTA methods."
CoSQA+ - Enhancing Code Search Dataset with Matching Code,https://arxiv.org/abs/2406.11589,2024-06-17,2024-06-19,0.0,0.0,"Semantic code search, retrieving code that matches a given natural language
query, is an important task to improve productivity in software engineering.
Existing code search datasets are problematic: either using unrealistic
queries, or with mismatched codes, and typically using one-to-one query-code
pairing, which fails to reflect the reality that a query might have multiple
valid code matches. This paper introduces CoSQA+, pairing high-quality queries
(reused from CoSQA) with multiple suitable codes. We collect code candidates
from diverse sources and form candidate pairs by pairing queries with these
codes. Utilizing the power of large language models (LLMs), we automate pair
annotation, filtering, and code generation for queries without suitable
matches. Through extensive experiments, CoSQA+ has demonstrated superior
quality over CoSQA. Models trained on CoSQA+ exhibit improved performance.
Furthermore, we propose a new metric Mean Multi-choice Reciprocal Rank (MMRR),
to assess one-to-N code search performance. We provide the code and data at
https://github.com/DeepSoftwareAnalytics/CoSQA_Plus."
Style Transfer with Multi-iteration Preference Optimization,https://arxiv.org/abs/2406.11581,2024-06-17,2024-06-19,0.0,0.0,"Numerous recent techniques for text style transfer characterize their
approaches as variants of reinforcement learning and preference optimization.
In this work, we consider the relationship between these approaches and a class
of optimization approaches developed primarily for (non-neural) statistical
machine translation, formerly known as `tuning'. Inspired by these techniques
from the past, we improve upon established preference optimization approaches,
incorporating multiple iterations of exploration and optimization, and choosing
contrastive examples by following a `hope' vs `fear' sampling strategy.
Cognizant of the difference between machine translation and style transfer,
however, we further tailor our framework with a new pseudo-parallel generation
method and a dynamic weighted reward aggregation method to tackle the lack of
parallel data and the need for a multi-objective reward. We evaluate our model
on two commonly used text style transfer datasets. Through automatic and human
evaluation results we show the effectiveness and the superiority of our model
compared to state-of-the-art baselines."
Mathematical Entities - Corpora and Benchmarks,https://arxiv.org/abs/2406.11577,2024-06-17,2024-06-19,0.0,0.0,"Mathematics is a highly specialized domain with its own unique set of
challenges. Despite this, there has been relatively little research on natural
language processing for mathematical texts, and there are few mathematical
language resources aimed at NLP. In this paper, we aim to provide annotated
corpora that can be used to study the language of mathematics in different
contexts, ranging from fundamental concepts found in textbooks to advanced
research mathematics. We preprocess the corpora with a neural parsing model and
some manual intervention to provide part-of-speech tags, lemmas, and dependency
trees. In total, we provide 182397 sentences across three corpora. We then aim
to test and evaluate several noteworthy natural language processing models
using these corpora, to show how well they can adapt to the domain of
mathematics and provide useful tools for exploring mathematical language. We
evaluate several neural and symbolic models against benchmarks that we extract
from the corpus metadata to show that terminology extraction and definition
extraction do not easily generalize to mathematics, and that additional work is
needed to achieve good performance on these metrics. Finally, we provide a
learning assistant that grants access to the content of these corpora in a
context-sensitive manner, utilizing text search and entity linking. Though our
corpora and benchmarks provide useful metrics for evaluating mathematical
language processing, further work is necessary to adapt models to mathematics
in order to provide more effective learning assistants and apply NLP methods to
different mathematical domains."
Towards an End-to-End Framework for Invasive Brain Signal Decoding with Large Language Models,https://arxiv.org/abs/2406.11568,2024-06-17,2024-06-19,0.0,0.0,"In this paper, we introduce a groundbreaking end-to-end (E2E) framework for
decoding invasive brain signals, marking a significant advancement in the field
of speech neuroprosthesis. Our methodology leverages the comprehensive
reasoning abilities of large language models (LLMs) to facilitate direct
decoding. By fully integrating LLMs, we achieve results comparable to the
state-of-the-art cascade models. Our findings underscore the immense potential
of E2E frameworks in speech neuroprosthesis, particularly as the technology
behind brain-computer interfaces (BCIs) and the availability of relevant
datasets continue to evolve. This work not only showcases the efficacy of
combining LLMs with E2E decoding for enhancing speech neuroprosthesis but also
sets a new direction for future research in BCI applications, underscoring the
impact of LLMs in decoding complex neural signals for communication
restoration. Code will be made available at
https://github.com/FsFrancis15/BrainLLM."
Quaternion Generative Adversarial Neural Networks and Applications to Color Image Inpainting,https://arxiv.org/abs/2406.11567,2024-06-17,2024-06-19,0.0,0.0,"Color image inpainting is a challenging task in imaging science. The existing
method is based on real operation, and the red, green and blue channels of the
color image are processed separately, ignoring the correlation between each
channel. In order to make full use of the correlation between each channel,
this paper proposes a Quaternion Generative Adversarial Neural Network (QGAN)
model and related theory, and applies it to solve the problem of color image
inpainting with large area missing. Firstly, the definition of quaternion
deconvolution is given and the quaternion batch normalization is proposed.
Secondly, the above two innovative modules are applied to generate adversarial
networks to improve stability. Finally, QGAN is applied to color image
inpainting and compared with other state-of-the-art algorithms. The
experimental results show that QGAN has superiority in color image inpainting
with large area missing."
MEMLA - Enhancing Multilingual Knowledge Editing with Neuron-Masked Low-Rank Adaptation,https://arxiv.org/abs/2406.11566,2024-06-17,2024-06-19,0.0,0.0,"Knowledge editing aims to adjust the knowledge within large language models
(LLMs) to prevent their responses from becoming obsolete or inaccurate.
However, existing works on knowledge editing are primarily conducted in a
single language, which is inadequate for multilingual language models. In this
paper, we focus on multilingual knowledge editing (MKE), which requires
propagating updates across multiple languages. This necessity poses a
significant challenge for the task. Furthermore, the limited availability of a
comprehensive dataset for MKE exacerbates this challenge, hindering progress in
this area. Hence, we introduce the Multilingual Knowledge Editing Benchmark
(MKEB), a novel dataset comprising 12 languages and providing a complete
evaluation framework. Additionally, we propose a method that enhances
Multilingual knowledge Editing with neuron-Masked Low-Rank Adaptation (MEMLA).
Specifically, we identify two categories of knowledge neurons to improve
editing precision. Moreover, we perform LoRA-based editing with neuron masks to
efficiently modify parameters and facilitate the propagation of updates across
multiple languages. Experiments demonstrate that our method outperforms
existing baselines and significantly enhances the multi-hop reasoning
capability of the edited model, with minimal impact on its downstream task
performance. The dataset and code will be made publicly available."
Extrinsic Evaluation of Cultural Competence in Large Language Models,https://arxiv.org/abs/2406.11565,2024-06-17,2024-06-19,0.0,0.0,"Productive interactions between diverse users and language technologies
require outputs from the latter to be culturally relevant and sensitive. Prior
works have evaluated models' knowledge of cultural norms, values, and
artifacts, without considering how this knowledge manifests in downstream
applications. In this work, we focus on extrinsic evaluation of cultural
competence in two text generation tasks, open-ended question answering and
story generation. We quantitatively and qualitatively evaluate model outputs
when an explicit cue of culture, specifically nationality, is perturbed in the
prompts. Although we find that model outputs do vary when varying nationalities
and feature culturally relevant words, we also find weak correlations between
text similarity of outputs for different countries and the cultural values of
these countries. Finally, we discuss important considerations in designing
comprehensive evaluation of cultural competence in user-facing tasks."
Intersymbolic AI - Interlinking Symbolic AI and Subsymbolic AI,https://arxiv.org/abs/2406.11563,2024-06-17,2024-06-19,0.0,0.0,"This perspective piece calls for the study of the new field of Intersymbolic
AI, by which we mean the combination of symbolic AI, whose building blocks have
inherent significance/meaning, with subsymbolic AI, whose entirety creates
significance/effect despite the fact that individual building blocks escape
meaning. Canonical kinds of symbolic AI are logic, games and planning.
Canonical kinds of subsymbolic AI are (un)supervised machine and reinforcement
learning. Intersymbolic AI interlinks the worlds of symbolic AI with its
compositional symbolic significance and meaning and of subsymbolic AI with its
summative significance or effect to enable culminations of insights from both
worlds by going between and across symbolic AI insights with subsymbolic AI
techniques that are being helped by symbolic AI principles. For example,
Intersymbolic AI may start with symbolic AI to understand a dynamic system,
continue with subsymbolic AI to learn its control, and end with symbolic AI to
safely use the outcome of the learned subsymbolic AI controller in the dynamic
system. The way Intersymbolic AI combines both symbolic and subsymbolic AI to
increase the effectiveness of AI compared to either kind of AI alone is likened
to the way that the combination of both conscious and subconscious thought
increases the effectiveness of human thought compared to either kind of thought
alone. Some successful contributions to the Intersymbolic AI paradigm are
surveyed here but many more are considered possible by advancing Intersymbolic
AI."
Input Conditioned Graph Generation for Language Agents,https://arxiv.org/abs/2406.11555,2024-06-17,2024-06-19,0.0,0.0,"Recent progress in Large Language Models (LLMs) and language agents has
demonstrated significant promise for various future applications across
multiple disciplines. While traditional approaches to language agents often
rely on fixed, handcrafted designs, our research aims to develop both learnable
and dynamic agents. Our method uses an existing framework that abstracts
language agents as graphs. Within this graph framework, we aim to learn a model
that can generate edges for every given input to the language agent. This
allows us to generate edges that represent the flow of communication within the
graph based on the given input, thereby adjusting the internal communication of
a language agent. We learn to generate these edges using a pretrained LLM that
is fine-tuned with reinforcement learning. This LLM can be fine-tuned on
several datasets simultaneously, and we hypothesize that the model learns to
adapt to these different domains during training, achieving good overall
performance when encountering data from different domains during deployment. We
demonstrate that our approach surpasses the previous static approach by nearly
6% accuracy on a combined dataset of MMLU and CMMLU, and by more than 10% when
trained with a sparsity-inducing loss. It also performs superior in additional
experiments conducted with the MMLU and Mini Crossword Puzzles datasets. The
code is available at https://github.com/lukasVierling/DynamicGPTSwarm."
DeepSeek-Coder-V2 - Breaking the Barrier of Closed-Source Models in Code Intelligence,https://arxiv.org/abs/2406.11931,2024-06-17,2024-06-19,0.0,0.0,"We present DeepSeek-Coder-V2, an open-source Mixture-of-Experts (MoE) code
language model that achieves performance comparable to GPT4-Turbo in
code-specific tasks. Specifically, DeepSeek-Coder-V2 is further pre-trained
from an intermediate checkpoint of DeepSeek-V2 with additional 6 trillion
tokens. Through this continued pre-training, DeepSeek-Coder-V2 substantially
enhances the coding and mathematical reasoning capabilities of DeepSeek-V2,
while maintaining comparable performance in general language tasks. Compared to
DeepSeek-Coder-33B, DeepSeek-Coder-V2 demonstrates significant advancements in
various aspects of code-related tasks, as well as reasoning and general
capabilities. Additionally, DeepSeek-Coder-V2 expands its support for
programming languages from 86 to 338, while extending the context length from
16K to 128K. In standard benchmark evaluations, DeepSeek-Coder-V2 achieves
superior performance compared to closed-source models such as GPT4-Turbo,
Claude 3 Opus, and Gemini 1.5 Pro in coding and math benchmarks."
AIC MLLM - Autonomous Interactive Correction MLLM for Robust Robotic Manipulation,https://arxiv.org/abs/2406.11548,2024-06-17,2024-06-19,0.0,0.0,"The ability to reflect on and correct failures is crucial for robotic systems
to interact stably with real-life objects.Observing the generalization and
reasoning capabilities of Multimodal Large Language Models (MLLMs), previous
approaches have aimed to utilize these models to enhance robotic systems
accordingly.However, these methods typically focus on high-level planning
corrections using an additional MLLM, with limited utilization of failed
samples to correct low-level contact poses. To address this gap, we propose an
Autonomous Interactive Correction (AIC) MLLM, which makes use of previous
low-level interaction experiences to correct SE(3) pose predictions.
Specifically, AIC MLLM is initially fine-tuned to acquire both pose prediction
and feedback prompt comprehension abilities.We carefully design two types of
prompt instructions through interactions with objects: 1) visual masks to
highlight unmovable parts for position correction, and 2)textual descriptions
to indicate potential directions for rotation correction.During inference, a
Feedback Information Extraction module is introduced to recognize the failure
cause, allowing AIC MLLM to adaptively correct the pose prediction using the
corresponding prompts. To further enhance manipulation stability, we devise a
Test Time Adaptation strategy that enables AIC MLLM to better adapt to the
current scene configuration.Finally, extensive experiments are conducted in
both simulated and real-world environments to evaluate the proposed method. The
results demonstrate that our AIC MLLM can efficiently correct failure samples
by leveraging interaction experience prompts.Real-world demonstration can be
found at https://sites.google.com/view/aic-mllm"
Do Parameters Reveal More than Loss for Membership Inference?,https://arxiv.org/abs/2406.11544,2024-06-17,2024-06-19,0.0,0.0,"Membership inference attacks aim to infer whether an individual record was
used to train a model, serving as a key tool for disclosure auditing. While
such evaluations are useful to demonstrate risk, they are computationally
expensive and often make strong assumptions about potential adversaries' access
to models and training environments, and thus do not provide very tight bounds
on leakage from potential attacks. We show how prior claims around black-box
access being sufficient for optimal membership inference do not hold for most
useful settings such as stochastic gradient descent, and that optimal
membership inference indeed requires white-box access. We validate our findings
with a new white-box inference attack IHA (Inverse Hessian Attack) that
explicitly uses model parameters by taking advantage of computing
inverse-Hessian vector products. Our results show that both audits and
adversaries may be able to benefit from access to model parameters, and we
advocate for further research into white-box methods for membership privacy
auditing."
Improving Quality Control of Whole Slide Images by Explicit Artifact Augmentation,https://arxiv.org/abs/2406.11538,2024-06-17,2024-06-19,0.0,0.0,"The problem of artifacts in whole slide image acquisition, prevalent in both
clinical workflows and research-oriented settings, necessitates human
intervention and re-scanning. Overcoming this challenge requires developing
quality control algorithms, that are hindered by the limited availability of
relevant annotated data in histopathology. The manual annotation of
ground-truth for artifact detection methods is expensive and time-consuming.
This work addresses the issue by proposing a method dedicated to augmenting
whole slide images with artifacts. The tool seamlessly generates and blends
artifacts from an external library to a given histopathology dataset. The
augmented datasets are then utilized to train artifact classification methods.
The evaluation shows their usefulness in classification of the artifacts, where
they show an improvement from 0.10 to 0.01 AUROC depending on the artifact
type. The framework, model, weights, and ground-truth annotations are freely
released to facilitate open science and reproducible research."
Explainable Artificial Intelligence and Multicollinearity  - A Mini Review of Current Approaches,https://arxiv.org/abs/2406.11524,2024-06-17,2024-06-19,0.0,0.0,"Explainable Artificial Intelligence (XAI) methods help to understand the
internal mechanism of machine learning models and how they reach a specific
decision or made a specific action. The list of informative features is one of
the most common output of XAI methods. Multicollinearity is one of the big
issue that should be considered when XAI generates the explanation in terms of
the most informative features in an AI system. No review has been dedicated to
investigate the current approaches to handle such significant issue. In this
paper, we provide a review of the current state-of-the-art approaches in
relation to the XAI in the context of recent advances in dealing with the
multicollinearity issue. To do so, we searched in three repositories that are:
Web of Science, Scopus and IEEE Xplore to find pertinent published papers.
After excluding irrelevant papers, seven papers were considered in the review.
In addition, we discuss the current XAI methods and their limitations in
dealing with the multicollinearity and suggest future directions."
FullCert - Deterministic End-to-End Certification for Training and Inference of Neural Networks,https://arxiv.org/abs/2406.11522,2024-06-17,2024-06-19,0.0,0.0,"Modern machine learning models are sensitive to the manipulation of both the
training data (poisoning attacks) and inference data (adversarial examples).
Recognizing this issue, the community has developed many empirical defenses
against both attacks and, more recently, certification methods with provable
guarantees against inference-time attacks. However, such guarantees are still
largely lacking for training-time attacks. In this work, we present FullCert,
the first end-to-end certifier with sound, deterministic bounds, which proves
robustness against both training-time and inference-time attacks. We first
bound all possible perturbations an adversary can make to the training data
under the considered threat model. Using these constraints, we bound the
perturbations' influence on the model's parameters. Finally, we bound the
impact of these parameter changes on the model's prediction, resulting in joint
robustness guarantees against poisoning and adversarial examples. To facilitate
this novel certification paradigm, we combine our theoretical work with a new
open-source library BoundFlow, which enables model training on bounded
datasets. We experimentally demonstrate FullCert's feasibility on two datasets."
Revisiting Spurious Correlation in Domain Generalization,https://arxiv.org/abs/2406.11517,2024-06-17,2024-06-19,0.0,0.0,"Without loss of generality, existing machine learning techniques may learn
spurious correlation dependent on the domain, which exacerbates the
generalization of models in out-of-distribution (OOD) scenarios. To address
this issue, recent works build a structural causal model (SCM) to describe the
causality within data generation process, thereby motivating methods to avoid
the learning of spurious correlation by models. However, from the machine
learning viewpoint, such a theoretical analysis omits the nuanced difference
between the data generation process and representation learning process,
resulting in that the causal analysis based on the former cannot well adapt to
the latter. To this end, we explore to build a SCM for representation learning
process and further conduct a thorough analysis of the mechanisms underlying
spurious correlation. We underscore that adjusting erroneous covariates
introduces bias, thus necessitating the correct selection of spurious
correlation mechanisms based on practical application scenarios. In this
regard, we substantiate the correctness of the proposed SCM and further propose
to control confounding bias in OOD generalization by introducing a propensity
score weighted estimator, which can be integrated into any existing OOD method
as a plug-and-play module. The empirical results comprehensively demonstrate
the effectiveness of our method on synthetic and large-scale real OOD datasets."
Counterfactual Debating with Preset Stances for Hallucination Elimination of LLMs,https://arxiv.org/abs/2406.11514,2024-06-17,2024-06-19,0.0,0.0,"Large Language Models (LLMs) excel in various natural language processing
tasks but struggle with hallucination issues. Existing solutions have
considered utilizing LLMs' inherent reasoning abilities to alleviate
hallucination, such as self-correction and diverse sampling methods. However,
these methods often overtrust LLMs' initial answers due to inherent biases. The
key to alleviating this issue lies in overriding LLMs' inherent biases for
answer inspection. To this end, we propose a CounterFactual Multi-Agent Debate
(CFMAD) framework. CFMAD presets the stances of LLMs to override their inherent
biases by compelling LLMs to generate justifications for a predetermined
answer's correctness. The LLMs with different predetermined stances are engaged
with a skeptical critic for counterfactual debate on the rationality of
generated justifications. Finally, the debate process is evaluated by a
third-party judge to determine the final answer. Extensive experiments on four
datasets of three tasks demonstrate the superiority of CFMAD over existing
methods."
A Critical Study of What Code-LLMs (Do Not) Learn,https://arxiv.org/abs/2406.11930,2024-06-17,2024-06-19,0.0,0.0,"Large Language Models trained on code corpora (code-LLMs) have demonstrated
impressive performance in various coding assistance tasks. However, despite
their increased size and training dataset, code-LLMs still have limitations
such as suggesting codes with syntactic errors, variable misuse etc. Some
studies argue that code-LLMs perform well on coding tasks because they use
self-attention and hidden representations to encode relations among input
tokens. However, previous works have not studied what code properties are not
encoded by code-LLMs. In this paper, we conduct a fine-grained analysis of
attention maps and hidden representations of code-LLMs. Our study indicates
that code-LLMs only encode relations among specific subsets of input tokens.
Specifically, by categorizing input tokens into syntactic tokens and
identifiers, we found that models encode relations among syntactic tokens and
among identifiers, but they fail to encode relations between syntactic tokens
and identifiers. We also found that fine-tuned models encode these relations
poorly compared to their pre-trained counterparts. Additionally, larger models
with billions of parameters encode significantly less information about code
than models with only a few hundred million parameters."
On the Feasibility of Fidelity$^-$ for Graph Pruning,https://arxiv.org/abs/2406.11504,2024-06-17,2024-06-19,0.0,0.0,"As one of popular quantitative metrics to assess the quality of explanation
of graph neural networks (GNNs), fidelity measures the output difference after
removing unimportant parts of the input graph. Fidelity has been widely used
due to its straightforward interpretation that the underlying model should
produce similar predictions when features deemed unimportant from the
explanation are removed. This raises a natural question: ""Does fidelity induce
a global (soft) mask for graph pruning?"" To solve this, we aim to explore the
potential of the fidelity measure to be used for graph pruning, eventually
enhancing the GNN models for better efficiency. To this end, we propose
Fidelity$^-$-inspired Pruning (FiP), an effective framework to construct global
edge masks from local explanations. Our empirical observations using 7 edge
attribution methods demonstrate that, surprisingly, general eXplainable AI
methods outperform methods tailored to GNNs in terms of graph pruning
performance."
GeoGPT4V - Towards Geometric Multi-modal Large Language Models with Geometric Image Generation,https://arxiv.org/abs/2406.11503,2024-06-17,2024-06-19,0.0,0.0,"Large language models have seen widespread adoption in math problem-solving.
However, in geometry problems that usually require visual aids for better
understanding, even the most advanced multi-modal models currently still face
challenges in effectively using image information. High-quality data is crucial
for enhancing the geometric capabilities of multi-modal models, yet existing
open-source datasets and related efforts are either too challenging for direct
model learning or suffer from misalignment between text and images. To overcome
this issue, we introduce a novel pipeline that leverages GPT-4 and GPT-4V to
generate relatively basic geometry problems with aligned text and images,
facilitating model learning. We have produced a dataset of 4.9K geometry
problems and combined it with 19K open-source data to form our GeoGPT4V
dataset. Experimental results demonstrate that the GeoGPT4V dataset
significantly improves the geometry performance of various models on the
MathVista and MathVision benchmarks. The code is available at
https://github.com/Lanyu0303/GeoGPT4V_Project"
Teleporter Theory - A General and Simple Approach for Modeling Cross-World Counterfactual Causality,https://arxiv.org/abs/2406.11501,2024-06-17,2024-06-19,0.0,0.0,"Leveraging the development of structural causal model (SCM), researchers can
establish graphical models for exploring the causal mechanisms behind machine
learning techniques. As the complexity of machine learning applications rises,
single-world interventionism causal analysis encounters theoretical adaptation
limitations. Accordingly, cross-world counterfactual approach extends our
understanding of causality beyond observed data, enabling hypothetical
reasoning about alternative scenarios. However, the joint involvement of
cross-world variables, encompassing counterfactual variables and real-world
variables, challenges the construction of the graphical model. Twin network is
a subtle attempt, establishing a symbiotic relationship, to bridge the gap
between graphical modeling and the introduction of counterfactuals albeit with
room for improvement in generalization. In this regard, we demonstrate the
theoretical breakdowns of twin networks in certain cross-world counterfactual
scenarios. To this end, we propose a novel teleporter theory to establish a
general and simple graphical representation of counterfactuals, which provides
criteria for determining teleporter variables to connect multiple worlds. In
theoretical application, we determine that introducing the proposed teleporter
theory can directly obtain the conditional independence between counterfactual
variables and real-world variables from the cross-world SCM without requiring
complex algebraic derivations. Accordingly, we can further identify
counterfactual causal effects through cross-world symbolic derivation. We
demonstrate the generality of the teleporter theory to the practical
application. Adhering to the proposed theory, we build a plug-and-play module,
and the effectiveness of which are substantiated by experiments on benchmarks."
CrAM - Credibility-Aware Attention Modification in LLMs for Combating Misinformation in RAG,https://arxiv.org/abs/2406.11497,2024-06-17,2024-06-19,0.0,0.0,"Retrieval-Augmented Generation (RAG) can alleviate hallucinations of Large
Language Models (LLMs) by referencing external documents. However, the
misinformation in external documents may mislead LLMs' generation. To address
this issue, we explore the task of ""credibility-aware RAG"", in which LLMs
automatically adjust the influence of retrieved documents based on their
credibility scores to counteract misinformation. To this end, we introduce a
plug-and-play method named $\textbf{Cr}$edibility-aware $\textbf{A}$ttention
$\textbf{M}$odification (CrAM). CrAM identifies influential attention heads in
LLMs and adjusts their attention weights based on the credibility of the
documents, thereby reducing the impact of low-credibility documents.
Experiments on Natual Questions and TriviaQA using Llama2-13B, Llama3-8B, and
Qwen-7B show that CrAM improves the RAG performance of LLMs against
misinformation pollution by over 20%, even surpassing supervised fine-tuning
methods."
Long-time asymptotics of noisy SVGD outside the population limit,https://arxiv.org/abs/2406.11929,2024-06-17,2024-06-19,0.0,0.0,"Stein Variational Gradient Descent (SVGD) is a widely used sampling algorithm
that has been successfully applied in several areas of Machine Learning. SVGD
operates by iteratively moving a set of interacting particles (which represent
the samples) to approximate the target distribution. Despite recent studies on
the complexity of SVGD and its variants, their long-time asymptotic behavior
(i.e., after numerous iterations ) is still not understood in the finite number
of particles regime. We study the long-time asymptotic behavior of a noisy
variant of SVGD. First, we establish that the limit set of noisy SVGD for large
is well-defined. We then characterize this limit set, showing that it
approaches the target distribution as increases. In particular, noisy SVGD
provably avoids the variance collapse observed for SVGD. Our approach involves
demonstrating that the trajectories of noisy SVGD closely resemble those
described by a McKean-Vlasov process."
Online Context Learning for Socially-compliant Navigation,https://arxiv.org/abs/2406.11495,2024-06-17,2024-06-19,0.0,0.0,"Robot social navigation needs to adapt to different human factors and
environmental contexts. However, since these factors and contexts are difficult
to predict and cannot be exhaustively enumerated, traditional learning-based
methods have difficulty in ensuring the social attributes of robots in
long-term and cross-environment deployments. This letter introduces an online
context learning method that aims to empower robots to adapt to new social
environments online. The proposed method adopts a two-layer structure. The
bottom layer is built using a deep reinforcement learning-based method to
ensure the output of basic robot navigation commands. The upper layer is
implemented using an online robot learning-based method to socialize the
control commands suggested by the bottom layer. Experiments using a
community-wide simulator show that our method outperforms the state-of-the-art
ones. Experimental results in the most challenging scenarios show that our
method improves the performance of the state-of-the-art by 8%. The source code
of the proposed method, the data used, and the tools for the per-training step
will be publicly available at https://github.com/Nedzhaken/SOCSARL-OL."
Interventional Imbalanced Multi-Modal Representation Learning via $$-Generalization Front-Door Criterion,https://arxiv.org/abs/2406.11490,2024-06-17,2024-06-19,0.0,0.0,"Multi-modal methods establish comprehensive superiority over uni-modal
methods. However, the imbalanced contributions of different modalities to
task-dependent predictions constantly degrade the discriminative performance of
canonical multi-modal methods. Based on the contribution to task-dependent
predictions, modalities can be identified as predominant and auxiliary
modalities. Benchmark methods raise a tractable solution: augmenting the
auxiliary modality with a minor contribution during training. However, our
empirical explorations challenge the fundamental idea behind such behavior, and
we further conclude that benchmark approaches suffer from certain defects:
insufficient theoretical interpretability and limited exploration capability of
discriminative knowledge. To this end, we revisit multi-modal representation
learning from a causal perspective and build the Structural Causal Model.
Following the empirical explorations, we determine to capture the true
causality between the discriminative knowledge of predominant modality and
predictive label while considering the auxiliary modality. Thus, we introduce
the $\beta$-generalization front-door criterion. Furthermore, we propose a
novel network for sufficiently exploring multi-modal discriminative knowledge.
Rigorous theoretical analyses and various empirical evaluations are provided to
support the effectiveness of the innate mechanism behind our proposed method."
Analysing zero-shot temporal relation extraction on clinical notes using temporal consistency,https://arxiv.org/abs/2406.11486,2024-06-17,2024-06-19,0.0,0.0,"This paper presents the first study for temporal relation extraction in a
zero-shot setting focusing on biomedical text. We employ two types of prompts
and five LLMs (GPT-3.5, Mixtral, Llama 2, Gemma, and PMC-LLaMA) to obtain
responses about the temporal relations between two events. Our experiments
demonstrate that LLMs struggle in the zero-shot setting performing worse than
fine-tuned specialized models in terms of F1 score, showing that this is a
challenging task for LLMs. We further contribute a novel comprehensive temporal
analysis by calculating consistency scores for each LLM. Our findings reveal
that LLMs face challenges in providing responses consistent to the temporal
properties of uniqueness and transitivity. Moreover, we study the relation
between the temporal consistency of an LLM and its accuracy and whether the
latter can be improved by solving temporal inconsistencies. Our analysis shows
that even when temporal consistency is achieved, the predictions can remain
inaccurate."
Active clustering with bandit feedback,https://arxiv.org/abs/2406.11485,2024-06-17,2024-06-19,0.0,0.0,"We investigate the Active Clustering Problem (ACP). A learner interacts with
an $N$-armed stochastic bandit with $d$-dimensional subGaussian feedback. There
exists a hidden partition of the arms into $K$ groups, such that arms within
the same group, share the same mean vector. The learner's task is to uncover
this hidden partition with the smallest budget - i.e., the least number of
observation - and with a probability of error smaller than a prescribed
constant $\delta$. In this paper, (i) we derive a non-asymptotic lower bound
for the budget, and (ii) we introduce the computationally efficient ACB
algorithm, whose budget matches the lower bound in most regimes. We improve on
the performance of a uniform sampling strategy. Importantly, contrary to the
batch setting, we establish that there is no computation-information gap in the
active setting."
Constrained Reinforcement Learning with Average Reward Objective - Model-Based and Model-Free Algorithms,https://arxiv.org/abs/2406.11481,2024-06-17,2024-06-19,0.0,0.0,"Reinforcement Learning (RL) serves as a versatile framework for sequential
decision-making, finding applications across diverse domains such as robotics,
autonomous driving, recommendation systems, supply chain optimization, biology,
mechanics, and finance. The primary objective in these applications is to
maximize the average reward. Real-world scenarios often necessitate adherence
to specific constraints during the learning process.
  This monograph focuses on the exploration of various model-based and
model-free approaches for Constrained RL within the context of average reward
Markov Decision Processes (MDPs). The investigation commences with an
examination of model-based strategies, delving into two foundational methods -
optimism in the face of uncertainty and posterior sampling. Subsequently, the
discussion transitions to parametrized model-free approaches, where the
primal-dual policy gradient-based algorithm is explored as a solution for
constrained MDPs. The monograph provides regret guarantees and analyzes
constraint violation for each of the discussed setups.
  For the above exploration, we assume the underlying MDP to be ergodic.
Further, this monograph extends its discussion to encompass results tailored
for weakly communicating MDPs, thereby broadening the scope of its findings and
their relevance to a wider range of practical scenarios."
Vocabulary Expansion for Low-resource Cross-lingual Transfer,https://arxiv.org/abs/2406.11477,2024-06-17,2024-06-19,0.0,0.0,"Large language models (LLMs) have shown remarkable capabilities in many
languages beyond English. Yet, LLMs require more inference steps when
generating non-English text due to their reliance on English-centric tokenizers
and vocabulary, resulting in higher usage costs to non-English speakers.
Vocabulary expansion with target language tokens is a widely used cross-lingual
vocabulary adaptation approach to remedy this issue. Despite its effectiveness
in inference speedup, previous work on vocabulary expansion has focused on
high-resource settings assuming access to a substantial amount of target
language data to effectively initialize the embeddings of the new tokens and
adapt the LLM to the target language. However, vocabulary expansion in
low-resource settings has yet to be explored. In this paper, we investigate
vocabulary expansion in low-resource settings by considering embedding
initialization methods and continual pre-training strategies. Through extensive
experiments across typologically diverse languages, tasks and models, we
establish a set of strategies to perform vocabulary expansion for faster
inference, maintaining competitive downstream performance to baselines with
only 30K sentences ($\sim$0.01GB text data) from the target language."
How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment,https://arxiv.org/abs/2406.11474,2024-06-17,2024-06-19,0.0,0.0,"Recent studies have demonstrated that In-Context Learning (ICL), through the
use of specific demonstrations, can align Large Language Models (LLMs) with
human preferences known as In-Context Alignment (ICA), indicating that models
can comprehend human instructions without requiring parameter adjustments.
However, the exploration of the mechanism and applicability of ICA remains
limited. In this paper, we begin by dividing the context text used in ICA into
three categories: format, system prompt, and example. Through ablation
experiments, we investigate the effectiveness of each part in enabling ICA to
function effectively. We then examine how variants in these parts impact the
model's alignment performance. Our findings indicate that the example part is
crucial for enhancing the model's alignment capabilities, with changes in
examples significantly affecting alignment performance. We also conduct a
comprehensive evaluation of ICA's zero-shot capabilities in various alignment
tasks. The results indicate that compared to parameter fine-tuning methods, ICA
demonstrates superior performance in knowledge-based tasks and tool-use tasks.
However, it still exhibits certain limitations in areas such as multi-turn
dialogues and instruction following."
"Promises, Outlooks and Challenges of Diffusion Language Modeling",https://arxiv.org/abs/2406.11473,2024-06-17,2024-06-19,0.0,0.0,"The modern autoregressive Large Language Models (LLMs) have achieved
outstanding performance on NLP benchmarks, and they are deployed in the real
world. However, they still suffer from limitations of the autoregressive
training paradigm. For example, autoregressive token generation is notably slow
and can be prone to \textit{exposure bias}. The diffusion-based language models
were proposed as an alternative to autoregressive generation to address some of
these limitations. We evaluate the recently proposed Score Entropy Discrete
Diffusion (SEDD) approach and show it is a promising alternative to
autoregressive generation but it has some short-comings too. We empirically
demonstrate the advantages and challenges of SEDD, and observe that SEDD
generally matches autoregressive models in perplexity and on benchmarks such as
HellaSwag, Arc or WinoGrande. Additionally, we show that in terms of inference
latency, SEDD can be up to 4.5$\times$ more efficient than GPT-2. While SEDD
allows conditioning on tokens at abitrary positions, SEDD appears slightly
weaker than GPT-2 for conditional generation given short prompts. Finally, we
reproduced the main results from the original SEDD paper."
Automating Easy Read Text Segmentation,https://arxiv.org/abs/2406.11464,2024-06-17,2024-06-19,0.0,0.0,"Easy Read text is one of the main forms of access to information for people
with reading difficulties. One of the key characteristics of this type of text
is the requirement to split sentences into smaller grammatical segments, to
facilitate reading. Automated segmentation methods could foster the creation of
Easy Read content, but their viability has yet to be addressed. In this work,
we study novel methods for the task, leveraging masked and generative language
models, along with constituent parsing. We conduct comprehensive automatic and
human evaluations in three languages, analysing the strengths and weaknesses of
the proposed alternatives, under scarce resource limitations. Our results
highlight the viability of automated ER segmentation and remaining deficiencies
compared to expert-driven human segmentation."
Just How Flexible are Neural Networks in Practice?,https://arxiv.org/abs/2406.11463,2024-06-17,2024-06-19,0.0,0.0,"It is widely believed that a neural network can fit a training set containing
at least as many samples as it has parameters, underpinning notions of
overparameterized and underparameterized models. In practice, however, we only
find solutions accessible via our training procedure, including the optimizer
and regularizers, limiting flexibility. Moreover, the exact parameterization of
the function class, built into an architecture, shapes its loss surface and
impacts the minima we find. In this work, we examine the ability of neural
networks to fit data in practice. Our findings indicate that: (1) standard
optimizers find minima where the model can only fit training sets with
significantly fewer samples than it has parameters; (2) convolutional networks
are more parameter-efficient than MLPs and ViTs, even on randomly labeled data;
(3) while stochastic training is thought to have a regularizing effect, SGD
actually finds minima that fit more training data than full-batch gradient
descent; (4) the difference in capacity to fit correctly labeled and
incorrectly labeled samples can be predictive of generalization; (5) ReLU
activation functions result in finding minima that fit more data despite being
designed to avoid vanishing and exploding gradients in deep architectures."
TRACE the Evidence - Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation,https://arxiv.org/abs/2406.11460,2024-06-17,2024-06-19,0.0,0.0,"Retrieval-augmented generation (RAG) offers an effective approach for
addressing question answering (QA) tasks. However, the imperfections of the
retrievers in RAG models often result in the retrieval of irrelevant
information, which could introduce noises and degrade the performance,
especially when handling multi-hop questions that require multiple steps of
reasoning. To enhance the multi-hop reasoning ability of RAG models, we propose
TRACE. TRACE constructs knowledge-grounded reasoning chains, which are a series
of logically connected knowledge triples, to identify and integrate supporting
evidence from the retrieved documents for answering questions. Specifically,
TRACE employs a KG Generator to create a knowledge graph (KG) from the
retrieved documents, and then uses an Autoregressive Reasoning Chain
Constructor to build reasoning chains. Experimental results on three multi-hop
QA datasets show that TRACE achieves an average performance improvement of up
to 14.03% compared to using all the retrieved documents. Moreover, the results
indicate that using reasoning chains as context, rather than the entire
documents, is often sufficient to correctly answer questions."
Adversaries With Incentives - A Strategic Alternative to Adversarial Robustness,https://arxiv.org/abs/2406.11458,2024-06-17,2024-06-19,0.0,0.0,"Adversarial training aims to defend against *adversaries*: malicious
opponents whose sole aim is to harm predictive performance in any way possible
- a rather harsh perspective, which we assert results in unnecessarily
conservative models. Instead, we propose to model opponents as simply pursuing
their own goals, rather than working directly against the classifier. Employing
tools from strategic modeling, our approach uses knowledge or beliefs regarding
the opponent's possible incentives as inductive bias for learning. Our method
of *strategic training* is designed to defend against opponents within an
*incentive uncertainty set*: this resorts to adversarial learning when the set
is maximal, but offers potential gains when it can be appropriately reduced. We
conduct a series of experiments that show how even mild knowledge regarding the
adversary's incentives can be useful, and that the degree of potential gains
depends on how incentives relate to the structure of the learning task."
Calibrating Where It Matters - Constrained Temperature Scaling,https://arxiv.org/abs/2406.11456,2024-06-17,2024-06-19,0.0,0.0,"We consider calibration of convolutional classifiers for diagnostic decision
making. Clinical decision makers can use calibrated classifiers to minimise
expected costs given their own cost function. Such functions are usually
unknown at training time. If minimising expected costs is the primary aim,
algorithms should focus on tuning calibration in regions of probability simplex
likely to effect decisions. We give an example, modifying temperature scaling
calibration, and demonstrate improved calibration where it matters using
convnets trained to classify dermoscopy images."
Adaptive Reinforcement Learning Planning - Harnessing Large Language Models for Complex Information Extraction,https://arxiv.org/abs/2406.11455,2024-06-17,2024-06-19,0.0,0.0,"Existing research on large language models (LLMs) shows that they can solve
information extraction tasks through multi-step planning. However, their
extraction behavior on complex sentences and tasks is unstable, emerging issues
such as false positives and missing elements. We observe that decomposing
complex extraction tasks and extracting them step by step can effectively
improve LLMs' performance, and the extraction orders of entities significantly
affect the final results of LLMs. This paper proposes a two-stage multi-step
method for LLM-based information extraction and adopts the RL framework to
execute the multi-step planning. We regard sequential extraction as a Markov
decision process, build an LLM-based extraction environment, design a decision
module to adaptively provide the optimal order for sequential entity extraction
on different sentences, and utilize the DDQN algorithm to train the decision
model. We also design the rewards and evaluation metrics suitable for the
extraction results of LLMs. We conduct extensive experiments on multiple public
datasets to demonstrate the effectiveness of our method in improving the
information extraction capabilities of LLMs."
Attention-Based Deep Reinforcement Learning for Qubit Allocation in Modular Quantum Architectures,https://arxiv.org/abs/2406.11452,2024-06-17,2024-06-19,0.0,0.0,"Modular, distributed and multi-core architectures are currently considered a
promising approach for scalability of quantum computing systems. The
integration of multiple Quantum Processing Units necessitates classical and
quantum-coherent communication, introducing challenges related to noise and
quantum decoherence in quantum state transfers between cores. Optimizing
communication becomes imperative, and the compilation and mapping of quantum
circuits onto physical qubits must minimize state transfers while adhering to
architectural constraints. The compilation process, inherently an NP-hard
problem, demands extensive search times even with a small number of qubits to
be solved to optimality. To address this challenge efficiently, we advocate for
the utilization of heuristic mappers that can rapidly generate solutions. In
this work, we propose a novel approach employing Deep Reinforcement Learning
(DRL) methods to learn these heuristics for a specific multi-core architecture.
Our DRL agent incorporates a Transformer encoder and Graph Neural Networks. It
encodes quantum circuits using self-attention mechanisms and produce outputs
through an attention-based pointer mechanism that directly signifies the
probability of matching logical qubits with physical cores. This enables the
selection of optimal cores for logical qubits efficiently. Experimental
evaluations show that the proposed method can outperform baseline approaches in
terms of reducing inter-core communications and minimizing online
time-to-solution. This research contributes to the advancement of scalable
quantum computing systems by introducing a novel learning-based heuristic
approach for efficient quantum circuit compilation and mapping."
FlexCare - Leveraging Cross-Task Synergy for Flexible Multimodal Healthcare Prediction,https://arxiv.org/abs/2406.11928,2024-06-17,2024-06-19,0.0,0.0,"Multimodal electronic health record (EHR) data can offer a holistic
assessment of a patient's health status, supporting various predictive
healthcare tasks. Recently, several studies have embraced the multitask
learning approach in the healthcare domain, exploiting the inherent
correlations among clinical tasks to predict multiple outcomes simultaneously.
However, existing methods necessitate samples to possess complete labels for
all tasks, which places heavy demands on the data and restricts the flexibility
of the model. Meanwhile, within a multitask framework with multimodal inputs,
how to comprehensively consider the information disparity among modalities and
among tasks still remains a challenging problem. To tackle these issues, a
unified healthcare prediction model, also named by \textbf{FlexCare}, is
proposed to flexibly accommodate incomplete multimodal inputs, promoting the
adaption to multiple healthcare tasks. The proposed model breaks the
conventional paradigm of parallel multitask prediction by decomposing it into a
series of asynchronous single-task prediction. Specifically, a task-agnostic
multimodal information extraction module is presented to capture decorrelated
representations of diverse intra- and inter-modality patterns. Taking full
account of the information disparities between different modalities and
different tasks, we present a task-guided hierarchical multimodal fusion module
that integrates the refined modality-level representations into an individual
patient-level representation. Experimental results on multiple tasks from
MIMIC-IV/MIMIC-CXR/MIMIC-NOTE datasets demonstrate the effectiveness of the
proposed method. Additionally, further analysis underscores the feasibility and
potential of employing such a multitask strategy in the healthcare domain. The
source code is available at https://github.com/mhxu1998/FlexCare."
GPT-Powered Elicitation Interview Script Generator for Requirements Engineering Training,https://arxiv.org/abs/2406.11439,2024-06-17,2024-06-19,0.0,0.0,"Elicitation interviews are the most common requirements elicitation
technique, and proficiency in conducting these interviews is crucial for
requirements elicitation. Traditional training methods, typically limited to
textbook learning, may not sufficiently address the practical complexities of
interviewing techniques. Practical training with various interview scenarios is
important for understanding how to apply theoretical knowledge in real-world
contexts. However, there is a shortage of educational interview material, as
creating interview scripts requires both technical expertise and creativity. To
address this issue, we develop a specialized GPT agent for auto-generating
interview scripts. The GPT agent is equipped with a dedicated knowledge base
tailored to the guidelines and best practices of requirements elicitation
interview procedures. We employ a prompt chaining approach to mitigate the
output length constraint of GPT to be able to generate thorough and detailed
interview scripts. This involves dividing the interview into sections and
crafting distinct prompts for each, allowing for the generation of complete
content for each section. The generated scripts are assessed through standard
natural language generation evaluation metrics and an expert judgment study,
confirming their applicability in requirements engineering training."
Analysing the Behaviour of Tree-Based Neural Networks in Regression Tasks,https://arxiv.org/abs/2406.11437,2024-06-17,2024-06-19,0.0,0.0,"The landscape of deep learning has vastly expanded the frontiers of source
code analysis, particularly through the utilization of structural
representations such as Abstract Syntax Trees (ASTs). While these methodologies
have demonstrated effectiveness in classification tasks, their efficacy in
regression applications, such as execution time prediction from source code,
remains underexplored. This paper endeavours to decode the behaviour of
tree-based neural network models in the context of such regression challenges.
We extend the application of established models--tree-based Convolutional
Neural Networks (CNNs), Code2Vec, and Transformer-based methods--to predict the
execution time of source code by parsing it to an AST. Our comparative analysis
reveals that while these models are benchmarks in code representation, they
exhibit limitations when tasked with regression. To address these deficiencies,
we propose a novel dual-transformer approach that operates on both source code
tokens and AST representations, employing cross-attention mechanisms to enhance
interpretability between the two domains. Furthermore, we explore the
adaptation of Graph Neural Networks (GNNs) to this tree-based problem,
theorizing the inherent compatibility due to the graphical nature of ASTs.
Empirical evaluations on real-world datasets showcase that our dual-transformer
model outperforms all other tree-based neural networks and the GNN-based
models. Moreover, our proposed dual transformer demonstrates remarkable
adaptability and robust performance across diverse datasets."
AnyTrans - Translate AnyText in the Image with Large Scale Models,https://arxiv.org/abs/2406.11432,2024-06-17,2024-06-19,0.0,0.0,"This paper introduces AnyTrans, an all-encompassing framework for the
task-Translate AnyText in the Image (TATI), which includes multilingual text
translation and text fusion within images. Our framework leverages the
strengths of large-scale models, such as Large Language Models (LLMs) and
text-guided diffusion models, to incorporate contextual cues from both textual
and visual elements during translation. The few-shot learning capability of
LLMs allows for the translation of fragmented texts by considering the overall
context. Meanwhile, the advanced inpainting and editing abilities of diffusion
models make it possible to fuse translated text seamlessly into the original
image while preserving its style and realism. Additionally, our framework can
be constructed entirely using open-source models and requires no training,
making it highly accessible and easily expandable. To encourage advancement in
the TATI task, we have meticulously compiled a test dataset called MTIT6, which
consists of multilingual text image translation data from six language pairs."
Super(ficial)-alignment - Strong Models May Deceive Weak Models in Weak-to-Strong Generalization,https://arxiv.org/abs/2406.11431,2024-06-17,2024-06-19,0.0,0.0,"Superalignment, where humans are weak supervisors of superhuman models, has
become an important and widely discussed issue in the current era of rapid
development of Large Language Models (LLMs). The recent work preliminarily
studies this problem by using weak models to supervise strong models. It
discovers that weakly supervised strong students can consistently outperform
weak teachers towards the alignment target, leading to a weak-to-strong
generalization phenomenon. However, we are concerned that behind such a
promising phenomenon, whether there exists an issue of weak-to-strong
deception, where strong models may deceive weak models by exhibiting
well-aligned in areas known to weak models but producing misaligned behaviors
in cases weak models do not know. We then take an initial step towards
exploring this security issue in a specific but realistic multi-objective
alignment case, where there may be some alignment targets conflicting with each
other (e.g., helpfulness v.s. harmlessness). Such a conflict is likely to cause
strong models to deceive weak models in one alignment dimension to gain high
reward in other alignment dimension. Our experiments on both the reward
modeling task and the preference optimization scenario indicate: (1) the
weak-to-strong deception exists; (2) the deception phenomenon may intensify as
the capability gap between weak and strong models increases. We also discuss
potential solutions and find bootstrapping with an intermediate model can
mitigate the deception to some extent. Our work highlights the urgent need to
pay more attention to the true reliability of superalignment."
A Simple and Effective $L_2$ Norm-Based Strategy for KV Cache Compression,https://arxiv.org/abs/2406.11430,2024-06-17,2024-06-19,0.0,0.0,"The deployment of large language models (LLMs) is often hindered by the
extensive memory requirements of the Key-Value (KV) cache, especially as
context lengths increase. Existing approaches to reduce the KV cache size
involve either fine-tuning the model to learn a compression strategy or
leveraging attention scores to reduce the sequence length. We analyse the
attention distributions in decoder-only Transformers-based models and observe
that attention allocation patterns stay consistent across most layers.
Surprisingly, we find a clear correlation between the $L_2$ and the attention
scores over cached KV pairs, where a low $L_2$ of a key embedding usually leads
to a high attention score during decoding. This finding indicates that the
influence of a KV pair is potentially determined by the key embedding itself
before being queried. Based on this observation, we compress the KV cache based
on the $L_2$ of key embeddings. Our experimental results show that this simple
strategy can reduce the KV cache size by 50% on language modelling and
needle-in-a-haystack tasks and 90% on passkey retrieval tasks without losing
accuracy. Moreover, without relying on the attention scores, this approach
remains compatible with FlashAttention, enabling broader applicability."
Fusion Makes Perfection - An Efficient Multi-Grained Matching Approach for Zero-Shot Relation Extraction,https://arxiv.org/abs/2406.11429,2024-06-17,2024-06-19,0.0,0.0,"Predicting unseen relations that cannot be observed during the training phase
is a challenging task in relation extraction. Previous works have made progress
by matching the semantics between input instances and label descriptions.
However, fine-grained matching often requires laborious manual annotation, and
rich interactions between instances and label descriptions come with
significant computational overhead. In this work, we propose an efficient
multi-grained matching approach that uses virtual entity matching to reduce
manual annotation cost, and fuses coarse-grained recall and fine-grained
classification for rich interactions with guaranteed inference speed.
Experimental results show that our approach outperforms the previous State Of
The Art (SOTA) methods, and achieves a balance between inference efficiency and
prediction accuracy in zero-shot relation extraction tasks. Our code is
available at https://github.com/longls777/EMMA."
DiTTo-TTS - Efficient and Scalable Zero-Shot Text-to-Speech with Diffusion Transformer,https://arxiv.org/abs/2406.11427,2024-06-17,2024-06-19,0.0,0.0,"Large-scale diffusion models have shown outstanding generative abilities
across multiple modalities including images, videos, and audio. However,
text-to-speech (TTS) systems typically involve domain-specific modeling factors
(e.g., phonemes and phoneme-level durations) to ensure precise temporal
alignments between text and speech, which hinders the efficiency and
scalability of diffusion models for TTS. In this work, we present an efficient
and scalable Diffusion Transformer (DiT) that utilizes off-the-shelf
pre-trained text and speech encoders. Our approach addresses the challenge of
text-speech alignment via cross-attention mechanisms with the prediction of the
total length of speech representations. To achieve this, we enhance the DiT
architecture to suit TTS and improve the alignment by incorporating semantic
guidance into the latent space of speech. We scale the training dataset and the
model size to 82K hours and 790M parameters, respectively. Our extensive
experiments demonstrate that the large-scale diffusion model for TTS without
domain-specific modeling not only simplifies the training pipeline but also
yields superior or comparable zero-shot performance to state-of-the-art TTS
models in terms of naturalness, intelligibility, and speaker similarity. Our
speech samples are available at https://ditto-tts.github.io."
Evaluating the Efficacy of Open-Source LLMs in Enterprise-Specific RAG Systems - A Comparative Study of Performance and Scalability,https://arxiv.org/abs/2406.11424,2024-06-17,2024-06-19,0.0,0.0,"This paper presents an analysis of open-source large language models (LLMs)
and their application in Retrieval-Augmented Generation (RAG) tasks, specific
for enterprise-specific data sets scraped from their websites. With the
increasing reliance on LLMs in natural language processing, it is crucial to
evaluate their performance, accessibility, and integration within specific
organizational contexts. This study examines various open-source LLMs, explores
their integration into RAG frameworks using enterprise-specific data, and
assesses the performance of different open-source embeddings in enhancing the
retrieval and generation process. Our findings indicate that open-source LLMs,
combined with effective embedding techniques, can significantly improve the
accuracy and efficiency of RAG systems, offering a viable alternative to
proprietary solutions for enterprises."
"Dredge Word, Social Media, and Webgraph Networks for Unreliable Website Classification and Identification",https://arxiv.org/abs/2406.11423,2024-06-17,2024-06-19,0.0,0.0,"Proactive content moderation requires platforms to rapidly and continuously
evaluate the credibility of websites. Leveraging the direct and indirect paths
users follow to unreliable websites, we develop a website credibility
classification and discovery system that integrates both webgraph and
large-scale social media contexts. We additionally introduce the concept of
dredge words, terms or phrases for which unreliable domains rank highly on
search engines, and provide the first exploration of their usage on social
media. Our graph neural networks that combine webgraph and social media
contexts generate to state-of-the-art results in website credibility
classification and significantly improves the top-k identification of
unreliable domains. Additionally, we release a novel dataset of dredge words,
highlighting their strong connections to both social media and online commerce
platforms."
Cross-domain Open-world Discovery,https://arxiv.org/abs/2406.11422,2024-06-17,2024-06-19,0.0,0.0,"In many real-world applications, test data may commonly exhibit categorical
shifts, characterized by the emergence of novel classes, as well as
distribution shifts arising from feature distributions different from the ones
the model was trained on. However, existing methods either discover novel
classes in the open-world setting or assume domain shifts without the ability
to discover novel classes. In this work, we consider a cross-domain open-world
discovery setting, where the goal is to assign samples to seen classes and
discover unseen classes under a domain shift. To address this challenging
problem, we present CROW, a prototype-based approach that introduces a
cluster-then-match strategy enabled by a well-structured representation space
of foundation models. In this way, CROW discovers novel classes by robustly
matching clusters with previously seen classes, followed by fine-tuning the
representation space using an objective designed for cross-domain open-world
discovery. Extensive experimental results on image classification benchmark
datasets demonstrate that CROW outperforms alternative baselines, achieving an
8% average performance improvement across 75 experimental settings."
BAMBINO-LM - (Bilingual-)Human-Inspired Continual Pretraining of BabyLM,https://arxiv.org/abs/2406.11418,2024-06-17,2024-06-19,0.0,0.0,"Children from bilingual backgrounds benefit from interactions with parents
and teachers to re-acquire their heritage language. In this paper, we
investigate how this insight from behavioral study can be incorporated into the
learning of small-scale language models. We introduce BAMBINO-LM, a continual
pre-training strategy for BabyLM that uses a novel combination of alternation
and PPO-based perplexity reward induced from a parent Italian model. Upon
evaluation on zero-shot classification tasks for English and Italian,
BAMBINO-LM improves the Italian language capability of a BabyLM baseline. Our
ablation analysis demonstrates that employing both the alternation strategy and
PPO-based modeling is key to this effectiveness gain. We also show that, as a
side effect, the proposed method leads to a similar degradation in L1
effectiveness as human children would have had in an equivalent learning
scenario. Through its modeling and findings, BAMBINO-LM makes a focused
contribution to the pre-training of small-scale language models by first
developing a human-inspired strategy for pre-training and then showing that it
results in behaviours similar to that of humans."
Formally Certified Approximate Model Counting,https://arxiv.org/abs/2406.11414,2024-06-17,2024-06-19,0.0,0.0,"Approximate model counting is the task of approximating the number of
solutions to an input Boolean formula. The state-of-the-art approximate model
counter for formulas in conjunctive normal form (CNF), ApproxMC, provides a
scalable means of obtaining model counts with probably approximately correct
(PAC)-style guarantees. Nevertheless, the validity of ApproxMC's approximation
relies on a careful theoretical analysis of its randomized algorithm and the
correctness of its highly optimized implementation, especially the latter's
stateful interactions with an incremental CNF satisfiability solver capable of
natively handling parity (XOR) constraints.
  We present the first certification framework for approximate model counting
with formally verified guarantees on the quality of its output approximation.
Our approach combines: (i) a static, once-off, formal proof of the algorithm's
PAC guarantee in the Isabelle/HOL proof assistant; and (ii) dynamic, per-run,
verification of ApproxMC's calls to an external CNF-XOR solver using proof
certificates. We detail our general approach to establish a rigorous connection
between these two parts of the verification, including our blueprint for
turning the formalized, randomized algorithm into a verified proof checker, and
our design of proof certificates for both ApproxMC and its internal CNF-XOR
solving steps. Experimentally, we show that certificate generation adds little
overhead to an approximate counter implementation, and that our certificate
checker is able to fully certify $84.7\%$ of instances with generated
certificates when given the same time and memory limits as the counter."
"HARE - HumAn pRiors, a key to small language model Efficiency",https://arxiv.org/abs/2406.11410,2024-06-17,2024-06-19,0.0,0.0,"Human priors play a crucial role in efficiently utilizing data in deep
learning. However, with the development of large language models (LLMs), there
is an increasing emphasis on scaling both model size and data volume, which
often diminishes the importance of human priors in data construction.
Influenced by these trends, existing Small Language Models (SLMs) mainly rely
on web-scraped large-scale training data, neglecting the proper incorporation
of human priors. This oversight limits the training efficiency of language
models in resource-constrained settings. In this paper, we propose a principle
to leverage human priors for data construction. This principle emphasizes
achieving high-performance SLMs by training on a concise dataset that
accommodates both semantic diversity and data quality consistency, while
avoiding benchmark data leakage. Following this principle, we train an SLM
named HARE-1.1B. Extensive experiments on large-scale benchmark datasets
demonstrate that HARE-1.1B performs favorably against state-of-the-art SLMs,
validating the effectiveness of the proposed principle. Additionally, this
provides new insights into efficient language model training in
resource-constrained environments from the view of human priors."
CodeGemma - Open Code Models Based on Gemma,https://arxiv.org/abs/2406.11409,2024-06-17,2024-06-19,0.0,0.0,"This paper introduces CodeGemma, a collection of specialized open code models
built on top of Gemma, capable of a variety of code and natural language
generation tasks. We release three model variants. CodeGemma 7B pretrained (PT)
and instruction-tuned (IT) variants have remarkably resilient natural language
understanding, excel in mathematical reasoning, and match code capabilities of
other open models. CodeGemma 2B is a state-of-the-art code completion model
designed for fast code infilling and open-ended generation in latency-sensitive
settings."
Multimodal Structured Generation - CVPR's 2nd MMFM Challenge Technical Report,https://arxiv.org/abs/2406.11403,2024-06-17,2024-06-19,0.0,0.0,"Multimodal Foundation Models (MMFMs) have shown remarkable performance on
various computer vision and natural language processing tasks. However, their
performance on particular tasks such as document understanding is still
limited. They also require more compute, time, and engineering resources to
finetune and deploy compared to traditional, unimodal models. In this report,
we present Multimodal Structured Generation, a general framework which
constrains the output logits of frozen MMFMs to force them to reason before
responding with structured outputs that downstream APIs can parse and use. We
provide a detailed account of our approach, including the technical details,
theoretical discussions, and final evaluation results in the 2nd Multimodal
Foundation Models Challenge hosted by the Computer Vision and Pattern
Recognition (CVPR) conference. Our approach achieved the second highest score
in the hidden test set for Phase 2 and third highest overall. This shows the
method's ability to generalize to unseen tasks. And that simple engineering can
beat expensive & complicated modelling steps as we first discussed in our
paper, Retrieval Augmented Structured Generation: Business Document Information
Extraction as Tool Use. All of our scripts, deployment steps, and evaluation
results can be accessed in https://github.com/leloykun/MMFM-Challenge"
"Evaluating Open Language Models Across Task Types, Application Domains, and Reasoning Types - An In-Depth Experimental Analysis",https://arxiv.org/abs/2406.11402,2024-06-17,2024-06-19,0.0,0.0,"The rapid rise of Language Models (LMs) has expanded their use in several
applications. Yet, due to constraints of model size, associated cost, or
proprietary restrictions, utilizing state-of-the-art (SOTA) LLMs is not always
feasible. With open, smaller LMs emerging, more applications can leverage their
capabilities, but selecting the right LM can be challenging as smaller LMs
don't perform well universally. This work tries to bridge this gap by proposing
a framework to experimentally evaluate small, open LMs in practical settings
through measuring semantic correctness of outputs across three practical
aspects: task types, application domains and reasoning types, using diverse
prompt styles. It also conducts an in-depth comparison of 10 small, open LMs to
identify best LM and prompt style depending on specific application requirement
using the proposed framework. We also show that if selected appropriately, they
can outperform SOTA LLMs like DeepSeek-v2, GPT-4o-mini, Gemini-1.5-Pro, and
even compete with GPT-4o."
REPOEXEC - Evaluate Code Generation with a Repository-Level Executable Benchmark,https://arxiv.org/abs/2406.11927,2024-06-17,2024-06-19,0.0,0.0,"CodeLLMs have gained widespread adoption for code generation tasks, yet their
capacity to handle repository-level code generation with complex contextual
dependencies remains underexplored. Our work underscores the critical
importance of leveraging repository-level contexts to generate executable and
functionally correct code. We present \textbf{\methodnamews}, a novel benchmark
designed to evaluate repository-level code generation, with a focus on three
key aspects: executability, functional correctness through comprehensive test
case generation, and accurate utilization of cross-file contexts. Our study
examines a controlled scenario where developers specify essential code
dependencies (contexts), challenging models to integrate them effectively.
Additionally, we introduce an instruction-tuned dataset that enhances CodeLLMs'
ability to leverage dependencies, along with a new metric, \textit{Dependency
Invocation Rate (DIR)}, to quantify context utilization. Experimental results
reveal that while pretrained LLMs demonstrate superior performance in terms of
correctness, instruction-tuned models excel in context utilization and
debugging capabilities. \methodnamews offers a comprehensive evaluation
framework for assessing code functionality and alignment with developer intent,
thereby advancing the development of more reliable CodeLLMs for real-world
applications. The dataset and source code are available
at~\url{https://github.com/FSoft-AI4Code/RepoExec}."
Large Language Models and Knowledge Graphs for Astronomical Entity Disambiguation,https://arxiv.org/abs/2406.11400,2024-06-17,2024-06-19,0.0,0.0,"This paper presents an experiment conducted during a hackathon, focusing on
using large language models (LLMs) and knowledge graph clustering to extract
entities and relationships from astronomical text. The study demonstrates an
approach to disambiguate entities that can appear in various contexts within
the astronomical domain. By collecting excerpts around specific entities and
leveraging the GPT-4 language model, relevant entities and relationships are
extracted. The extracted information is then used to construct a knowledge
graph, which is clustered using the Leiden algorithm. The resulting Leiden
communities are utilized to identify the percentage of association of unknown
excerpts to each community, thereby enabling disambiguation. The experiment
showcases the potential of combining LLMs and knowledge graph clustering
techniques for information extraction in astronomical research. The results
highlight the effectiveness of the approach in identifying and disambiguating
entities, as well as grouping them into meaningful clusters based on their
relationships."
Spillover Detection for Donor Selection in Synthetic Control Models,https://arxiv.org/abs/2406.11399,2024-06-17,2024-06-19,0.0,0.0,"Synthetic control (SC) models are widely used to estimate causal effects in
settings with observational time-series data. To identify the causal effect on
a target unit, SC requires the existence of correlated units that are not
impacted by the intervention. Given one of these potential donor units, how can
we decide whether it is in fact a valid donor - that is, one not subject to
spillover effects from the intervention? Such a decision typically requires
appealing to strong a priori domain knowledge specifying the units, which
becomes infeasible in situations with large pools of potential donors. In this
paper, we introduce a practical, theoretically-grounded donor selection
procedure, aiming to weaken this domain knowledge requirement. Our main result
is a Theorem that yields the assumptions required to identify donor values at
post-intervention time points using only pre-intervention data. We show how
this Theorem - and the assumptions underpinning it - can be turned into a
practical method for detecting potential spillover effects and excluding
invalid donors when constructing SCs. Importantly, we employ sensitivity
analysis to formally bound the bias in our SC causal estimate in situations
where an excluded donor was indeed valid, or where a selected donor was
invalid. Using ideas from the proximal causal inference and instrumental
variables literature, we show that the excluded donors can nevertheless be
leveraged to further debias causal effect estimates. Finally, we illustrate our
donor selection procedure on both simulated and real-world datasets."
DistPred - A Distribution-Free Probabilistic Inference Method for Regression and Forecasting,https://arxiv.org/abs/2406.11397,2024-06-17,2024-06-19,0.0,0.0,"Traditional regression and prediction tasks often only provide deterministic
point estimates. To estimate the uncertainty or distribution information of the
response variable, methods such as Bayesian inference, model ensembling, or MC
Dropout are typically used. These methods either assume that the posterior
distribution of samples follows a Gaussian process or require thousands of
forward passes for sample generation. We propose a novel approach called
DistPred for regression and forecasting tasks, which overcomes the limitations
of existing methods while remaining simple and powerful. Specifically, we
transform proper scoring rules that measure the discrepancy between the
predicted distribution and the target distribution into a differentiable
discrete form and use it as a loss function to train the model end-to-end. This
allows the model to sample numerous samples in a single forward pass to
estimate the potential distribution of the response variable. We have compared
our method with several existing approaches on multiple datasets and achieved
state-of-the-art performance. Additionally, our method significantly improves
computational efficiency. For example, compared to state-of-the-art models,
DistPred has a 90x faster inference speed. Experimental results can be
reproduced through https://github.com/Anoise/DistPred."
Unfolding Time - Generative Modeling for Turbulent Flows in 4D,https://arxiv.org/abs/2406.11390,2024-06-17,2024-06-19,0.0,0.0,"A recent study in turbulent flow simulation demonstrated the potential of
generative diffusion models for fast 3D surrogate modeling. This approach
eliminates the need for specifying initial states or performing lengthy
simulations, significantly accelerating the process. While adept at sampling
individual frames from the learned manifold of turbulent flow states, the
previous model lacks the capability to generate sequences, hindering analysis
of dynamic phenomena. This work addresses this limitation by introducing a 4D
generative diffusion model and a physics-informed guidance technique that
enables the generation of realistic sequences of flow states. Our findings
indicate that the proposed method can successfully sample entire subsequences
from the turbulent manifold, even though generalizing from individual frames to
sequences remains a challenging task. This advancement opens doors for the
application of generative modeling in analyzing the temporal evolution of
turbulent flows, providing valuable insights into their complex dynamics."
SEFraud - Graph-based Self-Explainable Fraud Detection via Interpretative Mask Learning,https://arxiv.org/abs/2406.11389,2024-06-17,2024-06-19,0.0,0.0,"Graph-based fraud detection has widespread application in modern industry
scenarios, such as spam review and malicious account detection. While
considerable efforts have been devoted to designing adequate fraud detectors,
the interpretability of their results has often been overlooked. Previous works
have attempted to generate explanations for specific instances using post-hoc
explaining methods such as a GNNExplainer. However, post-hoc explanations can
not facilitate the model predictions and the computational cost of these
methods cannot meet practical requirements, thus limiting their application in
real-world scenarios. To address these issues, we propose SEFraud, a novel
graph-based self-explainable fraud detection framework that simultaneously
tackles fraud detection and result in interpretability. Concretely, SEFraud
first leverages customized heterogeneous graph transformer networks with
learnable feature masks and edge masks to learn expressive representations from
the informative heterogeneously typed transactions. A new triplet loss is
further designed to enhance the performance of mask learning. Empirical results
on various datasets demonstrate the effectiveness of SEFraud as it shows
considerable advantages in both the fraud detection performance and
interpretability of prediction results. Moreover, SEFraud has been deployed and
offers explainable fraud detection service for the largest bank in China,
Industrial and Commercial Bank of China Limited (ICBC). Results collected from
the production environment of ICBC show that SEFraud can provide accurate
detection results and comprehensive explanations that align with the expert
business understanding, confirming its efficiency and applicability in
large-scale online services."
MetaGPT - Merging Large Language Models Using Model Exclusive Task Arithmetic,https://arxiv.org/abs/2406.11385,2024-06-17,2024-06-19,0.0,0.0,"The advent of large language models (LLMs) like GPT-4 has catalyzed the
exploration of multi-task learning (MTL), in which a single model demonstrates
proficiency across diverse tasks. Task arithmetic has emerged as a
cost-effective approach for MTL. It enables performance enhancement across
multiple tasks by adding their corresponding task vectors to a pre-trained
model. However, the current lack of a method that can simultaneously achieve
optimal performance, computational efficiency, and data privacy limits their
application to LLMs. In this paper, we propose \textbf{M}odel
\textbf{E}xclusive \textbf{T}ask \textbf{A}rithmetic for merging
\textbf{GPT}-scale models, which formalizes the objective of model merging into
a multi-task learning framework, aiming to minimize the average loss difference
between the merged model and each individual task model. Since data privacy
limits the use of multi-task training data, we leverage LLMs' local linearity
and task vectors' orthogonality to separate the data term and scaling
coefficients term and derive a model-exclusive task arithmetic method. Our
proposed MetaGPT is data-agnostic and bypasses the heavy search process, making
it cost-effective and easy to implement for LLMs.Extensive experiments
demonstrate that MetaGPT leads to improvements in task arithmetic and achieves
state-of-the-art performance on multiple tasks."
A Realistic Evaluation of LLMs for Quotation Attribution in Literary Texts - A Case Study of LLaMa3,https://arxiv.org/abs/2406.11380,2024-06-17,2024-06-19,0.0,0.0,"Large Language Models (LLMs) zero-shot and few-shot performance are subject
to memorization and data contamination, complicating the assessment of their
validity. In literary tasks, the performance of LLMs is often correlated to the
degree of book memorization. In this work, we carry out a realistic evaluation
of LLMs for quotation attribution in novels, taking the instruction fined-tuned
version of Llama3 as an example. We design a task-specific memorization measure
and use it to show that Llama3's ability to perform quotation attribution is
positively correlated to the novel degree of memorization. However, Llama3
still performs impressively well on books it has not memorized nor seen. Data
and code will be made publicly available."
Boosting Scientific Concepts Understanding - Can Analogy from Teacher Models Empower Student Models?,https://arxiv.org/abs/2406.11375,2024-06-17,2024-06-19,0.0,0.0,"Analogical reasoning plays a critical role in human cognition, enabling us to
understand new concepts by associating them with familiar ones. Previous
research in the AI community has mainly focused on identifying and generating
analogies and then examining their quality under human evaluation, which
overlooks the practical application of these analogies in real-world settings.
Inspired by the human education process, in this paper, we propose to
investigate how analogies created by teacher language models (LMs) can assist
student LMs in understanding scientific concepts, thereby aligning more closely
with practical scenarios. Our results suggest that free-form analogies can
indeed aid LMs in understanding concepts. Additionally, analogies generated by
student LMs can improve their own performance on scientific question answering,
demonstrating their capability to use analogies for self-learning new
knowledge. Resources are available at https://github.com/siyuyuan/SCUA."
Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments,https://arxiv.org/abs/2406.11370,2024-06-17,2024-06-19,0.0,0.0,"Large language models (LLMs) have shown promising abilities as cost-effective
and reference-free evaluators for assessing language generation quality. In
particular, pairwise LLM evaluators, which compare two generated texts and
determine the preferred one, have been employed in a wide range of
applications. However, LLMs exhibit preference biases and worrying sensitivity
to prompt designs. In this work, we first reveal that the predictive preference
of LLMs can be highly brittle and skewed, even with semantically equivalent
instructions. We find that fairer predictive preferences from LLMs consistently
lead to judgments that are better aligned with humans. Motivated by this
phenomenon, we propose an automatic Zero-shot Evaluation-oriented Prompt
Optimization framework, ZEPO, which aims to produce fairer preference decisions
and improve the alignment of LLM evaluators with human judgments. To this end,
we propose a zero-shot learning objective based on the preference decision
fairness. ZEPO demonstrates substantial performance improvements over
state-of-the-art LLM evaluators, without requiring labeled data, on
representative meta-evaluation benchmarks. Our findings underscore the critical
correlation between preference fairness and human alignment, positioning ZEPO
as an efficient prompt optimizer for bridging the gap between LLM evaluators
and human judgments."
Improving Quotation Attribution with Fictional Character Embeddings,https://arxiv.org/abs/2406.11368,2024-06-17,2024-06-19,0.0,0.0,"Humans naturally attribute utterances of direct speech to their speaker in
literary works. When attributing quotes, we process contextual information but
also access mental representations of characters that we build and revise
throughout the narrative. Recent methods to automatically attribute such
utterances have explored simulating human logic with deterministic rules or
learning new implicit rules with neural networks when processing contextual
information. However, these systems inherently lack \textit{character}
representations, which often leads to errors on more challenging examples of
attribution: anaphoric and implicit quotes. In this work, we propose to augment
a popular quotation attribution system, BookNLP, with character embeddings that
encode global information of characters. To build these embeddings, we create
DramaCV, a corpus of English drama plays from the 15th to 20th century focused
on Character Verification (CV), a task similar to Authorship Verification (AV),
that aims at analyzing fictional characters. We train a model similar to the
recently proposed AV model, Universal Authorship Representation (UAR), on this
dataset, showing that it outperforms concurrent methods of characters
embeddings on the CV task and generalizes better to literary novels. Then,
through an extensive evaluation on 22 novels, we show that combining BookNLP's
contextual information with our proposed global character embeddings improves
the identification of speakers for anaphoric and implicit quotes, reaching
state-of-the-art performance. Code and data will be made publicly available."
Refiner - Restructure Retrieval Content Efficiently to Advance Question-Answering Capabilities,https://arxiv.org/abs/2406.11357,2024-06-17,2024-06-19,0.0,0.0,"Large Language Models (LLMs) are limited by their parametric knowledge,
leading to hallucinations in knowledge-extensive tasks. To address this,
Retrieval-Augmented Generation (RAG) incorporates external document chunks to
expand LLM knowledge. Furthermore, compressing information from document chunks
through extraction or summarization can improve LLM performance. Nonetheless,
LLMs still struggle to notice and utilize scattered key information, a problem
known as the ""lost-in-the-middle"" syndrome. Therefore, we typically need to
restructure the content for LLM to recognize the key information. We propose
$\textit{Refiner}$, an end-to-end extract-and-restructure paradigm that
operates in the post-retrieval process of RAG. $\textit{Refiner}$ leverages a
single decoder-only LLM to adaptively extract query-relevant contents verbatim
along with the necessary context, and section them based on their
interconnectedness, thereby highlights information distinction, and aligns
downstream LLMs with the original context effectively. Experiments show that a
trained $\textit{Refiner}$ (with 7B parameters) exhibits significant gain to
downstream LLM in improving answer accuracy, and outperforms other
state-of-the-art advanced RAG and concurrent compressing approaches in various
single-hop and multi-hop QA tasks. Notably, $\textit{Refiner}$ achieves a 80.5%
tokens reduction and a 1.6-7.0% improvement margin in multi-hop tasks compared
to the next best solution. $\textit{Refiner}$ is a plug-and-play solution that
can be seamlessly integrated with RAG systems, facilitating its application
across diverse open-source frameworks."
Preserving Knowledge in Large Language Model - A Model-Agnostic Self-Decompression Approach,https://arxiv.org/abs/2406.11354,2024-06-17,2024-06-19,0.0,0.0,"Humans can retain old knowledge while learning new information, but Large
Language Models (LLMs) often suffer from catastrophic forgetting when
post-pretrained or supervised fine-tuned (SFT) on domain-specific data.
Moreover, for Multimodal Large Language Models (MLLMs) which are composed of
the LLM base and visual projector (e.g. LLaVA), a significant decline in
performance on language benchmarks was observed compared to their
single-modality counterparts. To address these challenges, we introduce a novel
model-agnostic self-decompression method, Tree Generation (TG), that
decompresses knowledge within LLMs into the training corpus. This paper focuses
on TG-SFT, which can synthetically generate SFT data for the instruction tuning
steps. By incorporating the dumped corpus during SFT for MLLMs, we
significantly reduce the forgetting problem."
$\texttt{MoE-RBench}$ - Towards Building Reliable Language Models with Sparse Mixture-of-Experts,https://arxiv.org/abs/2406.11353,2024-06-17,2024-06-19,0.0,0.0,"Mixture-of-Experts (MoE) has gained increasing popularity as a promising
framework for scaling up large language models (LLMs). However, the reliability
assessment of MoE lags behind its surging applications. Moreover, when
transferred to new domains such as in fine-tuning MoE models sometimes
underperform their dense counterparts. Motivated by the research gap and
counter-intuitive phenomenon, we propose $\texttt{MoE-RBench}$, the first
comprehensive assessment of SMoE reliability from three aspects: $\textit{(i)}$
safety and hallucination, $\textit{(ii)}$ resilience to adversarial attacks,
and $\textit{(iii)}$ out-of-distribution robustness. Extensive models and
datasets are tested to compare the MoE to dense networks from these reliability
dimensions. Our empirical observations suggest that with appropriate
hyperparameters, training recipes, and inference techniques, we can build the
MoE model more reliably than the dense LLM. In particular, we find that the
robustness of SMoE is sensitive to the basic training settings. We hope that
this study can provide deeper insights into how to adapt the pre-trained MoE
model to other tasks with higher-generation security, quality, and stability.
Codes are available at https://github.com/UNITES-Lab/MoE-RBench"
Full-ECE - A Metric For Token-level Calibration on Large Language Models,https://arxiv.org/abs/2406.11345,2024-06-17,2024-06-19,0.0,0.0,"Deep Neural Networks (DNNs) excel in various domains but face challenges in
providing accurate uncertainty estimates, which are crucial for high-stakes
applications. Large Language Models (LLMs) have recently emerged as powerful
tools, demonstrating exceptional performance in language tasks. However,
traditional calibration metrics such as Expected Calibration Error (ECE) and
classwise-ECE (cw-ECE) are inadequate for LLMs due to their vast vocabularies,
data complexity, and distributional focus. To address this, we propose a novel
calibration concept called full calibration and introduce its corresponding
metric, Full-ECE. Full-ECE evaluates the entire predicted probability
distribution, offering a more accurate and robust measure of calibration for
LLMs."
KAOS - Large Model Multi-Agent Operating System,https://arxiv.org/abs/2406.11342,2024-06-17,2024-06-19,0.0,0.0,"The intelligent interaction model based on large models reduces the
differences in user experience across various system platforms but faces
challenges in multi-agent collaboration and resource sharing. To demonstrate a
uniform user experience across different foundational software platforms and
address resource coordination management challenges, this paper proposes KAOS,
a multi-agent operating system based on the open-source Kylin. The research
method involves empowering agents with large models to serve applications.
First, by introducing management role agents and vertical multi-agent
collaboration to construct or replace typical application software. Second, by
studying system-level shared resource scheduling strategies to enhance user
experience and optimize resource utilization. And finally, by validating the
efficiency and superiority of the large model multi-agent operating system
through real applications and scoring intelligence. The feasibility of this
system is demonstrated, providing a new perspective for the development of
multi-agent operating systems. Experimental results show significant advantages
of multi-agent collaboration in various application scenarios."
A Systematic Analysis of Large Language Models as Soft Reasoners - The Case of Syllogistic Inferences,https://arxiv.org/abs/2406.11341,2024-06-17,2024-06-19,0.0,0.0,"The reasoning abilities of Large Language Models (LLMs) are becoming a
central focus of study in NLP. In this paper, we consider the case of
syllogistic reasoning, an area of deductive reasoning studied extensively in
logic and cognitive psychology. Previous research has shown that pre-trained
LLMs exhibit reasoning biases, such as $\textit{content effects}$, avoid
answering that $\textit{no conclusion follows}$, display human-like
difficulties, and struggle with multi-step reasoning. We contribute to this
research line by systematically investigating the effects of chain-of-thought
reasoning, in-context learning (ICL), and supervised fine-tuning (SFT) on
syllogistic reasoning, considering syllogisms with conclusions that support or
violate world knowledge, as well as ones with multiple premises. Crucially, we
go beyond the standard focus on accuracy, with an in-depth analysis of the
conclusions generated by the models. Our results suggest that the behavior of
pre-trained LLMs can be explained by heuristics studied in cognitive science
and that both ICL and SFT improve model performance on valid inferences,
although only the latter mitigates most reasoning biases without harming model
consistency."
Fine-grained Controllable Text Generation through In-context Learning with Feedback,https://arxiv.org/abs/2406.11338,2024-06-17,2024-06-19,0.0,0.0,"We present a method for rewriting an input sentence to match specific values
of nontrivial linguistic features, such as dependency depth. In contrast to
earlier work, our method uses in-context learning rather than finetuning,
making it applicable in use cases where data is sparse. We show that our model
performs accurate rewrites and matches the state of the art on rewriting
sentences to a specified school grade level."
Program Synthesis Benchmark for Visual Programming in XLogoOnline Environment,https://arxiv.org/abs/2406.11334,2024-06-17,2024-06-19,0.0,0.0,"Large language and multimodal models have shown remarkable successes on
various benchmarks focused on specific skills such as general-purpose
programming, natural language understanding, math word problem-solving, and
visual question answering. However, it is unclear how well these models perform
on tasks that require a combination of these skills. In this paper, we curate a
novel program synthesis benchmark based on the XLogoOnline visual programming
environment. The benchmark comprises 85 real-world tasks from the Mini-level of
the XLogoOnline environment, each requiring a combination of different skills
such as spatial planning, basic programming, and logical reasoning. Our
evaluation shows that current state-of-the-art models like GPT-4V and
Llama3-70B struggle to solve these tasks, achieving only 20% and 2.35% success
rates. Next, we develop a fine-tuning pipeline to boost the performance of
models by leveraging a large-scale synthetic training dataset with over 80000
tasks. Moreover, we showcase how emulator-driven feedback can be used to design
a curriculum over training data distribution. We showcase that a fine-tuned
Llama3-8B drastically outperforms GPT-4V and Llama3-70B models, and provide an
in-depth analysis of the models' expertise across different skill dimensions.
We will publicly release the benchmark for future research on program synthesis
in visual programming."
They're All Doctors - Synthesizing Diverse Counterfactuals to Mitigate Associative Bias,https://arxiv.org/abs/2406.11331,2024-06-17,2024-06-19,0.0,0.0,"Vision Language Models (VLMs) such as CLIP are powerful models; however they
can exhibit unwanted biases, making them less safe when deployed directly in
applications such as text-to-image, text-to-video retrievals, reverse search,
or classification tasks. In this work, we propose a novel framework to generate
synthetic counterfactual images to create a diverse and balanced dataset that
can be used to fine-tune CLIP. Given a set of diverse synthetic base images
from text-to-image models, we leverage off-the-shelf segmentation and
inpainting models to place humans with diverse visual appearances in context.
We show that CLIP trained on such datasets learns to disentangle the human
appearance from the context of an image, i.e., what makes a doctor is not
correlated to the person's visual appearance, like skin color or body type, but
to the context, such as background, the attire they are wearing, or the objects
they are holding. We demonstrate that our fine-tuned CLIP model, $CF_\alpha$,
improves key fairness metrics such as MaxSkew, MinSkew, and NDKL by 40-66\% for
image retrieval tasks, while still achieving similar levels of performance in
downstream tasks. We show that, by design, our model retains maximal
compatibility with the original CLIP models, and can be easily controlled to
support different accuracy versus fairness trade-offs in a plug-n-play fashion."
Are Large Language Models True Healthcare Jacks-of-All-Trades? Benchmarking Across Health Professions Beyond Physician Exams,https://arxiv.org/abs/2406.11328,2024-06-17,2024-06-19,0.0,0.0,"Recent advancements in Large Language Models (LLMs) have demonstrated their
potential in delivering accurate answers to questions about world knowledge.
Despite this, existing benchmarks for evaluating LLMs in healthcare
predominantly focus on medical doctors, leaving other critical healthcare
professions underrepresented. To fill this research gap, we introduce the
Examinations for Medical Personnel in Chinese (EMPEC), a pioneering large-scale
healthcare knowledge benchmark in traditional Chinese. EMPEC consists of
157,803 exam questions across 124 subjects and 20 healthcare professions,
including underrepresented occupations like Optometrists and Audiologists. Each
question is tagged with its release time and source, ensuring relevance and
authenticity. We conducted extensive experiments on 17 LLMs, including
proprietary, open-source models, general domain models and medical specific
models, evaluating their performance under various settings. Our findings
reveal that while leading models like GPT-4 achieve over 75\% accuracy, they
still struggle with specialized fields and alternative medicine. Surprisingly,
general-purpose LLMs outperformed medical-specific models, and incorporating
EMPEC's training data significantly enhanced performance. Additionally, the
results on questions released after the models' training cutoff date were
consistent with overall performance trends, suggesting that the models'
performance on the test set can predict their effectiveness in addressing
unseen healthcare-related queries. The transition from traditional to
simplified Chinese characters had a negligible impact on model performance,
indicating robust linguistic versatility. Our study underscores the importance
of expanding benchmarks to cover a broader range of healthcare professions to
better assess the applicability of LLMs in real-world healthcare scenarios."
Deep-Learning-Based Channel Estimation for Distributed MIMO with 1-bit Radio-Over-Fiber Fronthaul,https://arxiv.org/abs/2406.11325,2024-06-17,2024-06-19,0.0,0.0,"We consider the problem of pilot-aided, uplink channel estimation in a
distributed massive multiple-input multiple-output (MIMO) architecture, in
which the access points are connected to a central processing unit via
fiber-optical fronthaul links, carrying a two-level-quantized version of the
received analog radio-frequency signal. We adapt to this architecture the
deep-learning-based channel-estimation algorithm recently proposed by Nguyen et
al. (2023), and explore its robustness to the additional signal distortions
(beyond 1-bit quantization) introduced in the considered architecture by the
automatic gain controllers (AGCs) and by the comparators. These components are
used at the access points to generate the two-level analog waveform from the
received signal. Via simulation results, we illustrate that the proposed
channel-estimation method outperforms significantly the Bussgang linear minimum
mean-square error channel estimator, and it is robust against the additional
impairments introduced by the AGCs and the comparators."
GitHub Copilot - the perfect Code compLeeter?,https://arxiv.org/abs/2406.11326,2024-06-17,2024-06-19,0.0,0.0,"This paper aims to evaluate GitHub Copilot's generated code quality based on
the LeetCode problem set using a custom automated framework. We evaluate the
results of Copilot for 4 programming languages: Java, C++, Python3 and Rust. We
aim to evaluate Copilot's reliability in the code generation stage, the
correctness of the generated code and its dependency on the programming
language, problem's difficulty level and problem's topic. In addition to that,
we evaluate code's time and memory efficiency and compare it to the average
human results. In total, we generate solutions for 1760 problems for each
programming language and evaluate all the Copilot's suggestions for each
problem, resulting in over 50000 submissions to LeetCode spread over a 2-month
period. We found that Copilot successfully solved most of the problems.
However, Copilot was rather more successful in generating code in Java and C++
than in Python3 and Rust. Moreover, in case of Python3 Copilot proved to be
rather unreliable in the code generation phase. We also discovered that
Copilot's top-ranked suggestions are not always the best. In addition, we
analysed how the topic of the problem impacts the correctness rate. Finally,
based on statistics information from LeetCode, we can conclude that Copilot
generates more efficient code than an average human."
DocCGen - Document-based Controlled Code Generation,https://arxiv.org/abs/2406.11925,2024-06-17,2024-06-19,0.0,0.0,"Recent developments show that Large Language Models (LLMs) produce
state-of-the-art performance on natural language (NL) to code generation for
resource-rich general-purpose languages like C++, Java, and Python. However,
their practical usage for structured domain-specific languages (DSLs) such as
YAML, JSON is limited due to domain-specific schema, grammar, and
customizations generally unseen by LLMs during pre-training. Efforts have been
made to mitigate this challenge via in-context learning through relevant
examples or by fine-tuning. However, it suffers from problems, such as limited
DSL samples and prompt sensitivity but enterprises maintain good documentation
of the DSLs. Therefore, we propose DocCGen, a framework that can leverage such
rich knowledge by breaking the NL-to-Code generation task for structured code
languages into a two-step process. First, it detects the correct libraries
using the library documentation that best matches the NL query. Then, it
utilizes schema rules extracted from the documentation of these libraries to
constrain the decoding. We evaluate our framework for two complex structured
languages, Ansible YAML and Bash command, consisting of two settings:
Out-of-domain (OOD) and In-domain (ID). Our extensive experiments show that
DocCGen consistently improves different-sized language models across all six
evaluation metrics, reducing syntactic and semantic errors in structured code.
We plan to open-source the datasets and code to motivate research in
constrained code generation."
GUICourse - From General Vision Language Models to Versatile GUI Agents,https://arxiv.org/abs/2406.11317,2024-06-17,2024-06-19,0.0,0.0,"Utilizing Graphic User Interface (GUI) for human-computer interaction is
essential for accessing a wide range of digital tools. Recent advancements in
Vision Language Models (VLMs) highlight the compelling potential to develop
versatile agents to help humans finish GUI navigation tasks. However, current
VLMs are challenged in terms of fundamental abilities (OCR and grounding) and
GUI knowledge (the functions and control methods of GUI elements), preventing
them from becoming practical GUI agents. To solve these challenges, we
contribute GUICourse, a suite of datasets to train visual-based GUI agents from
general VLMs. First, we introduce the GUIEnv dataset to strengthen the OCR and
grounding capabilities of VLMs. Then, we introduce the GUIAct and GUIChat
datasets to enrich their knowledge of GUI components and interactions.
Experiments demonstrate that our GUI agents have better performance on common
GUI tasks than their baseline VLMs. Even the small-size GUI agent (with 3.1B
parameters) can still work well on single-step and multi-step GUI tasks.
Finally, we analyze the different varieties in the training stage of this agent
by ablation study. Our source codes and datasets are released at
https://github.com/yiye3/GUICourse."
Improved Algorithms for Contextual Dynamic Pricing,https://arxiv.org/abs/2406.11316,2024-06-17,2024-06-19,0.0,0.0,"In contextual dynamic pricing, a seller sequentially prices goods based on
contextual information. Buyers will purchase products only if the prices are
below their valuations. The goal of the seller is to design a pricing strategy
that collects as much revenue as possible. We focus on two different valuation
models. The first assumes that valuations linearly depend on the context and
are further distorted by noise. Under minor regularity assumptions, our
algorithm achieves an optimal regret bound of $\tilde{\mathcal{O}}(T^{2/3})$,
improving the existing results. The second model removes the linearity
assumption, requiring only that the expected buyer valuation is
$\beta$-H\""older in the context. For this model, our algorithm obtains a regret
$\tilde{\mathcal{O}}(T^{d+2\beta/d+3\beta})$, where $d$ is the dimension of the
context space."
Federated Active Learning Framework for Efficient Annotation Strategy in Skin-lesion Classification,https://arxiv.org/abs/2406.11310,2024-06-17,2024-06-19,0.0,0.0,"Federated Learning (FL) enables multiple institutes to train models
collaboratively without sharing private data. Current FL research focuses on
communication efficiency, privacy protection, and personalization and assumes
that the data of FL have already been ideally collected. In medical scenarios,
however, data annotation demands both expertise and intensive labor, which is a
critical problem in FL. Active learning (AL), has shown promising performance
in reducing the number of data annotations in medical image analysis. We
propose a federated AL (FedAL) framework in which AL is executed periodically
and interactively under FL. We exploit a local model in each hospital and a
global model acquired from FL to construct an ensemble. We use
ensemble-entropy-based AL as an efficient data-annotation strategy in FL.
Therefore, our FedAL framework can decrease the amount of annotated data and
preserve patient privacy while maintaining the performance of FL. To our
knowledge, this is the first FedAL framework applied to medical images. We
validated our framework on real-world dermoscopic datasets. Using only 50% of
samples, our framework was able to achieve state-of-the-art performance on a
skin-lesion classification task. Our framework performed better than several
state-of-the-art AL methods under FL and achieved comparable performance to
full-data FL."
"Management Decisions in Manufacturing using Causal Machine Learning -- To Rework, or not to Rework?",https://arxiv.org/abs/2406.11308,2024-06-17,2024-06-19,0.0,0.0,"In this paper, we present a data-driven model for estimating optimal rework
policies in manufacturing systems. We consider a single production stage within
a multistage, lot-based system that allows for optional rework steps. While the
rework decision depends on an intermediate state of the lot and system, the
final product inspection, and thus the assessment of the actual yield, is
delayed until production is complete. Repair steps are applied uniformly to the
lot, potentially improving some of the individual items while degrading others.
The challenge is thus to balance potential yield improvement with the rework
costs incurred. Given the inherently causal nature of this decision problem, we
propose a causal model to estimate yield improvement. We apply methods from
causal machine learning, in particular double/debiased machine learning (DML)
techniques, to estimate conditional treatment effects from data and derive
policies for rework decisions. We validate our decision model using real-world
data from opto-electronic semiconductor manufacturing, achieving a yield
improvement of 2 - 3% during the color-conversion process of white
light-emitting diodes (LEDs)."
An Empirical Investigation of Matrix Factorization Methods for Pre-trained Transformers,https://arxiv.org/abs/2406.11307,2024-06-17,2024-06-19,0.0,0.0,"The increasing size of transformer-based models in NLP makes the question of
compressing them important. In this work, we present a comprehensive analysis
of factorization based model compression techniques. Specifically, we focus on
comparing straightforward low-rank factorization against the recently
introduced Monarch factorization, which exhibits impressive performance
preservation on the GLUE benchmark. To mitigate stability issues associated
with low-rank factorization of the matrices in pre-trained transformers, we
introduce a staged factorization approach wherein layers are factorized one by
one instead of being factorized simultaneously. Through this strategy we
significantly enhance the stability and reliability of the compression process.
Further, we introduce a simple block-wise low-rank factorization method, which
has a close relationship to Monarch factorization. Our experiments lead to the
surprising conclusion that straightforward low-rank factorization consistently
outperforms Monarch factorization across both different compression ratios and
six different text classification tasks."
VideoVista - A Versatile Benchmark for Video Understanding and Reasoning,https://arxiv.org/abs/2406.11303,2024-06-17,2024-06-19,0.0,0.0,"Despite significant breakthroughs in video analysis driven by the rapid
development of large multimodal models (LMMs), there remains a lack of a
versatile evaluation benchmark to comprehensively assess these models'
performance in video understanding and reasoning. To address this, we present
VideoVista, a video QA benchmark that integrates challenges across diverse
content categories, durations, and abilities. Specifically, VideoVista
comprises 25,000 questions derived from 3,400 videos spanning 14 categories
(e.g., Howto, Film, and Entertainment) with durations ranging from a few
seconds to over 10 minutes. Besides, it encompasses 19 types of understanding
tasks (e.g., anomaly detection, interaction understanding) and 8 reasoning
tasks (e.g., logical reasoning, causal reasoning). To achieve this, we present
an automatic data construction framework, leveraging powerful GPT-4o alongside
advanced analysis tools (e.g., video splitting, object segmenting, and
tracking). We also utilize this framework to construct training data to enhance
the capabilities of video-related LMMs (Video-LMMs). Through a comprehensive
and quantitative evaluation of cutting-edge models, we reveal that: 1)
Video-LMMs face difficulties in fine-grained video tasks involving temporal
location, object tracking, and anomaly detection; 2) Video-LMMs present
inferior logical and relation reasoning abilities; 3) Open-source Video-LMMs'
performance is significantly lower than GPT-4o and Gemini-1.5, lagging by 20
points. This highlights the crucial role VideoVista will play in advancing LMMs
that can accurately understand videos and perform precise reasoning."
Optimizing and Testing Instruction-Following - Analyzing the Impact of Fine-Grained Instruction Variants on instruction-tuned LLMs,https://arxiv.org/abs/2406.11301,2024-06-17,2024-06-19,0.0,0.0,"The effective alignment of Large Language Models (LLMs) with precise
instructions is essential for their application in diverse real-world
scenarios. Current methods focus on enhancing the diversity and complexity of
training and evaluation samples, yet they fall short in accurately assessing
LLMs' ability to follow similar instruction variants. We introduce an effective
data augmentation technique that decomposes complex instructions into simpler
sub-components, modifies these, and reconstructs them into new variants,
thereby preserves the original instruction's context and complexity while
introducing variability, which is critical for training and evaluating LLMs'
instruction-following precision. We developed the DeMoRecon dataset using this
method to both fine-tune and evaluate LLMs. Our findings show that LLMs
fine-tuned with DeMoRecon will gain significant performance boost on both ours
and commonly used instructions-following benchmarks."
Explainable assessment of financial experts' credibility by classifying social media forecasts and checking the predictions with actual market data,https://arxiv.org/abs/2406.11924,2024-06-17,2024-06-19,0.0,0.0,"Social media include diverse interaction metrics related to user popularity,
the most evident example being the number of user followers. The latter has
raised concerns about the credibility of the posts by the most popular
creators. However, most existing approaches to assess credibility in social
media strictly consider this problem a binary classification, often based on a
priori information, without checking if actual real-world facts back the users'
comments. In addition, they do not provide automatic explanations of their
predictions to foster their trustworthiness. In this work, we propose a
credibility assessment solution for financial creators in social media that
combines Natural Language Processing and Machine Learning. The reputation of
the contributors is assessed by automatically classifying their forecasts on
asset values by type and verifying these predictions with actual market data to
approximate their probability of success. The outcome of this verification is a
continuous credibility score instead of a binary result, an entirely novel
contribution by this work. Moreover, social media metrics (i.e., user context)
are exploited by calculating their correlation with the credibility rankings,
providing insights on the interest of the end-users in financial posts and
their forecasts (i.e., drop or rise). Finally, the system provides natural
language explanations of its decisions based on a model-agnostic analysis of
relevant features."
Iterative Utility Judgment Framework via LLMs Inspired by Relevance in Philosophy,https://arxiv.org/abs/2406.11290,2024-06-17,2024-06-19,0.0,0.0,"Utility and topical relevance are critical measures in information retrieval
(IR), reflecting system and user perspectives, respectively. While topical
relevance has long been emphasized, utility is a higher standard of relevance
and is more useful for facilitating downstream tasks, e.g., in
Retrieval-Augmented Generation (RAG). When we incorporate utility judgments
into RAG, we realize that the topical relevance, utility, and answering in RAG
are closely related to the three types of relevance that Schutz discussed from
a philosophical perspective. They are topical relevance, interpretational
relevance, and motivational relevance, respectively. Inspired by the dynamic
iterations of the three types of relevance, we propose an Iterative utiliTy
judgmEnt fraMework (ITEM) to promote each step of the cycle of RAG. We
conducted extensive experiments on multi-grade passage retrieval and factoid
question-answering datasets (i.e., TREC DL, WebAP, and NQ). Experimental
results demonstrate significant improvements in utility judgments, ranking of
topical relevance, and answer generation upon representative baselines,
including multiple single-shot utility judging approaches. Our code and
benchmark can be found at https://anonymous.4open.science/r/ITEM-B486/."
A Systematic Survey of Text Summarization - From Statistical Methods to Large Language Models,https://arxiv.org/abs/2406.11289,2024-06-17,2024-06-19,0.0,0.0,"Text summarization research has undergone several significant transformations
with the advent of deep neural networks, pre-trained language models (PLMs),
and recent large language models (LLMs). This survey thus provides a
comprehensive review of the research progress and evolution in text
summarization through the lens of these paradigm shifts. It is organized into
two main parts: (1) a detailed overview of datasets, evaluation metrics, and
summarization methods before the LLM era, encompassing traditional statistical
methods, deep learning approaches, and PLM fine-tuning techniques, and (2) the
first detailed examination of recent advancements in benchmarking, modeling,
and evaluating summarization in the LLM era. By synthesizing existing
literature and presenting a cohesive overview, this survey also discusses
research trends, open challenges, and proposes promising research directions in
summarization, aiming to guide researchers through the evolving landscape of
summarization research."
MFC-Bench - Benchmarking Multimodal Fact-Checking with Large Vision-Language Models,https://arxiv.org/abs/2406.11288,2024-06-17,2024-06-19,0.0,0.0,"Large vision-language models (LVLMs) have significantly improved multimodal
reasoning tasks, such as visual question answering and image captioning. These
models embed multimodal facts within their parameters, rather than relying on
external knowledge bases to store factual information explicitly. However, the
content discerned by LVLMs may deviate from actual facts due to inherent bias
or incorrect inference. To address this issue, we introduce MFC-Bench, a
rigorous and comprehensive benchmark designed to evaluate the factual accuracy
of LVLMs across three tasks: Manipulation, Out-of-Context, and Veracity
Classification. Through our evaluation on MFC-Bench, we benchmarked 12 diverse
and representative LVLMs, uncovering that current models still fall short in
multimodal fact-checking and demonstrate insensitivity to various forms of
manipulated content. We hope that MFC-Bench could raise attention to the
trustworthy artificial intelligence potentially assisted by LVLMs in the
future. The MFC-Bench and accompanying resources are publicly accessible at
https://github.com/wskbest/MFC-Bench, contributing to ongoing research in the
multimodal fact-checking field."
Self and Cross-Model Distillation for LLMs - Effective Methods for Refusal Pattern Alignment,https://arxiv.org/abs/2406.11285,2024-06-17,2024-06-19,0.0,0.0,"Large Language Models (LLMs) like OpenAI's GPT series, Anthropic's Claude,
and Meta's LLaMa have shown remarkable capabilities in text generation.
However, their susceptibility to toxic prompts presents significant security
challenges. This paper investigates alignment techniques, including Supervised
Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF), to
mitigate these risks. We conduct an empirical study on refusal patterns across
nine LLMs, revealing that models with uniform refusal patterns, such as
Claude3, exhibit higher security. Based on these findings, we propose
self-distilling and cross-model distilling methods to enhance LLM security. Our
results show that these methods significantly improve refusal rates and reduce
unsafe content, with cross-model distilling achieving refusal rates close to
Claude3's 94.51%. These findings underscore the potential of distillation-based
alignment in securing LLMs against toxic prompts."
From Pixels to Progress - Generating Road Network from Satellite Imagery for Socioeconomic Insights in Impoverished Areas,https://arxiv.org/abs/2406.11282,2024-06-17,2024-06-19,0.0,0.0,"The Sustainable Development Goals (SDGs) aim to resolve societal challenges,
such as eradicating poverty and improving the lives of vulnerable populations
in impoverished areas. Those areas rely on road infrastructure construction to
promote accessibility and economic development. Although publicly available
data like OpenStreetMap is available to monitor road status, data completeness
in impoverished areas is limited. Meanwhile, the development of deep learning
techniques and satellite imagery shows excellent potential for earth
monitoring. To tackle the challenge of road network assessment in impoverished
areas, we develop a systematic road extraction framework combining an
encoder-decoder architecture and morphological operations on satellite imagery,
offering an integrated workflow for interdisciplinary researchers. Extensive
experiments of road network extraction on real-world data in impoverished
regions achieve a 42.7% enhancement in the F1-score over the baseline methods
and reconstruct about 80% of the actual roads. We also propose a comprehensive
road network dataset covering approximately 794,178 km2 area and 17.048 million
people in 382 impoverished counties in China. The generated dataset is further
utilized to conduct socioeconomic analysis in impoverished counties, showing
that road network construction positively impacts regional economic
development. The technical appendix, code, and generated dataset can be found
at
https://github.com/tsinghua-fib-lab/Road_network_extraction_impoverished_counties."
Statistical Learning of Distributionally Robust Stochastic Control in Continuous State Spaces,https://arxiv.org/abs/2406.11281,2024-06-17,2024-06-19,0.0,0.0,"We explore the control of stochastic systems with potentially continuous
state and action spaces, characterized by the state dynamics $X_{t+1} = f(X_t,
A_t, W_t)$. Here, $X$, $A$, and $W$ represent the state, action, and exogenous
random noise processes, respectively, with $f$ denoting a known function that
describes state transitions. Traditionally, the noise process $\{W_t, t \geq
0\}$ is assumed to be independent and identically distributed, with a
distribution that is either fully known or can be consistently estimated.
However, the occurrence of distributional shifts, typical in engineering
settings, necessitates the consideration of the robustness of the policy. This
paper introduces a distributionally robust stochastic control paradigm that
accommodates possibly adaptive adversarial perturbation to the noise
distribution within a prescribed ambiguity set. We examine two adversary
models: current-action-aware and current-action-unaware, leading to different
dynamic programming equations. Furthermore, we characterize the optimal finite
sample minimax rates for achieving uniform learning of the robust value
function across continuum states under both adversary types, considering
ambiguity sets defined by $f_k$-divergence and Wasserstein distance. Finally,
we demonstrate the applicability of our framework across various real-world
settings."
Rethinking Spatio-Temporal Transformer for Traffic Prediction -Multi-level Multi-view Augmented Learning Framework,https://arxiv.org/abs/2406.11921,2024-06-17,2024-06-19,0.0,0.0,"Traffic prediction is a challenging spatio-temporal forecasting problem that
involves highly complex spatio-temporal correlations. This paper proposes a
Multi-level Multi-view Augmented Spatio-temporal Transformer (LVSTformer) for
traffic prediction. The model aims to capture spatial dependencies from three
different levels: local geographic, global semantic, and pivotal nodes, along
with long- and short-term temporal dependencies. Specifically, we design three
spatial augmented views to delve into the spatial information from the
perspectives of local, global, and pivotal nodes. By combining three spatial
augmented views with three parallel spatial self-attention mechanisms, the
model can comprehensively captures spatial dependencies at different levels. We
design a gated temporal self-attention mechanism to effectively capture long-
and short-term temporal dependencies. Furthermore, a spatio-temporal context
broadcasting module is introduced between two spatio-temporal layers to ensure
a well-distributed allocation of attention scores, alleviating overfitting and
information loss, and enhancing the generalization ability and robustness of
the model. A comprehensive set of experiments is conducted on six well-known
traffic benchmarks, the experimental results demonstrate that LVSTformer
achieves state-of-the-art performance compared to competing baselines, with the
maximum improvement reaching up to 4.32%."
"Do Not Design, Learn - A Trainable Scoring Function for Uncertainty Estimation in Generative LLMs",https://arxiv.org/abs/2406.11278,2024-06-17,2024-06-19,0.0,0.0,"In this work, we introduce the Learnable Response Scoring Function (LARS) for
Uncertainty Estimation (UE) in generative Large Language Models (LLMs). Current
scoring functions for probability-based UE, such as length-normalized scoring
and semantic contribution-based weighting, are designed to solve specific
aspects of the problem but exhibit limitations, including the inability to
handle biased probabilities and under-performance in low-resource languages
like Turkish. To address these issues, we propose LARS, a scoring function that
leverages supervised data to capture complex dependencies between tokens and
probabilities, thereby producing more reliable and calibrated response scores
in computing the uncertainty of generations. Our extensive experiments across
multiple datasets show that LARS substantially outperforms existing scoring
functions considering various probability-based UE methods."
Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector,https://arxiv.org/abs/2406.11277,2024-06-17,2024-06-19,0.0,0.0,"Hallucination detection is a challenging task for large language models
(LLMs), and existing studies heavily rely on powerful closed-source LLMs such
as GPT-4. In this paper, we propose an autonomous LLM-based agent framework,
called HaluAgent, which enables relatively smaller LLMs (e.g. Baichuan2-Chat
7B) to actively select suitable tools for detecting multiple hallucination
types such as text, code, and mathematical expression. In HaluAgent, we
integrate the LLM, multi-functional toolbox, and design a fine-grained
three-stage detection framework along with memory mechanism. To facilitate the
effectiveness of HaluAgent, we leverage existing Chinese and English datasets
to synthesize detection trajectories for fine-tuning, which endows HaluAgent
with the capability for bilingual hallucination detection. Extensive
experiments demonstrate that only using 2K samples for tuning LLMs, HaluAgent
can perform hallucination detection on various types of tasks and datasets,
achieving performance comparable to or even higher than GPT-4 without tool
enhancements on both in-domain and out-of-domain datasets. We release our
dataset and code at https://github.com/RUCAIBox/HaluAgent."
Self-training Large Language Models through Knowledge Detection,https://arxiv.org/abs/2406.11275,2024-06-17,2024-06-19,0.0,0.0,"Large language models (LLMs) often necessitate extensive labeled datasets and
training compute to achieve impressive performance across downstream tasks.
This paper explores a self-training paradigm, where the LLM autonomously
curates its own labels and selectively trains on unknown data samples
identified through a reference-free consistency method. Empirical evaluations
demonstrate significant improvements in reducing hallucination in generation
across multiple subjects. Furthermore, the selective training framework
mitigates catastrophic forgetting in out-of-distribution benchmarks, addressing
a critical limitation in training LLMs. Our findings suggest that such an
approach can substantially reduce the dependency on large labeled datasets,
paving the way for more scalable and cost-effective language model training."
Skip-Layer Attention - Bridging Abstract and Detailed Dependencies in Transformers,https://arxiv.org/abs/2406.11274,2024-06-17,2024-06-19,0.0,0.0,"The Transformer architecture has significantly advanced deep learning,
particularly in natural language processing, by effectively managing long-range
dependencies. However, as the demand for understanding complex relationships
grows, refining the Transformer's architecture becomes critical. This paper
introduces Skip-Layer Attention (SLA) to enhance Transformer models by enabling
direct attention between non-adjacent layers. This method improves the model's
ability to capture dependencies between high-level abstract features and
low-level details. By facilitating direct attention between these diverse
feature levels, our approach overcomes the limitations of current Transformers,
which often rely on suboptimal intra-layer attention. Our implementation
extends the Transformer's functionality by enabling queries in a given layer to
interact with keys and values from both the current layer and one preceding
layer, thus enhancing the diversity of multi-head attention without additional
computational burden. Extensive experiments demonstrate that our enhanced
Transformer model achieves superior performance in language modeling tasks,
highlighting the effectiveness of our skip-layer attention mechanism."
Job-SDF - A Multi-Granularity Dataset for Job Skill Demand Forecasting and Benchmarking,https://arxiv.org/abs/2406.11920,2024-06-17,2024-06-19,0.0,0.0,"In a rapidly evolving job market, skill demand forecasting is crucial as it
enables policymakers and businesses to anticipate and adapt to changes,
ensuring that workforce skills align with market needs, thereby enhancing
productivity and competitiveness. Additionally, by identifying emerging skill
requirements, it directs individuals towards relevant training and education
opportunities, promoting continuous self-learning and development. However, the
absence of comprehensive datasets presents a significant challenge, impeding
research and the advancement of this field. To bridge this gap, we present
Job-SDF, a dataset designed to train and benchmark job-skill demand forecasting
models. Based on 10.35 million public job advertisements collected from major
online recruitment platforms in China between 2021 and 2023, this dataset
encompasses monthly recruitment demand for 2,324 types of skills across 521
companies. Our dataset uniquely enables evaluating skill demand forecasting
models at various granularities, including occupation, company, and regional
levels. We benchmark a range of models on this dataset, evaluating their
performance in standard scenarios, in predictions focused on lower value
ranges, and in the presence of structural breaks, providing new insights for
further research. Our code and dataset are publicly accessible via the
https://github.com/Job-SDF/benchmark."
Development of an Adaptive Multi-Domain Artificial Intelligence System Built using Machine Learning and Expert Systems Technologies,https://arxiv.org/abs/2406.11272,2024-06-17,2024-06-19,0.0,0.0,"Producing an artificial general intelligence (AGI) has been an elusive goal
in artificial intelligence (AI) research for some time. An AGI would have the
capability, like a human, to be exposed to a new problem domain, learn about it
and then use reasoning processes to make decisions. While AI techniques have
been used across a wide variety of problem domains, an AGI would require an AI
that could reason beyond its programming and training. This paper presents a
small step towards producing an AGI. It describes a mechanism for an AI to
learn about and develop reasoning pathways to make decisions in an a priori
unknown domain. It combines a classical AI technique, the expert system, with a
its modern adaptation - the gradient descent trained expert system (GDTES) -
and utilizes generative artificial intelligence (GAI) to create a network and
training data set for this system. These can be created from available sources
or may draw upon knowledge incorporated in a GAI's own pre-trained model. The
learning process in GDTES is used to optimize the AI's decision-making. While
this approach does not meet the standards that many have defined for an AGI, it
provides a somewhat similar capability, albeit one which requires a learning
process before use."
MINT-1T - Scaling Open-Source Multimodal Data by 10x - A Multimodal Dataset with One Trillion Tokens,https://arxiv.org/abs/2406.11271,2024-06-17,2024-06-19,0.0,0.0,"Multimodal interleaved datasets featuring free-form interleaved sequences of
images and text are crucial for training frontier large multimodal models
(LMMs). Despite the rapid progression of open-source LMMs, there remains a
pronounced scarcity of large-scale, diverse open-source multimodal interleaved
datasets. In response, we introduce MINT-1T, the most extensive and diverse
open-source Multimodal INTerleaved dataset to date. MINT-1T comprises one
trillion text tokens and 3.4 billion images, a 10x scale-up from existing
open-source datasets. Additionally, we include previously untapped sources such
as PDFs and ArXiv papers. As scaling multimodal interleaved datasets requires
substantial engineering effort, sharing the data curation process and releasing
the dataset greatly benefits the community. Our experiments show that LMMs
trained on MINT-1T rival the performance of models trained on the previous
leading dataset, OBELICS. Our data and code will be released at
https://github.com/mlfoundations/MINT-1T."
Mitigating Large Language Model Hallucination with Faithful Finetuning,https://arxiv.org/abs/2406.11267,2024-06-17,2024-06-19,0.0,0.0,"Large language models (LLMs) have demonstrated remarkable performance on
various natural language processing tasks. However, they are prone to
generating fluent yet untruthful responses, known as ""hallucinations"".
Hallucinations can lead to the spread of misinformation and cause harm in
critical applications. Mitigating hallucinations is challenging as they arise
from factors such as noisy data, model overconfidence, lack of knowledge, and
the generation process itself. Recent efforts have attempted to address this
issue through representation editing and decoding algorithms, reducing
hallucinations without major structural changes or retraining. However, these
approaches either implicitly edit LLMs' behavior in latent space or suppress
the tendency to output unfaithful results during decoding instead of explicitly
modeling on hallucination. In this work, we introduce Faithful Finetuning (F2),
a novel method that explicitly models the process of faithful question
answering through carefully designed loss functions during fine-tuning. We
conduct extensive experiments on popular datasets and demonstrate that F2
achieves significant improvements over vanilla models and baselines."
The Fall of ROME - Understanding the Collapse of LLMs in Model Editing,https://arxiv.org/abs/2406.11263,2024-06-17,2024-06-19,0.0,0.0,"Despite significant progress in model editing methods, their application in
real-world scenarios remains challenging as they often cause large language
models (LLMs) to collapse. Among them, ROME is particularly concerning, as it
could disrupt LLMs with only a single edit. In this paper, we study the root
causes of such collapse. Through extensive analysis, we identify two primary
factors that contribute to the collapse: i) inconsistent handling of prefixed
and unprefixed keys in the parameter update equation may result in very small
denominators, causing excessively large parameter updates; ii) the subject of
collapse cases is usually the first token, whose unprefixed key distribution
significantly differs from the prefixed key distribution in autoregressive
transformers, causing the aforementioned issue to materialize. To validate our
findings, we propose a simple yet effective approach: uniformly using prefixed
keys during editing phase and adding prefixes during testing phase to ensure
the consistency between training and testing. The experimental results show
that the proposed solution can prevent model collapse while maintaining the
effectiveness of the edits."
NLDF - Neural Light Dynamic Fields for Efficient 3D Talking Head Generation,https://arxiv.org/abs/2406.11259,2024-06-17,2024-06-19,0.0,0.0,"Talking head generation based on the neural radiation fields model has shown
promising visual effects. However, the slow rendering speed of NeRF seriously
limits its application, due to the burdensome calculation process over hundreds
of sampled points to synthesize one pixel. In this work, a novel Neural Light
Dynamic Fields model is proposed aiming to achieve generating high quality 3D
talking face with significant speedup. The NLDF represents light fields based
on light segments, and a deep network is used to learn the entire light beam's
information at once. In learning the knowledge distillation is applied and the
NeRF based synthesized result is used to guide the correct coloration of light
segments in NLDF. Furthermore, a novel active pool training strategy is
proposed to focus on high frequency movements, particularly on the speaker
mouth and eyebrows. The propose method effectively represents the facial light
dynamics in 3D talking video generation, and it achieves approximately 30 times
faster speed compared to state of the art NeRF based method, with comparable
generation visual quality."
Enhancing Biomedical Knowledge Retrieval-Augmented Generation with Self-Rewarding Tree Search and Proximal Policy Optimization,https://arxiv.org/abs/2406.11258,2024-06-17,2024-06-19,0.0,0.0,"Large Language Models (LLMs) have shown great potential in the biomedical
domain with the advancement of retrieval-augmented generation (RAG). However,
existing retrieval-augmented approaches face challenges in addressing diverse
queries and documents, particularly for medical knowledge queries, resulting in
sub-optimal performance. To address these limitations, we propose a novel
plug-and-play LLM-based retrieval method called Self-Rewarding Tree Search
(SeRTS) based on Monte Carlo Tree Search (MCTS) and a self-rewarding paradigm.
By combining the reasoning capabilities of LLMs with the effectiveness of tree
search, SeRTS boosts the zero-shot performance of retrieving high-quality and
informative results for RAG. We further enhance retrieval performance by
fine-tuning LLMs with Proximal Policy Optimization (PPO) objectives using the
trajectories collected by SeRTS as feedback. Controlled experiments using the
BioASQ-QA dataset with GPT-3.5-Turbo and LLama2-7b demonstrate that our method
significantly improves the performance of the BM25 retriever and surpasses the
strong baseline of self-reflection in both efficiency and scalability.
Moreover, SeRTS generates higher-quality feedback for PPO training than
self-reflection. Our proposed method effectively adapts LLMs to document
retrieval tasks, enhancing their ability to retrieve highly relevant documents
for RAG in the context of medical knowledge queries. This work presents a
significant step forward in leveraging LLMs for accurate and comprehensive
biomedical question answering."
ExCP - Extreme LLM Checkpoint Compression via Weight-Momentum Joint Shrinking,https://arxiv.org/abs/2406.11257,2024-06-17,2024-06-19,0.0,0.0,"Large language models (LLM) have recently attracted significant attention in
the field of artificial intelligence. However, the training process of these
models poses significant challenges in terms of computational and storage
capacities, thus compressing checkpoints has become an urgent problem. In this
paper, we propose a novel Extreme Checkpoint Compression (ExCP) framework,
which significantly reduces the required storage of training checkpoints while
achieving nearly lossless performance. We first calculate the residuals of
adjacent checkpoints to obtain the essential but sparse information for higher
compression ratio. To further excavate the redundancy parameters in
checkpoints, we then propose a weight-momentum joint shrinking method to
utilize another important information during the model optimization, i.e.,
momentum. In particular, we exploit the information of both model and optimizer
to discard as many parameters as possible while preserving critical information
to ensure optimal performance. Furthermore, we utilize non-uniform quantization
to further compress the storage of checkpoints. We extensively evaluate our
proposed ExCP framework on several models ranging from 410M to 7B parameters
and demonstrate significant storage reduction while maintaining strong
performance. For instance, we achieve approximately $70\times$ compression for
the Pythia-410M model, with the final performance being as accurate as the
original model on various downstream tasks. Codes will be available at
https://github.com/Gaffey/ExCP."
Dynamic Data Mixing Maximizes Instruction Tuning for Mixture-of-Experts,https://arxiv.org/abs/2406.11256,2024-06-17,2024-06-19,0.0,0.0,"Mixture-of-Experts (MoE) models have shown remarkable capability in
instruction tuning, especially when the number of tasks scales. However,
previous methods simply merge all training tasks (e.g. creative writing,
coding, and mathematics) and apply fixed sampling weights, without considering
the importance of different tasks as the model training state changes. In this
way, the most helpful data cannot be effectively distinguished, leading to
suboptimal model performance. To reduce the potential redundancies of datasets,
we make the first attempt and propose a novel dynamic data mixture for MoE
instruction tuning. Specifically, inspired by MoE's token routing preference,
we build dataset-level representations and then capture the subtle differences
among datasets. Finally, we propose to dynamically adjust the sampling weight
of datasets by their inter-redundancies, thus maximizing global performance
under a limited training budget. The experimental results on two MoE models
demonstrate the effectiveness of our approach on both downstream knowledge \&
reasoning tasks and open-ended queries. Code and models are available at
https://github.com/Spico197/MoE-SFT ."
Liberal Entity Matching as a Compound AI Toolchain,https://arxiv.org/abs/2406.11255,2024-06-17,2024-06-19,0.0,0.0,"Entity matching (EM), the task of identifying whether two descriptions refer
to the same entity, is essential in data management. Traditional methods have
evolved from rule-based to AI-driven approaches, yet current techniques using
large language models (LLMs) often fall short due to their reliance on static
knowledge and rigid, predefined prompts. In this paper, we introduce Libem, a
compound AI system designed to address these limitations by incorporating a
flexible, tool-oriented approach. Libem supports entity matching through
dynamic tool use, self-refinement, and optimization, allowing it to adapt and
refine its process based on the dataset and performance metrics. Unlike
traditional solo-AI EM systems, which often suffer from a lack of modularity
that hinders iterative design improvements and system optimization, Libem
offers a composable and reusable toolchain. This approach aims to contribute to
ongoing discussions and developments in AI-driven data management."
Can Machines Resonate with Humans? Evaluating the Emotional and Empathic Comprehension of LMs,https://arxiv.org/abs/2406.11250,2024-06-17,2024-06-19,0.0,0.0,"Empathy plays a pivotal role in fostering prosocial behavior, often triggered
by the sharing of personal experiences through narratives. However, modeling
empathy using NLP approaches remains challenging due to its deep
interconnection with human interaction dynamics. Previous approaches, which
involve fine-tuning language models (LMs) on human-annotated empathic datasets,
have had limited success. In our pursuit of improving empathy understanding in
LMs, we propose several strategies, including contrastive learning with masked
LMs and supervised fine-tuning with Large Language Models (LLMs). While these
methods show improvements over previous methods, the overall results remain
unsatisfactory. To better understand this trend, we performed an analysis which
reveals a low agreement among annotators. This lack of consensus hinders
training and highlights the subjective nature of the task. We also explore the
cultural impact on annotations. To study this, we meticulously collected story
pairs in Urdu language and find that subjectivity in interpreting empathy among
annotators appears to be independent of cultural background. The insights from
our systematic exploration of LMs' understanding of empathy suggest that there
is considerable room for exploration in both task formulation and modeling."
Relational Learning in Pre-Trained Models - A Theory from Hypergraph Recovery Perspective,https://arxiv.org/abs/2406.11249,2024-06-17,2024-06-19,0.0,0.0,"Foundation Models (FMs) have demonstrated remarkable insights into the
relational dynamics of the world, leading to the crucial question: how do these
models acquire an understanding of world hybrid relations? Traditional
statistical learning, particularly for prediction problems, may overlook the
rich and inherently structured information from the data, especially regarding
the relationships between objects. We introduce a mathematical model that
formalizes relational learning as hypergraph recovery to study pre-training of
FMs. In our framework, the world is represented as a hypergraph, with data
abstracted as random samples from hyperedges. We theoretically examine the
feasibility of a Pre-Trained Model (PTM) to recover this hypergraph and analyze
the data efficiency in a minimax near-optimal style. By integrating rich graph
theories into the realm of PTMs, our mathematical framework offers powerful
tools for an in-depth understanding of pre-training from a unique perspective
and can be used under various scenarios. As an example, we extend the framework
to entity alignment in multimodal learning."
Performance Improvement of Language-Queried Audio Source Separation Based on Caption Augmentation From Large Language Models for DCASE Challenge 2024 Task 9,https://arxiv.org/abs/2406.11248,2024-06-17,2024-06-19,0.0,0.0,"We present a prompt-engineering-based text-augmentation approach applied to a
language-queried audio source separation (LASS) task. To enhance the
performance of LASS, the proposed approach utilizes large language models
(LLMs) to generate multiple captions corresponding to each sentence of the
training dataset. To this end, we first perform experiments to identify the
most effective prompts for caption augmentation with a smaller number of
captions. A LASS model trained with these augmented captions demonstrates
improved performance on the DCASE 2024 Task 9 validation set compared to that
trained without augmentation. This study highlights the effectiveness of
LLM-based caption augmentation in advancing language-queried audio source
separation."
SpoT-Mamba - Learning Long-Range Dependency on Spatio-Temporal Graphs with Selective State Spaces,https://arxiv.org/abs/2406.11244,2024-06-17,2024-06-19,0.0,0.0,"Spatio-temporal graph (STG) forecasting is a critical task with extensive
applications in the real world, including traffic and weather forecasting.
Although several recent methods have been proposed to model complex dynamics in
STGs, addressing long-range spatio-temporal dependencies remains a significant
challenge, leading to limited performance gains. Inspired by a recently
proposed state space model named Mamba, which has shown remarkable capability
of capturing long-range dependency, we propose a new STG forecasting framework
named SpoT-Mamba. SpoT-Mamba generates node embeddings by scanning various
node-specific walk sequences. Based on the node embeddings, it conducts
temporal scans to capture long-range spatio-temporal dependencies. Experimental
results on the real-world traffic forecasting dataset demonstrate the
effectiveness of SpoT-Mamba."
FamiCom - Further Demystifying Prompts for Language Models with Task-Agnostic Performance Estimation,https://arxiv.org/abs/2406.11243,2024-06-17,2024-06-19,0.0,0.0,"Language models have shown impressive in-context-learning capabilities, which
allow them to benefit from input prompts and perform better on downstream end
tasks. Existing works investigate the mechanisms behind this observation, and
propose label-agnostic prompt metrics that can better estimate end-task
performances. One popular approach is using perplexity as a way to measure
models' familiarity with the prompt. While showing consistent improvements on
in-domain tasks, we found that familiarity metrics such as perplexity cannot
accurately estimate performance in complicated situations such as task or
domain transferring scenarios. In this work, we propose a revised measure
called FamiCom, providing a more comprehensive measure for task-agnostic
performance estimation. Specifically, FamiCom combines familiarity with
\textit{complexity} -- the inherent difficulty of end tasks, which is an
important factor missing from current metrics. Experiments show that FamiCom
strongly correlates with end-task performances, producing a 0.85 Spearman's
correlation, versus 0.43 of familiarity-only ones'. We further apply FamiCom to
automatic prompt and demonstration selection, and outperform existing methods
and baselines by more than 7.0% in accuracy."
The Benefits of Power Regularization in Cooperative Reinforcement Learning,https://arxiv.org/abs/2406.11240,2024-06-17,2024-06-19,0.0,0.0,"Cooperative Multi-Agent Reinforcement Learning (MARL) algorithms, trained
only to optimize task reward, can lead to a concentration of power where the
failure or adversarial intent of a single agent could decimate the reward of
every agent in the system. In the context of teams of people, it is often
useful to explicitly consider how power is distributed to ensure no person
becomes a single point of failure. Here, we argue that explicitly regularizing
the concentration of power in cooperative RL systems can result in systems
which are more robust to single agent failure, adversarial attacks, and
incentive changes of co-players. To this end, we define a practical pairwise
measure of power that captures the ability of any co-player to influence the
ego agent's reward, and then propose a power-regularized objective which
balances task reward and power concentration. Given this new objective, we show
that there always exists an equilibrium where every agent is playing a
power-regularized best-response balancing power and task reward. Moreover, we
present two algorithms for training agents towards this power-regularized
objective: Sample Based Power Regularization (SBPR), which injects adversarial
data during training; and Power Regularization via Intrinsic Motivation (PRIM),
which adds an intrinsic motivation to regulate power to the training objective.
Our experiments demonstrate that both algorithms successfully balance task
reward and power, leading to lower power behavior than the baseline of
task-only reward and avoid catastrophic events in case an agent in the system
goes off-policy."
Evading AI-Generated Content Detectors using Homoglyphs,https://arxiv.org/abs/2406.11239,2024-06-17,2024-06-19,0.0,0.0,"The advent of large language models (LLMs) has enabled the generation of text
that increasingly exhibits human-like characteristics. As the detection of such
content is of significant importance, numerous studies have been conducted with
the aim of developing reliable AI-generated text detectors. These detectors
have demonstrated promising results on test data, but recent research has
revealed that they can be circumvented by employing different techniques. In
this paper, we present homoglyph-based attacks ($a \rightarrow {\alpha}$) as a
means of circumventing existing detectors. A comprehensive evaluation was
conducted to assess the effectiveness of these attacks on seven detectors,
including ArguGPT, Binoculars, DetectGPT, Fast-DetectGPT, Ghostbuster, OpenAI's
detector, and watermarking techniques, on five different datasets. Our findings
demonstrate that homoglyph-based attacks can effectively circumvent
state-of-the-art detectors, leading them to classify all texts as either
AI-generated or human-written (decreasing the average Matthews Correlation
Coefficient from 0.64 to -0.01). We then examine the effectiveness of these
attacks by analyzing how homoglyphs impact different families of detectors.
Finally, we discuss the implications of these findings and potential defenses
against such attacks."
What Kinds of Tokens Benefit from Distant Text? An Analysis on Long Context Language Modeling,https://arxiv.org/abs/2406.11238,2024-06-17,2024-06-19,0.0,0.0,"As the context length that large language models can handle continues to
increase, these models demonstrate an enhanced ability to utilize distant
information for tasks such as language modeling. This capability contrasts with
human reading and writing habits, where it is uncommon to remember and use
particularly distant information, except in cases of foreshadowing. In this
paper, we aim to explore which kinds of words benefit more from long contexts
in language models. By analyzing the changes in token probabilities with
increasing context length, we find that content words (e.g., nouns, adjectives)
and the initial tokens of words benefit the most. Frequent patterns in the
context (N-grams) also significantly impact predictions. Additionally, the
model's prior knowledge plays a crucial role in influencing predictions,
especially for rare tokens. We also observe that language models become more
confident with longer contexts, resulting in sharper probability distributions.
This overconfidence may contribute to the increasing probabilities of tokens
with distant contextual information. We hope that our analysis will help the
community better understand long-text language modeling and contribute to the
design of more reliable long-context models."
QTIP - Quantization with Trellises and Incoherence Processing,https://arxiv.org/abs/2406.11235,2024-06-17,2024-06-19,0.0,0.0,"Post-training quantization (PTQ) reduces the memory footprint of LLMs by
quantizing weights to low-precision datatypes. Since LLM inference is usually
memory-bound, PTQ methods can improve inference throughput. Recent
state-of-the-art PTQ approaches have converged on using vector quantization
(VQ) to quantize multiple weights at once, which improves information
utilization through better shaping. However, VQ requires a codebook with size
exponential in the dimension. This limits current VQ-based PTQ works to low VQ
dimensions ($\le 8$) that in turn limit quantization quality. Here, we
introduce QTIP, which instead uses trellis coded quantization (TCQ) to achieve
ultra-high-dimensional quantization. TCQ uses a stateful decoder that separates
the codebook size from the bitrate and effective dimension. QTIP introduces a
spectrum of lookup-only to computed lookup-free trellis codes designed for a
hardware-efficient ""bitshift"" trellis structure; these codes achieve
state-of-the-art results in both quantization quality and inference speed."
MiniConGTS - A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction,https://arxiv.org/abs/2406.11234,2024-06-17,2024-06-19,0.0,0.0,"Aspect Sentiment Triplet Extraction (ASTE) aims to co-extract the sentiment
triplets in a given corpus. Existing approaches within the
pretraining-finetuning paradigm tend to either meticulously craft complex
tagging schemes and classification heads, or incorporate external semantic
augmentation to enhance performance. In this study, we, for the first time,
re-evaluate the redundancy in tagging schemes and the internal enhancement in
pretrained representations. We propose a method to improve and utilize
pretrained representations by integrating a minimalist tagging scheme and a
novel token-level contrastive learning strategy. The proposed approach
demonstrates comparable or superior performance compared to state-of-the-art
techniques while featuring a more compact design and reduced computational
overhead. Additionally, we are the first to formally evaluate GPT-4's
performance in few-shot learning and Chain-of-Thought scenarios for this task.
The results demonstrate that the pretraining-finetuning paradigm remains highly
effective even in the era of large language models."
Probing the Decision Boundaries of In-context Learning in Large Language Models,https://arxiv.org/abs/2406.11233,2024-06-17,2024-06-19,0.0,0.0,"In-context learning is a key paradigm in large language models (LLMs) that
enables them to generalize to new tasks and domains by simply prompting these
models with a few exemplars without explicit parameter updates. Many attempts
have been made to understand in-context learning in LLMs as a function of model
scale, pretraining data, and other factors. In this work, we propose a new
mechanism to probe and understand in-context learning from the lens of decision
boundaries for in-context binary classification. Decision boundaries are
straightforward to visualize and provide important information about the
qualitative behavior of the inductive biases of standard classifiers. To our
surprise, we find that the decision boundaries learned by current LLMs in
simple binary classification tasks are often irregular and non-smooth,
regardless of linear separability in the underlying task. This paper
investigates the factors influencing these decision boundaries and explores
methods to enhance their generalizability. We assess various approaches,
including training-free and fine-tuning methods for LLMs, the impact of model
architecture, and the effectiveness of active prompting techniques for
smoothing decision boundaries in a data-efficient manner. Our findings provide
a deeper understanding of in-context learning dynamics and offer practical
improvements for enhancing robustness and generalizability of in-context
learning."
A Collaborative Data Analytics System with Recommender for Diverse Users,https://arxiv.org/abs/2406.11232,2024-06-17,2024-06-19,0.0,0.0,"This paper presents the SLEGO (Software-Lego) system, a collaborative
analytics platform that bridges the gap between experienced developers and
novice users using a cloud-based platform with modular, reusable microservices.
These microservices enable developers to share their analytical tools and
workflows, while a simple graphical user interface (GUI) allows novice users to
build comprehensive analytics pipelines without programming skills. Supported
by a knowledge base and a Large Language Model (LLM) powered recommendation
system, SLEGO enhances the selection and integration of microservices,
increasing the efficiency of analytics pipeline construction. Case studies in
finance and machine learning illustrate how SLEGO promotes the sharing and
assembly of modular microservices, significantly improving resource reusability
and team collaboration. The results highlight SLEGO's role in democratizing
data analytics by integrating modular design, knowledge bases, and
recommendation systems, fostering a more inclusive and efficient analytical
environment."
Enabling robots to follow abstract instructions and complete complex dynamic tasks,https://arxiv.org/abs/2406.11231,2024-06-17,2024-06-19,0.0,0.0,"Completing complex tasks in unpredictable settings like home kitchens
challenges robotic systems. These challenges include interpreting high-level
human commands, such as ""make me a hot beverage"" and performing actions like
pouring a precise amount of water into a moving mug. To address these
challenges, we present a novel framework that combines Large Language Models
(LLMs), a curated Knowledge Base, and Integrated Force and Visual Feedback
(IFVF). Our approach interprets abstract instructions, performs long-horizon
tasks, and handles various uncertainties. It utilises GPT-4 to analyse the
user's query and surroundings, then generates code that accesses a curated
database of functions during execution. It translates abstract instructions
into actionable steps. Each step involves generating custom code by employing
retrieval-augmented generalisation to pull IFVF-relevant examples from the
Knowledge Base. IFVF allows the robot to respond to noise and disturbances
during execution. We use coffee making and plate decoration to demonstrate our
approach, including components ranging from pouring to drawer opening, each
benefiting from distinct feedback types and methods. This novel advancement
marks significant progress toward a scalable, efficient robotic framework for
completing complex tasks in uncertain environments. Our findings are
illustrated in an accompanying video and supported by an open-source GitHub
repository (released upon paper acceptance)."
Multimodal Needle in a Haystack - Benchmarking Long-Context Capability of Multimodal Large Language Models,https://arxiv.org/abs/2406.11230,2024-06-17,2024-06-19,0.0,0.0,"Multimodal Large Language Models (MLLMs) have shown significant promise in
various applications, leading to broad interest from researchers and
practitioners alike. However, a comprehensive evaluation of their long-context
capabilities remains underexplored. To address these gaps, we introduce the
MultiModal Needle-in-a-haystack (MMNeedle) benchmark, specifically designed to
assess the long-context capabilities of MLLMs. Besides multi-image input, we
employ image stitching to further increase the input context length, and
develop a protocol to automatically generate labels for sub-image level
retrieval. Essentially, MMNeedle evaluates MLLMs by stress-testing their
capability to locate a target sub-image (needle) within a set of images
(haystack) based on textual instructions and descriptions of image contents.
This setup necessitates an advanced understanding of extensive visual contexts
and effective information retrieval within long-context image inputs. With this
benchmark, we evaluate state-of-the-art MLLMs, encompassing both API-based and
open-source models. The findings reveal that GPT-4o consistently surpasses
other models in long-context scenarios, but suffers from hallucination problems
in negative samples, i.e., when needles are not in the haystacks. Our
comprehensive long-context evaluation of MLLMs also sheds lights on the
considerable performance gap between API-based and open-source models. All the
code, data, and instructions required to reproduce the main results are
available at https://github.com/Wang-ML-Lab/multimodal-needle-in-a-haystack."
ComperDial - Commonsense Persona-grounded Dialogue Dataset and Benchmark,https://arxiv.org/abs/2406.11228,2024-06-17,2024-06-19,0.0,0.0,"We propose a new benchmark, ComperDial, which facilitates the training and
evaluation of evaluation metrics for open-domain dialogue systems. ComperDial
consists of human-scored responses for 10,395 dialogue turns in 1,485
conversations collected from 99 dialogue agents submitted to the Commonsense
Persona-grounded Dialogue (CPD) challenge. As a result, for any dialogue, our
benchmark includes multiple diverse responses with variety of characteristics
to ensure more robust evaluation of learned dialogue metrics. In addition to
single-turn response scores, ComperDial also contains dialogue-level
human-annotated scores, enabling joint assessment of multi-turn model responses
throughout a dialogue. Finally, building off ComperDial, we devise a new
automatic evaluation metric to measure the general similarity of
model-generated dialogues to human conversations. Our experimental results
demonstrate that our novel metric, CPDScore is more correlated with human
judgments than existing metrics. We release both ComperDial and CPDScore to the
community to accelerate development of automatic evaluation metrics for
open-domain dialogue systems."
Compound Schema Registry,https://arxiv.org/abs/2406.11227,2024-06-17,2024-06-19,0.0,0.0,"Schema evolution is critical in managing database systems to ensure
compatibility across different data versions. A schema registry typically
addresses the challenges of schema evolution in real-time data streaming by
managing, validating, and ensuring schema compatibility. However, current
schema registries struggle with complex syntactic alterations like field
renaming or type changes, which often require significant manual intervention
and can disrupt service. To enhance the flexibility of schema evolution, we
propose the use of generalized schema evolution (GSE) facilitated by a compound
AI system. This system employs Large Language Models (LLMs) to interpret the
semantics of schema changes, supporting a broader range of syntactic
modifications without interrupting data streams. Our approach includes
developing a task-specific language, Schema Transformation Language (STL), to
generate schema mappings as an intermediate representation (IR), simplifying
the integration of schema changes across different data processing platforms.
Initial results indicate that this approach can improve schema mapping accuracy
and efficiency, demonstrating the potential of GSE in practical applications."
"Building another Spanish dictionary, this time with GPT-4",https://arxiv.org/abs/2406.11218,2024-06-17,2024-06-19,0.0,0.0,"We present the ""Spanish Built Factual Freectianary 2.0"" (Spanish-BFF-2) as
the second iteration of an AI-generated Spanish dictionary. Previously, we
developed the inaugural version of this unique free dictionary employing GPT-3.
In this study, we aim to improve the dictionary by using GPT-4-turbo instead.
Furthermore, we explore improvements made to the initial version and compare
the performance of both models."
Global Data Constraints - Ethical and Effectiveness Challenges in Large Language Model,https://arxiv.org/abs/2406.11214,2024-06-17,2024-06-19,0.0,0.0,"Recent advancements in large language models (LLMs), such as GPT-4 and
GPT-4o, have shown exceptional performance, especially in languages with
abundant resources like English, thanks to extensive datasets that ensure
robust training. Conversely, these models exhibit limitations when processing
under-resourced languages such as Chinese and Korean, where issues including
hallucinatory responses remain prevalent. This paper traces the roots of these
disparities to the tokenization process inherent to these models. Specifically,
it explores how the tokenizer vocabulary, often used to speed up the
tokenization process and reduce tokens but constructed independently of the
actual model training data, inadequately represents non-English languages. This
misrepresentation results in the propagation of 'under-trained' or 'untrained'
tokens, which perpetuate biases and pose serious concerns related to data
security and ethical standards. We aim to dissect the tokenization mechanics of
GPT-4o, illustrating how its simplified token-handling methods amplify these
risks and offer strategic solutions to mitigate associated security and ethical
issues. Through this study, we emphasize the critical need to rethink
tokenization frameworks to foster more equitable and secure AI technologies."
"What Operations can be Performed Directly on Compressed Arrays, and with What Error?",https://arxiv.org/abs/2406.11209,2024-06-17,2024-06-19,0.0,0.0,"In response to the rapidly escalating costs of computing with large matrices
and tensors caused by data movement, several lossy compression methods have
been developed to significantly reduce data volumes. Unfortunately, all these
methods require the data to be decompressed before further computations are
done. In this work, we develop a lossy compressor that allows a dozen fairly
fundamental operations directly on compressed data while offering good
compression ratios and modest errors. We implement a new compressor PyBlaz
based on the familiar GPU-powered PyTorch framework, and evaluate it on three
non-trivial applications, choosing different number systems for internal
representation. Our results demonstrate that the compressed-domain operations
achieve good scalability with problem sizes while incurring errors well within
acceptable limits. To our best knowledge, this is the first such lossy
compressor that supports compressed-domain operations while achieving
acceptable performance as well as error."
Retraining with Predicted Hard Labels Provably Increases Model Accuracy,https://arxiv.org/abs/2406.11206,2024-06-17,2024-06-19,0.0,0.0,"The performance of a model trained with \textit{noisy labels} is often
improved by simply \textit{retraining} the model with its own predicted
\textit{hard} labels (i.e., $1$/$0$ labels). Yet, a detailed theoretical
characterization of this phenomenon is lacking. In this paper, we theoretically
analyze retraining in a linearly separable setting with randomly corrupted
labels given to us and prove that retraining can improve the population
accuracy obtained by initially training with the given (noisy) labels. To the
best of our knowledge, this is the first such theoretical result. Retraining
finds application in improving training with label differential privacy (DP)
which involves training with noisy labels. We empirically show that retraining
selectively on the samples for which the predicted label matches the given
label significantly improves label DP training at \textit{no extra privacy
cost}; we call this \textit{consensus-based retraining}. For e.g., when
training ResNet-18 on CIFAR-100 with $\epsilon=3$ label DP, we obtain $6.4\%$
improvement in accuracy with consensus-based retraining."
Fine-Tuning or Fine-Failing? Debunking Performance Myths in Large Language Models,https://arxiv.org/abs/2406.11201,2024-06-17,2024-06-19,0.0,0.0,"Large Language Models (LLMs) have the unique capability to understand and
generate human-like text from input queries. When fine-tuned, these models show
enhanced performance on domain-specific queries. OpenAI highlights the process
of fine-tuning, stating: ""To fine-tune a model, you are required to provide at
least 10 examples. We typically see clear improvements from fine-tuning on 50
to 100 training examples, but the right number varies greatly based on the
exact use case."" This study extends this concept to the integration of LLMs
within Retrieval-Augmented Generation (RAG) pipelines, which aim to improve
accuracy and relevance by leveraging external corpus data for information
retrieval. However, RAG's promise of delivering optimal responses often falls
short in complex query scenarios. This study aims to specifically examine the
effects of fine-tuning LLMs on their ability to extract and integrate
contextual data to enhance the performance of RAG systems across multiple
domains. We evaluate the impact of fine-tuning on the LLMs' capacity for data
extraction and contextual understanding by comparing the accuracy and
completeness of fine-tuned models against baseline performances across datasets
from multiple domains. Our findings indicate that fine-tuning resulted in a
decline in performance compared to the baseline models, contrary to the
improvements observed in standalone LLM applications as suggested by OpenAI.
This study highlights the need for vigorous investigation and validation of
fine-tuned models for domain-specific tasks."
AvaTaR - Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval,https://arxiv.org/abs/2406.11200,2024-06-17,2024-06-19,0.0,0.0,"Large language model (LLM) agents have demonstrated impressive capability in
utilizing external tools and knowledge to boost accuracy and reduce
hallucinations. However, developing the prompting techniques that make LLM
agents able to effectively use external tools and knowledge is a heuristic and
laborious task. Here, we introduce AvaTaR, a novel and automatic framework that
optimizes an LLM agent to effectively use the provided tools and improve its
performance on a given task/domain. During optimization, we design a comparator
module to iteratively provide insightful and holistic prompts to the LLM agent
via reasoning between positive and negative examples sampled from training
data. We demonstrate AvaTaR on four complex multimodal retrieval datasets
featuring textual, visual, and relational information. We find AvaTaR
consistently outperforms state-of-the-art approaches across all four
challenging tasks and exhibits strong generalization ability when applied to
novel cases, achieving an average relative improvement of 14% on the Hit@1
metric. Code and dataset are available at https://github.com/zou-group/avatar."
Graph Knowledge Distillation to Mixture of Experts,https://arxiv.org/abs/2406.11919,2024-06-17,2024-06-19,0.0,0.0,"In terms of accuracy, Graph Neural Networks (GNNs) are the best architectural
choice for the node classification task. Their drawback in real-world
deployment is the latency that emerges from the neighbourhood processing
operation. One solution to the latency issue is to perform knowledge
distillation from a trained GNN to a Multi-Layer Perceptron (MLP), where the
MLP processes only the features of the node being classified (and possibly some
pre-computed structural information). However, the performance of such MLPs in
both transductive and inductive settings remains inconsistent for existing
knowledge distillation techniques. We propose to address the performance
concerns by using a specially-designed student model instead of an MLP. Our
model, named Routing-by-Memory (RbM), is a form of Mixture-of-Experts (MoE),
with a design that enforces expert specialization. By encouraging each expert
to specialize on a certain region on the hidden representation space, we
demonstrate experimentally that it is possible to derive considerably more
consistent performance across multiple datasets."
In-Context Editing - Learning Knowledge from Self-Induced Distributions,https://arxiv.org/abs/2406.11194,2024-06-17,2024-06-19,0.0,0.0,"The existing fine-tuning paradigm for language models is brittle in knowledge
editing scenarios, where the model must incorporate new information without
extensive retraining. This brittleness often results in overfitting, reduced
performance, and unnatural language generation. To address this, we propose
Consistent In-Context Editing (ICE), a novel approach that leverages the
model's in-context learning capability to tune toward a contextual distribution
rather than a one-hot target. ICE introduces a straightforward optimization
framework that includes both a target and a procedure, enhancing the robustness
and effectiveness of gradient-based tuning methods. We provide analytical
insights into ICE across four critical aspects of knowledge editing: accuracy,
locality, generalization, and linguistic quality, showing its advantages.
Experimental results across four datasets confirm the effectiveness of ICE and
demonstrate its potential for continual editing, ensuring that updated
information is incorporated while preserving the integrity of the model."
MMNeuron - Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model,https://arxiv.org/abs/2406.11193,2024-06-17,2024-06-19,0.0,0.0,"Projecting visual features into word embedding space has become a significant
fusion strategy adopted by Multimodal Large Language Models (MLLMs). However,
its internal mechanisms have yet to be explored. Inspired by multilingual
research, we identify domain-specific neurons in multimodal large language
models. Specifically, we investigate the distribution of domain-specific
neurons and the mechanism of how MLLMs process features from diverse domains.
Furthermore, we propose a three-stage mechanism for language model modules in
MLLMs when handling projected image features, and verify this hypothesis using
logit lens. Extensive experiments indicate that while current MLLMs exhibit
Visual Question Answering (VQA) capability, they may not fully utilize
domain-specific information. Manipulating domain-specific neurons properly will
result in a 10% change of accuracy at most, shedding light on the development
of cross-domain, all-encompassing MLLMs in the future. The source code is
available at https://github.com/Z1zs/MMNeuron."
Beyond Boundaries - Learning a Universal Entity Taxonomy across Datasets and Languages for Open Named Entity Recognition,https://arxiv.org/abs/2406.11192,2024-06-17,2024-06-19,0.0,0.0,"Open Named Entity Recognition (NER), which involves identifying arbitrary
types of entities from arbitrary domains, remains challenging for Large
Language Models (LLMs). Recent studies suggest that fine-tuning LLMs on
extensive NER data can boost their performance. However, training directly on
existing datasets faces issues due to inconsistent entity definitions and
redundant data, limiting LLMs to dataset-specific learning and hindering
out-of-domain generalization. To address this, we present B2NERD, a cohesive
and efficient dataset for Open NER, normalized from 54 existing English or
Chinese datasets using a two-step approach. First, we detect inconsistent
entity definitions across datasets and clarify them by distinguishable label
names to construct a universal taxonomy of 400+ entity types. Second, we
address redundancy using a data pruning strategy that selects fewer samples
with greater category and semantic diversity. Comprehensive evaluation shows
that B2NERD significantly improves LLMs' generalization on Open NER. Our B2NER
models, trained on B2NERD, outperform GPT-4 by 6.8-12.0 F1 points and surpass
previous methods in 3 out-of-domain benchmarks across 15 datasets and 6
languages."
A Survey on Human Preference Learning for Large Language Models,https://arxiv.org/abs/2406.11191,2024-06-17,2024-06-19,0.0,0.0,"The recent surge of versatile large language models (LLMs) largely depends on
aligning increasingly capable foundation models with human intentions by
preference learning, enhancing LLMs with excellent applicability and
effectiveness in a wide range of contexts. Despite the numerous related studies
conducted, a perspective on how human preferences are introduced into LLMs
remains limited, which may prevent a deeper comprehension of the relationships
between human preferences and LLMs as well as the realization of their
limitations. In this survey, we review the progress in exploring human
preference learning for LLMs from a preference-centered perspective, covering
the sources and formats of preference feedback, the modeling and usage of
preference signals, as well as the evaluation of the aligned LLMs. We first
categorize the human feedback according to data sources and formats. We then
summarize techniques for human preferences modeling and compare the advantages
and disadvantages of different schools of models. Moreover, we present various
preference usage methods sorted by the objectives to utilize human preference
signals. Finally, we summarize some prevailing approaches to evaluate LLMs in
terms of alignment with human intentions and discuss our outlooks on the human
intention alignment for LLMs."
Aligning Large Language Models from Self-Reference AI Feedback with one General Principle,https://arxiv.org/abs/2406.11190,2024-06-17,2024-06-19,0.0,0.0,"In aligning large language models (LLMs), utilizing feedback from existing
advanced AI rather than humans is an important method to scale supervisory
signals. However, it is highly challenging for AI to understand human
intentions and societal values, and provide accurate preference feedback based
on these. Current AI feedback methods rely on powerful LLMs, carefully designed
specific principles to describe human intentions, and are easily influenced by
position bias. To address these issues, we propose a self-reference-based AI
feedback framework that enables a 13B Llama2-Chat to provide high-quality
feedback under simple and general principles such as ``best for humanity``.
Specifically, we allow the AI to first respond to the user's instructions, then
generate criticism of other answers based on its own response as a reference,
and finally determine which answer better fits human preferences according to
the criticism. Additionally, we use a self-consistency method to further reduce
the impact of position bias, and employ semantic perplexity to calculate the
preference strength differences between different answers. Experimental results
show that our method enables 13B and 70B Llama2-Chat annotators to provide
high-quality preference feedback, and the policy models trained based on these
preference data achieve significant advantages in benchmark datasets through
reinforcement learning."
Save It All - Enabling Full Parameter Tuning for Federated Large Language Models via Cycle Black Gradient Descent,https://arxiv.org/abs/2406.11187,2024-06-17,2024-06-19,0.0,0.0,"The advent of large language models (LLMs) has revolutionized the deep
learning paradigm, yielding impressive results across a wide array of tasks.
However, the pre-training or fine-tuning of LLMs within a federated learning
(FL) framework poses substantial challenges, including considerable
computational and memory resource demands, as well as communication bottlenecks
between servers and clients. Existing solutions either make the unrealistic
assumption that the entire model is exchanged for training, or apply
parameter-effective fine-tuning methods from centralized learning to train LLMs
in FL which tend to underperform during training or fine-tuning stages due to
the limited search subspace of parameter updating. In this paper, we introduce
a novel method for the efficient training and fine-tuning of LLMs in FL, with
minimal resource consumption. Our approach, termed FedCyBGD, utilizes Cycle
Block Gradient Descent to periodically update the model. In particular, we
design a compression scheme for FedCyBGD, aiming to further decrease the model
download cost. It enables full parameter training in FL with only selected
block updates and uploads, thereby reducing communication, computation, and
memory costs. Our method achieves state-of-the-art performance for FL LLM
training, while significantly reducing associated costs. Codes are provided
here."
Learning Iterative Reasoning through Energy Diffusion,https://arxiv.org/abs/2406.11179,2024-06-17,2024-06-19,0.0,0.0,"We introduce iterative reasoning through energy diffusion (IRED), a novel
framework for learning to reason for a variety of tasks by formulating
reasoning and decision-making problems with energy-based optimization. IRED
learns energy functions to represent the constraints between input conditions
and desired outputs. After training, IRED adapts the number of optimization
steps during inference based on problem difficulty, enabling it to solve
problems outside its training distribution -- such as more complex Sudoku
puzzles, matrix completion with large value magnitudes, and pathfinding in
larger graphs. Key to our method's success is two novel techniques: learning a
sequence of annealed energy landscapes for easier inference and a combination
of score function and energy landscape supervision for faster and more stable
training. Our experiments show that IRED outperforms existing methods in
continuous-space reasoning, discrete-space reasoning, and planning tasks,
particularly in more challenging scenarios. Code and visualizations at
https://energy-based-model.github.io/ired/"
TIFG - Text-Informed Feature Generation with Large Language Models,https://arxiv.org/abs/2406.11177,2024-06-17,2024-06-19,0.0,0.0,"Textual information of data is of vital importance for data mining and
feature engineering. However, existing methods focus on learning the data
structures and overlook the textual information along with the data.
Consequently, they waste this valuable resource and miss out on the deeper data
relationships embedded within the texts. In this paper, we introduce
Text-Informed Feature Generation (TIFG), a novel LLM-based text-informed
feature generation framework. TIFG utilizes the textual information to generate
features by retrieving possible relevant features within external knowledge
with Retrieval Augmented Generation (RAG) technology. In this approach, the
TIFG can generate new explainable features to enrich the feature space and
further mine feature relationships. We design the TIFG to be an automated
framework that continuously optimizes the feature generation process, adapts to
new data inputs, and improves downstream task performance over iterations. A
broad range of experiments in various downstream tasks showcases that our
approach can generate high-quality and meaningful features, and is
significantly superior to existing methods."
Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement,https://arxiv.org/abs/2406.11176,2024-06-17,2024-06-19,0.0,0.0,"Large language model agents have exhibited exceptional performance across a
range of complex interactive tasks. Recent approaches have utilized tuning with
expert trajectories to enhance agent performance, yet they primarily
concentrate on outcome rewards, which may lead to errors or suboptimal actions
due to the absence of process supervision signals. In this paper, we introduce
the Iterative step-level Process Refinement (IPR) framework, which provides
detailed step-by-step guidance to enhance agent training. Specifically, we
adopt the Monte Carlo method to estimate step-level rewards. During each
iteration, the agent explores along the expert trajectory and generates new
actions. These actions are then evaluated against the corresponding step of
expert trajectory using step-level rewards. Such comparison helps identify
discrepancies, yielding contrastive action pairs that serve as training data
for the agent. Our experiments on three complex agent tasks demonstrate that
our framework outperforms a variety of strong baselines. Moreover, our
analytical findings highlight the effectiveness of IPR in augmenting action
efficiency and its applicability to diverse models."
BSRBF-KAN - A combination of B-splines and Radial Basic Functions in Kolmogorov-Arnold Networks,https://arxiv.org/abs/2406.11173,2024-06-17,2024-06-19,0.0,0.0,"In this paper, we introduce BSRBF-KAN, a Kolmogorov Arnold Network (KAN) that
combines B-splines and radial basis functions (RBFs) to fit input vectors
during data training. We perform experiments with BSRBF-KAN, multi-layer
perception (MLP), and other popular KANs, including EfficientKAN, FastKAN,
FasterKAN, and GottliebKAN over the MNIST and Fashion-MNIST datasets. BSRBF-KAN
shows stability in 5 training runs with a competitive average accuracy of
97.55% on MNIST and 89.33% on Fashion-MNIST and obtains convergence better than
other networks. We expect BSRBF-KAN to open many combinations of mathematical
functions to design KANs. Our repo is publicly available at:
https://github.com/hoangthangta/BSRBF_KAN."
Enhancing Criminal Case Matching through Diverse Legal Factors,https://arxiv.org/abs/2406.11172,2024-06-17,2024-06-19,0.0,0.0,"Criminal case matching endeavors to determine the relevance between different
criminal cases. Conventional methods predict the relevance solely based on
instance-level semantic features and neglect the diverse legal factors (LFs),
which are associated with diverse court judgments. Consequently,
comprehensively representing a criminal case remains a challenge for these
approaches. Moreover, extracting and utilizing these LFs for criminal case
matching face two challenges: (1) the manual annotations of LFs rely heavily on
specialized legal knowledge; (2) overlaps among LFs may potentially harm the
model's performance. In this paper, we propose a two-stage framework named
Diverse Legal Factor-enhanced Criminal Case Matching (DLF-CCM). Firstly,
DLF-CCM employs a multi-task learning framework to pre-train an LF extraction
network on a large-scale legal judgment prediction dataset. In stage two,
DLF-CCM introduces an LF de-redundancy module to learn shared LF and exclusive
LFs. Moreover, an entropy-weighted fusion strategy is introduced to dynamically
fuse the multiple relevance generated by all LFs. Experimental results validate
the effectiveness of DLF-CCM and show its significant improvements over
competitive baselines. Code: https://github.com/jiezhao6/DLF-CCM."
SUGARCREPE++ Dataset - Vision-Language Model Sensitivity to Semantic and Lexical Alterations,https://arxiv.org/abs/2406.11171,2024-06-17,2024-06-19,0.0,0.0,"Despite their remarkable successes, state-of-the-art large language models
(LLMs), including vision-and-language models (VLMs) and unimodal language
models (ULMs), fail to understand precise semantics. For example, semantically
equivalent sentences expressed using different lexical compositions elicit
diverging representations. The degree of this divergence and its impact on
encoded semantics is not very well understood. In this paper, we introduce the
SUGARCREPE++ dataset to analyze the sensitivity of VLMs and ULMs to lexical and
semantic alterations. Each sample in SUGARCREPE++ dataset consists of an image
and a corresponding triplet of captions: a pair of semantically equivalent but
lexically different positive captions and one hard negative caption. This poses
a 3-way semantic (in)equivalence problem to the language models. We
comprehensively evaluate VLMs and ULMs that differ in architecture,
pre-training objectives and datasets to benchmark the performance of
SUGARCREPE++ dataset. Experimental results highlight the difficulties of VLMs
in distinguishing between lexical and semantic variations, particularly in
object attributes and spatial relations. Although VLMs with larger pre-training
datasets, model sizes, and multiple pre-training objectives achieve better
performance on SUGARCREPE++, there is a significant opportunity for
improvement. We show that all the models which achieve better performance on
compositionality datasets need not perform equally well on SUGARCREPE++,
signifying that compositionality alone may not be sufficient for understanding
semantic and lexical alterations. Given the importance of the property that the
SUGARCREPE++ dataset targets, it serves as a new challenge to the
vision-and-language community."
Two-Timescale Optimization Framework for Decentralized Linear-Quadratic Optimal Control,https://arxiv.org/abs/2406.11168,2024-06-17,2024-06-19,0.0,0.0,"A $\mathcal{H}_2$-guaranteed decentralized linear-quadratic optimal control
with convex parameterization and convex-bounded uncertainty is studied in this
paper, where several sparsity promoting functions are added, respectively, into
the $\mathcal{H}_2$ cost to penalize the number of communication links among
decentralized controllers. Then, the sparse feedback gain is investigated to
minimize the modified $\mathcal{H}_2$ cost together with the stability
guarantee, and the corresponding main results are of three parts. First, the
weighted-$\ell_1$ sparsity promoting function is of concern, and a
two-timescale algorithm is developed based on the BSUM (Block Successive
Upper-bound Minimization) framework and a primal-dual splitting approach.
Second, the optimization problem induced by piecewise quadratic sparsity
penalty is investigated, which exhibits an accelerated convergence rate. Third,
the nonconvex sparse optimization problem with $\ell_0$-penalty is studied,
which can be approximated by successive coordinatewise convex optimization
problems."
How Good are LLMs at Relation Extraction under Low-Resource Scenario? Comprehensive Evaluation,https://arxiv.org/abs/2406.11162,2024-06-17,2024-06-19,0.0,0.0,"Relation Extraction (RE) serves as a crucial technology for transforming
unstructured text into structured information, especially within the framework
of Knowledge Graph development. Its importance is emphasized by its essential
role in various downstream tasks. Besides the conventional RE methods which are
based on neural networks and pre-trained language models, large language models
(LLMs) are also utilized in the research field of RE. However, on low-resource
languages (LRLs), both conventional RE methods and LLM-based methods perform
poorly on RE due to the data scarcity issues. To this end, this paper
constructs low-resource relation extraction datasets in 10 LRLs in three
regions (Central Asia, Southeast Asia and Middle East). The corpora are
constructed by translating the original publicly available English RE datasets
(NYT10, FewRel and CrossRE) using an effective multilingual machine
translation. Then, we use the language perplexity (PPL) to filter out the
low-quality data from the translated datasets. Finally, we conduct an empirical
study and validate the performance of several open-source LLMs on these
generated LRL RE datasets."
Emotion-LLaMA - Multimodal Emotion Recognition and Reasoning with Instruction Tuning,https://arxiv.org/abs/2406.11161,2024-06-17,2024-06-19,0.0,0.0,"Accurate emotion perception is crucial for various applications, including
human-computer interaction, education, and counseling. However, traditional
single-modality approaches often fail to capture the complexity of real-world
emotional expressions, which are inherently multimodal. Moreover, existing
Multimodal Large Language Models (MLLMs) face challenges in integrating audio
and recognizing subtle facial micro-expressions. To address this, we introduce
the MERR dataset, containing 28,618 coarse-grained and 4,487 fine-grained
annotated samples across diverse emotional categories. This dataset enables
models to learn from varied scenarios and generalize to real-world
applications. Furthermore, we propose Emotion-LLaMA, a model that seamlessly
integrates audio, visual, and textual inputs through emotion-specific encoders.
By aligning features into a shared space and employing a modified LLaMA model
with instruction tuning, Emotion-LLaMA significantly enhances both emotional
recognition and reasoning capabilities. Extensive evaluations show
Emotion-LLaMA outperforms other MLLMs, achieving top scores in Clue Overlap
(7.83) and Label Overlap (6.25) on EMER, an F1 score of 0.9036 on MER2023
challenge, and the highest UAR (45.59) and WAR (59.37) in zero-shot evaluations
on DFEW dataset."
Move Beyond Triples - Contextual Knowledge Graph Representation and Reasoning,https://arxiv.org/abs/2406.11160,2024-06-17,2024-06-19,0.0,0.0,"Knowledge Graphs (KGs) are foundational structures in many AI applications,
representing entities and their interrelations through triples. However,
triple-based KGs lack the contextual information of relational knowledge, like
temporal dynamics and provenance details, which are crucial for comprehensive
knowledge representation and effective reasoning. Instead, \textbf{Context
Graphs} (CGs) expand upon the conventional structure by incorporating
additional information such as time validity, geographic location, and source
provenance. This integration provides a more nuanced and accurate understanding
of knowledge, enabling KGs to offer richer insights and support more
sophisticated reasoning processes. In this work, we first discuss the inherent
limitations of triple-based KGs and introduce the concept of CGs, highlighting
their advantages in knowledge representation and reasoning. We then present a
context graph reasoning \textbf{CGR$^3$} paradigm that leverages large language
models (LLMs) to retrieve candidate entities and related contexts, rank them
based on the retrieved information, and reason whether sufficient information
has been obtained to answer a query. Our experimental results demonstrate that
CGR$^3$ significantly improves performance on KG completion (KGC) and KG
question answering (KGQA) tasks, validating the effectiveness of incorporating
contextual information on KG representation and reasoning."
Distributed Stochastic Gradient Descent with Staleness - A Stochastic Delay Differential Equation Based Framework,https://arxiv.org/abs/2406.11159,2024-06-17,2024-06-19,0.0,0.0,"Distributed stochastic gradient descent (SGD) has attracted considerable
recent attention due to its potential for scaling computational resources,
reducing training time, and helping protect user privacy in machine learning.
However, the staggers and limited bandwidth may induce random
computational/communication delays, thereby severely hindering the learning
process. Therefore, how to accelerate asynchronous SGD by efficiently
scheduling multiple workers is an important issue. In this paper, a unified
framework is presented to analyze and optimize the convergence of asynchronous
SGD based on stochastic delay differential equations (SDDEs) and the Poisson
approximation of aggregated gradient arrivals. In particular, we present the
run time and staleness of distributed SGD without a memorylessness assumption
on the computation times. Given the learning rate, we reveal the relevant
SDDE's damping coefficient and its delay statistics, as functions of the number
of activated clients, staleness threshold, the eigenvalues of the Hessian
matrix of the objective function, and the overall computational/communication
delay. The formulated SDDE allows us to present both the distributed SGD's
convergence condition and speed by calculating its characteristic roots,
thereby optimizing the scheduling policies for asynchronous/event-triggered
SGD. It is interestingly shown that increasing the number of activated workers
does not necessarily accelerate distributed SGD due to staleness. Moreover, a
small degree of staleness does not necessarily slow down the convergence, while
a large degree of staleness will result in the divergence of distributed SGD.
Numerical results demonstrate the potential of our SDDE framework, even in
complex learning tasks with non-convex objective functions."
DELRec - Distilling Sequential Pattern to Enhance LLM-based Recommendation,https://arxiv.org/abs/2406.11156,2024-06-17,2024-06-19,0.0,0.0,"Sequential recommendation (SR) tasks enhance recommendation accuracy by
capturing the connection between users' past interactions and their changing
preferences. Conventional models often focus solely on capturing sequential
patterns within the training data, neglecting the broader context and semantic
information embedded in item titles from external sources. This limits their
predictive power and adaptability. Recently, large language models (LLMs) have
shown promise in SR tasks due to their advanced understanding capabilities and
strong generalization abilities. Researchers have attempted to enhance LLMs'
recommendation performance by incorporating information from SR models.
However, previous approaches have encountered problems such as 1) only
influencing LLMs at the result level; 2) increased complexity of LLMs
recommendation methods leading to reduced interpretability; 3) incomplete
understanding and utilization of SR models information by LLMs.
  To address these problems, we proposes a novel framework, DELRec, which aims
to extract knowledge from SR models and enable LLMs to easily comprehend and
utilize this supplementary information for more effective sequential
recommendations. DELRec consists of two main stages: 1) SR Models Pattern
Distilling, focusing on extracting behavioral patterns exhibited by SR models
using soft prompts through two well-designed strategies; 2) LLMs-based
Sequential Recommendation, aiming to fine-tune LLMs to effectively use the
distilled auxiliary information to perform SR tasks. Extensive experimental
results conducted on three real datasets validate the effectiveness of the
DELRec framework."
Interpretable modulated differentiable STFT and physics-informed balanced spectrum metric for freight train wheelset bearing cross-machine transfer fault diagnosis under speed fluctuations,https://arxiv.org/abs/2406.11917,2024-06-17,2024-06-19,0.0,0.0,"The service conditions of wheelset bearings has a direct impact on the safe
operation of railway heavy haul freight trains as the key components. However,
speed fluctuation of the trains and few fault samples are the two main problems
that restrict the accuracy of bearing fault diagnosis. Therefore, a
cross-machine transfer diagnosis (pyDSN) network coupled with interpretable
modulated differentiable short-time Fourier transform (STFT) and
physics-informed balanced spectrum quality metric is proposed to learn
domain-invariant and discriminative features under time-varying speeds.
Firstly, due to insufficiency in extracting extract frequency components of
time-varying speed signals using fixed windows, a modulated differentiable STFT
(MDSTFT) that is interpretable with STFT-informed theoretical support, is
proposed to extract the robust time-frequency spectrum (TFS). During training
process, multiple windows with different lengths dynamically change. Also, in
addition to the classification metric and domain discrepancy metric, we
creatively introduce a third kind of metric, referred to as the
physics-informed metric, to enhance transferable TFS. A physics-informed
balanced spectrum quality (BSQ) regularization loss is devised to guide an
optimization direction for MDSTFT and model. With it, not only can model
acquire high-quality TFS, but also a physics-restricted domain adaptation
network can be also acquired, making it learn real-world physics knowledge,
ultimately diminish the domain discrepancy across different datasets. The
experiment is conducted in the scenario of migrating from the laboratory
datasets to the freight train dataset, indicating that the hybrid-driven pyDSN
outperforms existing methods and has practical value."
Recent and Upcoming Developments in Randomized Numerical Linear Algebra for Machine Learning,https://arxiv.org/abs/2406.11151,2024-06-17,2024-06-19,0.0,0.0,"Large matrices arise in many machine learning and data analysis applications,
including as representations of datasets, graphs, model weights, and first and
second-order derivatives. Randomized Numerical Linear Algebra (RandNLA) is an
area which uses randomness to develop improved algorithms for ubiquitous matrix
problems. The area has reached a certain level of maturity; but recent hardware
trends, efforts to incorporate RandNLA algorithms into core numerical
libraries, and advances in machine learning, statistics, and random matrix
theory, have lead to new theoretical and practical challenges. This article
provides a self-contained overview of RandNLA, in light of these developments."
GoldCoin - Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory,https://arxiv.org/abs/2406.11149,2024-06-17,2024-06-19,0.0,0.0,"Privacy issues arise prominently during the inappropriate transmission of
information between entities. Existing research primarily studies privacy by
exploring various privacy attacks, defenses, and evaluations within narrowly
predefined patterns, while neglecting that privacy is not an isolated,
context-free concept limited to traditionally sensitive data (e.g., social
security numbers), but intertwined with intricate social contexts that
complicate the identification and analysis of potential privacy violations. The
advent of Large Language Models (LLMs) offers unprecedented opportunities for
incorporating the nuanced scenarios outlined in privacy laws to tackle these
complex privacy issues. However, the scarcity of open-source relevant case
studies restricts the efficiency of LLMs in aligning with specific legal
statutes. To address this challenge, we introduce a novel framework, GoldCoin,
designed to efficiently ground LLMs in privacy laws for judicial assessing
privacy violations. Our framework leverages the theory of contextual integrity
as a bridge, creating numerous synthetic scenarios grounded in relevant privacy
statutes (e.g., HIPAA), to assist LLMs in comprehending the complex contexts
for identifying privacy risks in the real world. Extensive experimental results
demonstrate that GoldCoin markedly enhances LLMs' capabilities in recognizing
privacy risks across real court cases, surpassing the baselines on different
judicial tasks."
Few-Shot Recognition via Stage-Wise Augmented Finetuning,https://arxiv.org/abs/2406.11148,2024-06-17,2024-06-19,0.0,0.0,"Few-shot recognition aims to train a classification model with only a few
labeled examples of pre-defined concepts, where annotation can be costly in a
downstream task. In another related research area, zero-shot recognition, which
assumes no access to any downstream-task data, has been greatly advanced by
using pretrained Vision-Language Models (VLMs). In this area,
retrieval-augmented learning (RAL) effectively boosts zero-shot accuracy by
retrieving and learning from external data relevant to downstream concepts.
Motivated by these advancements, our work explores RAL for few-shot
recognition. While seemingly straightforward despite being under-explored in
the literature (till now!), we present novel challenges and opportunities for
applying RAL for few-shot recognition. First, perhaps surprisingly, simply
finetuning the VLM on a large amount of retrieved data barely surpasses
state-of-the-art zero-shot methods due to the imbalanced distribution of
retrieved data and its domain gaps compared to few-shot annotated data. Second,
finetuning a VLM on few-shot examples alone significantly outperforms prior
methods, and finetuning on the mix of retrieved and few-shot data yields even
better results. Third, to mitigate the imbalanced distribution and domain gap
issue, we propose Stage-Wise Augmented fineTuning (SWAT) method, which involves
end-to-end finetuning on mixed data for the first stage and retraining the
classifier solely on the few-shot data in the second stage. Extensive
experiments show that SWAT achieves the best performance on standard benchmark
datasets, resoundingly outperforming prior works by ~10% in accuracy. Code is
available at https://github.com/tian1327/SWAT."
Vul-RAG - Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG,https://arxiv.org/abs/2406.11147,2024-06-17,2024-06-19,0.0,0.0,"Vulnerability detection is essential for software quality assurance. In
recent years, deep learning models (especially large language models) have
shown promise in vulnerability detection. In this work, we propose a novel
LLM-based vulnerability detection technique Vul-RAG, which leverages
knowledge-level retrieval-augmented generation (RAG) framework to detect
vulnerability for the given code in three phases. First, Vul-RAG constructs a
vulnerability knowledge base by extracting multi-dimension knowledge via LLMs
from existing CVE instances; second, for a given code snippet, Vul-RAG}
retrieves the relevant vulnerability knowledge from the constructed knowledge
base based on functional semantics; third, Vul-RAG leverages LLMs to check the
vulnerability of the given code snippet by reasoning the presence of
vulnerability causes and fixing solutions of the retrieved vulnerability
knowledge. Our evaluation of Vul-RAG on our constructed benchmark PairVul shows
that Vul-RAG substantially outperforms all baselines by 12.96\%/110\% relative
improvement in accuracy/pairwise-accuracy. In addition, our user study shows
that the vulnerability knowledge generated by Vul-RAG can serve as high-quality
explanations which can improve the manual detection accuracy from 0.60 to 0.77."
Scorecards for Synthetic Medical Data Evaluation and Reporting,https://arxiv.org/abs/2406.11143,2024-06-17,2024-06-19,0.0,0.0,"The growing utilization of synthetic medical data (SMD) in training and
testing AI-driven tools in healthcare necessitates a systematic framework for
assessing SMD quality. The current lack of a standardized methodology to
evaluate SMD, particularly in terms of its applicability in various medical
scenarios, is a significant hindrance to its broader acceptance and utilization
in healthcare applications. Here, we outline an evaluation framework designed
to meet the unique requirements of medical applications, and introduce the
concept of SMD scorecards, which can serve as comprehensive reports that
accompany artificially generated datasets. This can help standardize evaluation
and enable SMD developers to assess and further enhance the quality of SMDs by
identifying areas in need of attention and ensuring that the synthetic data
more accurately approximate patient data."
Breaking Boundaries - Investigating the Effects of Model Editing on Cross-linguistic Performance,https://arxiv.org/abs/2406.11139,2024-06-17,2024-06-19,0.0,0.0,"The integration of pretrained language models (PLMs) like BERT and GPT has
revolutionized NLP, particularly for English, but it has also created
linguistic imbalances. This paper strategically identifies the need for
linguistic equity by examining several knowledge editing techniques in
multilingual contexts. We evaluate the performance of models such as Mistral,
TowerInstruct, OpenHathi, Tamil-Llama, and Kan-Llama across languages including
English, German, French, Italian, Spanish, Hindi, Tamil, and Kannada. Our
research identifies significant discrepancies in normal and merged models
concerning cross-lingual consistency. We employ strategies like 'each language
for itself' (ELFI) and 'each language for others' (ELFO) to stress-test these
models. Our findings demonstrate the potential for LLMs to overcome linguistic
barriers, laying the groundwork for future research in achieving linguistic
inclusivity in AI technologies."
Diffusion Models in Low-Level Vision - A Survey,https://arxiv.org/abs/2406.11138,2024-06-17,2024-06-19,0.0,0.0,"Deep generative models have garnered significant attention in low-level
vision tasks due to their generative capabilities. Among them, diffusion
model-based solutions, characterized by a forward diffusion process and a
reverse denoising process, have emerged as widely acclaimed for their ability
to produce samples of superior quality and diversity. This ensures the
generation of visually compelling results with intricate texture information.
Despite their remarkable success, a noticeable gap exists in a comprehensive
survey that amalgamates these pioneering diffusion model-based works and
organizes the corresponding threads. This paper proposes the comprehensive
review of diffusion model-based techniques. We present three generic diffusion
modeling frameworks and explore their correlations with other deep generative
models, establishing the theoretical foundation. Following this, we introduce a
multi-perspective categorization of diffusion models, considering both the
underlying framework and the target task. Additionally, we summarize extended
diffusion models applied in other tasks, including medical, remote sensing, and
video scenarios. Moreover, we provide an overview of commonly used benchmarks
and evaluation metrics. We conduct a thorough evaluation, encompassing both
performance and efficiency, of diffusion model-based techniques in three
prominent tasks. Finally, we elucidate the limitations of current diffusion
models and propose seven intriguing directions for future research. This
comprehensive examination aims to facilitate a profound understanding of the
landscape surrounding denoising diffusion models in the context of low-level
vision tasks. A curated list of diffusion model-based techniques in over 20
low-level vision tasks can be found at
https://github.com/ChunmingHe/awesome-diffusion-models-in-low-level-vision."
Towards Understanding Emotions for Engaged Mental Health Conversations,https://arxiv.org/abs/2406.11135,2024-06-17,2024-06-19,0.0,0.0,"Providing timely support and intervention is crucial in mental health
settings. As the need to engage youth comfortable with texting increases,
mental health providers are exploring and adopting text-based media such as
chatbots, community-based forums, online therapies with licensed professionals,
and helplines operated by trained responders. To support these text-based media
for mental health--particularly for crisis care--we are developing a system to
perform passive emotion-sensing using a combination of keystroke dynamics and
sentiment analysis. Our early studies of this system posit that the analysis of
short text messages and keyboard typing patterns can provide emotion
information that may be used to support both clients and responders. We use our
preliminary findings to discuss the way forward for applying AI to support
mental health providers in providing better care."
RePrompt - Planning by Automatic Prompt Engineering for Large Language Models Agents,https://arxiv.org/abs/2406.11132,2024-06-17,2024-06-19,0.0,0.0,"In this past year, large language models (LLMs) have had remarkable success
in domains outside the traditional natural language processing, and people are
starting to explore the usage of LLMs in more general and close to application
domains like code generation, travel planning, and robot controls. Connecting
these LLMs with great capacity and external tools, people are building the
so-called LLM agents, which are supposed to help people do all kinds of work in
everyday life. In all these domains, the prompt to the LLMs has been shown to
make a big difference in what the LLM would generate and thus affect the
performance of the LLM agents. Therefore, automatic prompt engineering has
become an important question for many researchers and users of LLMs. In this
paper, we propose a novel method, \textsc{RePrompt}, which does ""gradient
descent"" to optimize the step-by-step instructions in the prompt of the LLM
agents based on the chat history obtained from interactions with LLM agents. By
optimizing the prompt, the LLM will learn how to plan in specific domains. We
have used experiments in PDDL generation and travel planning to show that our
method could generally improve the performance for different reasoning tasks
when using the updated prompt as the initial prompt."
Are Large Language Models a Good Replacement of Taxonomies?,https://arxiv.org/abs/2406.11131,2024-06-17,2024-06-19,0.0,0.0,"Large language models (LLMs) demonstrate an impressive ability to internalize
knowledge and answer natural language questions. Although previous studies
validate that LLMs perform well on general knowledge while presenting poor
performance on long-tail nuanced knowledge, the community is still doubtful
about whether the traditional knowledge graphs should be replaced by LLMs. In
this paper, we ask if the schema of knowledge graph (i.e., taxonomy) is made
obsolete by LLMs. Intuitively, LLMs should perform well on common taxonomies
and at taxonomy levels that are common to people. Unfortunately, there lacks a
comprehensive benchmark that evaluates the LLMs over a wide range of taxonomies
from common to specialized domains and at levels from root to leaf so that we
can draw a confident conclusion. To narrow the research gap, we constructed a
novel taxonomy hierarchical structure discovery benchmark named TaxoGlimpse to
evaluate the performance of LLMs over taxonomies. TaxoGlimpse covers ten
representative taxonomies from common to specialized domains with in-depth
experiments of different levels of entities in this taxonomy from root to leaf.
Our comprehensive experiments of eighteen state-of-the-art LLMs under three
prompting settings validate that LLMs can still not well capture the knowledge
of specialized taxonomies and leaf-level entities."
Dynamic Order Template Prediction for Generative Aspect-Based Sentiment Analysis,https://arxiv.org/abs/2406.11130,2024-06-17,2024-06-19,0.0,0.0,"Aspect-based sentiment analysis (ABSA) assesses sentiments towards specific
aspects within texts, resulting in detailed sentiment tuples. Previous ABSA
models often use static templates to predict all of the elements in the tuples,
and these models often fail to accurately capture dependencies between
elements. Multi-view prompting method improves the performance of ABSA by
predicting tuples with various templates and then ensembling the results.
However, this method suffers from inefficiencies and out-of-distribution
errors. In this paper, we propose a Dynamic Order Template (DOT) method for
ABSA, which dynamically generates necessary views for each instance based on
instance-level entropy. Ensuring the diverse and relevant view generation, our
proposed method improves F1-scores on ASQP and ACOS datasets while
significantly reducing inference time."
Model Adaptation for Time Constrained Embodied Control,https://arxiv.org/abs/2406.11128,2024-06-17,2024-06-19,0.0,0.0,"When adopting a deep learning model for embodied agents, it is required that
the model structure be optimized for specific tasks and operational conditions.
Such optimization can be static such as model compression or dynamic such as
adaptive inference. Yet, these techniques have not been fully investigated for
embodied control systems subject to time constraints, which necessitate
sequential decision-making for multiple tasks, each with distinct inference
latency limitations. In this paper, we present MoDeC, a time constraint-aware
embodied control framework using the modular model adaptation. We formulate
model adaptation to varying operational conditions on resource and time
restrictions as dynamic routing on a modular network, incorporating these
conditions as part of multi-task objectives. Our evaluation across several
vision-based embodied environments demonstrates the robustness of MoDeC,
showing that it outperforms other model adaptation methods in both performance
and adherence to time constraints in robotic manipulation and autonomous
driving applications"
Incentivizing Quality Text Generation via Statistical Contracts,https://arxiv.org/abs/2406.11118,2024-06-17,2024-06-19,0.0,0.0,"While the success of large language models (LLMs) increases demand for
machine-generated text, current pay-per-token pricing schemes create a
misalignment of incentives known in economics as moral hazard: Text-generating
agents have strong incentive to cut costs by preferring a cheaper model over
the cutting-edge one, and this can be done ""behind the scenes"" since the agent
performs inference internally. In this work, we approach this issue from an
economic perspective, by proposing a pay-for-performance, contract-based
framework for incentivizing quality. We study a principal-agent game where the
agent generates text using costly inference, and the contract determines the
principal's payment for the text according to an automated quality evaluation.
Since standard contract theory is inapplicable when internal inference costs
are unknown, we introduce cost-robust contracts. As our main theoretical
contribution, we characterize optimal cost-robust contracts through a direct
correspondence to optimal composite hypothesis tests from statistics,
generalizing a result of Saig et al. (NeurIPS'23). We evaluate our framework
empirically by deriving contracts for a range of objectives and LLM evaluation
benchmarks, and find that cost-robust contracts sacrifice only a marginal
increase in objective value compared to their cost-aware counterparts."
Grammaticality Representation in ChatGPT as Compared to Linguists and Laypeople,https://arxiv.org/abs/2406.11116,2024-06-17,2024-06-19,0.0,0.0,"Large language models (LLMs) have demonstrated exceptional performance across
various linguistic tasks. However, it remains uncertain whether LLMs have
developed human-like fine-grained grammatical intuition. This preregistered
study (https://osf.io/t5nes) presents the first large-scale investigation of
ChatGPT's grammatical intuition, building upon a previous study that collected
laypeople's grammatical judgments on 148 linguistic phenomena that linguists
judged to be grammatical, ungrammatical, or marginally grammatical (Sprouse,
Schutze, & Almeida, 2013). Our primary focus was to compare ChatGPT with both
laypeople and linguists in the judgement of these linguistic constructions. In
Experiment 1, ChatGPT assigned ratings to sentences based on a given reference
sentence. Experiment 2 involved rating sentences on a 7-point scale, and
Experiment 3 asked ChatGPT to choose the more grammatical sentence from a pair.
Overall, our findings demonstrate convergence rates ranging from 73% to 95%
between ChatGPT and linguists, with an overall point-estimate of 89%.
Significant correlations were also found between ChatGPT and laypeople across
all tasks, though the correlation strength varied by task. We attribute these
results to the psychometric nature of the judgment tasks and the differences in
language processing styles between humans and LLMs."
Text Grafting - Near-Distribution Weak Supervision for Minority Classes in Text Classification,https://arxiv.org/abs/2406.11115,2024-06-17,2024-06-19,0.0,0.0,"For extremely weak-supervised text classification, pioneer research generates
pseudo labels by mining texts similar to the class names from the raw corpus,
which may end up with very limited or even no samples for the minority classes.
Recent works have started to generate the relevant texts by prompting LLMs
using the class names or definitions; however, there is a high risk that LLMs
cannot generate in-distribution (i.e., similar to the corpus where the text
classifier will be applied) data, leading to ungeneralizable classifiers. In
this paper, we combine the advantages of these two approaches and propose to
bridge the gap via a novel framework, \emph{text grafting}, which aims to
obtain clean and near-distribution weak supervision for minority classes.
Specifically, we first use LLM-based logits to mine masked templates from the
raw corpus, which have a high potential for data synthesis into the target
minority class. Then, the templates are filled by state-of-the-art LLMs to
synthesize near-distribution texts falling into minority classes. Text grafting
shows significant improvement over direct mining or synthesis on minority
classes. We also use analysis and case studies to comprehend the property of
text grafting."
How Neural Networks Learn the Support is an Implicit Regularization Effect of SGD,https://arxiv.org/abs/2406.11110,2024-06-17,2024-06-19,0.0,0.0,"We investigate the ability of deep neural networks to identify the support of
the target function. Our findings reveal that mini-batch SGD effectively learns
the support in the first layer of the network by shrinking to zero the weights
associated with irrelevant components of input. In contrast, we demonstrate
that while vanilla GD also approximates the target function, it requires an
explicit regularization term to learn the support in the first layer. We prove
that this property of mini-batch SGD is due to a second-order implicit
regularization effect which is proportional to $\eta / b$ (step size / batch
size). Our results are not only another proof that implicit regularization has
a significant impact on training optimization dynamics but they also shed light
on the structure of the features that are learned by the network. Additionally,
they suggest that smaller batches enhance feature interpretability and reduce
dependency on initialization."
Exploring Safety-Utility Trade-Offs in Personalized Language Models,https://arxiv.org/abs/2406.11107,2024-06-17,2024-06-19,0.0,0.0,"As large language models (LLMs) become increasingly integrated into daily
applications, it is essential to ensure they operate fairly across diverse user
demographics. In this work, we show that LLMs suffer from personalization bias,
where their performance is impacted when they are personalized to a user's
identity. We quantify personalization bias by evaluating the performance of
LLMs along two axes - safety and utility. We measure safety by examining how
benign LLM responses are to unsafe prompts with and without personalization. We
measure utility by evaluating the LLM's performance on various tasks, including
general knowledge, mathematical abilities, programming, and reasoning skills.
We find that various LLMs, ranging from open-source models like Llama (Touvron
et al., 2023) and Mistral (Jiang et al., 2023) to API-based ones like GPT-3.5
and GPT-4o (Ouyang et al., 2022), exhibit significant variance in performance
in terms of safety-utility trade-offs depending on the user's identity.
Finally, we discuss several strategies to mitigate personalization bias using
preference tuning and prompt-based defenses."
From Intentions to Techniques - A Comprehensive Taxonomy and Challenges in Text Watermarking for Large Language Models,https://arxiv.org/abs/2406.11106,2024-06-17,2024-06-19,0.0,0.0,"With the rapid growth of Large Language Models (LLMs), safeguarding textual
content against unauthorized use is crucial. Text watermarking offers a vital
solution, protecting both - LLM-generated and plain text sources. This paper
presents a unified overview of different perspectives behind designing
watermarking techniques, through a comprehensive survey of the research
literature. Our work has two key advantages, (1) we analyze research based on
the specific intentions behind different watermarking techniques, evaluation
datasets used, watermarking addition, and removal methods to construct a
cohesive taxonomy. (2) We highlight the gaps and open challenges in text
watermarking to promote research in protecting text authorship. This extensive
coverage and detailed analysis sets our work apart, offering valuable insights
into the evolving landscape of text watermarking in language models."
Exploiting Diffusion Prior for Out-of-Distribution Detection,https://arxiv.org/abs/2406.11105,2024-06-16,2024-06-19,0.0,0.0,"Out-of-distribution (OOD) detection is crucial for deploying robust machine
learning models, especially in areas where security is critical. However,
traditional OOD detection methods often fail to capture complex data
distributions from large scale date. In this paper, we present a novel approach
for OOD detection that leverages the generative ability of diffusion models and
the powerful feature extraction capabilities of CLIP. By using these features
as conditional inputs to a diffusion model, we can reconstruct the images after
encoding them with CLIP. The difference between the original and reconstructed
images is used as a signal for OOD identification. The practicality and
scalability of our method is increased by the fact that it does not require
class-specific labeled ID data, as is the case with many other methods.
Extensive experiments on several benchmark datasets demonstrates the robustness
and effectiveness of our method, which have significantly improved the
detection accuracy."
Grading Massive Open Online Courses Using Large Language Models,https://arxiv.org/abs/2406.11102,2024-06-16,2024-06-19,0.0,0.0,"Massive open online courses (MOOCs) offer free education globally to anyone
with a computer and internet access. Despite this democratization of learning,
the massive enrollment in these courses makes it impractical for one instructor
to assess every student's writing assignment. As a result, peer grading, often
guided by a straightforward rubric, is the method of choice. While convenient,
peer grading often falls short in terms of reliability and validity. In this
study, we explore the feasibility of using large language models (LLMs) to
replace peer grading in MOOCs. Specifically, we use two LLMs, GPT-4 and
GPT-3.5, across three MOOCs: Introductory Astronomy, Astrobiology, and the
History and Philosophy of Astronomy. To instruct LLMs, we use three different
prompts based on the zero-shot chain-of-thought (ZCoT) prompting technique: (1)
ZCoT with instructor-provided correct answers, (2) ZCoT with both
instructor-provided correct answers and rubrics, and (3) ZCoT with
instructor-provided correct answers and LLM-generated rubrics. Tested on 18
settings, our results show that ZCoT, when augmented with instructor-provided
correct answers and rubrics, produces grades that are more aligned with those
assigned by instructors compared to peer grading. Finally, our findings
indicate a promising potential for automated grading systems in MOOCs,
especially in subjects with well-defined rubrics, to improve the learning
experience for millions of online learners worldwide."
InstructCMP - Length Control in Sentence Compression through Instruction-based Large Language Models,https://arxiv.org/abs/2406.11097,2024-06-16,2024-06-19,0.0,0.0,"Extractive summarization can produce faithful summaries but often requires
additional constraints such as a desired summary length. Traditional sentence
compression models do not typically consider the constraints because of their
restricted model abilities, which require model modifications for coping with
them. To bridge this gap, we propose Instruction-based Compression
(InstructCMP), an approach to the sentence compression task that can consider
the length constraint through instructions by leveraging the zero-shot
task-solving abilities of Large Language Models (LLMs). For this purpose, we
created new evaluation datasets by transforming traditional sentence
compression datasets into an instruction format. By using the datasets, we
first reveal that the current LLMs still face challenges in accurately
controlling the length for a compressed text. To address this issue, we propose
an approach named ""length priming,"" that incorporates additional length
information into the instructions without external resources. While the length
priming effectively works in a zero-shot setting, a training dataset with the
instructions would further improve the ability of length control. Thus, we
additionally created a training dataset in an instruction format to fine-tune
the model on it. Experimental results and analysis show that applying the
length priming significantly improves performances of InstructCMP in both
zero-shot and fine-tuning settings without the need of any model modifications."
"The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models",https://arxiv.org/abs/2406.11096,2024-06-16,2024-06-19,0.0,0.0,"Recent advances in Large Language Models (LLMs) have sparked wide interest in
validating and comprehending the human-like cognitive-behavioral traits LLMs
may have. These cognitive-behavioral traits include typically Attitudes,
Opinions, Values (AOV). However, measuring AOV embedded within LLMs remains
opaque, and different evaluation methods may yield different results. This has
led to a lack of clarity on how different studies are related to each other and
how they can be interpreted. This paper aims to bridge this gap by providing an
overview of recent works on the evaluation of AOV in LLMs. Moreover, we survey
related approaches in different stages of the evaluation pipeline in these
works. By doing so, we address the potential and challenges with respect to
understanding the model, human-AI alignment, and downstream application in
social sciences. Finally, we provide practical insights into evaluation
methods, model enhancement, and interdisciplinary collaboration, thereby
contributing to the evolving landscape of evaluating AOV in LLMs."
RAEmoLLM - Retrieval Augmented LLMs for Cross-Domain Misinformation Detection Using In-Context Learning based on Emotional Information,https://arxiv.org/abs/2406.11093,2024-06-16,2024-06-19,0.0,0.0,"Misinformation is prevalent in various fields such as education, politics,
health, etc., causing significant harm to society. However, current methods for
cross-domain misinformation detection rely on time and resources consuming
fine-tuning and complex model structures. With the outstanding performance of
LLMs, many studies have employed them for misinformation detection.
Unfortunately, they focus on in-domain tasks and do not incorporate significant
sentiment and emotion features (which we jointly call affect). In this paper,
we propose RAEmoLLM, the first retrieval augmented (RAG) LLMs framework to
address cross-domain misinformation detection using in-context learning based
on affective information. It accomplishes this by applying an emotion-aware LLM
to construct a retrieval database of affective embeddings. This database is
used by our retrieval module to obtain source-domain samples, which are
subsequently used for the inference module's in-context few-shot learning to
detect target domain misinformation. We evaluate our framework on three
misinformation benchmarks. Results show that RAEmoLLM achieves significant
improvements compared to the zero-shot method on three datasets, with the
highest increases of 20.69%, 23.94%, and 39.11% respectively. This work will be
released on https://github.com/lzw108/RAEmoLLM."
Guaranteed Sampling Flexibility for Low-tubal-rank Tensor Completion,https://arxiv.org/abs/2406.11092,2024-06-16,2024-06-19,0.0,0.0,"While Bernoulli sampling is extensively studied in tensor completion, t-CUR
sampling approximates low-tubal-rank tensors via lateral and horizontal
subtensors. However, both methods lack sufficient flexibility for diverse
practical applications. To address this, we introduce Tensor Cross-Concentrated
Sampling (t-CCS), a novel and straightforward sampling model that advances the
matrix cross-concentrated sampling concept within a tensor framework. t-CCS
effectively bridges the gap between Bernoulli and t-CUR sampling, offering
additional flexibility that can lead to computational savings in various
contexts. A key aspect of our work is the comprehensive theoretical analysis
provided. We establish a sufficient condition for the successful recovery of a
low-rank tensor from its t-CCS samples. In support of this, we also develop a
theoretical framework validating the feasibility of t-CUR via uniform random
sampling and conduct a detailed theoretical sampling complexity analysis for
tensor completion problems utilizing the general Bernoulli sampling model.
Moreover, we introduce an efficient non-convex algorithm, the Iterative t-CUR
Tensor Completion (ITCURTC) algorithm, specifically designed to tackle the
t-CCS-based tensor completion. We have intensively tested and validated the
effectiveness of the t-CCS model and the ITCURTC algorithm across both
synthetic and real-world datasets."
MemDPT - Differential Privacy for Memory Efficient Language Models,https://arxiv.org/abs/2406.11087,2024-06-16,2024-06-19,0.0,0.0,"Large language models have repeatedly shown outstanding performance across
diverse applications. However, deploying these models can inadvertently risk
user privacy. The significant memory demands during training pose a major
challenge in terms of resource consumption. This substantial size places a
heavy load on memory resources, raising considerable practical concerns. In
this paper, we introduce DP-MemArc, a novel training framework aimed at
reducing the memory costs of large language models while emphasizing the
protection of user data privacy. DP-MemArc incorporates side network or
reversible network designs to support a variety of differential privacy
memory-efficient fine-tuning schemes. Our approach not only achieves in memory
optimization but also ensures robust privacy protection, keeping user data
secure and confidential. Extensive experiments have demonstrated that DP-MemArc
effectively provides differential privacy-efficient fine-tuning across
different task scenarios."
Multiple Sources are Better Than One - Incorporating External Knowledge in Low-Resource Glossing,https://arxiv.org/abs/2406.11085,2024-06-16,2024-06-19,0.0,0.0,"In this paper, we address the data scarcity problem in automatic data-driven
glossing for low-resource languages by coordinating multiple sources of
linguistic expertise. We supplement models with translations at both the token
and sentence level as well as leverage the extensive linguistic capability of
modern LLMs. Our enhancements lead to an average absolute improvement of
5%-points in word-level accuracy over the previous state of the art on a
typologically diverse dataset spanning six low-resource languages. The
improvements are particularly noticeable for the lowest-resourced language
Gitksan, where we achieve a 10%-point improvement. Furthermore, in a simulated
ultra-low resource setting for the same six languages, training on fewer than
100 glossed sentences, we establish an average 10%-point improvement in
word-level accuracy over the previous state-of-the-art system."
Enhanced Elephant Herding Optimization for Large Scale Information Access on Social Media,https://arxiv.org/abs/2406.11916,2024-06-16,2024-06-19,0.0,0.0,"In this article, we present a novel information access approach inspired by
the information foraging theory (IFT) and elephant herding optimization (EHO).
First, we propose a model for information access on social media based on the
IFT. We then elaborate an adaptation of the original EHO algorithm to apply it
to the information access problem. The combination of the IFT and EHO
constitutes a good opportunity to find relevant information on social media.
However, when dealing with voluminous data, the performance undergoes a sharp
drop. To overcome this issue, we developed an enhanced version of EHO for large
scale information access. We introduce new operators to the algorithm,
including territories delimitation and clan migration using clustering. To
validate our work, we created a dataset of more than 1.4 million tweets, on
which we carried out extensive experiments. The outcomes reveal the ability of
our approach to find relevant information in an effective and efficient way.
They also highlight the advantages of the improved version of EHO over the
original algorithm regarding different aspects. Furthermore, we undertook a
comparative study with two other metaheuristic-based information foraging
approaches, namely ant colony system and particle swarm optimization. Overall,
the results are very promising."
miniCodeProps - a Minimal Benchmark for Proving Code Properties,https://arxiv.org/abs/2406.11915,2024-06-16,2024-06-19,0.0,0.0,"Neural networks have shown initial promise in automating mathematical theorem
proving in proof assistants such as Lean. The same proof assistants can be used
to verify the correctness of code by pairing code with specifications and
proofs that the specifications hold. Automating the writing of code,
specifications, and proofs could lower the cost of verification, or,
ambitiously, enable a machine learning system to output provably correct code.
However, it remains unclear whether current neural theorem provers can
automatically verify even relatively simple programs. We present miniCodeProps,
a benchmark of 177 program specifications in the Lean proof assistant, aimed at
the subproblem of automatically generating a proof for a provided program and
specification. miniCodeProps contains specifications about simple,
self-contained programs (e.g., lists, natural numbers, binary trees) with
varied proof difficulty. Despite its simplicity, miniCodeProps is challenging
for current LLM-based provers, which succeed in proving about 25 percent of the
specifications. We publicly release miniCodeProps as a benchmark for furthering
automated theorem proving in the context of formally verified code."
Exploring the Limitations of Detecting Machine-Generated Text,https://arxiv.org/abs/2406.11073,2024-06-16,2024-06-19,0.0,0.0,"Recent improvements in the quality of the generations by large language
models have spurred research into identifying machine-generated text. Systems
proposed for the task often achieve high performance. However, humans and
machines can produce text in different styles and in different domains, and it
remains unclear whether machine generated-text detection models favour
particular styles or domains. In this paper, we critically examine the
classification performance for detecting machine-generated text by evaluating
on texts with varying writing styles. We find that classifiers are highly
sensitive to stylistic changes and differences in text complexity, and in some
cases degrade entirely to random classifiers. We further find that detection
systems are particularly susceptible to misclassify easy-to-read texts while
they have high performance for complex texts."
Fine-grained Classes and How to Find Them,https://arxiv.org/abs/2406.11070,2024-06-16,2024-06-19,0.0,0.0,"In many practical applications, coarse-grained labels are readily available
compared to fine-grained labels that reflect subtle differences between
classes. However, existing methods cannot leverage coarse labels to infer
fine-grained labels in an unsupervised manner. To bridge this gap, we propose
FALCON, a method that discovers fine-grained classes from coarsely labeled data
without any supervision at the fine-grained level. FALCON simultaneously infers
unknown fine-grained classes and underlying relationships between coarse and
fine-grained classes. Moreover, FALCON is a modular method that can effectively
learn from multiple datasets labeled with different strategies. We evaluate
FALCON on eight image classification tasks and a single-cell classification
task. FALCON outperforms baselines by a large margin, achieving 22% improvement
over the best baseline on the tieredImageNet dataset with over 600 fine-grained
classes."
WildVision - Evaluating Vision-Language Models in the Wild with Human Preferences,https://arxiv.org/abs/2406.11069,2024-06-16,2024-06-19,0.0,0.0,"Recent breakthroughs in vision-language models (VLMs) emphasize the necessity
of benchmarking human preferences in real-world multimodal interactions. To
address this gap, we launched WildVision-Arena (WV-Arena), an online platform
that collects human preferences to evaluate VLMs. We curated WV-Bench by
selecting 500 high-quality samples from 8,000 user submissions in WV-Arena.
WV-Bench uses GPT-4 as the judge to compare each VLM with Claude-3-Sonnet,
achieving a Spearman correlation of 0.94 with the WV-Arena Elo. This
significantly outperforms other benchmarks like MMVet, MMMU, and MMStar.
  Our comprehensive analysis of 20K real-world interactions reveals important
insights into the failure cases of top-performing VLMs. For example, we find
that although GPT-4V surpasses many other models like Reka-Flash, Opus, and
Yi-VL-Plus in simple visual recognition and reasoning tasks, it still faces
challenges with subtle contextual cues, spatial reasoning, visual imagination,
and expert domain knowledge. Additionally, current VLMs exhibit issues with
hallucinations and safety when intentionally provoked. We are releasing our
chat and feedback data to further advance research in the field of VLMs."
A Unified View of Abstract Visual Reasoning Problems,https://arxiv.org/abs/2406.11068,2024-06-16,2024-06-19,0.0,0.0,"The field of Abstract Visual Reasoning (AVR) encompasses a wide range of
problems, many of which are inspired by human IQ tests. The variety of AVR
tasks has resulted in state-of-the-art AVR methods being task-specific
approaches. Furthermore, contemporary methods consider each AVR problem
instance not as a whole, but in the form of a set of individual panels with
particular locations and roles (context vs. answer panels) pre-assigned
according to the task-specific arrangements. While these highly specialized
approaches have recently led to significant progress in solving particular AVR
tasks, considering each task in isolation hinders the development of universal
learning systems in this domain. In this paper, we introduce a unified view of
AVR tasks, where each problem instance is rendered as a single image, with no a
priori assumptions about the number of panels, their location, or role. The
main advantage of the proposed unified view is the ability to develop universal
learning models applicable to various AVR tasks. What is more, the proposed
approach inherently facilitates transfer learning in the AVR domain, as various
types of problems share a common representation. The experiments conducted on
four AVR datasets with Raven's Progressive Matrices and Visual Analogy
Problems, and one real-world visual analogy dataset show that the proposed
unified representation of AVR tasks poses a challenge to state-of-the-art Deep
Learning (DL) AVR models and, more broadly, contemporary DL image recognition
methods. In order to address this challenge, we introduce the Unified Model for
Abstract Visual Reasoning (UMAVR) capable of dealing with various types of AVR
problems in a unified manner. UMAVR outperforms existing AVR methods in
selected single-task learning experiments, and demonstrates effective knowledge
reuse in transfer learning and curriculum learning setups."
Can LLMs Understand the Implication of Emphasized Sentences in Dialogue?,https://arxiv.org/abs/2406.11065,2024-06-16,2024-06-19,0.0,0.0,"Emphasis is a crucial component in human communication, which indicates the
speaker's intention and implication beyond pure text in dialogue. While Large
Language Models (LLMs) have revolutionized natural language processing, their
ability to understand emphasis in dialogue remains unclear. This paper
introduces Emphasized-Talk, a benchmark with emphasis-annotated dialogue
samples capturing the implications of emphasis. We evaluate various LLMs, both
open-source and commercial, to measure their performance in understanding
emphasis. Additionally, we propose an automatic evaluation pipeline using
GPT-4, which achieves a high correlation with human rating. Our findings reveal
that although commercial LLMs generally perform better, there is still
significant room for improvement in comprehending emphasized sentences."
Generalization and Knowledge Transfer in Abstract Visual Reasoning Models,https://arxiv.org/abs/2406.11061,2024-06-16,2024-06-19,0.0,0.0,"We study generalization and knowledge reuse capabilities of deep neural
networks in the domain of abstract visual reasoning (AVR), employing Raven's
Progressive Matrices (RPMs), a recognized benchmark task for assessing AVR
abilities. Two knowledge transfer scenarios referring to the I-RAVEN dataset
are investigated. Firstly, inspired by generalization assessment capabilities
of the PGM dataset and popularity of I-RAVEN, we introduce
Attributeless-I-RAVEN, a benchmark with four generalization regimes that allow
to test generalization of abstract rules applied to held-out attributes.
Secondly, we construct I-RAVEN-Mesh, a dataset that enriches RPMs with a novel
component structure comprising line-based patterns, facilitating assessment of
progressive knowledge acquisition in transfer learning setting. The developed
benchmarks reveal shortcomings of the contemporary deep learning models, which
we partly address with Pathways of Normalized Group Convolution (PoNG) model, a
novel neural architecture for solving AVR tasks. PoNG excels in both presented
challenges, as well as the standard I-RAVEN and PGM setups."
Initial Investigation of Kolmogorov-Arnold Networks (KANs) as Feature Extractors for IMU Based Human Activity Recognition,https://arxiv.org/abs/2406.11914,2024-06-16,2024-06-19,0.0,0.0,"In this work, we explore the use of a novel neural network architecture, the
Kolmogorov-Arnold Networks (KANs) as feature extractors for sensor-based
(specifically IMU) Human Activity Recognition (HAR). Where conventional
networks perform a parameterized weighted sum of the inputs at each node and
then feed the result into a statically defined nonlinearity, KANs perform
non-linear computations represented by B-SPLINES on the edges leading to each
node and then just sum up the inputs at the node. Instead of learning weights,
the system learns the spline parameters. In the original work, such networks
have been shown to be able to more efficiently and exactly learn sophisticated
real valued functions e.g. in regression or PDE solution. We hypothesize that
such an ability is also advantageous for computing low-level features for
IMU-based HAR. To this end, we have implemented KAN as the feature extraction
architecture for IMU-based human activity recognition tasks, including four
architecture variations. We present an initial performance investigation of the
KAN feature extractor on four public HAR datasets. It shows that the KAN-based
feature extractor outperforms CNN-based extractors on all datasets while being
more parameter efficient."
A Peek into Token Bias - Large Language Models Are Not Yet Genuine Reasoners,https://arxiv.org/abs/2406.11050,2024-06-16,2024-06-19,0.0,0.0,"This study introduces a hypothesis-testing framework to assess whether large
language models (LLMs) possess genuine reasoning abilities or primarily depend
on token bias. We go beyond evaluating LLMs on accuracy; rather, we aim to
investigate their token bias in solving logical reasoning tasks. Specifically,
we develop carefully controlled synthetic datasets, featuring conjunction
fallacy and syllogistic problems. Our framework outlines a list of hypotheses
where token biases are readily identifiable, with all null hypotheses assuming
genuine reasoning capabilities of LLMs. The findings in this study suggest,
with statistical guarantee, that most LLMs still struggle with logical
reasoning. While they may perform well on classic problems, their success
largely depends on recognizing superficial patterns with strong token bias,
thereby raising concerns about their actual reasoning and generalization
abilities."
Reconsidering Sentence-Level Sign Language Translation,https://arxiv.org/abs/2406.11049,2024-06-16,2024-06-19,0.0,0.0,"Historically, sign language machine translation has been posed as a
sentence-level task: datasets consisting of continuous narratives are chopped
up and presented to the model as isolated clips. In this work, we explore the
limitations of this task framing. First, we survey a number of linguistic
phenomena in sign languages that depend on discourse-level context. Then as a
case study, we perform the first human baseline for sign language translation
that actually substitutes a human into the machine learning task framing,
rather than provide the human with the entire document as context. This human
baseline -- for ASL to English translation on the How2Sign dataset -- shows
that for 33% of sentences in our sample, our fluent Deaf signer annotators were
only able to understand key parts of the clip in light of additional
discourse-level context. These results underscore the importance of
understanding and sanity checking examples when adapting machine learning to
new domains."
Leveraging Foundation Models for Multi-modal Federated Learning with Incomplete Modality,https://arxiv.org/abs/2406.11048,2024-06-16,2024-06-19,0.0,0.0,"Federated learning (FL) has obtained tremendous progress in providing
collaborative training solutions for distributed data silos with privacy
guarantees. However, few existing works explore a more realistic scenario where
the clients hold multiple data modalities. In this paper, we aim to solve a
novel challenge in multi-modal federated learning (MFL) -- modality missing --
the clients may lose part of the modalities in their local data sets. To tackle
the problems, we propose a novel multi-modal federated learning method,
Federated Multi-modal contrastiVe training with Pre-trained completion
(FedMVP), which integrates the large-scale pre-trained models to enhance the
federated training. In the proposed FedMVP framework, each client deploys a
large-scale pre-trained model with frozen parameters for modality completion
and representation knowledge transfer, enabling efficient and robust local
training. On the server side, we utilize generated data to uniformly measure
the representation similarity among the uploaded client models and construct a
graph perspective to aggregate them according to their importance in the
system. We demonstrate that the model achieves superior performance over two
real-world image-text classification datasets and is robust to the performance
degradation caused by missing modality."
Enhancing Supermarket Robot Interaction - A Multi-Level LLM Conversational Interface for Handling Diverse Customer Intents,https://arxiv.org/abs/2406.11047,2024-06-16,2024-06-19,0.0,0.0,"This paper presents the design and evaluation of a novel multi-level LLM
interface for supermarket robots to assist customers. The proposed interface
allows customers to convey their needs through both generic and specific
queries. While state-of-the-art systems like OpenAI's GPTs are highly adaptable
and easy to build and deploy, they still face challenges such as increased
response times and limitations in strategic control of the underlying model for
tailored use-case and cost optimization. Driven by the goal of developing
faster and more efficient conversational agents, this paper advocates for using
multiple smaller, specialized LLMs fine-tuned to handle different user queries
based on their specificity and user intent. We compare this approach to a
specialized GPT model powered by GPT-4 Turbo, using the Artificial Social Agent
Questionnaire (ASAQ) and qualitative participant feedback in a counterbalanced
within-subjects experiment. Our findings show that our multi-LLM chatbot
architecture outperformed the benchmarked GPT model across all 13 measured
criteria, with statistically significant improvements in four key areas:
performance, user satisfaction, user-agent partnership, and self-image
enhancement. The paper also presents a method for supermarket robot navigation
by mapping the final chatbot response to correct shelf numbers, enabling the
robot to sequentially navigate towards the respective products, after which
lower-level robot perception, control, and planning can be used for automated
object retrieval. We hope this work encourages more efforts into using
multiple, specialized smaller models instead of relying on a single powerful,
but more expensive and slower model."
Kolmogorov Arnold Informed neural network - A physics-informed deep learning framework for solving PDEs based on Kolmogorov Arnold Networks,https://arxiv.org/abs/2406.11045,2024-06-16,2024-06-19,0.0,0.0,"AI for partial differential equations (PDEs) has garnered significant
attention, particularly with the emergence of Physics-informed neural networks
(PINNs). The recent advent of Kolmogorov-Arnold Network (KAN) indicates that
there is potential to revisit and enhance the previously MLP-based PINNs.
Compared to MLPs, KANs offer interpretability and require fewer parameters.
PDEs can be described in various forms, such as strong form, energy form, and
inverse form. While mathematically equivalent, these forms are not
computationally equivalent, making the exploration of different PDE
formulations significant in computational physics. Thus, we propose different
PDE forms based on KAN instead of MLP, termed Kolmogorov-Arnold-Informed Neural
Network (KINN) for solving forward and inverse problems. We systematically
compare MLP and KAN in various numerical examples of PDEs, including
multi-scale, singularity, stress concentration, nonlinear hyperelasticity,
heterogeneous, and complex geometry problems. Our results demonstrate that KINN
significantly outperforms MLP regarding accuracy and convergence speed for
numerous PDEs in computational solid mechanics, except for the complex geometry
problem. This highlights KINN's potential for more efficient and accurate PDE
solutions in AI for PDEs."
Evaluating the Performance of Large Language Models via Debates,https://arxiv.org/abs/2406.11044,2024-06-16,2024-06-19,0.0,0.0,"Large Language Models (LLMs) are rapidly evolving and impacting various
fields, necessitating the development of effective methods to evaluate and
compare their performance. Most current approaches for performance evaluation
are either based on fixed, domain-specific questions that lack the flexibility
required in many real-world applications where tasks are not always from a
single domain, or rely on human input, making them unscalable. We propose an
automated benchmarking framework based on debates between LLMs, judged by
another LLM. This method assesses not only domain knowledge, but also skills
such as problem definition and inconsistency recognition. We evaluate the
performance of various state-of-the-art LLMs using the debate framework and
achieve rankings that align closely with popular rankings based on human input,
eliminating the need for costly human crowdsourcing."
Dynamic Normativity - Necessary and Sufficient Conditions for Value Alignment,https://arxiv.org/abs/2406.11039,2024-06-16,2024-06-19,0.0,0.0,"The critical inquiry pervading the realm of Philosophy, and perhaps extending
its influence across all Humanities disciplines, revolves around the
intricacies of morality and normativity. Surprisingly, in recent years, this
thematic thread has woven its way into an unexpected domain, one not
conventionally associated with pondering ""what ought to be"": the field of
artificial intelligence (AI) research. Central to morality and AI, we find
""alignment"", a problem related to the challenges of expressing human goals and
values in a manner that artificial systems can follow without leading to
unwanted adversarial effects. More explicitly and with our current paradigm of
AI development in mind, we can think of alignment as teaching human values to
non-anthropomorphic entities trained through opaque, gradient-based learning
techniques. This work addresses alignment as a technical-philosophical problem
that requires solid philosophical foundations and practical implementations
that bring normative theory to AI system development. To accomplish this, we
propose two sets of necessary and sufficient conditions that, we argue, should
be considered in any alignment process. While necessary conditions serve as
metaphysical and metaethical roots that pertain to the permissibility of
alignment, sufficient conditions establish a blueprint for aligning AI systems
under a learning-based paradigm. After laying such foundations, we present
implementations of this approach by using state-of-the-art techniques and
methods for aligning general-purpose language systems. We call this framework
Dynamic Normativity. Its central thesis is that any alignment process under a
learning paradigm that cannot fulfill its necessary and sufficient conditions
will fail in producing aligned systems."
garak - A Framework for Security Probing Large Language Models,https://arxiv.org/abs/2406.11036,2024-06-16,2024-06-19,0.0,0.0,"As Large Language Models (LLMs) are deployed and integrated into thousands of
applications, the need for scalable evaluation of how models respond to
adversarial attacks grows rapidly. However, LLM security is a moving target:
models produce unpredictable output, are constantly updated, and the potential
adversary is highly diverse: anyone with access to the internet and a decent
command of natural language. Further, what constitutes a security weak in one
context may not be an issue in a different context; one-fits-all guardrails
remain theoretical. In this paper, we argue that it is time to rethink what
constitutes ``LLM security'', and pursue a holistic approach to LLM security
evaluation, where exploration and discovery of issues are central. To this end,
this paper introduces garak (Generative AI Red-teaming and Assessment Kit), a
framework which can be used to discover and identify vulnerabilities in a
target LLM or dialog system. garak probes an LLM in a structured fashion to
discover potential vulnerabilities. The outputs of the framework describe a
target model's weaknesses, contribute to an informed discussion of what
composes vulnerabilities in unique contexts, and can inform alignment and
policy discussions for LLM deployment."
Scaling Synthetic Logical Reasoning Datasets with Context-Sensitive Declarative Grammars,https://arxiv.org/abs/2406.11035,2024-06-16,2024-06-19,0.0,0.0,"Logical reasoning remains a challenge for natural language processing, but it
can be improved by training language models to mimic theorem provers on
procedurally generated problems. Previous work used domain-specific proof
generation algorithms, which biases reasoning toward specific proof traces and
limits auditability and extensibility. We present a simpler and more general
declarative framework with flexible context-sensitive rules binding multiple
languages (specifically, simplified English and the TPTP theorem-proving
language). We construct first-order logic problems by selecting up to 32
premises and one hypothesis. We demonstrate that using semantic constraints
during generation and careful English verbalization of predicates enhances
logical reasoning without hurting natural English tasks. We use relatively
small DeBERTa-v3 models to achieve state-of-the-art accuracy on the FOLIO
human-authored logic dataset, surpassing GPT-4 in accuracy with or without an
external solver by 12%."
HAIChart - Human and AI Paired Visualization System,https://arxiv.org/abs/2406.11033,2024-06-16,2024-06-19,0.0,0.0,"The growing importance of data visualization in business intelligence and
data science emphasizes the need for tools that can efficiently generate
meaningful visualizations from large datasets. Existing tools fall into two
main categories: human-powered tools (e.g., Tableau and PowerBI), which require
intensive expert involvement, and AI-powered automated tools (e.g., Draco and
Table2Charts), which often fall short of guessing specific user needs. In this
paper, we aim to achieve the best of both worlds. Our key idea is to initially
auto-generate a set of high-quality visualizations to minimize manual effort,
then refine this process iteratively with user feedback to more closely align
with their needs. To this end, we present HAIChart, a reinforcement
learning-based framework designed to iteratively recommend good visualizations
for a given dataset by incorporating user feedback. Specifically, we propose a
Monte Carlo Graph Search-based visualization generation algorithm paired with a
composite reward function to efficiently explore the visualization space and
automatically generate good visualizations. We devise a visualization hints
mechanism to actively incorporate user feedback, thus progressively refining
the visualization generation module. We further prove that the top-k
visualization hints selection problem is NP-hard and design an efficient
algorithm. We conduct both quantitative evaluations and user studies, showing
that HAIChart significantly outperforms state-of-the-art human-powered tools
(21% better at Recall and 1.8 times faster) and AI-powered automatic tools
(25.1% and 14.9% better in terms of Hit@3 and R10@30, respectively)."
FoodieQA - A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture,https://arxiv.org/abs/2406.11030,2024-06-16,2024-06-19,0.0,0.0,"Food is a rich and varied dimension of cultural heritage, crucial to both
individuals and social groups. To bridge the gap in the literature on the
often-overlooked regional diversity in this domain, we introduce FoodieQA, a
manually curated, fine-grained image-text dataset capturing the intricate
features of food cultures across various regions in China. We evaluate
vision-language Models (VLMs) and large language models (LLMs) on newly
collected, unseen food images and corresponding questions. FoodieQA comprises
three multiple-choice question-answering tasks where models need to answer
questions based on multiple images, a single image, and text-only descriptions,
respectively. While LLMs excel at text-based question answering, surpassing
human accuracy, the open-sourced VLMs still fall short by 41% on multi-image
and 21% on single-image VQA tasks, although closed-weights models perform
closer to human levels (within 10%). Our findings highlight that understanding
food and its cultural implications remains a challenging and under-explored
direction."
Curating Stopwords in Marathi - A TF-IDF Approach for Improved Text Analysis and Information Retrieval,https://arxiv.org/abs/2406.11029,2024-06-16,2024-06-19,0.0,0.0,"Stopwords are commonly used words in a language that are often considered to
be of little value in determining the meaning or significance of a document.
These words occur frequently in most texts and don't provide much useful
information for tasks like sentiment analysis and text classification. English,
which is a high-resource language, takes advantage of the availability of
stopwords, whereas low-resource Indian languages like Marathi are very limited,
standardized, and can be used in available packages, but the number of
available words in those packages is low. Our work targets the curation of
stopwords in the Marathi language using the MahaCorpus, with 24.8 million
sentences. We make use of the TF-IDF approach coupled with human evaluation to
curate a strong stopword list of 400 words. We apply the stop word removal to
the text classification task and show its efficacy. The work also presents a
simple recipe for stopword curation in a low-resource language. The stopwords
are integrated into the mahaNLP library and publicly available on
https://github.com/l3cube-pune/MarathiNLP ."
Universal Cross-Lingual Text Classification,https://arxiv.org/abs/2406.11028,2024-06-16,2024-06-19,0.0,0.0,"Text classification, an integral task in natural language processing,
involves the automatic categorization of text into predefined classes. Creating
supervised labeled datasets for low-resource languages poses a considerable
challenge. Unlocking the language potential of low-resource languages requires
robust datasets with supervised labels. However, such datasets are scarce, and
the label space is often limited. In our pursuit to address this gap, we aim to
optimize existing labels/datasets in different languages. This research
proposes a novel perspective on Universal Cross-Lingual Text Classification,
leveraging a unified model across languages. Our approach involves blending
supervised data from different languages during training to create a universal
model. The supervised data for a target classification task might come from
different languages covering different labels. The primary goal is to enhance
label and language coverage, aiming for a label set that represents a union of
labels from various languages. We propose the usage of a strong multilingual
SBERT as our base model, making our novel training strategy feasible. This
strategy contributes to the adaptability and effectiveness of the model in
cross-lingual language transfer scenarios, where it can categorize text in
languages not encountered during training. Thus, the paper delves into the
intricacies of cross-lingual text classification, with a particular focus on
its application for low-resource languages, exploring methodologies and
implications for the development of a robust and adaptable universal
cross-lingual model."
AgileCoder - Dynamic Collaborative Agents for Software Development based on Agile Methodology,https://arxiv.org/abs/2406.11912,2024-06-16,2024-06-19,0.0,0.0,"Software agents have emerged as promising tools for addressing complex
software engineering tasks. Existing works, on the other hand, frequently
oversimplify software development workflows, despite the fact that such
workflows are typically more complex in the real world. Thus, we propose
AgileCoder, a multi agent system that integrates Agile Methodology (AM) into
the framework. This system assigns specific AM roles - such as Product Manager,
Developer, and Tester to different agents, who then collaboratively develop
software based on user inputs. AgileCoder enhances development efficiency by
organizing work into sprints, focusing on incrementally developing software
through sprints. Additionally, we introduce Dynamic Code Graph Generator, a
module that creates a Code Dependency Graph dynamically as updates are made to
the codebase. This allows agents to better comprehend the codebase, leading to
more precise code generation and modifications throughout the software
development process. AgileCoder surpasses existing benchmarks, like ChatDev and
MetaGPT, establishing a new standard and showcasing the capabilities of multi
agent systems in advanced software engineering environments."
Boosting Medical Image Classification with Segmentation Foundation Model,https://arxiv.org/abs/2406.11026,2024-06-16,2024-06-19,0.0,0.0,"The Segment Anything Model (SAM) exhibits impressive capabilities in
zero-shot segmentation for natural images. Recently, SAM has gained a great
deal of attention for its applications in medical image segmentation. However,
to our best knowledge, no studies have shown how to harness the power of SAM
for medical image classification. To fill this gap and make SAM a true
``foundation model'' for medical image analysis, it is highly desirable to
customize SAM specifically for medical image classification. In this paper, we
introduce SAMAug-C, an innovative augmentation method based on SAM for
augmenting classification datasets by generating variants of the original
images. The augmented datasets can be used to train a deep learning
classification model, thereby boosting the classification performance.
Furthermore, we propose a novel framework that simultaneously processes raw and
SAMAug-C augmented image input, capitalizing on the complementary information
that is offered by both. Experiments on three public datasets validate the
effectiveness of our new approach."
Large Language Models for Dysfluency Detection in Stuttered Speech,https://arxiv.org/abs/2406.11025,2024-06-16,2024-06-19,0.0,0.0,"Accurately detecting dysfluencies in spoken language can help to improve the
performance of automatic speech and language processing components and support
the development of more inclusive speech and language technologies. Inspired by
the recent trend towards the deployment of large language models (LLMs) as
universal learners and processors of non-lexical inputs, such as audio and
video, we approach the task of multi-label dysfluency detection as a language
modeling problem. We present hypotheses candidates generated with an automatic
speech recognition system and acoustic representations extracted from an audio
encoder model to an LLM, and finetune the system to predict dysfluency labels
on three datasets containing English and German stuttered speech. The
experimental results show that our system effectively combines acoustic and
lexical information and achieves competitive results on the multi-label
stuttering detection task."
Physics-Informed Deep Learning and Partial Transfer Learning for Bearing Fault Diagnosis in the Presence of Highly Missing Data,https://arxiv.org/abs/2406.11023,2024-06-16,2024-06-19,0.0,0.0,"One of the most significant obstacles in bearing fault diagnosis is a lack of
labeled data for various fault types. Also, sensor-acquired data frequently
lack labels and have a large amount of missing data. This paper tackles these
issues by presenting the PTPAI method, which uses a physics-informed deep
learning-based technique to generate synthetic labeled data. Labeled synthetic
data makes up the source domain, whereas unlabeled data with missing data is
present in the target domain. Consequently, imbalanced class problems and
partial-set fault diagnosis hurdles emerge. To address these challenges, the
RF-Mixup approach is used to handle imbalanced classes. As domain adaptation
strategies, the MK-MMSD and CDAN are employed to mitigate the disparity in
distribution between synthetic and actual data. Furthermore, the partial-set
challenge is tackled by applying weighting methods at the class and instance
levels. Experimental outcomes on the CWRU and JNU datasets indicate that the
proposed approach effectively addresses these problems."
RUPBench - Benchmarking Reasoning Under Perturbations for Robustness Evaluation in Large Language Models,https://arxiv.org/abs/2406.11020,2024-06-16,2024-06-19,0.0,0.0,"With the increasing use of large language models (LLMs), ensuring reliable
performance in diverse, real-world environments is essential. Despite their
remarkable achievements, LLMs often struggle with adversarial inputs,
significantly impacting their effectiveness in practical applications. To
systematically understand the robustness of LLMs, we present RUPBench, a
comprehensive benchmark designed to evaluate LLM robustness across diverse
reasoning tasks. Our benchmark incorporates 15 reasoning datasets, categorized
into commonsense, arithmetic, logical, and knowledge-intensive reasoning, and
introduces nine types of textual perturbations at lexical, syntactic, and
semantic levels. By examining the performance of state-of-the-art LLMs such as
GPT-4o, Llama3, Phi-3, and Gemma on both original and perturbed datasets, we
provide a detailed analysis of their robustness and error patterns. Our
findings highlight that larger models tend to exhibit greater robustness to
perturbations. Additionally, common error types are identified through manual
inspection, revealing specific challenges faced by LLMs in different reasoning
contexts. This work provides insights into areas where LLMs need further
improvement to handle diverse and noisy inputs effectively."
Optimized Speculative Sampling for GPU Hardware Accelerators,https://arxiv.org/abs/2406.11016,2024-06-16,2024-06-19,0.0,0.0,"In this work, we optimize speculative sampling for parallel hardware
accelerators to improve sampling speed. We notice that substantial portions of
the intermediate matrices necessary for speculative sampling can be computed
concurrently. This allows us to distribute the workload across multiple GPU
threads, enabling simultaneous operations on matrix segments within thread
blocks. Additionally, we use fast on-chip memory to store intermediate results,
thereby minimizing the frequency of slow read and write operations across
different types of memory. This results in profiling time improvements ranging
from 6% to 13% relative to the baseline implementation, without compromising
accuracy. To further accelerate speculative sampling, probability distributions
parameterized by softmax are approximated by sigmoid. This approximation
approach results in significantly greater relative improvements in profiling
time, ranging from 37% to 94%, with a slight decline in accuracy. We conduct
extensive experiments on both automatic speech recognition and summarization
tasks to validate the effectiveness of our optimization methods."
Latent Communication in Artificial Neural Networks,https://arxiv.org/abs/2406.11014,2024-06-16,2024-06-19,0.0,0.0,"As NNs permeate various scientific and industrial domains, understanding the
universality and reusability of their representations becomes crucial. At their
core, these networks create intermediate neural representations, indicated as
latent spaces, of the input data and subsequently leverage them to perform
specific downstream tasks. This dissertation focuses on the universality and
reusability of neural representations. Do the latent representations crafted by
a NN remain exclusive to a particular trained instance, or can they generalize
across models, adapting to factors such as randomness during training, model
architecture, or even data domain? This adaptive quality introduces the notion
of Latent Communication -- a phenomenon that describes when representations can
be unified or reused across neural spaces. A salient observation from our
research is the emergence of similarities in latent representations, even when
these originate from distinct or seemingly unrelated NNs. By exploiting a
partial correspondence between the two data distributions that establishes a
semantic link, we found that these representations can either be projected into
a universal representation, coined as Relative Representation, or be directly
translated from one space to another. Latent Communication allows for a bridge
between independently trained NN, irrespective of their training regimen,
architecture, or the data modality they were trained on -- as long as the data
semantic content stays the same (e.g., images and their captions). This holds
true for both generation, classification and retrieval downstream tasks; in
supervised, weakly supervised, and unsupervised settings; and spans various
data modalities including images, text, audio, and graphs -- showcasing the
universality of the Latent Communication phenomenon. [...]"
Connecting the Dots - Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game,https://arxiv.org/abs/2406.11012,2024-06-16,2024-06-19,0.0,0.0,"The New York Times Connections game has emerged as a popular and challenging
pursuit for word puzzle enthusiasts. We collect 200 Connections games to
evaluate the performance of state-of-the-art large language models (LLMs)
against expert and novice human players. Our results show that even the
best-performing LLM, GPT-4o, which has otherwise shown impressive reasoning
abilities on a wide variety of benchmarks, can only fully solve 8% of the
games. Compared to GPT-4o, novice and expert players perform better, with
expert human players significantly outperforming GPT-4o. To deepen our
understanding we create a taxonomy of the knowledge types required to
successfully categorize words in the Connections game, revealing that LLMs
struggle with associative, encyclopedic, and linguistic knowledge. Our findings
establish the New York Times Connections game as a challenging benchmark for
evaluating abstract reasoning capabilities in humans and AI systems."
Data Shapley in One Training Run,https://arxiv.org/abs/2406.11011,2024-06-16,2024-06-19,0.0,0.0,"Data Shapley provides a principled framework for attributing data's
contribution within machine learning contexts. However, existing approaches
require re-training models on different data subsets, which is computationally
intensive, foreclosing their application to large-scale models. Furthermore,
they produce the same attribution score for any models produced by running the
learning algorithm, meaning they cannot perform targeted attribution towards a
specific model obtained from a single run of the algorithm. This paper
introduces In-Run Data Shapley, which addresses these limitations by offering
scalable data attribution for a target model of interest. In its most efficient
implementation, our technique incurs negligible additional runtime compared to
standard model training. This dramatic efficiency improvement makes it possible
to perform data attribution for the foundation model pretraining stage for the
first time. We present several case studies that offer fresh insights into
pretraining data's contribution and discuss their implications for copyright in
generative AI and pretraining data curation."
WeShap - Weak Supervision Source Evaluation with Shapley Values,https://arxiv.org/abs/2406.11010,2024-06-16,2024-06-19,0.0,0.0,"Efficient data annotation stands as a significant bottleneck in training
contemporary machine learning models. The Programmatic Weak Supervision (PWS)
pipeline presents a solution by utilizing multiple weak supervision sources to
automatically label data, thereby expediting the annotation process. Given the
varied contributions of these weak supervision sources to the accuracy of PWS,
it is imperative to employ a robust and efficient metric for their evaluation.
This is crucial not only for understanding the behavior and performance of the
PWS pipeline but also for facilitating corrective measures.
  In our study, we introduce WeShap values as an evaluation metric, which
quantifies the average contribution of weak supervision sources within a proxy
PWS pipeline, leveraging the theoretical underpinnings of Shapley values. We
demonstrate efficient computation of WeShap values using dynamic programming,
achieving quadratic computational complexity relative to the number of weak
supervision sources.
  Our experiments demonstrate the versatility of WeShap values across various
applications, including the identification of beneficial or detrimental
labeling functions, refinement of the PWS pipeline, and rectification of
mislabeled data. Furthermore, WeShap values aid in comprehending the behavior
of the PWS pipeline and scrutinizing specific instances of mislabeled data.
Although initially derived from a specific proxy PWS pipeline, we empirically
demonstrate the generalizability of WeShap values to other PWS pipeline
configurations.
  Our findings indicate a noteworthy average improvement of 4.8 points in
downstream model accuracy through the revision of the PWS pipeline compared to
previous state-of-the-art methods, underscoring the efficacy of WeShap values
in enhancing data quality for training machine learning models."
A Notion of Complexity for Theory of Mind via Discrete World Models,https://arxiv.org/abs/2406.11911,2024-06-16,2024-06-19,0.0,0.0,"Theory of Mind (ToM) can be used to assess the capabilities of Large Language
Models (LLMs) in complex scenarios where social reasoning is required. While
the research community has proposed many ToM benchmarks, their hardness varies
greatly, and their complexity is not well defined. This work proposes a
framework to measure the complexity of ToM tasks. We quantify a problem's
complexity as the number of states necessary to solve it correctly. Our
complexity measure also accounts for spurious states of a ToM problem designed
to make it apparently harder. We use our method to assess the complexity of
five widely adopted ToM benchmarks. On top of this framework, we design a
prompting technique that augments the information available to a model with a
description of how the environment changes with the agents' interactions. We
name this technique Discrete World Models (DWM) and show how it elicits
superior performance on ToM tasks."
SPEAR - Receiver-to-Receiver Acoustic Neural Warping Field,https://arxiv.org/abs/2406.11006,2024-06-16,2024-06-19,0.0,0.0,"We present SPEAR, a continuous receiver-to-receiver acoustic neural warping
field for spatial acoustic effects prediction in an acoustic 3D space with a
single stationary audio source. Unlike traditional source-to-receiver modelling
methods that require prior space acoustic properties knowledge to rigorously
model audio propagation from source to receiver, we propose to predict by
warping the spatial acoustic effects from one reference receiver position to
another target receiver position, so that the warped audio essentially
accommodates all spatial acoustic effects belonging to the target position.
SPEAR can be trained in a data much more readily accessible manner, in which we
simply ask two robots to independently record spatial audio at different
positions. We further theoretically prove the universal existence of the
warping field if and only if one audio source presents. Three physical
principles are incorporated to guide SPEAR network design, leading to the
learned warping field physically meaningful. We demonstrate SPEAR superiority
on both synthetic, photo-realistic and real-world dataset, showing the huge
potential of SPEAR to various down-stream robotic tasks."
3D Gaze Tracking for Studying Collaborative Interactions in Mixed-Reality Environments,https://arxiv.org/abs/2406.11003,2024-06-16,2024-06-19,0.0,0.0,"This study presents a novel framework for 3D gaze tracking tailored for
mixed-reality settings, aimed at enhancing joint attention and collaborative
efforts in team-based scenarios. Conventional gaze tracking, often limited by
monocular cameras and traditional eye-tracking apparatus, struggles with
simultaneous data synchronization and analysis from multiple participants in
group contexts. Our proposed framework leverages state-of-the-art computer
vision and machine learning techniques to overcome these obstacles, enabling
precise 3D gaze estimation without dependence on specialized hardware or
complex data fusion. Utilizing facial recognition and deep learning, the
framework achieves real-time, tracking of gaze patterns across several
individuals, addressing common depth estimation errors, and ensuring spatial
and identity consistency within the dataset. Empirical results demonstrate the
accuracy and reliability of our method in group environments. This provides
mechanisms for significant advances in behavior and interaction analysis in
educational and professional training applications in dynamic and unstructured
environments."
Not All Bias is Bad - Balancing Rational Deviations and Cognitive Biases in Large Language Model Reasoning,https://arxiv.org/abs/2406.10999,2024-06-16,2024-06-19,0.0,0.0,"This paper examines the role of cognitive biases in the decision-making
processes of large language models (LLMs), challenging the conventional goal of
eliminating all biases. We show that certain cognitive biases when properly
balanced, can enhance decision-making efficiency through rational deviations
and heuristic shortcuts. By introducing heuristic moderation and an abstention
option, which allows LLMs to withhold responses when uncertain, we reduce error
rates, improve decision accuracy, and optimize decision rates. Using the
Balance Rigor and Utility (BRU) dataset, developed through expert
collaboration, our findings demonstrate that targeted inspection of cognitive
biases aligns LLM decisions more closely with human reasoning, enhancing
reliability and suggesting strategies for future improvements. This approach
offers a novel way to leverage cognitive biases to improve the practical
utility of LLMs across various applications."
Two-level overlapping additive Schwarz preconditioner for training scientific machine learning applications,https://arxiv.org/abs/2406.10997,2024-06-16,2024-06-19,0.0,0.0,"We introduce a novel two-level overlapping additive Schwarz preconditioner
for accelerating the training of scientific machine learning applications. The
design of the proposed preconditioner is motivated by the nonlinear two-level
overlapping additive Schwarz preconditioner. The neural network parameters are
decomposed into groups (subdomains) with overlapping regions. In addition, the
network's feed-forward structure is indirectly imposed through a novel
subdomain-wise synchronization strategy and a coarse-level training step.
Through a series of numerical experiments, which consider physics-informed
neural networks and operator learning approaches, we demonstrate that the
proposed two-level preconditioner significantly speeds up the convergence of
the standard (LBFGS) optimizer while also yielding more accurate machine
learning models. Moreover, the devised preconditioner is designed to take
advantage of model-parallel computations, which can further reduce the training
time."
THEANINE - Revisiting Memory Management in Long-term Conversations with Timeline-augmented Response Generation,https://arxiv.org/abs/2406.10996,2024-06-16,2024-06-19,0.0,0.0,"Large language models (LLMs) are capable of processing lengthy dialogue
histories during prolonged interaction with users without additional memory
modules; however, their responses tend to overlook or incorrectly recall
information from the past. In this paper, we revisit memory-augmented response
generation in the era of LLMs. While prior work focuses on getting rid of
outdated memories, we argue that such memories can provide contextual cues that
help dialogue systems understand the development of past events and, therefore,
benefit response generation. We present Theanine, a framework that augments
LLMs' response generation with memory timelines -- series of memories that
demonstrate the development and causality of relevant past events. Along with
Theanine, we introduce TeaFarm, a counterfactual-driven question-answering
pipeline addressing the limitation of G-Eval in long-term conversations.
Supplementary videos of our methods and the TeaBag dataset for TeaFarm
evaluation are in https://theanine-693b0.web.app/."
Concept-skill Transferability-based Data Selection for Large Vision-Language Models,https://arxiv.org/abs/2406.10995,2024-06-16,2024-06-19,0.0,0.0,"Instruction tuning, or supervised finetuning on extensive task-specific data,
is necessary for Large Vision-Language Models (LVLMs) to generalize well across
a broad range of vision-language (VL) tasks. However, training on large VL
datasets can become prohibitively expensive. In this work, we introduce
COINCIDE, an effective and scalable data selection technique that uses a small
model as a reference model to select visual instruction tuning data for
efficient finetuning of a target LVLM, focusing on diversity and
transferability. Specifically, we cluster the training data using internal
activations from a small model, which identifies VL concept-skill compositions
needed by a target LVLM. We then sample data from these diverse clusters by
considering their density and transferability, or the ability to transfer well
to other concept-skill compositions. This approach ensures the diversity of
these compositions, which is vital for LVLM generalization. Extensive
experiments demonstrate that COINCIDE achieves superior performance and data
selection efficiency against 8 strong baselines on two distinct datasets:
LLaVA-1.5 and Vision-Flan. Using only 20% of the LLaVA-1.5 dataset, COINCIDE
achieves performance comparable to the LVLM finetuned on the whole dataset,
with 70% reduction of the wall-clock running time. On the Vision-Flan dataset,
our method achieves superior results with only 16.7% of the training data."
CoSTA - Code-Switched Speech Translation using Aligned Speech-Text Interleaving,https://arxiv.org/abs/2406.10993,2024-06-16,2024-06-19,0.0,0.0,"Code-switching is a widely prevalent linguistic phenomenon in multilingual
societies like India. Building speech-to-text models for code-switched speech
is challenging due to limited availability of datasets. In this work, we focus
on the problem of spoken translation (ST) of code-switched speech in Indian
languages to English text. We present a new end-to-end model architecture COSTA
that scaffolds on pretrained automatic speech recognition (ASR) and machine
translation (MT) modules (that are more widely available for many languages).
Speech and ASR text representations are fused using an aligned interleaving
scheme and are fed further as input to a pretrained MT module; the whole
pipeline is then trained end-to-end for spoken translation using synthetically
created ST data. We also release a new evaluation benchmark for code-switched
Bengali-English, Hindi-English, Marathi-English and Telugu- English speech to
English text. COSTA significantly outperforms many competitive cascaded and
end-to-end multimodal baselines by up to 3.5 BLEU points."
Adaptive Query Rewriting - Aligning Rewriters through Marginal Probability of Conversational Answers,https://arxiv.org/abs/2406.10991,2024-06-16,2024-06-19,0.0,0.0,"Query rewriting is a crucial technique for passage retrieval in open-domain
conversational question answering (CQA). It decontexualizes conversational
queries into self-contained questions suitable for off-the-shelf retrievers.
Existing methods attempt to incorporate retriever's preference during the
training of rewriting models. However, these approaches typically rely on
extensive annotations such as in-domain rewrites and/or relevant passage
labels, limiting the models' generalization and adaptation capabilities. In
this paper, we introduce AdaQR ($\textbf{Ada}$ptive $\textbf{Q}$uery
$\textbf{R}$ewriting), a framework for training query rewriting models with
limited rewrite annotations from seed datasets and completely no passage label.
Our approach begins by fine-tuning compact large language models using only
~$10\%$ of rewrite annotations from the seed dataset training split. The models
are then utilized to generate rewrite candidates for each query instance. A
novel approach is then proposed to assess retriever's preference for these
candidates by the probability of answers conditioned on the conversational
query by marginalizing the Top-$K$ passages. This serves as the reward for
optimizing the rewriter further using Direct Preference Optimization (DPO), a
process free of rewrite and retrieval annotations. Experimental results on four
open-domain CQA datasets demonstrate that AdaQR not only enhances the in-domain
capabilities of the rewriter with limited annotation requirement, but also
adapts effectively to out-of-domain datasets."
Predicting the Understandability of Computational Notebooks through Code Metrics Analysis,https://arxiv.org/abs/2406.10989,2024-06-16,2024-06-19,0.0,0.0,"Computational notebooks have become the primary coding environment for data
scientists. However, research on their code quality is still emerging, and the
code shared is often of poor quality. Given the importance of maintenance and
reusability, understanding the metrics that affect notebook code
comprehensibility is crucial. Code understandability, a qualitative variable,
is closely tied to user opinions. Traditional approaches to measuring it either
use limited questionnaires to review a few code pieces or rely on metadata such
as likes and votes in software repositories. Our approach enhances the
measurement of Jupyter notebook understandability by leveraging user comments
related to code understandability. As a case study, we used 542,051 Kaggle
Jupyter notebooks from our previous research, named DistilKaggle. We employed a
fine-tuned DistilBERT transformer to identify user comments associated with
code understandability. We established a criterion called User Opinion Code
Understandability (UOCU), which considers the number of relevant comments,
upvotes on those comments, total notebook views, and total notebook upvotes.
UOCU proved to be more effective than previous methods. Furthermore, we trained
machine learning models to predict notebook code understandability based solely
on their metrics. We collected 34 metrics for 132,723 final notebooks as
features in our dataset, using UOCU as the label. Our predictive model, using
the Random Forest classifier, achieved 89% accuracy in predicting the
understandability levels of computational notebooks."
Taking a Deep Breath - Enhancing Language Modeling of Large Language Models with Sentinel Tokens,https://arxiv.org/abs/2406.10985,2024-06-16,2024-06-19,0.0,0.0,"Large language models (LLMs) have shown promising efficacy across various
tasks, becoming powerful tools in numerous aspects of human life. However,
Transformer-based LLMs suffer a performance degradation when modeling long-term
contexts due to they discard some information to reduce computational overhead.
In this work, we propose a simple yet effective method to enable LLMs to take a
deep breath, encouraging them to summarize information contained within
discrete text chunks. Specifically, we segment the text into multiple chunks
and insert special token <SR> at the end of each chunk. We then modify the
attention mask to integrate the chunk's information into the corresponding <SR>
token. This facilitates LLMs to interpret information not only from historical
individual tokens but also from the <SR> token, aggregating the chunk's
semantic information. Experiments on language modeling and out-of-domain
downstream tasks validate the superiority of our approach."
Revisiting Cosine Similarity via Normalized ICA-transformed Embeddings,https://arxiv.org/abs/2406.10984,2024-06-16,2024-06-19,0.0,0.0,"Cosine similarity is widely used to measure the similarity between two
embeddings, while interpretations based on angle and correlation coefficient
are common. In this study, we focus on the interpretable axes of embeddings
transformed by Independent Component Analysis (ICA), and propose a novel
interpretation of cosine similarity as the sum of semantic similarities over
axes. The normalized ICA-transformed embeddings exhibit sparsity, enhancing the
interpretability of each axis, and the semantic similarity defined by the
product of the components represents the shared meaning between the two
embeddings along each axis. The effectiveness of this approach is demonstrated
through intuitive numerical examples and thorough numerical experiments. By
deriving the probability distributions that govern each component and the
product of components, we propose a method for selecting statistically
significant axes."
Toward Optimal LLM Alignments Using Two-Player Games,https://arxiv.org/abs/2406.10977,2024-06-16,2024-06-19,0.0,0.0,"The standard Reinforcement Learning from Human Feedback (RLHF) framework
primarily focuses on optimizing the performance of large language models using
pre-collected prompts. However, collecting prompts that provide comprehensive
coverage is both tedious and challenging, and often fails to include scenarios
that LLMs need to improve on the most. In this paper, we investigate alignment
through the lens of two-agent games, involving iterative interactions between
an adversarial and a defensive agent. The adversarial agent's task at each step
is to generate prompts that expose the weakness of the defensive agent. In
return, the defensive agent seeks to improve its responses to these newly
identified prompts it struggled with, based on feedback from the reward model.
We theoretically demonstrate that this iterative reinforcement learning
optimization converges to a Nash Equilibrium for the game induced by the
agents. Experimental results in safety scenarios demonstrate that learning in
such a competitive environment not only fully trains agents but also leads to
policies with enhanced generalization capabilities for both adversarial and
defensive agents."
Promoting Data and Model Privacy in Federated Learning through Quantized LoRA,https://arxiv.org/abs/2406.10976,2024-06-16,2024-06-19,0.0,0.0,"Conventional federated learning primarily aims to secure the privacy of data
distributed across multiple edge devices, with the global model dispatched to
edge devices for parameter updates during the learning process. However, the
development of large language models (LLMs) requires substantial data and
computational resources, rendering them valuable intellectual properties for
their developers and owners. To establish a mechanism that protects both data
and model privacy in a federated learning context, we introduce a method that
just needs to distribute a quantized version of the model's parameters during
training. This method enables accurate gradient estimations for parameter
updates while preventing clients from accessing a model whose performance is
comparable to the centrally hosted one. Moreover, we combine this quantization
strategy with LoRA, a popular and parameter-efficient fine-tuning method, to
significantly reduce communication costs in federated learning. The proposed
framework, named \textsc{FedLPP}, successfully ensures both data and model
privacy in the federated learning context. Additionally, the learned central
model exhibits good generalization and can be trained in a resource-efficient
manner."
Towards Supporting Legal Argumentation with NLP - Is More Data Really All You Need?,https://arxiv.org/abs/2406.10974,2024-06-16,2024-06-19,0.0,0.0,"Modeling legal reasoning and argumentation justifying decisions in cases has
always been central to AI & Law, yet contemporary developments in legal NLP
have increasingly focused on statistically classifying legal conclusions from
text. While conceptually simpler, these approaches often fall short in
providing usable justifications connecting to appropriate legal concepts. This
paper reviews both traditional symbolic works in AI & Law and recent advances
in legal NLP, and distills possibilities of integrating expert-informed
knowledge to strike a balance between scalability and explanation in symbolic
vs. data-driven approaches. We identify open challenges and discuss the
potential of modern NLP models and methods that integrate"
ExPLoRA - Parameter-Efficient Extended Pre-Training to Adapt Vision Transformers under Domain Shifts,https://arxiv.org/abs/2406.10973,2024-06-16,2024-06-19,0.0,0.0,"Parameter-efficient fine-tuning (PEFT) techniques such as low-rank adaptation
(LoRA) can effectively adapt large pre-trained foundation models to downstream
tasks using only a small fraction (0.1%-10%) of the original trainable weights.
An under-explored question of PEFT is in extending the pre-training phase
without supervised labels; that is, can we adapt a pre-trained foundation model
to a new domain via efficient self-supervised pre-training on this new domain?
In this work, we introduce ExPLoRA, a highly effective technique to improve
transfer learning of pre-trained vision transformers (ViTs) under domain
shifts. Initializing a ViT with pre-trained weights on large, natural-image
datasets such as from DinoV2 or MAE, ExPLoRA continues the unsupervised
pre-training objective on a new domain. In this extended pre-training phase,
ExPLoRA only unfreezes 1-2 pre-trained ViT blocks and all normalization layers,
and then tunes all other layers with LoRA. Finally, we fine-tune the resulting
model only with LoRA on this new domain for supervised learning. Our
experiments demonstrate state-of-the-art results on satellite imagery, even
outperforming fully pre-training and fine-tuning ViTs. Using the DinoV2
training objective, we demonstrate up to 7% improvement in linear probing top-1
accuracy on downstream tasks while using <10% of the number of parameters that
are used in prior fully-tuned state-of-the art approaches. Our ablation studies
confirm the efficacy of our approach over other baselines, including PEFT and
simply unfreezing more transformer blocks."
DocNet - Semantic Structure in Inductive Bias Detection Models,https://arxiv.org/abs/2406.10965,2024-06-16,2024-06-19,0.0,0.0,"News will have biases so long as people have opinions. However, as social
media becomes the primary entry point for news and partisan gaps increase, it
is increasingly important for informed citizens to be able to identify bias.
People will be able to take action to avoid polarizing echo chambers if they
know how the news they are consuming is biased. In this paper, we explore an
often overlooked aspect of bias detection in documents: the semantic structure
of news articles. We present DocNet, a novel, inductive, and low-resource
document embedding and bias detection model that outperforms large language
models. We also demonstrate that the semantic structure of news articles from
opposing partisan sides, as represented in document-level graph embeddings,
have significant similarities. These results can be used to advance bias
detection in low-resource environments. Our code and data are made available at
https://github.com/nlpresearchanon."
"Ontology Embedding - A Survey of Methods, Applications and Resources",https://arxiv.org/abs/2406.10964,2024-06-16,2024-06-19,0.0,0.0,"Ontologies are widely used for representing domain knowledge and meta data,
playing an increasingly important role in Information Systems, the Semantic
Web, Bioinformatics and many other domains. However, logical reasoning that
ontologies can directly support are quite limited in learning, approximation
and prediction. One straightforward solution is to integrate statistical
analysis and machine learning. To this end, automatically learning vector
representation for knowledge of an ontology i.e., ontology embedding has been
widely investigated in recent years. Numerous papers have been published on
ontology embedding, but a lack of systematic reviews hinders researchers from
gaining a comprehensive understanding of this field. To bridge this gap, we
write this survey paper, which first introduces different kinds of semantics of
ontologies, and formally defines ontology embedding from the perspectives of
both mathematics and machine learning, as well as its property of faithfulness.
Based on this, it systematically categorises and analyses a relatively complete
set of over 80 papers, according to the ontologies and semantics that they aim
at, and their technical solutions including geometric modeling, sequence
modeling and graph propagation. This survey also introduces the applications of
ontology embedding in ontology engineering, machine learning augmentation and
life sciences, presents a new library mOWL, and discusses the challenges and
future directions."
SynthTree - Co-supervised Local Model Synthesis for Explainable Prediction,https://arxiv.org/abs/2406.10962,2024-06-16,2024-06-19,0.0,0.0,"Explainable machine learning (XML) has emerged as a major challenge in
artificial intelligence (AI). Although black-box models such as Deep Neural
Networks and Gradient Boosting often exhibit exceptional predictive accuracy,
their lack of interpretability is a notable drawback, particularly in domains
requiring transparency and trust. This paper tackles this core AI problem by
proposing a novel method to enhance explainability with minimal accuracy loss,
using a Mixture of Linear Models (MLM) estimated under the co-supervision of
black-box models. We have developed novel methods for estimating MLM by
leveraging AI techniques. Specifically, we explore two approaches for
partitioning the input space: agglomerative clustering and decision trees. The
agglomerative clustering approach provides greater flexibility in model
construction, while the decision tree approach further enhances explainability,
yielding a decision tree model with linear or logistic regression models at its
leaf nodes. Comparative analyses with widely-used and state-of-the-art
predictive models demonstrate the effectiveness of our proposed methods.
Experimental results show that statistical models can significantly enhance the
explainability of AI, thereby broadening their potential for real-world
applications. Our findings highlight the critical role that statistical
methodologies can play in advancing explainable AI."
Open-Vocabulary X-ray Prohibited Item Detection via Fine-tuning CLIP,https://arxiv.org/abs/2406.10961,2024-06-16,2024-06-19,0.0,0.0,"X-ray prohibited item detection is an essential component of security check
and categories of prohibited item are continuously increasing in accordance
with the latest laws. Previous works all focus on close-set scenarios, which
can only recognize known categories used for training and often require
time-consuming as well as labor-intensive annotations when learning novel
categories, resulting in limited real-world applications. Although the success
of vision-language models (e.g. CLIP) provides a new perspectives for open-set
X-ray prohibited item detection, directly applying CLIP to X-ray domain leads
to a sharp performance drop due to domain shift between X-ray data and general
data used for pre-training CLIP. To address aforementioned challenges, in this
paper, we introduce distillation-based open-vocabulary object detection (OVOD)
task into X-ray security inspection domain by extending CLIP to learn visual
representations in our specific X-ray domain, aiming to detect novel prohibited
item categories beyond base categories on which the detector is trained.
Specifically, we propose X-ray feature adapter and apply it to CLIP within OVOD
framework to develop OVXD model. X-ray feature adapter containing three adapter
submodules of bottleneck architecture, which is simple but can efficiently
integrate new knowledge of X-ray domain with original knowledge, further bridge
domain gap and promote alignment between X-ray images and textual concepts.
Extensive experiments conducted on PIXray and PIDray datasets demonstrate that
proposed method performs favorably against other baseline OVOD methods in
detecting novel categories in X-ray scenario. It outperforms previous best
result by 15.2 AP50 and 1.5 AP50 on PIXray and PIDray with achieving 21.0 AP50
and 27.8 AP50 respectively."
ESCoT - Towards Interpretable Emotional Support Dialogue Systems,https://arxiv.org/abs/2406.10960,2024-06-16,2024-06-19,0.0,0.0,"Understanding the reason for emotional support response is crucial for
establishing connections between users and emotional support dialogue systems.
Previous works mostly focus on generating better responses but ignore
interpretability, which is extremely important for constructing reliable
dialogue systems. To empower the system with better interpretability, we
propose an emotional support response generation scheme, named
$\textbf{E}$motion-Focused and $\textbf{S}$trategy-Driven
$\textbf{C}$hain-$\textbf{o}$f-$\textbf{T}$hought ($\textbf{ESCoT}$), mimicking
the process of $\textit{identifying}$, $\textit{understanding}$, and
$\textit{regulating}$ emotions. Specially, we construct a new dataset with
ESCoT in two steps: (1) $\textit{Dialogue Generation}$ where we first generate
diverse conversation situations, then enhance dialogue generation using richer
emotional support strategies based on these situations; (2) $\textit{Chain
Supplement}$ where we focus on supplementing selected dialogues with elements
such as emotion, stimuli, appraisal, and strategy reason, forming the manually
verified chains. Additionally, we further develop a model to generate dialogue
responses with better interpretability. We also conduct extensive experiments
and human evaluations to validate the effectiveness of the proposed ESCoT and
generated dialogue responses. Our data and code are available at
$\href{https://github.com/TeigenZhang/ESCoT}{https://github.com/TeigenZhang/ESCoT}$."
On Convergence and Rate of Convergence of Policy Improvement Algorithms,https://arxiv.org/abs/2406.10959,2024-06-16,2024-06-19,0.0,0.0,"In this paper we investigate the issues regarding the convergence of the
Policy Iteration Algorithm(PIA) for a class of general continuous-time
entropy-regularized stochastic control problems. In particular, instead of
employing sophisticated PDE estimates for the iterative PDEs involved in the
PIA (see, e.g., Huang-Wang-Zhou(2023)), we shall provide a simple proof from
scratch for the convergence of the PIA. Our approach builds on probabilistic
representation formulae for solutions of PDEs and their derivatives. Moreover,
in the infinite horizon model with large discount factor and in the finite
horizon model, the similar arguments lead to the exponential rate of
convergence of PIA without tear. Finally, with some extra efforts we show that
our approach can also be extended to the case when diffusion contains control,
in the one dimensional setting but without much extra constraints on the
coefficients. We believe that these results are new in the literature."
City-LEO - Toward Transparent City Management Using LLM with End-to-End Optimization,https://arxiv.org/abs/2406.10958,2024-06-16,2024-06-19,0.0,0.0,"Existing operations research (OR) models and tools play indispensable roles
in smart-city operations, yet their practical implementation is limited by the
complexity of modeling and deficiencies in optimization proficiency. To
generate more relevant and accurate solutions to users' requirements, we
propose a large language model (LLM)-based agent (""City-LEO"") that enhances the
efficiency and transparency of city management through conversational
interactions. Specifically, to accommodate diverse users' requirements and
enhance computational tractability, City-LEO leverages LLM's logical reasoning
capabilities on prior knowledge to scope down large-scale optimization problems
efficiently. In the human-like decision process, City-LEO also incorporates
End-to-end (E2E) model to synergize the prediction and optimization. The E2E
framework be conducive to coping with environmental uncertainties and involving
more query-relevant features, and then facilitates transparent and
interpretable decision-making process. In case study, we employ City-LEO in the
operations management of e-bike sharing (EBS) system. The numerical results
demonstrate that City-LEO has superior performance when benchmarks against the
full-scale optimization problem. With less computational time, City-LEO
generates more satisfactory and relevant solutions to the users' requirements,
and achieves lower global suboptimality without significantly compromising
accuracy. In a broader sense, our proposed agent offers promise to develop
LLM-embedded OR tools for smart-city operations management."
Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence,https://arxiv.org/abs/2406.10957,2024-06-16,2024-06-19,0.0,0.0,"Direct Preference Optimization (DPO) has emerged as a prominent algorithm for
the direct and robust alignment of Large Language Models (LLMs) with human
preferences, offering a more straightforward alternative to the complex
Reinforcement Learning from Human Feedback (RLHF). Despite its promising
efficacy, DPO faces a notable drawback: ""verbosity"", a common over-optimization
phenomenon also observed in RLHF. While previous studies mainly attributed
verbosity to biased labels within the data, we propose that the issue also
stems from an inherent algorithmic length reliance in DPO. Specifically, we
suggest that the discrepancy between sequence-level Kullback-Leibler (KL)
divergences between chosen and rejected sequences, used in DPO, results in
overestimated or underestimated rewards due to varying token lengths.
Empirically, we utilize datasets with different label lengths to demonstrate
the presence of biased rewards. We then introduce an effective downsampling
approach, named SamPO, to eliminate potential length reliance. Our experimental
evaluations, conducted across three LLMs of varying scales and a diverse array
of conditional and open-ended benchmarks, highlight the efficacy of SamPO in
mitigating verbosity, achieving improvements of 5% to 12% over DPO through
debaised rewards. Our codes can be accessed at:
https://github.com/LuJunru/SamPO/."
Mixture-of-Subspaces in Low-Rank Adaptation,https://arxiv.org/abs/2406.11909,2024-06-16,2024-06-19,0.0,0.0,"In this paper, we introduce a subspace-inspired Low-Rank Adaptation (LoRA)
method, which is computationally efficient, easy to implement, and readily
applicable to large language, multimodal, and diffusion models. Initially, we
equivalently decompose the weights of LoRA into two subspaces, and find that
simply mixing them can enhance performance. To study such a phenomenon, we
revisit it through a fine-grained subspace lens, showing that such modification
is equivalent to employing a fixed mixer to fuse the subspaces. To be more
flexible, we jointly learn the mixer with the original LoRA weights, and term
the method Mixture-of-Subspaces LoRA (MoSLoRA). MoSLoRA consistently
outperforms LoRA on tasks in different modalities, including commonsense
reasoning, visual instruction tuning, and subject-driven text-to-image
generation, demonstrating its effectiveness and robustness. Codes are available
at https://github.com/wutaiqiang/MoSLoRA."
Robust Channel Learning for Large-Scale Radio Speaker Verification,https://arxiv.org/abs/2406.10956,2024-06-16,2024-06-19,0.0,0.0,"Recent research in speaker verification has increasingly focused on achieving
robust and reliable recognition under challenging channel conditions and noisy
environments. Identifying speakers in radio communications is particularly
difficult due to inherent limitations such as constrained bandwidth and
pervasive noise interference. To address this issue, we present a Channel
Robust Speaker Learning (CRSL) framework that enhances the robustness of the
current speaker verification pipeline, considering data source, data
augmentation, and the efficiency of model transfer processes. Our framework
introduces an augmentation module that mitigates bandwidth variations in radio
speech datasets by manipulating the bandwidth of training inputs. It also
addresses unknown noise by introducing noise within the manifold space.
Additionally, we propose an efficient fine-tuning method that reduces the need
for extensive additional training time and large amounts of data. Moreover, we
develop a toolkit for assembling a large-scale radio speech corpus and
establish a benchmark specifically tailored for radio scenario speaker
verification studies. Experimental results demonstrate that our proposed
methodology effectively enhances performance and mitigates degradation caused
by radio transmission in speaker verification tasks. The code will be available
on Github."
Towards Efficient Target-Level Machine Unlearning Based on Essential Graph,https://arxiv.org/abs/2406.10954,2024-06-16,2024-06-19,0.0,0.0,"Machine unlearning is an emerging technology that has come to attract
widespread attention. A number of factors, including regulations and laws,
privacy, and usability concerns, have resulted in this need to allow a trained
model to forget some of its training data. Existing studies of machine
unlearning mainly focus on unlearning requests that forget a cluster of
instances or all instances from one class. While these approaches are effective
in removing instances, they do not scale to scenarios where partial targets
within an instance need to be forgotten. For example, one would like to only
unlearn a person from all instances that simultaneously contain the person and
other targets. Directly migrating instance-level unlearning to target-level
unlearning will reduce the performance of the model after the unlearning
process, or fail to erase information completely. To address these concerns, we
have proposed a more effective and efficient unlearning scheme that focuses on
removing partial targets from the model, which we name ""target unlearning"".
Specifically, we first construct an essential graph data structure to describe
the relationships between all important parameters that are selected based on
the model explanation method. After that, we simultaneously filter parameters
that are also important for the remaining targets and use the pruning-based
unlearning method, which is a simple but effective solution to remove
information about the target that needs to be forgotten. Experiments with
different training models on various datasets demonstrate the effectiveness of
the proposed approach."
Avoiding Copyright Infringement via Machine Unlearning,https://arxiv.org/abs/2406.10952,2024-06-16,2024-06-19,0.0,0.0,"Pre-trained Large Language Models (LLMs) have demonstrated remarkable
capabilities but also pose risks by learning and generating copyrighted
material, leading to significant legal and ethical concerns. To address these
issues, it is critical for model owners to be able to unlearn copyrighted
content at various time steps. We explore the setting of sequential unlearning,
where copyrighted content is removed over multiple time steps - a scenario that
has not been rigorously addressed. To tackle this challenge, we propose Stable
Sequential Unlearning (SSU), a novel unlearning framework for LLMs, designed to
have a more stable process to remove copyrighted content from LLMs throughout
different time steps using task vectors, by incorporating additional random
labeling loss and applying gradient-based weight saliency mapping. Experiments
demonstrate that SSU finds a good balance between unlearning efficacy and
maintaining the model's general knowledge compared to existing baselines."
E-Bench - Towards Evaluating the Ease-of-Use of Large Language Models,https://arxiv.org/abs/2406.10950,2024-06-16,2024-06-19,0.0,0.0,"Most large language models (LLMs) are sensitive to prompts, and another
synonymous expression or a typo may lead to unexpected results for the model.
Composing an optimal prompt for a specific demand lacks theoretical support and
relies entirely on human experimentation, which poses a considerable obstacle
to popularizing generative artificial intelligence. However, there is no
systematic analysis of the stability of LLMs in resisting prompt perturbations
in real-world scenarios. In this work, we propose to evaluate the ease-of-use
of LLMs and construct E-Bench, simulating the actual situation of human use
from synonymous perturbation (including paraphrasing, simplification, and
colloquialism) and typographical perturbation (such as typing). On this basis,
we also discuss the combination of these two types of perturbation and analyze
the main reasons for performance degradation. Experimental results indicate
that with the increase of model size, although the ease-of-use are
significantly improved, there is still a long way to go to build a sufficiently
user-friendly model."
Incorporating uncertainty quantification into travel mode choice modeling - a Bayesian neural network (BNN) approach and an uncertainty-guided active survey framework,https://arxiv.org/abs/2406.10948,2024-06-16,2024-06-19,0.0,0.0,"Existing deep learning approaches for travel mode choice modeling fail to
inform modelers about their prediction uncertainty. Even when facing scenarios
that are out of the distribution of training data, which implies high
prediction uncertainty, these approaches still provide deterministic answers,
potentially leading to misguidance. To address this limitation, this study
introduces the concept of uncertainty from the field of explainable artificial
intelligence into travel mode choice modeling. We propose a Bayesian neural
network-based travel mode prediction model (BTMP) that quantifies the
uncertainty of travel mode predictions, enabling the model itself to ""know"" and
""tell"" what it doesn't know. With BTMP, we further propose an
uncertainty-guided active survey framework, which dynamically formulates survey
questions representing travel mode choice scenarios with high prediction
uncertainty. Through iterative collection of responses to these dynamically
tailored survey questions, BTMP is iteratively trained to achieve the desired
accuracy faster with fewer questions, thereby reducing survey costs.
Experimental validation using synthetic datasets confirms the effectiveness of
BTMP in quantifying prediction uncertainty. Furthermore, experiments, utilizing
both synthetic and real-world data, demonstrate that the BTMP model, trained
with the uncertainty-guided active survey framework, requires 20% to 50% fewer
survey responses to match the performance of the model trained on randomly
collected survey data. Overall, the proposed BTMP model and active survey
framework innovatively incorporate uncertainty quantification into travel mode
choice modeling, providing model users with essential insights into prediction
reliability while optimizing data collection for deep learning model training
in a cost-efficient manner."
Effective Generative AI - The Human-Algorithm Centaur,https://arxiv.org/abs/2406.10942,2024-06-16,2024-06-19,0.0,0.0,"Advanced analytics science methods have enabled combining the power of
artificial and human intelligence, creating \textit{centaurs} that allow
superior decision-making. Centaurs are hybrid human-algorithm AI models that
combine both formal analytics and human intuition in a symbiotic manner within
their learning and reasoning process. We argue that the future of AI
development and use in many domains needs to focus on centaurs as opposed to
traditional AI approaches. This paradigm shift from traditional AI methods to
centaur-based AI methods raises some fundamental questions: How are centaurs
different from traditional human-in-the-loop methods? What are the most
effective methods for creating centaurs? When should centaurs be used, and when
should the lead be given to traditional AI models? Doesn't the incorporation of
human intuition -- which at times can be misleading -- in centaurs'
decision-making process degrade its performance compared to traditional AI
methods? This work aims to address these fundamental questions, focusing on
recent advancements in generative AI, and especially in Large Language Models
(LLMs), as a main case study to illustrate centaurs' critical essentiality to
future AI endeavors."
Towards augmented data quality management - Automation of Data Quality Rule Definition in Data Warehouses,https://arxiv.org/abs/2406.10940,2024-06-16,2024-06-19,0.0,0.0,"In the contemporary data-driven landscape, ensuring data quality (DQ) is
crucial for deriving actionable insights from vast data repositories. The
objective of this study is to explore the potential for automating data quality
management within data warehouses as data repository commonly used by large
organizations. By conducting a systematic review of existing DQ tools available
in the market and academic literature, the study assesses their capability to
automatically detect and enforce data quality rules. The review encompassed 151
tools from various sources, revealing that most current tools focus on data
cleansing and fixing in domain-specific databases rather than data warehouses.
Only a limited number of tools, specifically ten, demonstrated the capability
to detect DQ rules, not to mention implementing this in data warehouses. The
findings underscore a significant gap in the market and academic research
regarding AI-augmented DQ rule detection in data warehouses. This paper
advocates for further development in this area to enhance the efficiency of DQ
management processes, reduce human workload, and lower costs. The study
highlights the necessity of advanced tools for automated DQ rule detection,
paving the way for improved practices in data quality management tailored to
data warehouse environments. The study can guide organizations in selecting
data quality tool that would meet their requirements most."
Understanding Understanding - A Pragmatic Framework Motivated by Large Language Models,https://arxiv.org/abs/2406.10937,2024-06-16,2024-06-19,0.0,0.0,"Motivated by the rapid ascent of Large Language Models (LLMs) and debates
about the extent to which they possess human-level qualities, we propose a
framework for testing whether any agent (be it a machine or a human)
understands a subject matter. In Turing-test fashion, the framework is based
solely on the agent's performance, and specifically on how well it answers
questions. Elements of the framework include circumscribing the set of
questions (the ""scope of understanding""), requiring general competence
(""passing grade""), avoiding ""ridiculous answers"", but still allowing wrong and
""I don't know"" answers to some questions. Reaching certainty about these
conditions requires exhaustive testing of the questions which is impossible for
nontrivial scopes, but we show how high confidence can be achieved via random
sampling and the application of probabilistic confidence bounds. We also show
that accompanying answers with explanations can improve the sample complexity
required to achieve acceptable bounds, because an explanation of an answer
implies the ability to answer many similar questions. According to our
framework, current LLMs cannot be said to understand nontrivial domains, but as
the framework provides a practical recipe for testing understanding, it thus
also constitutes a tool for building AI agents that do understand."
Imperceptible Rhythm Backdoor Attacks - Exploring Rhythm Transformation for Embedding Undetectable Vulnerabilities on Speech Recognition,https://arxiv.org/abs/2406.10932,2024-06-16,2024-06-19,0.0,0.0,"Speech recognition is an essential start ring of human-computer interaction,
and recently, deep learning models have achieved excellent success in this
task. However, when the model training and private data provider are always
separated, some security threats that make deep neural networks (DNNs) abnormal
deserve to be researched. In recent years, the typical backdoor attacks have
been researched in speech recognition systems. The existing backdoor methods
are based on data poisoning. The attacker adds some incorporated changes to
benign speech spectrograms or changes the speech components, such as pitch and
timbre. As a result, the poisoned data can be detected by human hearing or
automatic deep algorithms. To improve the stealthiness of data poisoning, we
propose a non-neural and fast algorithm called Random Spectrogram Rhythm
Transformation (RSRT) in this paper. The algorithm combines four steps to
generate stealthy poisoned utterances. From the perspective of rhythm component
transformation, our proposed trigger stretches or squeezes the mel spectrograms
and recovers them back to signals. The operation keeps timbre and content
unchanged for good stealthiness. Our experiments are conducted on two kinds of
speech recognition tasks, including testing the stealthiness of poisoned
samples by speaker verification and automatic speech recognition. The results
show that our method has excellent effectiveness and stealthiness. The rhythm
trigger needs a low poisoning rate and gets a very high attack success rate."
Make Your Home Safe - Time-aware Unsupervised User Behavior Anomaly Detection in Smart Homes via Loss-guided Mask,https://arxiv.org/abs/2406.10928,2024-06-16,2024-06-19,0.0,0.0,"Smart homes, powered by the Internet of Things, offer great convenience but
also pose security concerns due to abnormal behaviors, such as improper
operations of users and potential attacks from malicious attackers. Several
behavior modeling methods have been proposed to identify abnormal behaviors and
mitigate potential risks. However, their performance often falls short because
they do not effectively learn less frequent behaviors, consider temporal
context, or account for the impact of noise in human behaviors. In this paper,
we propose SmartGuard, an autoencoder-based unsupervised user behavior anomaly
detection framework. First, we design a Loss-guided Dynamic Mask Strategy
(LDMS) to encourage the model to learn less frequent behaviors, which are often
overlooked during learning. Second, we propose a Three-level Time-aware
Position Embedding (TTPE) to incorporate temporal information into positional
embedding to detect temporal context anomaly. Third, we propose a Noise-aware
Weighted Reconstruction Loss (NWRL) that assigns different weights for routine
behaviors and noise behaviors to mitigate the interference of noise behaviors
during inference. Comprehensive experiments on three datasets with ten types of
anomaly behaviors demonstrates that SmartGuard consistently outperforms
state-of-the-art baselines and also offers highly interpretable results."
Investigating Video Reasoning Capability of Large Language Models with Tropes in Movies,https://arxiv.org/abs/2406.10923,2024-06-16,2024-06-19,0.0,0.0,"Large Language Models (LLMs) have demonstrated effectiveness not only in
language tasks but also in video reasoning. This paper introduces a novel
dataset, Tropes in Movies (TiM), designed as a testbed for exploring two
critical yet previously overlooked video reasoning skills: (1) Abstract
Perception: understanding and tokenizing abstract concepts in videos, and (2)
Long-range Compositional Reasoning: planning and integrating intermediate
reasoning steps for understanding long-range videos with numerous frames.
Utilizing tropes from movie storytelling, TiM evaluates the reasoning
capabilities of state-of-the-art LLM-based approaches. Our experiments show
that current methods, including Captioner-Reasoner, Large Multimodal Model
Instruction Fine-tuning, and Visual Programming, only marginally outperform a
random baseline when tackling the challenges of Abstract Perception and
Long-range Compositional Reasoning. To address these deficiencies, we propose
Face-Enhanced Viper of Role Interactions (FEVoRI) and Context Query Reduction
(ConQueR), which enhance Visual Programming by fostering role interaction
awareness and progressively refining movie contexts and trope queries during
reasoning processes, significantly improving performance by 15 F1 points.
However, this performance still lags behind human levels (40 vs. 65 F1).
Additionally, we introduce a new protocol to evaluate the necessity of Abstract
Perception and Long-range Compositional Reasoning for task resolution. This is
done by analyzing the code generated through Visual Programming using an
Abstract Syntax Tree (AST), thereby confirming the increased complexity of TiM.
The dataset and code are available at: https://ander1119.github.io/TiM"
Generating Tables from the Parametric Knowledge of Language Models,https://arxiv.org/abs/2406.10922,2024-06-16,2024-06-19,0.0,0.0,"We explore generating factual and accurate tables from the parametric
knowledge of large language models (LLMs). While LLMs have demonstrated
impressive capabilities in recreating knowledge bases and generating free-form
text, we focus on generating structured tabular data, which is crucial in
domains like finance and healthcare. We examine the table generation abilities
of four state-of-the-art LLMs: GPT-3.5, GPT-4, Llama2-13B, and Llama2-70B,
using three prompting methods for table generation: (a) full-table, (b)
row-by-row; (c) cell-by-cell. For evaluation, we introduce a novel benchmark,
WikiTabGen which contains 100 curated Wikipedia tables. Tables are further
processed to ensure their factual correctness and manually annotated with short
natural language descriptions. Our findings reveal that table generation
remains a challenge, with GPT-4 reaching the highest accuracy at 19.6%. Our
detailed analysis sheds light on how various table properties, such as size,
table popularity, and numerical content, influence generation performance. This
work highlights the unique challenges in LLM-based table generation and
provides a solid evaluation framework for future research. Our code, prompts
and data are all publicly available:
https://github.com/analysis-bots/WikiTabGen"
Hamilton-Jacobi Based Policy-Iteration via Deep Operator Learning,https://arxiv.org/abs/2406.10920,2024-06-16,2024-06-19,0.0,0.0,"The framework of deep operator network (DeepONet) has been widely exploited
thanks to its capability of solving high dimensional partial differential
equations. In this paper, we incorporate DeepONet with a recently developed
policy iteration scheme to numerically solve optimal control problems and the
corresponding Hamilton--Jacobi--Bellman (HJB) equations. A notable feature of
our approach is that once the neural network is trained, the solution to the
optimal control problem and HJB equations with different terminal functions can
be inferred quickly thanks to the unique feature of operator learning.
Furthermore, a quantitative analysis of the accuracy of the algorithm is
carried out via comparison principles of viscosity solutions. The effectiveness
of the method is verified with various examples, including 10-dimensional
linear quadratic regulator problems (LQRs)."
Embodied Question Answering via Multi-LLM Systems,https://arxiv.org/abs/2406.10918,2024-06-16,2024-06-19,0.0,0.0,"Embodied Question Answering (EQA) is an important problem, which involves an
agent exploring the environment to answer user queries. In the existing
literature, EQA has exclusively been studied in single-agent scenarios, where
exploration can be time-consuming and costly. In this work, we consider EQA in
a multi-agent framework involving multiple large language models (LLM) based
agents independently answering queries about a household environment. To
generate one answer for each query, we use the individual responses to train a
Central Answer Model (CAM) that aggregates responses for a robust answer. While
prior Question Answering (QA) work has used a central module based on answers
from multiple LLM-based experts, we specifically look at applying this
framework to embodied LLM-based agents that must physically explore the
environment first to become experts on their given environment to answer
questions. Our work is the first to utilize a central answer model framework
with embodied agents that must rely on exploring an unknown environment. We set
up a variation of EQA where instead of the agents exploring the environment
after the question is asked, the agents first explore the environment for a set
amount of time and then answer a set of queries. Using CAM, we observe a $46\%$
higher EQA accuracy when compared against aggregation methods for ensemble LLM,
such as voting schemes and debates. CAM does not require any form of agent
communication, alleviating it from the associated costs. We ablate CAM with
various nonlinear (neural network, random forest, decision tree, XGBoost) and
linear (logistic regression classifier, SVM) algorithms. We experiment in
various topological graph environments and examine the case where one of the
agents is malicious and purposes contribute responses it believes to be wrong."
Bayesian Intervention Optimization for Causal Discovery,https://arxiv.org/abs/2406.10917,2024-06-16,2024-06-19,0.0,0.0,"Causal discovery is crucial for understanding complex systems and informing
decisions. While observational data can uncover causal relationships under
certain assumptions, it often falls short, making active interventions
necessary. Current methods, such as Bayesian and graph-theoretical approaches,
do not prioritize decision-making and often rely on ideal conditions or
information gain, which is not directly related to hypothesis testing. We
propose a novel Bayesian optimization-based method inspired by Bayes factors
that aims to maximize the probability of obtaining decisive and correct
evidence. Our approach uses observational data to estimate causal models under
different hypotheses, evaluates potential interventions pre-experimentally, and
iteratively updates priors to refine interventions. We demonstrate the
effectiveness of our method through various experiments. Our contributions
provide a robust framework for efficient causal discovery through active
interventions, enhancing the practical application of theoretical advancements."
First-Order Manifold Data Augmentation for Regression Learning,https://arxiv.org/abs/2406.10914,2024-06-16,2024-06-19,0.0,0.0,"Data augmentation (DA) methods tailored to specific domains generate
synthetic samples by applying transformations that are appropriate for the
characteristics of the underlying data domain, such as rotations on images and
time warping on time series data. In contrast, domain-independent approaches,
e.g. mixup, are applicable to various data modalities, and as such they are
general and versatile. While regularizing classification tasks via DA is a
well-explored research topic, the effect of DA on regression problems received
less attention. To bridge this gap, we study the problem of domain-independent
augmentation for regression, and we introduce FOMA: a new data-driven
domain-independent data augmentation method. Essentially, our approach samples
new examples from the tangent planes of the train distribution. Augmenting data
in this way aligns with the network tendency towards capturing the dominant
features of its input signals. We evaluate FOMA on in-distribution
generalization and out-of-distribution robustness benchmarks, and we show that
it improves the generalization of several neural architectures. We also find
that strong baselines based on mixup are less effective in comparison to our
approach. Our code is publicly available
athttps://github.com/azencot-group/FOMA."
MICL - Improving In-Context Learning through Multiple-Label Words in Demonstration,https://arxiv.org/abs/2406.10908,2024-06-16,2024-06-19,0.0,0.0,"In-context learning (ICL) enables large language models (LLMs) to perform new
tasks by using sample-label pairs as demonstrations. However, variations in
demonstrations can lead to significantly different performances. Current
research mainly focuses on selecting demonstration samples, preassuming the
class name to be the label word when creating sample-label pairs. However, the
choice of label words is crucial for ICL performance. Besides, we observe that
using a single class name in demonstration may not yield optimal results while
using multiple label words in one sample-label pair can enhance ICL
performance. In this paper, we propose a comprehensive approach that organizes
both samples and labels in demonstrations based on LLMs' output space
distribution. This approach uses multiple label words in one sample-label pair
to enhance label instruction. Evaluation results from seven classification
datasets show that this demonstration organization method, which incorporates
multiple label words to provide diverse label information, improves ICL
performance."
Breaking the Attention Bottleneck,https://arxiv.org/abs/2406.10906,2024-06-16,2024-06-19,0.0,0.0,"Attention-based transformers have become the standard architecture in many
deep learning fields, primarily due to their ability to model long-range
dependencies and handle variable-length input sequences. However, the attention
mechanism with its quadratic complexity is a significant bottleneck in the
transformer architecture. This algorithm is only uni-directional in the decoder
and converges to a static pattern in over-parametrized decoder-only models. I
address this issue by developing a generative function as attention or
activation replacement. It still has the auto-regressive character by comparing
each token with the previous one. In my test setting with nanoGPT this yields a
smaller loss while having a smaller model. The loss further drops by
incorporating an average context vector. This concept of attention replacement
is distributed under the GNU AGPL v3 license at
https://gitlab.com/Bachstelze/causal_generation."
"New Solutions on LLM Acceleration, Optimization, and Application",https://arxiv.org/abs/2406.10903,2024-06-16,2024-06-19,0.0,0.0,"Large Language Models (LLMs) have become extremely potent instruments with
exceptional capacities for comprehending and producing human-like text in a
wide range of applications. However, the increasing size and complexity of LLMs
present significant challenges in both training and deployment, leading to
substantial computational and storage costs as well as heightened energy
consumption. In this paper, we provide a review of recent advancements and
research directions aimed at addressing these challenges and enhancing the
efficiency of LLM-based systems. We begin by discussing algorithm-level
acceleration techniques focused on optimizing LLM inference speed and resource
utilization. We also explore LLM-hardware co-design strategies with a vision to
improve system efficiency by tailoring hardware architectures to LLM
requirements. Further, we delve into LLM-to-accelerator compilation approaches,
which involve customizing hardware accelerators for efficient LLM deployment.
Finally, as a case study to leverage LLMs for assisting circuit design, we
examine LLM-aided design methodologies for an important task: High-Level
Synthesis (HLS) functional verification, by creating a new dataset that
contains a large number of buggy and bug-free codes, which can be essential for
training LLMs to specialize on HLS verification and debugging. For each aspect
mentioned above, we begin with a detailed background study, followed by the
presentation of several novel solutions proposed to overcome specific
challenges. We then outline future research directions to drive further
advancements. Through these efforts, we aim to pave the way for more efficient
and scalable deployment of LLMs across a diverse range of applications."
Light Up the Shadows - Enhance Long-Tailed Entity Grounding with Concept-Guided Vision-Language Models,https://arxiv.org/abs/2406.10902,2024-06-16,2024-06-19,0.0,0.0,"Multi-Modal Knowledge Graphs (MMKGs) have proven valuable for various
downstream tasks. However, scaling them up is challenging because building
large-scale MMKGs often introduces mismatched images (i.e., noise). Most
entities in KGs belong to the long tail, meaning there are few images of them
available online. This scarcity makes it difficult to determine whether a found
image matches the entity. To address this, we draw on the Triangle of Reference
Theory and suggest enhancing vision-language models with concept guidance.
Specifically, we introduce COG, a two-stage framework with COncept-Guided
vision-language models. The framework comprises a Concept Integration module,
which effectively identifies image-text pairs of long-tailed entities, and an
Evidence Fusion module, which offers explainability and enables human
verification. To demonstrate the effectiveness of COG, we create a dataset of
25k image-text pairs of long-tailed entities. Our comprehensive experiments
show that COG not only improves the accuracy of recognizing long-tailed
image-text pairs compared to baselines but also offers flexibility and
explainability."
Benchmarking Label Noise in Instance Segmentation - Spatial Noise Matters,https://arxiv.org/abs/2406.10891,2024-06-16,2024-06-19,0.0,0.0,"Obtaining accurate labels for instance segmentation is particularly
challenging due to the complex nature of the task. Each image necessitates
multiple annotations, encompassing not only the object's class but also its
precise spatial boundaries. These requirements elevate the likelihood of errors
and inconsistencies in both manual and automated annotation processes. By
simulating different noise conditions, we provide a realistic scenario for
assessing the robustness and generalization capabilities of instance
segmentation models in different segmentation tasks, introducing COCO-N and
Cityscapes-N. We also propose a benchmark for weakly annotation noise, dubbed
COCO-WAN, which utilizes foundation models and weak annotations to simulate
semi-automated annotation tools and their noisy labels. This study sheds light
on the quality of segmentation masks produced by various models and challenges
the efficacy of popular methods designed to address learning with label noise."
RWKU - Benchmarking Real-World Knowledge Unlearning for Large Language Models,https://arxiv.org/abs/2406.10890,2024-06-16,2024-06-19,0.0,0.0,"Large language models (LLMs) inevitably memorize sensitive, copyrighted, and
harmful knowledge from the training corpus; therefore, it is crucial to erase
this knowledge from the models. Machine unlearning is a promising solution for
efficiently removing specific knowledge by post hoc modifying models. In this
paper, we propose a Real-World Knowledge Unlearning benchmark (RWKU) for LLM
unlearning. RWKU is designed based on the following three key factors: (1) For
the task setting, we consider a more practical and challenging unlearning
setting, where neither the forget corpus nor the retain corpus is accessible.
(2) For the knowledge source, we choose 200 real-world famous people as the
unlearning targets and show that such popular knowledge is widely present in
various LLMs. (3) For the evaluation framework, we design the forget set and
the retain set to evaluate the model's capabilities across various real-world
applications. Regarding the forget set, we provide four four membership
inference attack (MIA) methods and nine kinds of adversarial attack probes to
rigorously test unlearning efficacy. Regarding the retain set, we assess
locality and utility in terms of neighbor perturbation, general ability,
reasoning ability, truthfulness, factuality, and fluency. We conduct extensive
experiments across two unlearning scenarios, two models and six baseline
methods and obtain some meaningful findings. We release our benchmark and code
publicly at http://rwku-bench.github.io for future work."
VELOCITI - Can Video-Language Models Bind Semantic Concepts through Time?,https://arxiv.org/abs/2406.10889,2024-06-16,2024-06-19,0.0,0.0,"Compositionality is a fundamental aspect of vision-language understanding and
is especially required for videos since they contain multiple entities (e.g.
persons, actions, and scenes) interacting dynamically over time. Existing
benchmarks focus primarily on perception capabilities. However, they do not
study binding, the ability of a model to associate entities through appropriate
relationships. To this end, we propose VELOCITI, a new benchmark building on
complex movie clips and dense semantic role label annotations to test
perception and binding in video language models (contrastive and Video-LLMs).
Our perception-based tests require discriminating video-caption pairs that
share similar entities, and the binding tests require models to associate the
correct entity to a given situation while ignoring the different yet plausible
entities that also appear in the same video. While current state-of-the-art
models perform moderately well on perception tests, accuracy is near random
when both entities are present in the same video, indicating that they fail at
binding tests. Even the powerful Gemini 1.5 Flash has a substantial gap
(16-28%) with respect to human accuracy in such binding tests."
Distilling Opinions at Scale - Incremental Opinion Summarization using XL-OPSUMM,https://arxiv.org/abs/2406.10886,2024-06-16,2024-06-19,0.0,0.0,"Opinion summarization in e-commerce encapsulates the collective views of
numerous users about a product based on their reviews. Typically, a product on
an e-commerce platform has thousands of reviews, each review comprising around
10-15 words. While Large Language Models (LLMs) have shown proficiency in
summarization tasks, they struggle to handle such a large volume of reviews due
to context limitations. To mitigate, we propose a scalable framework called
Xl-OpSumm that generates summaries incrementally. However, the existing test
set, AMASUM has only 560 reviews per product on average. Due to the lack of a
test set with thousands of reviews, we created a new test set called
Xl-Flipkart by gathering data from the Flipkart website and generating
summaries using GPT-4. Through various automatic evaluations and extensive
analysis, we evaluated the framework's efficiency on two datasets, AMASUM and
Xl-Flipkart. Experimental results show that our framework, Xl-OpSumm powered by
Llama-3-8B-8k, achieves an average ROUGE-1 F1 gain of 4.38% and a ROUGE-L F1
gain of 3.70% over the next best-performing model."
"On the Role of Entity and Event Level Conceptualization in Generalizable Reasoning - A Survey of Tasks, Methods, Applications, and Future Directions",https://arxiv.org/abs/2406.10885,2024-06-16,2024-06-19,0.0,0.0,"Entity- and event-level conceptualization, as fundamental elements of human
cognition, plays a pivotal role in generalizable reasoning. This process
involves abstracting specific instances into higher-level concepts and forming
abstract knowledge that can be applied in unfamiliar or novel situations, which
can enhance models' inferential capabilities and support the effective transfer
of knowledge across various domains. Despite its significance, there is
currently a lack of a systematic overview that comprehensively examines
existing works in the definition, execution, and application of
conceptualization to enhance reasoning tasks. In this paper, we address this
gap by presenting the first comprehensive survey of 150+ papers, categorizing
various definitions, resources, methods, and downstream applications related to
conceptualization into a unified taxonomy, with a focus on the entity and event
levels. Furthermore, we shed light on potential future directions in this field
and hope to garner more attention from the community."
SCAR - Efficient Instruction-Tuning for Large Language Models via Style Consistency-Aware Response Ranking,https://arxiv.org/abs/2406.10882,2024-06-16,2024-06-19,0.0,0.0,"Recent studies have shown that maintaining a consistent response style by
human experts and enhancing data quality in training sets can significantly
improve the performance of fine-tuned Large Language Models (LLMs) while
reducing the number of training examples needed. However, the precise
definition of style and the relationship between style, data quality, and LLM
performance remains unclear. This research identifies two key stylistic
elements in responses: linguistic form and semantic surprisal. We find that,
among training data of comparable quality, higher consistency in these response
elements leads to better LLM performance. Inspired by this, we introduce Style
Consistency-Aware Response Ranking (SCAR), which automatically prioritizes
instruction-response pairs in the training set based on their response
stylistic consistency. By selecting the most style-consistent examples,
sometimes as few as 0.7% of the full dataset, the fine-tuned LLMs can match or
even surpass the performance of models trained on the entire dataset in coding
and open-ended question-answering benchmarks. Code and data are available at
https://github.com/zhuang-li/SCAR ."
Teaching Large Language Models to Express Knowledge Boundary from Their Own Signals,https://arxiv.org/abs/2406.10881,2024-06-16,2024-06-19,0.0,0.0,"Large language models (LLMs) have achieved great success, but their
occasional content fabrication, or hallucination, limits their practical
application. Hallucination arises because LLMs struggle to admit ignorance due
to inadequate training on knowledge boundaries. We call it a limitation of LLMs
that they can not accurately express their knowledge boundary, answering
questions they know while admitting ignorance to questions they do not know. In
this paper, we aim to teach LLMs to recognize and express their knowledge
boundary, so they can reduce hallucinations caused by fabricating when they do
not know. We propose CoKE, which first probes LLMs' knowledge boundary via
internal confidence given a set of questions, and then leverages the probing
results to elicit the expression of the knowledge boundary. Extensive
experiments show CoKE helps LLMs express knowledge boundaries, answering known
questions while declining unknown ones, significantly improving in-domain and
out-of-domain performance."
Exploring the Potential of Multimodal LLM with Knowledge-Intensive Multimodal ASR,https://arxiv.org/abs/2406.10880,2024-06-16,2024-06-19,0.0,0.0,"Recent advancements in multimodal large language models (MLLMs) have made
significant progress in integrating information across various modalities, yet
real-world applications in educational and scientific domains remain
challenging. This paper introduces the Multimodal Scientific ASR (MS-ASR) task,
which focuses on transcribing scientific conference videos by leveraging visual
information from slides to enhance the accuracy of technical terminologies.
Realized that traditional metrics like WER fall short in assessing performance
accurately, prompting the proposal of severity-aware WER (SWER) that considers
the content type and severity of ASR errors. We propose the Scientific Vision
Augmented ASR (SciVASR) framework as a baseline method, enabling MLLMs to
improve transcript quality through post-editing. Evaluations of
state-of-the-art MLLMs, including GPT-4o, show a 45% improvement over
speech-only baselines, highlighting the importance of multimodal information
integration."
Demonstration Notebook - Finding the Most Suited In-Context Learning Example from Interactions,https://arxiv.org/abs/2406.10878,2024-06-16,2024-06-19,0.0,0.0,"Large language models (LLMs) benefit greatly from prompt engineering, with
in-context learning standing as a pivital technique. While former approaches
have provided various ways to construct the demonstrations used for in-context
learning, they often ignore the inherent heterogeneity within datasets,
applying the same demonstrations to all reasoning questions. We observed that
the effectiveness of demonstrations varies depending on the specific question.
This motivates our exploration of using prompt engineering to select
appropriate demonstrations. To address the challenge of automatically creating
and choosing demonstrations tailored to each question, we propose a novel
prompt engineering workflow built around a novel object called the
""demonstration notebook."" This notebook helps identify the most suitable
in-context learning example for a question by gathering and reusing information
from the LLM's past interactions. Our experiments show that this approach
outperforms all existing methods for automatic demonstration construction and
selection (as far as we know), achieving state-of-the-art results on serveral
reasoning benchmarks. The method's versatility is further demonstrated by its
success in text summarization and prompt compression tasks. Additionally, we
contribute a rigorous analysis method to reveal the ""demonstrative regime"" of a
demonstration, providing valuable insights into how demonstrations relate to
different question types within a dataset."
"Deep neural networks with ReLU, leaky ReLU, and softplus activation provably overcome the curse of dimensionality for space-time solutions of semilinear partial differential equations",https://arxiv.org/abs/2406.10876,2024-06-16,2024-06-19,0.0,0.0,"It is a challenging topic in applied mathematics to solve high-dimensional
nonlinear partial differential equations (PDEs). Standard approximation methods
for nonlinear PDEs suffer under the curse of dimensionality (COD) in the sense
that the number of computational operations of the approximation method grows
at least exponentially in the PDE dimension and with such methods it is
essentially impossible to approximately solve high-dimensional PDEs even when
the fastest currently available computers are used. However, in the last years
great progress has been made in this area of research through suitable deep
learning (DL) based methods for PDEs in which deep neural networks (DNNs) are
used to approximate solutions of PDEs. Despite the remarkable success of such
DL methods in simulations, it remains a fundamental open problem of research to
prove (or disprove) that such methods can overcome the COD in the approximation
of PDEs. However, there are nowadays several partial error analysis results for
DL methods for high-dimensional nonlinear PDEs in the literature which prove
that DNNs can overcome the COD in the sense that the number of parameters of
the approximating DNN grows at most polynomially in both the reciprocal of the
prescribed approximation accuracy $\varepsilon>0$ and the PDE dimension
$d\in\mathbb{N}$. In the main result of this article we prove that for all
$T,p\in(0,\infty)$ it holds that solutions
$u_d\colon[0,T]\times\mathbb{R}^d\to\mathbb{R}$, $d\in\mathbb{N}$, of
semilinear heat equations with Lipschitz continuous nonlinearities can be
approximated in the $L^p$-sense on space-time regions without the COD by DNNs
with the rectified linear unit (ReLU), the leaky ReLU, or the softplus
activation function. In previous articles similar results have been established
not for space-time regions but for the solutions $u_d(T,\cdot)$,
$d\in\mathbb{N}$, at the terminal time $T$."
Optimizing Automatic Speech Assessment - W-RankSim Regularization and Hybrid Feature Fusion Strategies,https://arxiv.org/abs/2406.10873,2024-06-16,2024-06-19,0.0,0.0,"Automatic Speech Assessment (ASA) has seen notable advancements with the
utilization of self-supervised features (SSL) in recent research. However, a
key challenge in ASA lies in the imbalanced distribution of data, particularly
evident in English test datasets. To address this challenge, we approach ASA as
an ordinal classification task, introducing Weighted Vectors Ranking Similarity
(W-RankSim) as a novel regularization technique. W-RankSim encourages closer
proximity of weighted vectors in the output layer for similar classes, implying
that feature vectors with similar labels would be gradually nudged closer to
each other as they converge towards corresponding weighted vectors. Extensive
experimental evaluations confirm the effectiveness of our approach in improving
ordinal classification performance for ASA. Furthermore, we propose a hybrid
model that combines SSL and handcrafted features, showcasing how the inclusion
of handcrafted features enhances performance in an ASA system."
Graph Neural Reaction Diffusion Models,https://arxiv.org/abs/2406.10871,2024-06-16,2024-06-19,0.0,0.0,"The integration of Graph Neural Networks (GNNs) and Neural Ordinary and
Partial Differential Equations has been extensively studied in recent years.
GNN architectures powered by neural differential equations allow us to reason
about their behavior, and develop GNNs with desired properties such as
controlled smoothing or energy conservation. In this paper we take inspiration
from Turing instabilities in a Reaction Diffusion (RD) system of partial
differential equations, and propose a novel family of GNNs based on neural RD
systems. We \textcolor{black}{demonstrate} that our RDGNN is powerful for the
modeling of various data types, from homophilic, to heterophilic, and
spatio-temporal datasets. We discuss the theoretical properties of our RDGNN,
its implementation, and show that it improves or offers competitive performance
to state-of-the-art methods."
Analyzing Key Neurons in Large Language Models,https://arxiv.org/abs/2406.10868,2024-06-16,2024-06-19,0.0,0.0,"Large Language Models (LLMs) possess vast amounts of knowledge within their
parameters, prompting research into methods for locating and editing this
knowledge. Previous work has largely focused on locating entity-related (often
single-token) facts in smaller models. However, several key questions remain
unanswered: (1) How can we effectively locate query-relevant neurons in
contemporary autoregressive LLMs, such as Llama and Mistral? (2) How can we
address the challenge of long-form text generation? (3) Are there localized
knowledge regions in LLMs? In this study, we introduce Query-Relevant Neuron
Cluster Attribution (QRNCA), a novel architecture-agnostic framework capable of
identifying query-relevant neurons in LLMs. QRNCA allows for the examination of
long-form answers beyond triplet facts by employing the proxy task of
multi-choice question answering. To evaluate the effectiveness of our detected
neurons, we build two multi-choice QA datasets spanning diverse domains and
languages. Empirical evaluations demonstrate that our method outperforms
baseline methods significantly. Further, analysis of neuron distributions
reveals the presence of visible localized regions, particularly within
different domains. Finally, we show potential applications of our detected
neurons in knowledge editing and neuron-based prediction."
Geometric-informed GFlowNets for Structure-Based Drug Design,https://arxiv.org/abs/2406.10867,2024-06-16,2024-06-19,0.0,0.0,"The rise of cost involved with drug discovery and current speed of which they
are discover, underscore the need for more efficient structure-based drug
design (SBDD) methods. We employ Generative Flow Networks (GFlowNets), to
effectively explore the vast combinatorial space of drug-like molecules, which
traditional virtual screening methods fail to cover. We introduce a novel
modification to the GFlowNet framework by incorporating trigonometrically
consistent embeddings, previously utilized in tasks involving protein
conformation and protein-ligand interactions, to enhance the model's ability to
generate molecules tailored to specific protein pockets. We have modified the
existing protein conditioning used by GFlowNets, blending geometric information
from both protein and ligand embeddings to achieve more geometrically
consistent embeddings. Experiments conducted using CrossDocked2020 demonstrated
an improvement in the binding affinity between generated molecules and protein
pockets for both single and multi-objective tasks, compared to previous work.
Additionally, we propose future work aimed at further increasing the geometric
information captured in protein-ligand interactions."
Global-Local Graph Neural Networks for Node-Classification,https://arxiv.org/abs/2406.10863,2024-06-16,2024-06-19,0.0,0.0,"The task of graph node classification is often approached by utilizing a
local Graph Neural Network (GNN), that learns only local information from the
node input features and their adjacency. In this paper, we propose to improve
the performance of node classification GNNs by utilizing both global and local
information, specifically by learning label- and node- features. We therefore
call our method Global-Local-GNN (GLGNN). To learn proper label features, for
each label, we maximize the similarity between its features and nodes features
that belong to the label, while maximizing the distance between nodes that do
not belong to the considered label. We then use the learnt label features to
predict the node classification map. We demonstrate our GLGNN using three
different GNN backbones, and show that our approach improves baseline
performance, revealing the importance of global information utilization for
node classification."
Knowledge Distillation in Federated Learning - a Survey on Long Lasting Challenges and New Solutions,https://arxiv.org/abs/2406.10861,2024-06-16,2024-06-19,0.0,0.0,"Federated Learning (FL) is a distributed and privacy-preserving machine
learning paradigm that coordinates multiple clients to train a model while
keeping the raw data localized. However, this traditional FL poses some
challenges, including privacy risks, data heterogeneity, communication
bottlenecks, and system heterogeneity issues. To tackle these challenges,
knowledge distillation (KD) has been widely applied in FL since 2020. KD is a
validated and efficacious model compression and enhancement algorithm. The core
concept of KD involves facilitating knowledge transfer between models by
exchanging logits at intermediate or output layers. These properties make KD an
excellent solution for the long-lasting challenges in FL. Up to now, there have
been few reviews that summarize and analyze the current trend and methods for
how KD can be applied in FL efficiently. This article aims to provide a
comprehensive survey of KD-based FL, focusing on addressing the above
challenges. First, we provide an overview of KD-based FL, including its
motivation, basics, taxonomy, and a comparison with traditional FL and where KD
should execute. We also analyze the critical factors in KD-based FL in the
appendix, including teachers, knowledge, data, and methods. We discuss how KD
can address the challenges in FL, including privacy protection, data
heterogeneity, communication efficiency, and personalization. Finally, we
discuss the challenges facing KD-based FL algorithms and future research
directions. We hope this survey can provide insights and guidance for
researchers and practitioners in the FL area."
Step-level Value Preference Optimization for Mathematical Reasoning,https://arxiv.org/abs/2406.10858,2024-06-16,2024-06-19,0.0,0.0,"Direct Preference Optimization (DPO) using an implicit reward model has
proven to be an effective alternative to reinforcement learning from human
feedback (RLHF) for fine-tuning preference aligned large language models
(LLMs). However, the overall preference annotations of responses do not fully
capture the fine-grained quality of model outputs in complex multi-step
reasoning tasks, such as mathematical reasoning. To address this limitation, we
introduce a novel algorithm called Step-level Value Preference Optimization
(SVPO). Our approach employs Monte Carlo Tree Search (MCTS) to automatically
annotate step-level preferences for multi-step reasoning. Furthermore, from the
perspective of learning-to-rank, we train an explicit value model to replicate
the behavior of the implicit reward model, complementing standard preference
optimization. This value model enables the LLM to generate higher reward
responses with minimal cost during inference. Experimental results demonstrate
that our method achieves state-of-the-art performance on both in-domain and
out-of-domain mathematical reasoning benchmarks. Our code is available at
\url{https://github.com/MARIO-Math-Reasoning/Super_MARIO}."
ALPS - An Auto-Labeling and Pre-training Scheme for Remote Sensing Segmentation With Segment Anything Model,https://arxiv.org/abs/2406.10855,2024-06-16,2024-06-19,0.0,0.0,"In the fast-growing field of Remote Sensing (RS) image analysis, the gap
between massive unlabeled datasets and the ability to fully utilize these
datasets for advanced RS analytics presents a significant challenge. To fill
the gap, our work introduces an innovative auto-labeling framework named ALPS
(Automatic Labeling for Pre-training in Segmentation), leveraging the Segment
Anything Model (SAM) to predict precise pseudo-labels for RS images without
necessitating prior annotations or additional prompts. The proposed pipeline
significantly reduces the labor and resource demands traditionally associated
with annotating RS datasets. By constructing two comprehensive pseudo-labeled
RS datasets via ALPS for pre-training purposes, our approach enhances the
performance of downstream tasks across various benchmarks, including iSAID and
ISPRS Potsdam. Experiments demonstrate the effectiveness of our framework,
showcasing its ability to generalize well across multiple tasks even under the
scarcity of extensively annotated datasets, offering a scalable solution to
automatic segmentation and annotation challenges in the field. In addition, the
proposed a pipeline is flexible and can be applied to medical image
segmentation, remarkably boosting the performance. Note that ALPS utilizes
pre-trained SAM to semi-automatically annotate RS images without additional
manual annotations. Though every component in the pipeline has bee well
explored, integrating clustering algorithms with SAM and novel pseudo-label
alignment significantly enhances RS segmentation, as an off-the-shelf tool for
pre-training data preparation. Our source code is available at:
https://github.com/StriveZs/ALPS."
IG2 - Integrated Gradient on Iterative Gradient Path for Feature Attribution,https://arxiv.org/abs/2406.10852,2024-06-16,2024-06-19,0.0,0.0,"Feature attribution explains Artificial Intelligence (AI) at the instance
level by providing importance scores of input features' contributions to model
prediction. Integrated Gradients (IG) is a prominent path attribution method
for deep neural networks, involving the integration of gradients along a path
from the explained input (explicand) to a counterfactual instance (baseline).
Current IG variants primarily focus on the gradient of explicand's output.
However, our research indicates that the gradient of the counterfactual output
significantly affects feature attribution as well. To achieve this, we propose
Iterative Gradient path Integrated Gradients (IG2), considering both gradients.
IG2 incorporates the counterfactual gradient iteratively into the integration
path, generating a novel path (GradPath) and a novel baseline (GradCF). These
two novel IG components effectively address the issues of attribution noise and
arbitrary baseline choice in earlier IG methods. IG2, as a path method,
satisfies many desirable axioms, which are theoretically justified in the
paper. Experimental results on XAI benchmark, ImageNet, MNIST, TREC questions
answering, wafer-map failure patterns, and CelebA face attributes validate that
IG2 delivers superior feature attributions compared to the state-of-the-art
techniques. The code is released at: https://github.com/JoeZhuo-ZY/IG2."
Leading Whitespaces of Language Models' Subword Vocabulary Poses a Confound for Calculating Word Probabilities,https://arxiv.org/abs/2406.10851,2024-06-16,2024-06-19,0.0,0.0,"Predictions of word-by-word conditional probabilities from Transformer-based
language models are often evaluated to model the incremental processing
difficulty of human readers. In this paper, we argue that there is a confound
posed by the most common method of aggregating subword probabilities of such
language models into word probabilities. This is due to the fact that tokens in
the subword vocabulary of most language models have leading whitespaces and
therefore do not naturally define stop probabilities of words. We first prove
that this can result in distributions over word probabilities that sum to more
than one, thereby violating the axiom that $\mathsf{P}(\Omega) = 1$. This
property results in a misallocation of word-by-word surprisal, where the
unacceptability of the end of the current word is incorrectly carried over to
the next word. Additionally, this implicit prediction of word boundaries
incorrectly models psycholinguistic experiments where human subjects directly
observe upcoming word boundaries. We present a simple decoding technique to
reaccount the probability of the trailing whitespace into that of the current
word, which resolves this confound. Experiments show that this correction
reveals lower estimates of garden-path effects in transitive/intransitive
sentences and poorer fits to naturalistic reading times."
TorchOpera - A Compound AI System for LLM Safety,https://arxiv.org/abs/2406.10847,2024-06-16,2024-06-19,0.0,0.0,"We introduce TorchOpera, a compound AI system for enhancing the safety and
quality of prompts and responses for Large Language Models. TorchOpera ensures
that all user prompts are safe, contextually grounded, and effectively
processed, while enhancing LLM responses to be relevant and high quality.
TorchOpera utilizes the vector database for contextual grounding, rule-based
wrappers for flexible modifications, and specialized mechanisms for detecting
and adjusting unsafe or incorrect content. We also provide a view of the
compound AI system to reduce the computational cost. Extensive experiments show
that TorchOpera ensures the safety, reliability, and applicability of LLMs in
real-world settings while maintaining the efficiency of LLM responses."
Enriching the Machine Learning Workloads in BigBench,https://arxiv.org/abs/2406.10843,2024-06-16,2024-06-19,0.0,0.0,"In the era of Big Data and the growing support for Machine Learning, Deep
Learning and Artificial Intelligence algorithms in the current software
systems, there is an urgent need of standardized application benchmarks that
stress test and evaluate these new technologies. Relying on the standardized
BigBench (TPCx-BB) benchmark, this work enriches the improved BigBench V2 with
three new workloads and expands the coverage of machine learning algorithms.
Our workloads utilize multiple algorithms and compare different implementations
for the same algorithm across several popular libraries like MLlib, SystemML,
Scikit-learn and Pandas, demonstrating the relevance and usability of our
benchmark extension."
Large Language Models for Automatic Milestone Detection in Group Discussions,https://arxiv.org/abs/2406.10842,2024-06-16,2024-06-19,0.0,0.0,"Large language models like GPT have proven widely successful on natural
language understanding tasks based on written text documents. In this paper, we
investigate an LLM's performance on recordings of a group oral communication
task in which utterances are often truncated or not well-formed. We propose a
new group task experiment involving a puzzle with several milestones that can
be achieved in any order. We investigate methods for processing transcripts to
detect if, when, and by whom a milestone has been completed. We demonstrate
that iteratively prompting GPT with transcription chunks outperforms semantic
similarity search methods using text embeddings, and further discuss the
quality and randomness of GPT responses under different context window sizes."
CBGBench - Fill in the Blank of Protein-Molecule Complex Binding Graph,https://arxiv.org/abs/2406.10840,2024-06-16,2024-06-19,0.0,0.0,"Structure-based drug design (SBDD) aims to generate potential drugs that can
bind to a target protein and is greatly expedited by the aid of AI techniques
in generative models. However, a lack of systematic understanding persists due
to the diverse settings, complex implementation, difficult reproducibility, and
task singularity. Firstly, the absence of standardization can lead to unfair
comparisons and inconclusive insights. To address this dilemma, we propose
CBGBench, a comprehensive benchmark for SBDD, that unifies the task as a
generative heterogeneous graph completion, analogous to fill-in-the-blank of
the 3D complex binding graph. By categorizing existing methods based on their
attributes, CBGBench facilitates a modular and extensible framework that
implements various cutting-edge methods. Secondly, a single task on \textit{de
novo} molecule generation can hardly reflect their capabilities. To broaden the
scope, we have adapted these models to a range of tasks essential in drug
design, which are considered sub-tasks within the graph fill-in-the-blank
tasks. These tasks include the generative designation of \textit{de novo}
molecules, linkers, fragments, scaffolds, and sidechains, all conditioned on
the structures of protein pockets. Our evaluations are conducted with fairness,
encompassing comprehensive perspectives on interaction, chemical properties,
geometry authenticity, and substructure validity. We further provide the
pre-trained versions of the state-of-the-art models and deep insights with
analysis from empirical studies. The codebase for CBGBench is publicly
accessible at \url{https://github.com/Edapinenut/CBGBench}."
Reminding Multimodal Large Language Models of Object-aware Knowledge with Retrieved Tags,https://arxiv.org/abs/2406.10839,2024-06-16,2024-06-19,0.0,0.0,"Despite recent advances in the general visual instruction-following ability
of Multimodal Large Language Models (MLLMs), they still struggle with critical
problems when required to provide a precise and detailed response to a visual
instruction: (1) failure to identify novel objects or entities, (2) mention of
non-existent objects, and (3) neglect of object's attributed details. Intuitive
solutions include improving the size and quality of data or using larger
foundation models. They show effectiveness in mitigating these issues, but at
an expensive cost of collecting a vast amount of new data and introducing a
significantly larger model. Standing at the intersection of these approaches,
we examine the three object-oriented problems from the perspective of the
image-to-text mapping process by the multimodal connector. In this paper, we
first identify the limitations of multimodal connectors stemming from
insufficient training data. Driven by this, we propose to enhance the mapping
with retrieval-augmented tag tokens, which contain rich object-aware
information such as object names and attributes. With our Tag-grounded visual
instruction tuning with retrieval Augmentation (TUNA), we outperform baselines
that share the same language model and training data on 12 benchmarks.
Furthermore, we show the zero-shot capability of TUNA when provided with
specific datastores."
Exposing the Achilles' Heel - Evaluating LLMs Ability to Handle Mistakes in Mathematical Reasoning,https://arxiv.org/abs/2406.10834,2024-06-16,2024-06-19,0.0,0.0,"Large Language Models (LLMs) have been applied to Math Word Problems (MWPs)
with transformative impacts, revolutionizing how these complex problems are
approached and solved in various domains including educational settings.
However, the evaluation of these models often prioritizes final accuracy,
overlooking the crucial aspect of reasoning capabilities. This work addresses
this gap by focusing on the ability of LLMs to detect and correct reasoning
mistakes. We introduce a novel dataset MWP-MISTAKE, incorporating MWPs with
both correct and incorrect reasoning steps generated through rule-based methods
and smaller language models. Our comprehensive benchmarking reveals significant
insights into the strengths and weaknesses of state-of-the-art models, such as
GPT-4o, GPT-4, GPT-3.5Turbo, and others. We highlight GPT-$o's superior
performance in mistake detection and rectification and the persistent
challenges faced by smaller models. Additionally, we identify issues related to
data contamination and memorization, impacting the reliability of LLMs in
real-world applications. Our findings emphasize the importance of rigorous
evaluation of reasoning processes and propose future directions to enhance the
generalization and robustness of LLMs in mathematical problem-solving."
A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery,https://arxiv.org/abs/2406.10833,2024-06-16,2024-06-19,0.0,0.0,"In many scientific fields, large language models (LLMs) have revolutionized
the way text and other modalities of data (e.g., molecules and proteins) are
handled, achieving superior performance in various applications and augmenting
the scientific discovery process. Nevertheless, previous surveys on scientific
LLMs often concentrate on one or two fields or a single modality. In this
paper, we aim to provide a more holistic view of the research landscape by
unveiling cross-field and cross-modal connections between scientific LLMs
regarding their architectures and pre-training techniques. To this end, we
comprehensively survey over 260 scientific LLMs, discuss their commonalities
and differences, as well as summarize pre-training datasets and evaluation
tasks for each field and modality. Moreover, we investigate how LLMs have been
deployed to benefit scientific discovery. Resources related to this survey are
available at https://github.com/yuzhimanhua/Awesome-Scientific-Language-Models."
Design and Optimization of Hierarchical Gradient Coding for Distributed Learning at Edge Devices,https://arxiv.org/abs/2406.10831,2024-06-16,2024-06-19,0.0,0.0,"Edge computing has recently emerged as a promising paradigm to boost the
performance of distributed learning by leveraging the distributed resources at
edge nodes. Architecturally, the introduction of edge nodes adds an additional
intermediate layer between the master and workers in the original distributed
learning systems, potentially leading to more severe straggler effect.
Recently, coding theory-based approaches have been proposed for stragglers
mitigation in distributed learning, but the majority focus on the conventional
workers-master architecture. In this paper, along a different line, we
investigate the problem of mitigating the straggler effect in hierarchical
distributed learning systems with an additional layer composed of edge nodes.
Technically, we first derive the fundamental trade-off between the
computational loads of workers and the stragglers tolerance. Then, we propose a
hierarchical gradient coding framework, which provides better stragglers
mitigation, to achieve the derived computational trade-off. To further improve
the performance of our framework in heterogeneous scenarios, we formulate an
optimization problem with the objective of minimizing the expected execution
time for each iteration in the learning process. We develop an efficient
algorithm to mathematically solve the problem by outputting the optimum
strategy. Extensive simulation results demonstrate the superiority of our
schemes compared with conventional solutions."
Citation-Based Summarization of Landmark Judgments,https://arxiv.org/abs/2406.10824,2024-06-16,2024-06-19,0.0,0.0,"Landmark judgments are of prime importance in the Common Law System because
of their exceptional jurisprudence and frequent references in other judgments.
In this work, we leverage contextual references available in citing judgments
to create an extractive summary of the target judgment. We evaluate the
proposed algorithm on two datasets curated from the judgments of Indian Courts
and find the results promising."
Iterated Schrdinger bridge approximation to Wasserstein Gradient Flows,https://arxiv.org/abs/2406.10823,2024-06-16,2024-06-19,0.0,0.0,"We introduce a novel discretization scheme for Wasserstein gradient flows
that involves successively computing Schr\""{o}dinger bridges with the same
marginals. This is different from both the forward/geodesic approximation and
the backward/Jordan-Kinderlehrer-Otto (JKO) approximations. The proposed scheme
has two advantages: one, it avoids the use of the score function, and, two, it
is amenable to particle-based approximations using the Sinkhorn algorithm. Our
proof hinges upon showing that relative entropy between the Schr\""{o}dinger
bridge with the same marginals at temperature $\epsilon$ and the joint
distribution of a stationary Langevin diffusion at times zero and $\epsilon$ is
of the order $o(\epsilon^2)$ with an explicit dependence given by Fisher
information. Owing to this inequality, we can show, using a triangular
approximation argument, that the interpolated iterated application of the
Schr\""{o}dinger bridge approximation converge to the Wasserstein gradient flow,
for a class of gradient flows, including the heat flow. The results also
provide a probabilistic and rigorous framework for the convergence of the
self-attention mechanisms in transformer networks to the solutions of heat
flows, first observed in the inspiring work SABP22 in machine learning
research."
Optimization of Armv9 architecture general large language model inference performance based on Llama.cpp,https://arxiv.org/abs/2406.10816,2024-06-16,2024-06-19,0.0,0.0,"This article optimizes the inference performance of the Qwen-1.8B model by
performing Int8 quantization, vectorizing some operators in llama.cpp, and
modifying the compilation script to improve the compiler optimization level. On
the Yitian 710 experimental platform, the prefill performance is increased by
1.6 times, the decoding performance is increased by 24 times, the memory usage
is reduced to 1/5 of the original, and the accuracy loss is almost negligible."
On the Effectiveness of Supervision in Asymmetric Non-Contrastive Learning,https://arxiv.org/abs/2406.10815,2024-06-16,2024-06-19,0.0,0.0,"Supervised contrastive representation learning has been shown to be effective
in various transfer learning scenarios. However, while asymmetric
non-contrastive learning (ANCL) often outperforms its contrastive learning
counterpart in self-supervised representation learning, the extension of ANCL
to supervised scenarios is less explored. To bridge the gap, we study ANCL for
supervised representation learning, coined SupSiam and SupBYOL, leveraging
labels in ANCL to achieve better representations. The proposed supervised ANCL
framework improves representation learning while avoiding collapse. Our
analysis reveals that providing supervision to ANCL reduces intra-class
variance, and the contribution of supervision should be adjusted to achieve the
best performance. Experiments demonstrate the superiority of supervised ANCL
across various datasets and tasks. The code is available at:
https://github.com/JH-Oh-23/Sup-ANCL."
Self-Evolution Fine-Tuning for Policy Optimization,https://arxiv.org/abs/2406.10813,2024-06-16,2024-06-19,0.0,0.0,"The alignment of large language models (LLMs) is crucial not only for
unlocking their potential in specific tasks but also for ensuring that
responses meet human expectations and adhere to safety and ethical principles.
Current alignment methodologies face considerable challenges. For instance,
supervised fine-tuning (SFT) requires extensive, high-quality annotated
samples, while reinforcement learning from human feedback (RLHF) is complex and
often unstable. In this paper, we introduce self-evolution fine-tuning (SEFT)
for policy optimization, with the aim of eliminating the need for annotated
samples while retaining the stability and efficiency of SFT. SEFT first trains
an adaptive reviser to elevate low-quality responses while maintaining
high-quality ones. The reviser then gradually guides the policy's optimization
by fine-tuning it with enhanced responses. One of the prominent features of
this method is its ability to leverage unlimited amounts of unannotated data
for policy optimization through supervised fine-tuning. Our experiments on
AlpacaEval 2.0 and MT-Bench demonstrate the effectiveness of SEFT. We also
provide a comprehensive analysis of its advantages over existing alignment
techniques."
LLMFactor - Extracting Profitable Factors through Prompts for Explainable Stock Movement Prediction,https://arxiv.org/abs/2406.10811,2024-06-16,2024-06-19,0.0,0.0,"Recently, Large Language Models (LLMs) have attracted significant attention
for their exceptional performance across a broad range of tasks, particularly
in text analysis. However, the finance sector presents a distinct challenge due
to its dependence on time-series data for complex forecasting tasks. In this
study, we introduce a novel framework called LLMFactor, which employs
Sequential Knowledge-Guided Prompting (SKGP) to identify factors that influence
stock movements using LLMs. Unlike previous methods that relied on keyphrases
or sentiment analysis, this approach focuses on extracting factors more
directly related to stock market dynamics, providing clear explanations for
complex temporal changes. Our framework directs the LLMs to create background
knowledge through a fill-in-the-blank strategy and then discerns potential
factors affecting stock prices from related news. Guided by background
knowledge and identified factors, we leverage historical stock prices in
textual format to predict stock movement. An extensive evaluation of the
LLMFactor framework across four benchmark datasets from both the U.S. and
Chinese stock markets demonstrates its superiority over existing
state-of-the-art methods and its effectiveness in financial time-series
forecasting."
Post-hoc Utterance Refining Method by Entity Mining for Faithful Knowledge Grounded Conversations,https://arxiv.org/abs/2406.10809,2024-06-16,2024-06-19,0.0,0.0,"Despite the striking advances in recent language generation performance,
model-generated responses have suffered from the chronic problem of
hallucinations that are either untrue or unfaithful to a given source.
Especially in the task of knowledge grounded conversation, the models are
required to generate informative responses, but hallucinated utterances lead to
miscommunication. In particular, entity-level hallucination that causes
critical misinformation and undesirable conversation is one of the major
concerns. To address this issue, we propose a post-hoc refinement method called
REM. It aims to enhance the quality and faithfulness of hallucinated utterances
by refining them based on the source knowledge. If the generated utterance has
a low source-faithfulness score with the given knowledge, REM mines the key
entities in the knowledge and implicitly uses them for refining the utterances.
We verify that our method reduces entity hallucination in the utterance. Also,
we show the adaptability and efficacy of REM with extensive experiments and
generative results. Our code is available at https://github.com/YOONNAJANG/REM."
Diffusion Model With Optimal Covariance Matching,https://arxiv.org/abs/2406.10808,2024-06-16,2024-06-19,0.0,0.0,"The probabilistic diffusion model has become highly effective across various
domains. Typically, sampling from a diffusion model involves using a denoising
distribution characterized by a Gaussian with a learned mean and either fixed
or learned covariances. In this paper, we leverage the recently proposed full
covariance moment matching technique and introduce a novel method for learning
covariances. Unlike traditional data-driven covariance approximation
approaches, our method involves directly regressing the optimal analytic
covariance using a new, unbiased objective named Optimal Covariance Matching
(OCM). This approach can significantly reduce the approximation error in
covariance prediction. We demonstrate how our method can substantially enhance
the sampling efficiency of both Markovian (DDPM) and non-Markovian (DDIM)
diffusion model families."
Bayesian Networks and Machine Learning for COVID-19 Severity Explanation and Demographic Symptom Classification,https://arxiv.org/abs/2406.10807,2024-06-16,2024-06-19,0.0,0.0,"With the prevailing efforts to combat the coronavirus disease 2019 (COVID-19)
pandemic, there are still uncertainties that are yet to be discovered about its
spread, future impact, and resurgence. In this paper, we present a three-stage
data-driven approach to distill the hidden information about COVID-19. The
first stage employs a Bayesian network structure learning method to identify
the causal relationships among COVID-19 symptoms and their intrinsic
demographic variables. As a second stage, the output from the Bayesian network
structure learning, serves as a useful guide to train an unsupervised machine
learning (ML) algorithm that uncovers the similarities in patients' symptoms
through clustering. The final stage then leverages the labels obtained from
clustering to train a demographic symptom identification (DSID) model which
predicts a patient's symptom class and the corresponding demographic
probability distribution. We applied our method on the COVID-19 dataset
obtained from the Centers for Disease Control and Prevention (CDC) in the
United States. Results from the experiments show a testing accuracy of 99.99%,
as against the 41.15% accuracy of a heuristic ML method. This strongly reveals
the viability of our Bayesian network and ML approach in understanding the
relationship between the virus symptoms, and providing insights on patients'
stratification towards reducing the severity of the virus."
ptt5-v2 - A Closer Look at Continued Pretraining of T5 Models for the Portuguese Language,https://arxiv.org/abs/2406.10806,2024-06-16,2024-06-19,0.0,0.0,"Despite advancements in Natural Language Processing (NLP) and the growing
availability of pretrained models, the English language remains the primary
focus of model development. Continued pretraining on language-specific corpora
provides a practical solution for adapting models to other languages. However,
the impact of different pretraining settings on downstream tasks remains
underexplored. This work introduces $\texttt{ptt5-v2}$, investigating the
continued pretraining of T5 models for Portuguese. We first develop a baseline
set of settings and pretrain models with sizes up to 3B parameters. Finetuning
on three Portuguese downstream tasks (assin2 STS, assin2 RTE, and TweetSentBR)
yields SOTA results on the latter two. We then explore the effects of different
pretraining configurations, including quality filters, optimization strategies,
and multi-epoch pretraining. Perhaps surprisingly, their impact remains subtle
compared to our baseline. We release $\texttt{ptt5-v2}$ pretrained checkpoints
and the finetuned MonoT5 rerankers on HuggingFace at
https://huggingface.co/collections/unicamp-dl/ptt5-v2-666538a650188ba00aa8d2d0
and
https://huggingface.co/collections/unicamp-dl/monoptt5-66653981877df3ea727f720d."
HiddenTables & PyQTax - A Cooperative Game and Dataset For TableQA to Ensure Scale and Data Privacy Across a Myriad of Taxonomies,https://arxiv.org/abs/2406.10803,2024-06-16,2024-06-19,0.0,0.0,"A myriad of different Large Language Models (LLMs) face a common challenge in
contextually analyzing table question-answering tasks. These challenges are
engendered from (1) finite context windows for large tables, (2) multi-faceted
discrepancies amongst tokenization patterns against cell boundaries, and (3)
various limitations stemming from data confidentiality in the process of using
external models such as gpt-3.5-turbo. We propose a cooperative game dubbed
""HiddenTables"" as a potential resolution to this challenge. In essence,
""HiddenTables"" is played between the code-generating LLM ""Solver"" and the
""Oracle"" which evaluates the ability of the LLM agents to solve Table QA tasks.
This game is based on natural language schemas and importantly, ensures the
security of the underlying data. We provide evidential experiments on a diverse
set of tables that demonstrate an LLM's collective inability to generalize and
perform on complex queries, handle compositional dependencies, and align
natural language to programmatic commands when concrete table schemas are
provided. Unlike encoder-based models, we have pushed the boundaries of
""HiddenTables"" to not be limited by the number of rows - therefore we exhibit
improved efficiency in prompt and completion tokens. Our infrastructure has
spawned a new dataset ""PyQTax"" that spans across 116,671 question-table-answer
triplets and provides additional fine-grained breakdowns & labels for varying
question taxonomies. Therefore, in tandem with our academic contributions
regarding LLMs' deficiency in TableQA tasks, ""HiddenTables"" is a tactile
manifestation of how LLMs can interact with massive datasets while ensuring
data security and minimizing generation costs."
KGPA - Robustness Evaluation for Large Language Models via Cross-Domain Knowledge Graphs,https://arxiv.org/abs/2406.10802,2024-06-16,2024-06-19,0.0,0.0,"Existing frameworks for assessing robustness of large language models (LLMs)
overly depend on specific benchmarks, increasing costs and failing to evaluate
performance of LLMs in professional domains due to dataset limitations. This
paper proposes a framework that systematically evaluates the robustness of LLMs
under adversarial attack scenarios by leveraging knowledge graphs (KGs). Our
framework generates original prompts from the triplets of knowledge graphs and
creates adversarial prompts by poisoning, assessing the robustness of LLMs
through the results of these adversarial attacks. We systematically evaluate
the effectiveness of this framework and its modules. Experiments show that
adversarial robustness of the ChatGPT family ranks as GPT-4-turbo > GPT-4o >
GPT-3.5-turbo, and the robustness of large language models is influenced by the
professional domains in which they operate."
Federated Learning Optimization - A Comparative Study of Data and Model Exchange Strategies in Dynamic Networks,https://arxiv.org/abs/2406.10798,2024-06-16,2024-06-19,0.0,0.0,"The promise and proliferation of large-scale dynamic federated learning gives
rise to a prominent open question - is it prudent to share data or model across
nodes, if efficiency of transmission and fast knowledge transfer are the prime
objectives. This work investigates exactly that. Specifically, we study the
choices of exchanging raw data, synthetic data, or (partial) model updates
among devices. The implications of these strategies in the context of
foundational models are also examined in detail. Accordingly, we obtain key
insights about optimal data and model exchange mechanisms considering various
environments with different data distributions and dynamic device and network
connections. Across various scenarios that we considered, time-limited
knowledge transfer efficiency can differ by up to 9.08\%, thus highlighting the
importance of this work."
Diffusion Models Are Promising for Ab Initio Structure Solutions from Nanocrystalline Powder Diffraction Data,https://arxiv.org/abs/2406.10796,2024-06-16,2024-06-19,0.0,0.0,"A major challenge in materials science is the determination of the structure
of nanometer sized objects. Here we present a novel approach that uses a
generative machine learning model based on a Diffusion model that is trained on
45,229 known structures. The model factors both the measured diffraction
pattern as well as relevant statistical priors on the unit cell of atomic
cluster structures. Conditioned only on the chemical formula and the
information-scarce finite-size broadened powder diffraction pattern, we find
that our model, PXRDnet, can successfully solve simulated nanocrystals as small
as 10 angstroms across 200 materials of varying symmetry and complexity,
including structures from all seven crystal systems. We show that our model can
determine structural solutions with up to $81.5\%$ accuracy, as measured by
structural correlation. Furthermore, PXRDnet is capable of solving structures
from noisy diffraction patterns gathered in real-world experiments. We suggest
that data driven approaches, bootstrapped from theoretical simulation, will
ultimately provide a path towards determining the structure of previously
unsolved nano-materials."
Improving Reward-Conditioned Policies for Multi-Armed Bandits using Normalized Weight Functions,https://arxiv.org/abs/2406.10795,2024-06-16,2024-06-19,0.0,0.0,"Recently proposed reward-conditioned policies (RCPs) offer an appealing
alternative in reinforcement learning. Compared with policy gradient methods,
policy learning in RCPs is simpler since it is based on supervised learning,
and unlike value-based methods, it does not require optimization in the action
space to take actions. However, for multi-armed bandit (MAB) problems, we find
that RCPs are slower to converge and have inferior expected rewards at
convergence, compared with classic methods such as the upper confidence bound
and Thompson sampling. In this work, we show that the performance of RCPs can
be enhanced by constructing policies through the marginalization of rewards
using normalized weight functions, whose sum or integral equal $1$, although
the function values may be negative. We refer to this technique as generalized
marginalization, whose advantage is that negative weights for policies
conditioned on low rewards can make the resulting policies more distinct from
them. Strategies to perform generalized marginalization in MAB with discrete
action spaces are studied. Through simulations, we demonstrate that the
proposed technique improves RCPs and makes them competitive with classic
methods, showing superior performance on challenging MABs with large action
spaces and sparse reward signals."
Towards Understanding Jailbreak Attacks in LLMs - A Representation Space Analysis,https://arxiv.org/abs/2406.10794,2024-06-16,2024-06-19,0.0,0.0,"Large language models (LLMs) are susceptible to a type of attack known as
jailbreaking, which misleads LLMs to output harmful contents. Although there
are diverse jailbreak attack strategies, there is no unified understanding on
why some methods succeed and others fail. This paper explores the behavior of
harmful and harmless prompts in the LLM's representation space to investigate
the intrinsic properties of successful jailbreak attacks. We hypothesize that
successful attacks share some similar properties: They are effective in moving
the representation of the harmful prompt towards the direction to the harmless
prompts. We leverage hidden representations into the objective of existing
jailbreak attacks to move the attacks along the acceptance direction, and
conduct experiments to validate the above hypothesis using the proposed
objective. We hope this study provides new insights into understanding how LLMs
understand harmfulness information."
Evidential Uncertainty Sets in Deep Classifiers Using Conformal Prediction,https://arxiv.org/abs/2406.10787,2024-06-16,2024-06-19,0.0,0.0,"In this paper, we propose Evidential Conformal Prediction (ECP) method for
image classifiers to generate the conformal prediction sets. Our method is
designed based on a non-conformity score function that has its roots in
Evidential Deep Learning (EDL) as a method of quantifying model (epistemic)
uncertainty in DNN classifiers. We use evidence that are derived from the logit
values of target labels to compute the components of our non-conformity score
function: the heuristic notion of uncertainty in CP, uncertainty surprisal, and
expected utility. Our extensive experimental evaluation demonstrates that ECP
outperforms three state-of-the-art methods for generating CP sets, in terms of
their set sizes and adaptivity while maintaining the coverage of true labels."
Evaluating LLMs with Multiple Problems at once - A New Paradigm for Probing LLM Capabilities,https://arxiv.org/abs/2406.10786,2024-06-16,2024-06-19,0.0,0.0,"Current LLM evaluation predominantly performs evaluation with prompts
comprising single problems. We propose multi-problem evaluation as an
additional approach to study the multiple problem handling capabilities of
LLMs. We present a systematic study in this regard by comprehensively examining
7 LLMs on 4 related types of tasks constructed from 6 classification
benchmarks. The 4 task types include traditional single-problem tasks,
homogeneous multi-problem tasks, and two index selection tasks that embed the
multi-problem tasks. We find that LLMs are competent multi-problem solvers:
they generally perform (nearly) as well on multi-problem tasks as on
single-problem tasks. Furthermore, contrary to common expectation, they often
do not suffer from a positional bias with long inputs. This makes multi-problem
prompting a simple and cost-efficient prompting method of practical
significance. However, our results also strongly indicate that LLMs lack true
understanding: they perform significantly worse in the two index selection
tasks than in the multi-problem task under various evaluation settings,
although they can indeed do index selection in general."
ShareLoRA - Parameter Efficient and Robust Large Language Model Fine-tuning via Shared Low-Rank Adaptation,https://arxiv.org/abs/2406.10785,2024-06-16,2024-06-19,0.0,0.0,"This study introduces an approach to optimize Parameter Efficient Fine Tuning
(PEFT) for Pretrained Language Models (PLMs) by implementing a Shared Low Rank
Adaptation (ShareLoRA). By strategically deploying ShareLoRA across different
layers and adapting it for the Query, Key, and Value components of
self-attention layers, we achieve a substantial reduction in the number of
training parameters and memory usage. Importantly, ShareLoRA not only maintains
model performance but also exhibits robustness in both classification and
generation tasks across a variety of models, including RoBERTa, GPT-2, LLaMA
and LLaMA2. It demonstrates superior transfer learning capabilities compared to
standard LoRA applications and mitigates overfitting by sharing weights across
layers. Our findings affirm that ShareLoRA effectively boosts parameter
efficiency while ensuring scalable and high-quality performance across
different language model architectures."
RoseLoRA - Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning,https://arxiv.org/abs/2406.10777,2024-06-16,2024-06-19,0.0,0.0,"Pre-trained language models, trained on large-scale corpora, demonstrate
strong generalizability across various NLP tasks. Fine-tuning these models for
specific tasks typically involves updating all parameters, which is
resource-intensive. Parameter-efficient fine-tuning (PEFT) methods, such as the
popular LoRA family, introduce low-rank matrices to learn only a few parameters
efficiently. However, during inference, the product of these matrices updates
all pre-trained parameters, complicating tasks like knowledge editing that
require selective updates. We propose a novel PEFT method, which conducts
\textbf{r}ow and c\textbf{o}lumn-wise spar\textbf{se}
\textbf{lo}w-\textbf{r}ank \textbf{a}daptation (RoseLoRA), to address this
challenge. RoseLoRA identifies and updates only the most important parameters
for a specific task, maintaining efficiency while preserving other model
knowledge. By adding a sparsity constraint on the product of low-rank matrices
and converting it to row and column-wise sparsity, we ensure efficient and
precise model updates. Our theoretical analysis guarantees the lower bound of
the sparsity with respective to the matrix product. Extensive experiments on
five benchmarks across twenty datasets demonstrate that RoseLoRA outperforms
baselines in both general fine-tuning and knowledge editing tasks."
A Rate-Distortion View of Uncertainty Quantification,https://arxiv.org/abs/2406.10775,2024-06-16,2024-06-19,0.0,0.0,"In supervised learning, understanding an input's proximity to the training
data can help a model decide whether it has sufficient evidence for reaching a
reliable prediction. While powerful probabilistic models such as Gaussian
Processes naturally have this property, deep neural networks often lack it. In
this paper, we introduce Distance Aware Bottleneck (DAB), i.e., a new method
for enriching deep neural networks with this property. Building on prior
information bottleneck approaches, our method learns a codebook that stores a
compressed representation of all inputs seen during training. The distance of a
new example from this codebook can serve as an uncertainty estimate for the
example. The resulting model is simple to train and provides deterministic
uncertainty estimates by a single forward pass. Finally, our method achieves
better out-of-distribution (OOD) detection and misclassification prediction
than prior methods, including expensive ensemble methods, deep kernel Gaussian
Processes, and approaches based on the standard information bottleneck."
Quest - Query-Aware Sparsity for Efficient Long-Context LLM Inference,https://arxiv.org/abs/2406.10774,2024-06-16,2024-06-19,0.0,0.0,"As the demand for long-context large language models (LLMs) increases, models
with context windows of up to 128K or 1M tokens are becoming increasingly
prevalent. However, long-context LLM inference is challenging since the
inference speed decreases significantly as the sequence length grows. This
slowdown is primarily caused by loading a large KV cache during self-attention.
Previous works have shown that a small portion of critical tokens will dominate
the attention outcomes. However, we observe the criticality of a token highly
depends on the query. To this end, we propose Quest, a query-aware KV cache
selection algorithm. Quest keeps track of the minimal and maximal Key values in
KV cache pages and estimates the criticality of a given page using Query
vectors. By only loading the Top-K critical KV cache pages for attention, Quest
significantly speeds up self-attention without sacrificing accuracy. We show
that Quest can achieve up to 2.23x self-attention speedup, which reduces
inference latency by 7.03x while performing well on tasks with long
dependencies with negligible accuracy loss. Code is available at
http://github.com/mit-han-lab/Quest ."
Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles,https://arxiv.org/abs/2406.10773,2024-06-16,2024-06-19,0.0,0.0,"Large language models (LLMs) are increasingly being utilised across a range
of tasks and domains, with a burgeoning interest in their application within
the field of journalism. This trend raises concerns due to our limited
understanding of LLM behaviour in this domain, especially with respect to
political bias. Existing studies predominantly focus on LLMs undertaking
political questionnaires, which offers only limited insights into their biases
and operational nuances. To address this gap, our study establishes a new
curated dataset that contains 2,100 human-written articles and utilises their
descriptions to generate 56,700 synthetic articles using nine LLMs. This
enables us to analyse shifts in properties between human-authored and
machine-generated articles, with this study focusing on political bias,
detecting it using both supervised models and LLMs. Our findings reveal
significant disparities between base and instruction-tuned LLMs, with
instruction-tuned models exhibiting consistent political bias. Furthermore, we
are able to study how LLMs behave as classifiers, observing their display of
political bias even in this role. Overall, for the first time within the
journalistic domain, this study outlines a framework and provides a structured
dataset for quantifiable experiments, serving as a foundation for further
research into LLM political bias and its implications."
Predicting Exoplanetary Features with a Residual Model for Uniform and Gaussian Distributions,https://arxiv.org/abs/2406.10771,2024-06-16,2024-06-19,0.0,0.0,"The advancement of technology has led to rampant growth in data collection
across almost every field, including astrophysics, with researchers turning to
machine learning to process and analyze this data. One prominent example of
this data in astrophysics is the atmospheric retrievals of exoplanets. In order
to help bridge the gap between machine learning and astrophysics domain
experts, the 2023 Ariel Data Challenge was hosted to predict posterior
distributions of 7 exoplanetary features. The procedure outlined in this paper
leveraged a combination of two deep learning models to address this challenge:
a Multivariate Gaussian model that generates the mean and covariance matrix of
a multivariate Gaussian distribution, and a Uniform Quantile model that
predicts quantiles for use as the upper and lower bounds of a uniform
distribution. Training of the Multivariate Gaussian model was found to be
unstable, while training of the Uniform Quantile model was stable. An ensemble
of uniform distributions was found to have competitive results during testing
(posterior score of 696.43), and when combined with a multivariate Gaussian
distribution achieved a final rank of third in the 2023 Ariel Data Challenge
(final score of 681.57)."
GNOME - Generating Negotiations through Open-Domain Mapping of Exchanges,https://arxiv.org/abs/2406.10764,2024-06-16,2024-06-19,0.0,0.0,"Language Models have previously shown strong negotiation capabilities in
closed domains where the negotiation strategy prediction scope is constrained
to a specific setup. In this paper, we first show that these models are not
generalizable beyond their original training domain despite their wide-scale
pretraining. Following this, we propose an automated framework called GNOME,
which processes existing human-annotated, closed-domain datasets using Large
Language Models and produces synthetic open-domain dialogues for negotiation.
GNOME improves the generalizability of negotiation systems while reducing the
expensive and subjective task of manual data curation. Through our experimental
setup, we create a benchmark comparing encoder and decoder models trained on
existing datasets against datasets created through GNOME. Our results show that
models trained on our dataset not only perform better than previous state of
the art models on domain specific strategy prediction, but also generalize
better to previously unseen domains."
EvIL - Evolution Strategies for Generalisable Imitation Learning,https://arxiv.org/abs/2406.11905,2024-06-15,2024-06-19,0.0,0.0,"Often times in imitation learning (IL), the environment we collect expert
demonstrations in and the environment we want to deploy our learned policy in
aren't exactly the same (e.g. demonstrations collected in simulation but
deployment in the real world). Compared to policy-centric approaches to IL like
behavioural cloning, reward-centric approaches like inverse reinforcement
learning (IRL) often better replicate expert behaviour in new environments.
This transfer is usually performed by optimising the recovered reward under the
dynamics of the target environment. However, (a) we find that modern deep IL
algorithms frequently recover rewards which induce policies far weaker than the
expert, even in the same environment the demonstrations were collected in.
Furthermore, (b) these rewards are often quite poorly shaped, necessitating
extensive environment interaction to optimise effectively. We provide simple
and scalable fixes to both of these concerns. For (a), we find that reward
model ensembles combined with a slightly different training objective
significantly improves re-training and transfer performance. For (b), we
propose a novel evolution-strategies based method EvIL to optimise for a
reward-shaping term that speeds up re-training in the target environment,
closing a gap left open by the classical theory of IRL. On a suite of
continuous control tasks, we are able to re-train policies in target (and
source) environments more interaction-efficiently than prior work."
SparseCL - Sparse Contrastive Learning for Contradiction Retrieval,https://arxiv.org/abs/2406.10746,2024-06-15,2024-06-19,0.0,0.0,"Contradiction retrieval refers to identifying and extracting documents that
explicitly disagree with or refute the content of a query, which is important
to many downstream applications like fact checking and data cleaning. To
retrieve contradiction argument to the query from large document corpora,
existing methods such as similarity search and crossencoder models exhibit
significant limitations. The former struggles to capture the essence of
contradiction due to its inherent nature of favoring similarity, while the
latter suffers from computational inefficiency, especially when the size of
corpora is large. To address these challenges, we introduce a novel approach:
SparseCL that leverages specially trained sentence embeddings designed to
preserve subtle, contradictory nuances between sentences. Our method utilizes a
combined metric of cosine similarity and a sparsity function to efficiently
identify and retrieve documents that contradict a given query. This approach
dramatically enhances the speed of contradiction detection by reducing the need
for exhaustive document comparisons to simple vector calculations. We validate
our model using the Arguana dataset, a benchmark dataset specifically geared
towards contradiction retrieval, as well as synthetic contradictions generated
from the MSMARCO and HotpotQA datasets using GPT-4. Our experiments demonstrate
the efficacy of our approach not only in contradiction retrieval with more than
30% accuracy improvements on MSMARCO and HotpotQA across different model
architectures but also in applications such as cleaning corrupted corpora to
restore high-quality QA retrieval. This paper outlines a promising direction
for improving the accuracy and efficiency of contradiction retrieval in
large-scale text corpora."
Occam's Razor for Self Supervised Learning - What is Sufficient to Learn Good Representations?,https://arxiv.org/abs/2406.10743,2024-06-15,2024-06-19,0.0,0.0,"Deep Learning is often depicted as a trio of data-architecture-loss. Yet,
recent Self Supervised Learning (SSL) solutions have introduced numerous
additional design choices, e.g., a projector network, positive views, or
teacher-student networks. These additions pose two challenges. First, they
limit the impact of theoretical studies that often fail to incorporate all
those intertwined designs. Second, they slow-down the deployment of SSL methods
to new domains as numerous hyper-parameters need to be carefully tuned. In this
study, we bring forward the surprising observation that--at least for
pretraining datasets of up to a few hundred thousands samples--the additional
designs introduced by SSL do not contribute to the quality of the learned
representations. That finding not only provides legitimacy to existing
theoretical studies, but also simplifies the practitioner's path to SSL
deployment in numerous small and medium scale settings. Our finding answers a
long-lasting question: the often-experienced sensitivity to training settings
and hyper-parameters encountered in SSL come from their design, rather than the
absence of supervised guidance."
Speech Emotion Recognition Using CNN and Its Use Case in Digital Healthcare,https://arxiv.org/abs/2406.10741,2024-06-15,2024-06-19,0.0,0.0,"The process of identifying human emotion and affective states from speech is
known as speech emotion recognition (SER). This is based on the observation
that tone and pitch in the voice frequently convey underlying emotion. Speech
recognition includes the ability to recognize emotions, which is becoming
increasingly popular and in high demand. With the help of appropriate factors
(such modalities, emotions, intensities, repetitions, etc.) found in the data,
my research seeks to use the Convolutional Neural Network (CNN) to distinguish
emotions from audio recordings and label them in accordance with the range of
different emotions. I have developed a machine learning model to identify
emotions from supplied audio files with the aid of machine learning methods.
The evaluation is mostly focused on precision, recall, and F1 score, which are
common machine learning metrics. To properly set up and train the machine
learning framework, the main objective is to investigate the influence and
cross-relation of all input and output parameters. To improve the ability to
recognize intentions, a key condition for communication, I have evaluated
emotions using my specialized machine learning algorithm via voice that would
address the emotional state from voice with the help of digital healthcare,
bridging the gap between human and artificial intelligence (AI)."
Adaptive Experimentation When You Can't Experiment,https://arxiv.org/abs/2406.10738,2024-06-15,2024-06-19,0.0,0.0,"This paper introduces the \emph{confounded pure exploration transductive
linear bandit} (\texttt{CPET-LB}) problem. As a motivating example, often
online services cannot directly assign users to specific control or treatment
experiences either for business or practical reasons. In these settings,
naively comparing treatment and control groups that may result from
self-selection can lead to biased estimates of underlying treatment effects.
Instead, online services can employ a properly randomized encouragement that
incentivizes users toward a specific treatment. Our methodology provides online
services with an adaptive experimental design approach for learning the
best-performing treatment for such \textit{encouragement designs}. We consider
a more general underlying model captured by a linear structural equation and
formulate pure exploration linear bandits in this setting. Though pure
exploration has been extensively studied in standard adaptive experimental
design settings, we believe this is the first work considering a setting where
noise is confounded. Elimination-style algorithms using experimental design
methods in combination with a novel finite-time confidence interval on an
instrumental variable style estimator are presented with sample complexity
upper bounds nearly matching a minimax lower bound. Finally, experiments are
conducted that demonstrate the efficacy of our approach."
"Dynamic Domains, Dynamic Solutions - DPCore for Continual Test-Time Adaptation",https://arxiv.org/abs/2406.10737,2024-06-15,2024-06-19,0.0,0.0,"Continual Test-Time Adaptation (CTTA) seeks to adapt a source pre-trained
model to continually changing, unlabeled target domains. Existing TTA methods
are typically designed for environments where domain changes occur sequentially
and can struggle in more dynamic scenarios, as illustrated in Figure
\ref{fig:settings}. Inspired by the principles of online K-Means, we introduce
a novel approach to CTTA through visual prompting. We propose a \emph{Dynamic
Prompt Coreset} that not only preserves knowledge from previously visited
domains but also accommodates learning from new potential domains. This is
complemented by a distance-based \emph{Weight Updating Mechanism} that ensures
the coreset remains current and relevant. Our approach employs a fixed model
architecture alongside the coreset and an innovative updating system to
effectively mitigate challenges such as catastrophic forgetting and error
accumulation. Extensive testing on four widely-used benchmarks demonstrates
that our method consistently outperforms state-of-the-art alternatives in both
classification and segmentation CTTA tasks across the structured and dynamic
CTTA settings, with $99\%$ fewer trainable parameters."
How Should We Extract Discrete Audio Tokens from Self-Supervised Models?,https://arxiv.org/abs/2406.10735,2024-06-15,2024-06-19,0.0,0.0,"Discrete audio tokens have recently gained attention for their potential to
bridge the gap between audio and language processing. Ideal audio tokens must
preserve content, paralinguistic elements, speaker identity, and many other
audio details. Current audio tokenization methods fall into two categories:
Semantic tokens, acquired through quantization of Self-Supervised Learning
(SSL) models, and Neural compression-based tokens (codecs). Although previous
studies have benchmarked codec models to identify optimal configurations, the
ideal setup for quantizing pretrained SSL models remains unclear. This paper
explores the optimal configuration of semantic tokens across discriminative and
generative tasks. We propose a scalable solution to train a universal vocoder
across multiple SSL layers. Furthermore, an attention mechanism is employed to
identify task-specific influential layers, enhancing the adaptability and
performance of semantic tokens in diverse audio applications."
"Order-theoretic models for decision-making - Learning, optimization, complexity and computation",https://arxiv.org/abs/2406.10730,2024-06-15,2024-06-19,0.0,0.0,"The study of intelligent systems explains behaviour in terms of economic
rationality. This results in an optimization principle involving a function or
utility, which states that the system will evolve until the configuration of
maximum utility is achieved. Recently, this theory has incorporated
constraints, i.e., the optimum is achieved when the utility is maximized while
respecting some information-processing constraints. This is reminiscent of
thermodynamic systems. As such, the study of intelligent systems has benefited
from the tools of thermodynamics. The first aim of this thesis is to clarify
the applicability of these results in the study of intelligent systems.
  We can think of the local transition steps in thermodynamic or intelligent
systems as being driven by uncertainty. In fact, the transitions in both
systems can be described in terms of majorization. Hence, real-valued
uncertainty measures like Shannon entropy are simply a proxy for their more
involved behaviour. More in general, real-valued functions are fundamental to
study optimization and complexity in the order-theoretic approach to several
topics, including economics, thermodynamics, and quantum mechanics. The second
aim of this thesis is to improve on this classification.
  The basic similarity between thermodynamic and intelligent systems is based
on an uncertainty notion expressed by a preorder. We can also think of the
transitions in the steps of a computational process as a decision-making
procedure. In fact, by adding some requirements on the considered order
structures, we can build an abstract model of uncertainty reduction that allows
to incorporate computability, that is, to distinguish the objects that can be
constructed by following a finite set of instructions from those that cannot.
The third aim of this thesis is to clarify the requirements on the order
structure that allow such a framework."
A Comprehensive Survey of Foundation Models in Medicine,https://arxiv.org/abs/2406.10729,2024-06-15,2024-06-19,0.0,0.0,"Foundation models (FMs) are large-scale deep-learning models trained on
extensive datasets using self-supervised techniques. These models serve as a
base for various downstream tasks, including healthcare. FMs have been adopted
with great success across various domains within healthcare, including natural
language processing (NLP), computer vision, graph learning, biology, and omics.
Existing healthcare-based surveys have not yet included all of these domains.
Therefore, this survey provides a comprehensive overview of FMs in healthcare.
We focus on the history, learning strategies, flagship models, applications,
and challenges of FMs. We explore how FMs such as the BERT and GPT families are
reshaping various healthcare domains, including clinical large language models,
medical image analysis, and omics data. Furthermore, we provide a detailed
taxonomy of healthcare applications facilitated by FMs, such as clinical NLP,
medical computer vision, graph learning, and other biology-related tasks.
Despite the promising opportunities FMs provide, they also have several
associated challenges, which are explained in detail. We also outline potential
future directions to provide researchers and practitioners with insights into
the potential and limitations of FMs in healthcare to advance their deployment
and mitigate associated risks."
Text-space Graph Foundation Models - Comprehensive Benchmarks and New Insights,https://arxiv.org/abs/2406.10727,2024-06-15,2024-06-19,0.0,0.0,"Given the ubiquity of graph data and its applications in diverse domains,
building a Graph Foundation Model (GFM) that can work well across different
graphs and tasks with a unified backbone has recently garnered significant
interests. A major obstacle to achieving this goal stems from the fact that
graphs from different domains often exhibit diverse node features. Inspired by
multi-modal models that align different modalities with natural language, the
text has recently been adopted to provide a unified feature space for diverse
graphs. Despite the great potential of these text-space GFMs, current research
in this field is hampered by two problems. First, the absence of a
comprehensive benchmark with unified problem settings hinders a clear
understanding of the comparative effectiveness and practical value of different
text-space GFMs. Second, there is a lack of sufficient datasets to thoroughly
explore the methods' full potential and verify their effectiveness across
diverse settings. To address these issues, we conduct a comprehensive benchmark
providing novel text-space datasets and comprehensive evaluation under unified
problem settings. Empirical results provide new insights and inspire future
research directions. Our code and data are publicly available from
\url{https://github.com/CurryTang/TSGFM}."
GenMM - Geometrically and Temporally Consistent Multimodal Data Generation for Video and LiDAR,https://arxiv.org/abs/2406.10722,2024-06-15,2024-06-19,0.0,0.0,"Multimodal synthetic data generation is crucial in domains such as autonomous
driving, robotics, augmented/virtual reality, and retail. We propose a novel
approach, GenMM, for jointly editing RGB videos and LiDAR scans by inserting
temporally and geometrically consistent 3D objects. Our method uses a reference
image and 3D bounding boxes to seamlessly insert and blend new objects into
target videos. We inpaint the 2D Regions of Interest (consistent with 3D boxes)
using a diffusion-based video inpainting model. We then compute semantic
boundaries of the object and estimate it's surface depth using state-of-the-art
semantic segmentation and monocular depth estimation techniques. Subsequently,
we employ a geometry-based optimization algorithm to recover the 3D shape of
the object's surface, ensuring it fits precisely within the 3D bounding box.
Finally, LiDAR rays intersecting with the new object surface are updated to
reflect consistent depths with its geometry. Our experiments demonstrate the
effectiveness of GenMM in inserting various 3D objects across video and LiDAR
modalities."
RoboPoint - A Vision-Language Model for Spatial Affordance Prediction for Robotics,https://arxiv.org/abs/2406.10721,2024-06-15,2024-06-19,0.0,0.0,"From rearranging objects on a table to putting groceries into shelves, robots
must plan precise action points to perform tasks accurately and reliably. In
spite of the recent adoption of vision language models (VLMs) to control robot
behavior, VLMs struggle to precisely articulate robot actions using language.
We introduce an automatic synthetic data generation pipeline that
instruction-tunes VLMs to robotic domains and needs. Using the pipeline, we
train RoboPoint, a VLM that predicts image keypoint affordances given language
instructions. Compared to alternative approaches, our method requires no
real-world data collection or human demonstration, making it much more scalable
to diverse environments and viewpoints. In addition, RoboPoint is a general
model that enables several downstream applications such as robot navigation,
manipulation, and augmented reality (AR) assistance. Our experiments
demonstrate that RoboPoint outperforms state-of-the-art VLMs (GPT-4o) and
visual prompting techniques (PIVOT) by 21.8% in the accuracy of predicting
spatial affordance and by 30.5% in the success rate of downstream tasks.
Project website: https://robo-point.github.io."
Trading Devil - Robust backdoor attack via Stochastic investment models and Bayesian approach,https://arxiv.org/abs/2406.10719,2024-06-15,2024-06-19,0.0,0.0,"With the growing use of voice-activated systems and speech recognition
technologies, the danger of backdoor attacks on audio data has grown
significantly. This research looks at a specific type of attack, known as a
Stochastic investment-based backdoor attack (MarketBack), in which adversaries
strategically manipulate the stylistic properties of audio to fool speech
recognition systems. The security and integrity of machine learning models are
seriously threatened by backdoor attacks, in order to maintain the reliability
of audio applications and systems, the identification of such attacks becomes
crucial in the context of audio data. Experimental results demonstrated that
MarketBack is feasible to achieve an average attack success rate close to 100%
in seven victim models when poisoning less than 1% of the training data."
Stacking for Probabilistic Short-term Load Forecasting,https://arxiv.org/abs/2406.10718,2024-06-15,2024-06-19,0.0,0.0,"In this study, we delve into the realm of meta-learning to combine point base
forecasts for probabilistic short-term electricity demand forecasting. Our
approach encompasses the utilization of quantile linear regression, quantile
regression forest, and post-processing techniques involving residual simulation
to generate quantile forecasts. Furthermore, we introduce both global and local
variants of meta-learning. In the local-learning mode, the meta-model is
trained using patterns most similar to the query pattern.Through extensive
experimental studies across 35 forecasting scenarios and employing 16 base
forecasting models, our findings underscored the superiority of quantile
regression forest over its competitors"
Object Detection using Oriented Window Learning Vi-sion Transformer - Roadway Assets Recognition,https://arxiv.org/abs/2406.10712,2024-06-15,2024-06-19,0.0,0.0,"Object detection is a critical component of transportation systems,
particularly for applications such as autonomous driving, traffic monitoring,
and infrastructure maintenance. Traditional object detection methods often
struggle with limited data and variability in object appearance. The Oriented
Window Learning Vision Transformer (OWL-ViT) offers a novel approach by
adapting window orientations to the geometry and existence of objects, making
it highly suitable for detecting diverse roadway assets. This study leverages
OWL-ViT within a one-shot learning framework to recognize transportation
infrastructure components, such as traffic signs, poles, pavement, and cracks.
This study presents a novel method for roadway asset detection using OWL-ViT.
We conducted a series of experiments to evaluate the performance of the model
in terms of detection consistency, semantic flexibility, visual context
adaptability, resolution robustness, and impact of non-max suppression. The
results demonstrate the high efficiency and reliability of the OWL-ViT across
various scenarios, underscoring its potential to enhance the safety and
efficiency of intelligent transportation systems."
Symmetry-driven embedding of networks in hyperbolic space,https://arxiv.org/abs/2406.10711,2024-06-15,2024-06-19,0.0,0.0,"Hyperbolic models can reproduce the heavy-tailed degree distribution, high
clustering, and hierarchical structure of empirical networks. Current
algorithms for finding the hyperbolic coordinates of networks, however, do not
quantify uncertainty in the inferred coordinates. We present BIGUE, a Markov
chain Monte Carlo (MCMC) algorithm that samples the posterior distribution of a
Bayesian hyperbolic random graph model. We show that combining random walk and
random cluster transformations significantly improves mixing compared to the
commonly used and state-of-the-art dynamic Hamiltonian Monte Carlo algorithm.
Using this algorithm, we also provide evidence that the posterior distribution
cannot be approximated by a multivariate normal distribution, thereby
justifying the use of MCMC to quantify the uncertainty of the inferred
parameters."
SyntheT2C - Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task,https://arxiv.org/abs/2406.10710,2024-06-15,2024-06-19,0.0,0.0,"Integrating Large Language Models (LLMs) with existing Knowledge Graph (KG)
databases presents a promising avenue for enhancing LLMs' efficacy and
mitigating their ""hallucinations"". Given that most KGs reside in graph
databases accessible solely through specialized query languages (e.g., Cypher),
there exists a critical need to bridge the divide between LLMs and KG databases
by automating the translation of natural language into Cypher queries (commonly
termed the ""Text2Cypher"" task). Prior efforts tried to bolster LLMs'
proficiency in Cypher generation through Supervised Fine-Tuning. However, these
explorations are hindered by the lack of annotated datasets of Query-Cypher
pairs, resulting from the labor-intensive and domain-specific nature of
annotating such datasets. In this study, we propose SyntheT2C, a methodology
for constructing a synthetic Query-Cypher pair dataset, comprising two distinct
pipelines: (1) LLM-based prompting and (2) template-filling. SyntheT2C
facilitates the generation of extensive Query-Cypher pairs with values sampled
from an underlying Neo4j graph database. Subsequently, SyntheT2C is applied to
two medical databases, culminating in the creation of a synthetic dataset,
MedT2C. Comprehensive experiments demonstrate that the MedT2C dataset
effectively enhances the performance of backbone LLMs on the Text2Cypher task.
Both the SyntheT2C codebase and the MedT2C dataset will be released soon."
DataStates-LLM - Lazy Asynchronous Checkpointing for Large Language Models,https://arxiv.org/abs/2406.10707,2024-06-15,2024-06-19,0.0,0.0,"LLMs have seen rapid adoption in all domains. They need to be trained on
high-end high-performance computing (HPC) infrastructures and ingest massive
amounts of input data. Unsurprisingly, at such a large scale, unexpected events
(e.g., failures of components, instability of the software, undesirable
learning patterns, etc.), are frequent and typically impact the training in a
negative fashion. Thus, LLMs need to be checkpointed frequently so that they
can be rolled back to a stable state and subsequently fine-tuned. However,
given the large sizes of LLMs, a straightforward checkpointing solution that
directly writes the model parameters and optimizer state to persistent storage
(e.g., a parallel file system), incurs significant I/O overheads. To address
this challenge, in this paper we study how to reduce the I/O overheads for
enabling fast and scalable checkpointing for LLMs that can be applied at high
frequency (up to the granularity of individual iterations) without significant
impact on the training process. Specifically, we introduce a lazy asynchronous
multi-level approach that takes advantage of the fact that the tensors making
up the model and optimizer state shards remain immutable for extended periods
of time, which makes it possible to copy their content in the background with
minimal interference during the training process. We evaluate our approach at
scales of up to 180 GPUs using different model sizes, parallelism settings, and
checkpointing frequencies. The results show up to 48$\times$ faster
checkpointing and 2.2$\times$ faster end-to-end training runtime compared with
the state-of-art checkpointing approaches."
Calibrating Neural Networks' parameters through Optimal Contraction in a Prediction Problem,https://arxiv.org/abs/2406.10703,2024-06-15,2024-06-19,0.0,0.0,"This study introduces a novel approach to ensure the existence and uniqueness
of optimal parameters in neural networks. The paper details how a recurrent
neural networks (RNN) can be transformed into a contraction in a domain where
its parameters are linear. It then demonstrates that a prediction problem
modeled through an RNN, with a specific regularization term in the loss
function, can have its first-order conditions expressed analytically. This
system of equations is reduced to two matrix equations involving Sylvester
equations, which can be partially solved. We establish that, if certain
conditions are met, optimal parameters exist, are unique, and can be found
through a straightforward algorithm to any desired precision. Also, as the
number of neurons grows the conditions of convergence become easier to fulfill.
Feedforward neural networks (FNNs) are also explored by including linear
constraints on parameters. According to our model, incorporating loops (with
fixed or variable weights) will produce loss functions that train easier,
because it assures the existence of a region where an iterative method
converges."
MIND - Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding,https://arxiv.org/abs/2406.10701,2024-06-15,2024-06-19,0.0,0.0,"Improving user experience and providing personalized search results in
E-commerce platforms heavily rely on understanding purchase intention. However,
existing methods for acquiring large-scale intentions bank on distilling large
language models with human annotation for verification. Such an approach tends
to generate product-centric intentions, overlook valuable visual information
from product images, and incurs high costs for scalability. To address these
issues, we introduce MIND, a multimodal framework that allows Large
Vision-Language Models (LVLMs) to infer purchase intentions from multimodal
product metadata and prioritize human-centric ones. Using Amazon Review data,
we apply MIND and create a multimodal intention knowledge base, which contains
1,264,441 million intentions derived from 126,142 co-buy shopping records
across 107,215 products. Extensive human evaluations demonstrate the high
plausibility and typicality of our obtained intentions and validate the
effectiveness of our distillation framework and filtering mechanism. Additional
experiments reveal that our obtained intentions significantly enhance large
language models in two intention comprehension tasks."
Statistical arbitrage in multi-pair trading strategy based on graph clustering algorithms in US equities market,https://arxiv.org/abs/2406.10695,2024-06-15,2024-06-19,0.0,0.0,"The study seeks to develop an effective strategy based on the novel framework
of statistical arbitrage based on graph clustering algorithms. Amalgamation of
quantitative and machine learning methods, including the Kelly criterion, and
an ensemble of machine learning classifiers have been used to improve
risk-adjusted returns and increase immunity to transaction costs over existing
approaches. The study seeks to provide an integrated approach to optimal signal
detection and risk management. As a part of this approach, innovative ways of
optimizing take profit and stop loss functions for daily frequency trading
strategies have been proposed and tested. All of the tested approaches
outperformed appropriate benchmarks. The best combinations of the techniques
and parameters demonstrated significantly better performance metrics than the
relevant benchmarks. The results have been obtained under the assumption of
realistic transaction costs, but are sensitive to changes in some key
parameters."
Bridging the Gap in Drug Safety Data Analysis - Large Language Models for SQL Query Generation,https://arxiv.org/abs/2406.10690,2024-06-15,2024-06-19,0.0,0.0,"Objective: To enhance the efficiency and accuracy of information retrieval
from pharmacovigilance (PV) databases by employing Large Language Models (LLMs)
to convert natural language queries (NLQs) into Structured Query Language (SQL)
queries, leveraging a business context document.
  Materials and Methods: We utilized OpenAI's GPT-4 model within a
retrieval-augmented generation (RAG) framework, enriched with a business
context document, to transform NLQs into syntactically precise SQL queries.
Each NLQ was presented to the LLM randomly and independently to prevent
memorization. The study was conducted in three phases, varying query
complexity, and assessing the LLM's performance both with and without the
business context document.
  Results: Our approach significantly improved NLQ-to-SQL accuracy, increasing
from 8.3\% with the database schema alone to 78.3\% with the business context
document. This enhancement was consistent across low, medium, and high
complexity queries, indicating the critical role of contextual knowledge in
query generation.
  Discussion: The integration of a business context document markedly improved
the LLM's ability to generate accurate and contextually relevant SQL queries.
Performance achieved a maximum of 85\% when high complexity queries are
excluded, suggesting promise for routine deployment.
  Conclusion: This study presents a novel approach to employing LLMs for safety
data retrieval and analysis, demonstrating significant advancements in query
generation accuracy. The methodology offers a framework applicable to various
data-intensive domains, enhancing the accessibility and efficiency of
information retrieval for non-technical users."
Integration of Programmable Diffraction with Digital Neural Networks,https://arxiv.org/abs/2406.10688,2024-06-15,2024-06-19,0.0,0.0,"Optical imaging and sensing systems based on diffractive elements have seen
massive advances over the last several decades. Earlier generations of
diffractive optical processors were, in general, designed to deliver
information to an independent system that was separately optimized, primarily
driven by human vision or perception. With the recent advances in deep learning
and digital neural networks, there have been efforts to establish diffractive
processors that are jointly optimized with digital neural networks serving as
their back-end. These jointly optimized hybrid (optical+digital) processors
establish a new ""diffractive language"" between input electromagnetic waves that
carry analog information and neural networks that process the digitized
information at the back-end, providing the best of both worlds. Such hybrid
designs can process spatially and temporally coherent, partially coherent, or
incoherent input waves, providing universal coverage for any spatially varying
set of point spread functions that can be optimized for a given task, executed
in collaboration with digital neural networks. In this article, we highlight
the utility of this exciting collaboration between engineered and programmed
diffraction and digital neural networks for a diverse range of applications. We
survey some of the major innovations enabled by the push-pull relationship
between analog wave processing and digital neural networks, also covering the
significant benefits that could be reaped through the synergy between these two
complementary paradigms."
Graph Neural Thompson Sampling,https://arxiv.org/abs/2406.10686,2024-06-15,2024-06-19,0.0,0.0,"We consider an online decision-making problem with a reward function defined
over graph-structured data. We formally formulate the problem as an instance of
graph action bandit. We then propose \texttt{GNN-TS}, a Graph Neural Network
(GNN) powered Thompson Sampling (TS) algorithm which employs a GNN approximator
for estimating the mean reward function and the graph neural tangent features
for uncertainty estimation. We prove that, under certain boundness assumptions
on the reward function, GNN-TS achieves a state-of-the-art regret bound which
is (1) sub-linear of order $\tilde{\mathcal{O}}((\tilde{d} T)^{1/2})$ in the
number of interaction rounds, $T$, and a notion of effective dimension
$\tilde{d}$, and (2) independent of the number of graph nodes. Empirical
results validate that our proposed \texttt{GNN-TS} exhibits competitive
performance and scales well on graph action bandit problems."
Scale Equivariant Graph Metanetworks,https://arxiv.org/abs/2406.10685,2024-06-15,2024-06-19,0.0,0.0,"This paper pertains to an emerging machine learning paradigm: learning
higher-order functions, i.e. functions whose inputs are functions themselves,
$\textit{particularly when these inputs are Neural Networks (NNs)}$. With the
growing interest in architectures that process NNs, a recurring design
principle has permeated the field: adhering to the permutation symmetries
arising from the connectionist structure of NNs. $\textit{However, are these
the sole symmetries present in NN parameterizations}$? Zooming into most
practical activation functions (e.g. sine, ReLU, tanh) answers this question
negatively and gives rise to intriguing new symmetries, which we collectively
refer to as $\textit{scaling symmetries}$, that is, non-zero scalar
multiplications and divisions of weights and biases. In this work, we propose
$\textit{Scale Equivariant Graph MetaNetworks - ScaleGMNs}$, a framework that
adapts the Graph Metanetwork (message-passing) paradigm by incorporating
scaling symmetries and thus rendering neuron and edge representations
equivariant to valid scalings. We introduce novel building blocks, of
independent technical interest, that allow for equivariance or invariance with
respect to individual scalar multipliers or their product and use them in all
components of ScaleGMN. Furthermore, we prove that, under certain expressivity
conditions, ScaleGMN can simulate the forward and backward pass of any input
feedforward neural network. Experimental results demonstrate that our method
advances the state-of-the-art performance for several datasets and activation
functions, highlighting the power of scaling symmetries as an inductive bias
for NN processing."
"A Survey of Large Language Models for Financial Applications - Progress, Prospects and Challenges",https://arxiv.org/abs/2406.11903,2024-06-15,2024-06-19,0.0,0.0,"Recent advances in large language models (LLMs) have unlocked novel
opportunities for machine learning applications in the financial domain. These
models have demonstrated remarkable capabilities in understanding context,
processing vast amounts of data, and generating human-preferred contents. In
this survey, we explore the application of LLMs on various financial tasks,
focusing on their potential to transform traditional practices and drive
innovation. We provide a discussion of the progress and advantages of LLMs in
financial contexts, analyzing their advanced technologies as well as
prospective capabilities in contextual understanding, transfer learning
flexibility, complex emotion detection, etc. We then highlight this survey for
categorizing the existing literature into key application areas, including
linguistic tasks, sentiment analysis, financial time series, financial
reasoning, agent-based modeling, and other applications. For each application
area, we delve into specific methodologies, such as textual analysis,
knowledge-based analysis, forecasting, data augmentation, planning, decision
support, and simulations. Furthermore, a comprehensive collection of datasets,
model assets, and useful codes associated with mainstream applications are
presented as resources for the researchers and practitioners. Finally, we
outline the challenges and opportunities for future research, particularly
emphasizing a number of distinctive aspects in this field. We hope our work can
help facilitate the adoption and further development of LLMs in the financial
sector."
CoLoR-Filter - Conditional Loss Reduction Filtering for Targeted Language Model Pre-training,https://arxiv.org/abs/2406.10670,2024-06-15,2024-06-19,0.0,0.0,"Selecting high-quality data for pre-training is crucial in shaping the
downstream task performance of language models. A major challenge lies in
identifying this optimal subset, a problem generally considered intractable,
thus necessitating scalable and effective heuristics. In this work, we propose
a data selection method, CoLoR-Filter (Conditional Loss Reduction Filtering),
which leverages an empirical Bayes-inspired approach to derive a simple and
computationally efficient selection criterion based on the relative loss values
of two auxiliary models.
  In addition to the modeling rationale, we evaluate CoLoR-Filter empirically
on two language modeling tasks: (1) selecting data from C4 for domain
adaptation to evaluation on Books and (2) selecting data from C4 for a suite of
downstream multiple-choice question answering tasks. We demonstrate favorable
scaling both as we subselect more aggressively and using small auxiliary models
to select data for large target models. As one headline result, CoLoR-Filter
data selected using a pair of 150m parameter auxiliary models can train a 1.2b
parameter target model to match a 1.2b parameter model trained on 25b randomly
selected tokens with 25x less data for Books and 11x less data for the
downstream tasks.
  Code: https://github.com/davidbrandfonbrener/color-filter-olmo
  Filtered data:
https://huggingface.co/datasets/davidbrandfonbrener/color-filtered-c4"
Augmenting Biomedical Named Entity Recognition with General-domain Resources,https://arxiv.org/abs/2406.10671,2024-06-15,2024-06-19,0.0,0.0,"Training a neural network-based biomedical named entity recognition (BioNER)
model usually requires extensive and costly human annotations. While several
studies have employed multi-task learning with multiple BioNER datasets to
reduce human effort, this approach does not consistently yield performance
improvements and may introduce label ambiguity in different biomedical corpora.
We aim to tackle those challenges through transfer learning from easily
accessible resources with fewer concept overlaps with biomedical datasets. In
this paper, we proposed GERBERA, a simple-yet-effective method that utilized a
general-domain NER dataset for training. Specifically, we performed multi-task
learning to train a pre-trained biomedical language model with both the target
BioNER dataset and the general-domain dataset. Subsequently, we fine-tuned the
models specifically for the BioNER dataset. We systematically evaluated GERBERA
on five datasets of eight entity types, collectively consisting of 81,410
instances. Despite using fewer biomedical resources, our models demonstrated
superior performance compared to baseline models trained with multiple
additional BioNER datasets. Specifically, our models consistently outperformed
the baselines in six out of eight entity types, achieving an average
improvement of 0.9% over the best baseline performance across eight biomedical
entity types sourced from five different corpora. Our method was especially
effective in amplifying performance on BioNER datasets characterized by limited
data, with a 4.7% improvement in F1 scores on the JNLPBA-RNA dataset."
UniZero - Generalized and Efficient Planning with Scalable Latent World Models,https://arxiv.org/abs/2406.10667,2024-06-15,2024-06-19,0.0,0.0,"Learning predictive world models is essential for enhancing the planning
capabilities of reinforcement learning agents. Notably, the MuZero-style
algorithms, based on the value equivalence principle and Monte Carlo Tree
Search (MCTS), have achieved superhuman performance in various domains.
However, in environments that require capturing long-term dependencies,
MuZero's performance deteriorates rapidly. We identify that this is partially
due to the \textit{entanglement} of latent representations with historical
information, which results in incompatibility with the auxiliary
self-supervised state regularization. To overcome this limitation, we present
\textit{UniZero}, a novel approach that \textit{disentangles} latent states
from implicit latent history using a transformer-based latent world model. By
concurrently predicting latent dynamics and decision-oriented quantities
conditioned on the learned latent history, UniZero enables joint optimization
of the long-horizon world model and policy, facilitating broader and more
efficient planning in latent space. We demonstrate that UniZero, even with
single-frame inputs, matches or surpasses the performance of MuZero-style
algorithms on the Atari 100k benchmark. Furthermore, it significantly
outperforms prior baselines in benchmarks that require long-term memory.
Lastly, we validate the effectiveness and scalability of our design choices
through extensive ablation studies, visual analyses, and multi-task learning
results. The code is available at
\textcolor{magenta}{https://github.com/opendilab/LightZero}."
DIEKAE - Difference Injection for Efficient Knowledge Augmentation and Editing of Large Language Models,https://arxiv.org/abs/2406.10660,2024-06-15,2024-06-19,0.0,0.0,"Pretrained Language Models (PLMs) store extensive knowledge within their
weights, enabling them to recall vast amount of information. However, relying
on this parametric knowledge brings some limitations such as outdated
information or gaps in the training data. This work addresses these problems by
distinguish between two separate solutions: knowledge editing and knowledge
augmentation. We introduce Difference Injection for Efficient Knowledge
Augmentation and Editing (DIEK\AE), a new method that decouples knowledge
processing from the PLM (LLaMA2-7B, in particular) by adopting a series of
encoders. These encoders handle external knowledge and inject it into the PLM
layers, significantly reducing computational costs and improving performance of
the PLM. We propose a novel training technique for these encoders that does not
require back-propagation through the PLM, thus greatly reducing the memory and
time required to train them. Our findings demonstrate how our method is faster
and more efficient compared to multiple baselines in knowledge augmentation and
editing during both training and inference. We have released our code and data
at https://github.com/alessioGalatolo/DIEKAE."
Justice in Healthcare Artificial Intelligence in Africa,https://arxiv.org/abs/2406.10653,2024-06-15,2024-06-19,0.0,0.0,"There is an ongoing debate on balancing the benefits and risks of artificial
intelligence (AI) as AI is becoming critical to improving healthcare delivery
and patient outcomes. Such improvements are essential in resource-constrained
settings where millions lack access to adequate healthcare services, such as in
Africa. AI in such a context can potentially improve the effectiveness,
efficiency, and accessibility of healthcare services. Nevertheless, the
development and use of AI-driven healthcare systems raise numerous ethical,
legal, and socio-economic issues. Justice is a major concern in AI that has
implications for amplifying social inequities. This paper discusses these
implications and related justice concepts such as solidarity, Common Good,
sustainability, AI bias, and fairness. For Africa to effectively benefit from
AI, these principles should align with the local context while balancing the
risks. Compared to mainstream ethical debates on justice, this perspective
offers context-specific considerations for equitable healthcare AI development
in Africa."
The Implicit Bias of Adam on Separable Data,https://arxiv.org/abs/2406.10650,2024-06-15,2024-06-19,0.0,0.0,"Adam has become one of the most favored optimizers in deep learning problems.
Despite its success in practice, numerous mysteries persist regarding its
theoretical understanding. In this paper, we study the implicit bias of Adam in
linear logistic regression. Specifically, we show that when the training data
are linearly separable, Adam converges towards a linear classifier that
achieves the maximum $\ell_\infty$-margin. Notably, for a general class of
diminishing learning rates, this convergence occurs within polynomial time. Our
result shed light on the difference between Adam and (stochastic) gradient
descent from a theoretical perspective."
"Applications of Generative AI in Healthcare - algorithmic, ethical, legal and societal considerations",https://arxiv.org/abs/2406.10632,2024-06-15,2024-06-19,0.0,0.0,"Generative AI is rapidly transforming medical imaging and text analysis,
offering immense potential for enhanced diagnosis and personalized care.
However, this transformative technology raises crucial ethical, societal, and
legal questions. This paper delves into these complexities, examining issues of
accuracy, informed consent, data privacy, and algorithmic limitations in the
context of generative AI's application to medical imaging and text. We explore
the legal landscape surrounding liability and accountability, emphasizing the
need for robust regulatory frameworks. Furthermore, we dissect the algorithmic
challenges, including data biases, model limitations, and workflow integration.
By critically analyzing these challenges and proposing responsible solutions,
we aim to foster a roadmap for ethical and responsible implementation of
generative AI in healthcare, ensuring its transformative potential serves
humanity with utmost care and precision."
Fast Last-Iterate Convergence of Learning in Games Requires Forgetful Algorithms,https://arxiv.org/abs/2406.10631,2024-06-15,2024-06-19,0.0,0.0,"Self-play via online learning is one of the premier ways to solve large-scale
two-player zero-sum games, both in theory and practice. Particularly popular
algorithms include optimistic multiplicative weights update (OMWU) and
optimistic gradient-descent-ascent (OGDA). While both algorithms enjoy $O(1/T)$
ergodic convergence to Nash equilibrium in two-player zero-sum games, OMWU
offers several advantages including logarithmic dependence on the size of the
payoff matrix and $\widetilde{O}(1/T)$ convergence to coarse correlated
equilibria even in general-sum games. However, in terms of last-iterate
convergence in two-player zero-sum games, an increasingly popular topic in this
area, OGDA guarantees that the duality gap shrinks at a rate of
$O(1/\sqrt{T})$, while the best existing last-iterate convergence for OMWU
depends on some game-dependent constant that could be arbitrarily large. This
begs the question: is this potentially slow last-iterate convergence an
inherent disadvantage of OMWU, or is the current analysis too loose? Somewhat
surprisingly, we show that the former is true. More generally, we prove that a
broad class of algorithms that do not forget the past quickly all suffer the
same issue: for any arbitrarily small $\delta>0$, there exists a $2\times 2$
matrix game such that the algorithm admits a constant duality gap even after
$1/\delta$ rounds. This class of algorithms includes OMWU and other standard
optimistic follow-the-regularized-leader algorithms."
Emerging Safety Attack and Defense in Federated Instruction Tuning of Large Language Models,https://arxiv.org/abs/2406.10630,2024-06-15,2024-06-19,0.0,0.0,"Federated learning (FL) enables multiple parties to collaboratively fine-tune
an large language model (LLM) without the need of direct data sharing. Ideally,
by training on decentralized data that is aligned with human preferences and
safety principles, federated instruction tuning can result in an LLM that could
behave in a helpful and safe manner. In this paper, we for the first time
reveal the vulnerability of safety alignment in FedIT by proposing a simple,
stealthy, yet effective safety attack method. Specifically, the malicious
clients could automatically generate attack data without involving manual
efforts and attack the FedIT system by training their local LLMs on such attack
data. Unfortunately, this proposed safety attack not only can compromise the
safety alignment of LLM trained via FedIT, but also can not be effectively
defended against by many existing FL defense methods. Targeting this, we
further propose a post-hoc defense method, which could rely on a fully
automated pipeline: generation of defense data and further fine-tuning of the
LLM. Extensive experiments show that our safety attack method can significantly
compromise the LLM's safety alignment (e.g., reduce safety rate by 70\%), which
can not be effectively defended by existing defense methods (at most 4\%
absolute improvement), while our safety defense method can significantly
enhance the attacked LLM's safety alignment (at most 69\% absolute
improvement)."
Public Computer Vision Datasets for Precision Livestock Farming - A Systematic Survey,https://arxiv.org/abs/2406.10628,2024-06-15,2024-06-19,0.0,0.0,"Technology-driven precision livestock farming (PLF) empowers practitioners to
monitor and analyze animal growth and health conditions for improved
productivity and welfare. Computer vision (CV) is indispensable in PLF by using
cameras and computer algorithms to supplement or supersede manual efforts for
livestock data acquisition. Data availability is crucial for developing
innovative monitoring and analysis systems through artificial
intelligence-based techniques. However, data curation processes are tedious,
time-consuming, and resource intensive. This study presents the first
systematic survey of publicly available livestock CV datasets
(https://github.com/Anil-Bhujel/Public-Computer-Vision-Dataset-A-Systematic-Survey).
Among 58 public datasets identified and analyzed, encompassing different
species of livestock, almost half of them are for cattle, followed by swine,
poultry, and other animals. Individual animal detection and color imaging are
the dominant application and imaging modality for livestock. The
characteristics and baseline applications of the datasets are discussed,
emphasizing the implications for animal welfare advocates. Challenges and
opportunities are also discussed to inspire further efforts in developing
livestock CV datasets. This study highlights that the limited quantity of
high-quality annotated datasets collected from diverse environments, animals,
and applications, the absence of contextual metadata, are a real bottleneck in
PLF."
On the Hardness of Faithful Chain-of-Thought Reasoning in Large Language Models,https://arxiv.org/abs/2406.10625,2024-06-15,2024-06-19,0.0,0.0,"As Large Language Models (LLMs) are increasingly being employed in real-world
applications in critical domains such as healthcare, it is important to ensure
that the Chain-of-Thought (CoT) reasoning generated by these models faithfully
captures their underlying behavior.
  While LLMs are known to generate CoT reasoning that is appealing to humans,
prior studies have shown that these explanations do not accurately reflect the
actual behavior of the underlying LLMs. In this work, we explore the promise of
three broad approaches commonly employed to steer the behavior of LLMs to
enhance the faithfulness of the CoT reasoning generated by LLMs: in-context
learning, fine-tuning, and activation editing. Specifically, we introduce novel
strategies for in-context learning, fine-tuning, and activation editing aimed
at improving the faithfulness of the CoT reasoning. We then carry out extensive
empirical analyses with multiple benchmark datasets to explore the promise of
these strategies. Our analyses indicate that these strategies offer limited
success in improving the faithfulness of the CoT reasoning, with only slight
performance enhancements in controlled scenarios. Activation editing
demonstrated minimal success, while fine-tuning and in-context learning
achieved marginal improvements that failed to generalize across diverse
reasoning and truthful question-answering benchmarks. In summary, our work
underscores the inherent difficulty in eliciting faithful CoT reasoning from
LLMs, suggesting that the current array of approaches may not be sufficient to
address this complex challenge."
StructBench - An Autogenerated Benchmark for Evaluating Large Language Model's Ability in Structure-Rich Text Understanding,https://arxiv.org/abs/2406.10621,2024-06-15,2024-06-19,0.0,0.0,"Given the substantial volumes of structured data held by many companies,
enabling Large Language Models (LLMs) to directly understand structured text in
non-structured forms could significantly enhance their capabilities across
various business scenarios. To this end, we propose evaluation data generation
method for assessing LLM's ability in understanding the structure-rich text,
which generates structured data of controllable complexity based on manually
crafted question templates and generation rules. Building on this generation
method, we introduce StrucText-Eval, a benchmark comprising 6,032 questions
across 8 different structured languages and 29 specific tasks. Furthermore,
considering human proficiency in rule-based tasks, we also present
StrucText-Eval-Hard, which includes 3,016 questions designed to further examine
the gap between LLMs and human performance. Results indicate that the
best-performing LLM currently achieve an accuracy of 65.0\% on
StrucText-Eval-Hard, while human accuracy reaches up to 95.7\%. Moreover, while
fine-tuning using StrucText-Eval can enhance existing LLMs' understanding of
all structured languages, it does not necessarily improve performance across
all task types. The benchmark and generation codes are open sourced in
https://github.com/MikeGu721/StrucText-Eval"
HiFGL - A Hierarchical Framework for Cross-silo Cross-device Federated Graph Learning,https://arxiv.org/abs/2406.10616,2024-06-15,2024-06-19,0.0,0.0,"Federated Graph Learning (FGL) has emerged as a promising way to learn
high-quality representations from distributed graph data with privacy
preservation. Despite considerable efforts have been made for FGL under either
cross-device or cross-silo paradigm, how to effectively capture graph knowledge
in a more complicated cross-silo cross-device environment remains an
under-explored problem. However, this task is challenging because of the
inherent hierarchy and heterogeneity of decentralized clients, diversified
privacy constraints in different clients, and the cross-client graph integrity
requirement. To this end, in this paper, we propose a Hierarchical Federated
Graph Learning (HiFGL) framework for cross-silo cross-device FGL. Specifically,
we devise a unified hierarchical architecture to safeguard federated GNN
training on heterogeneous clients while ensuring graph integrity. Moreover, we
propose a Secret Message Passing (SecMP) scheme to shield unauthorized access
to subgraph-level and node-level sensitive information simultaneously.
Theoretical analysis proves that HiFGL achieves multi-level privacy
preservation with complexity guarantees. Extensive experiments on real-world
datasets validate the superiority of the proposed framework against several
baselines. Furthermore, HiFGL's versatile nature allows for its application in
either solely cross-silo or cross-device settings, further broadening its
utility in real-world FGL applications."
Leveraging Locality to Boost Sample Efficiency in Robotic Manipulation,https://arxiv.org/abs/2406.10615,2024-06-15,2024-06-19,0.0,0.0,"Given the high cost of collecting robotic data in the real world, sample
efficiency is a consistently compelling pursuit in robotics. In this paper, we
introduce SGRv2, an imitation learning framework that enhances sample
efficiency through improved visual and action representations. Central to the
design of SGRv2 is the incorporation of a critical inductive bias-action
locality, which posits that robot's actions are predominantly influenced by the
target object and its interactions with the local environment. Extensive
experiments in both simulated and real-world settings demonstrate that action
locality is essential for boosting sample efficiency. SGRv2 excels in RLBench
tasks with keyframe control using merely 5 demonstrations and surpasses the RVT
baseline in 23 of 26 tasks. Furthermore, when evaluated on ManiSkill2 and
MimicGen using dense control, SGRv2's success rate is 2.54 times that of SGR.
In real-world environments, with only eight demonstrations, SGRv2 can perform a
variety of tasks at a markedly higher success rate compared to baseline models.
Project website: http://sgrv2-robot.github.io"
Last-iterate Convergence Separation between Extra-gradient and Optimism in Constrained Periodic Games,https://arxiv.org/abs/2406.10605,2024-06-15,2024-06-19,0.0,0.0,"Last-iterate behaviors of learning algorithms in repeated two-player zero-sum
games have been extensively studied due to their wide applications in machine
learning and related tasks. Typical algorithms that exhibit the last-iterate
convergence property include optimistic and extra-gradient methods. However,
most existing results establish these properties under the assumption that the
game is time-independent. Recently, (Feng et al, 2023) studied the last-iterate
behaviors of optimistic and extra-gradient methods in games with a time-varying
payoff matrix, and proved that in an unconstrained periodic game,
extra-gradient method converges to the equilibrium while optimistic method
diverges. This finding challenges the conventional wisdom that these two
methods are expected to behave similarly as they do in time-independent games.
However, compared to unconstrained games, games with constrains are more common
both in practical and theoretical studies. In this paper, we investigate the
last-iterate behaviors of optimistic and extra-gradient methods in the
constrained periodic games, demonstrating that similar separation results for
last-iterate convergence also hold in this setting."
Multilingual Large Language Models and Curse of Multilinguality,https://arxiv.org/abs/2406.10602,2024-06-15,2024-06-19,0.0,0.0,"Multilingual Large Language Models (LLMs) have gained large popularity among
Natural Language Processing (NLP) researchers and practitioners. These models,
trained on huge datasets, show proficiency across various languages and
demonstrate effectiveness in numerous downstream tasks. This paper navigates
the landscape of multilingual LLMs, providing an introductory overview of their
technical aspects. It explains underlying architectures, objective functions,
pre-training data sources, and tokenization methods. This work explores the
unique features of different model types: encoder-only (mBERT, XLM-R),
decoder-only (XGLM, PALM, BLOOM, GPT-3), and encoder-decoder models (mT5,
mBART). Additionally, it addresses one of the significant limitations of
multilingual LLMs - the curse of multilinguality - and discusses current
attempts to overcome it."
BlockPruner - Fine-grained Pruning for Large Language Models,https://arxiv.org/abs/2406.10594,2024-06-15,2024-06-19,0.0,0.0,"With the rapid growth in the size and complexity of large language models
(LLMs), the costs associated with their training and inference have escalated
significantly. Research indicates that certain layers in LLMs harbor
substantial redundancy, and pruning these layers has minimal impact on the
overall performance. While various layer pruning methods have been developed
based on this insight, they generally overlook the finer-grained redundancies
within the layers themselves. In this paper, we delve deeper into the
architecture of LLMs and demonstrate that finer-grained pruning can be achieved
by targeting redundancies in multi-head attention (MHA) and multi-layer
perceptron (MLP) blocks. We propose a novel, training-free structured pruning
approach called BlockPruner. Unlike existing layer pruning methods, BlockPruner
segments each Transformer layer into MHA and MLP blocks. It then assesses the
importance of these blocks using perplexity measures and applies a heuristic
search for iterative pruning. We applied BlockPruner to LLMs of various sizes
and architectures and validated its performance across a wide range of
downstream tasks. Experimental results show that BlockPruner achieves more
granular and effective pruning compared to state-of-the-art baselines."
QDA-SQL - Questions Enhanced Dialogue Augmentation for Multi-Turn Text-to-SQL,https://arxiv.org/abs/2406.10593,2024-06-15,2024-06-19,0.0,0.0,"Fine-tuning large language models (LLMs) for specific domain tasks has
achieved great success in Text-to-SQL tasks. However, these fine-tuned models
often face challenges with multi-turn Text-to-SQL tasks caused by ambiguous or
unanswerable questions. It is desired to enhance LLMs to handle multiple types
of questions in multi-turn Text-to-SQL tasks. To address this, we propose a
novel data augmentation method, called QDA-SQL, which generates multiple types
of multi-turn Q\&A pairs by using LLMs. In QDA-SQL, we introduce a novel data
augmentation method incorporating validation and correction mechanisms to
handle complex multi-turn Text-to-SQL tasks. Experimental results demonstrate
that QDA-SQL enables fine-tuned models to exhibit higher performance on SQL
statement accuracy and enhances their ability to handle complex, unanswerable
questions in multi-turn Text-to-SQL tasks. The generation script and test set
are released at https://github.com/mcxiaoxiao/QDA-SQL."
MINT - a Multi-modal Image and Narrative Text Dubbing Dataset for Foley Audio Content Planning and Generation,https://arxiv.org/abs/2406.10591,2024-06-15,2024-06-19,0.0,0.0,"Foley audio, critical for enhancing the immersive experience in multimedia
content, faces significant challenges in the AI-generated content (AIGC)
landscape. Despite advancements in AIGC technologies for text and image
generation, the foley audio dubbing remains rudimentary due to difficulties in
cross-modal scene matching and content correlation. Current text-to-audio
technology, which relies on detailed and acoustically relevant textual
descriptions, falls short in practical video dubbing applications. Existing
datasets like AudioSet, AudioCaps, Clotho, Sound-of-Story, and WavCaps do not
fully meet the requirements for real-world foley audio dubbing task. To address
this, we introduce the Multi-modal Image and Narrative Text Dubbing Dataset
(MINT), designed to enhance mainstream dubbing tasks such as literary story
audiobooks dubbing, image/silent video dubbing. Besides, to address the
limitations of existing TTA technology in understanding and planning complex
prompts, a Foley Audio Content Planning, Generation, and Alignment (CPGA)
framework is proposed, which includes a content planning module leveraging
large language models for complex multi-modal prompts comprehension.
Additionally, the training process is optimized using Proximal Policy
Optimization based reinforcement learning, significantly improving the
alignment and auditory realism of generated foley audio. Experimental results
demonstrate that our approach significantly advances the field of foley audio
dubbing, providing robust solutions for the challenges of multi-modal dubbing.
Even when utilizing the relatively lightweight GPT-2 model, our framework
outperforms open-source multimodal large models such as LLaVA, DeepSeek-VL, and
Moondream2. The dataset is available at https://github.com/borisfrb/MINT ."
Concentrate Attention - Towards Domain-Generalizable Prompt Optimization for Language Models,https://arxiv.org/abs/2406.10584,2024-06-15,2024-06-19,0.0,0.0,"Recent advances in prompt optimization have notably enhanced the performance
of pre-trained language models (PLMs) on downstream tasks. However, the
potential of optimized prompts on domain generalization has been
under-explored. To explore the nature of prompt generalization on unknown
domains, we conduct pilot experiments and find that (i) Prompts gaining more
attention weight from PLMs' deep layers are more generalizable and (ii) Prompts
with more stable attention distributions in PLMs' deep layers are more
generalizable. Thus, we offer a fresh objective towards domain-generalizable
prompts optimization named ""Concentration"", which represents the ""lookback""
attention from the current decoding token to the prompt tokens, to increase the
attention strength on prompts and reduce the fluctuation of attention
distribution. We adapt this new objective to popular soft prompt and hard
prompt optimization methods, respectively. Extensive experiments demonstrate
that our idea improves comparison prompt optimization methods by 1.42% for soft
prompt generalization and 2.16% for hard prompt generalization in accuracy on
the multi-source domain generalization setting, while maintaining satisfying
in-domain performance. The promising results validate the effectiveness of our
proposed prompt optimization objective and provide key insights into
domain-generalizable prompts."
Robust Image Classification in the Presence of Out-of-Distribution and Adversarial Samples Using Attractors in Neural Networks,https://arxiv.org/abs/2406.10579,2024-06-15,2024-06-19,0.0,0.0,"The proper handling of out-of-distribution (OOD) samples in deep classifiers
is a critical concern for ensuring the suitability of deep neural networks in
safety-critical systems. Existing approaches developed for robust OOD detection
in the presence of adversarial attacks lose their performance by increasing the
perturbation levels. This study proposes a method for robust classification in
the presence of OOD samples and adversarial attacks with high perturbation
levels. The proposed approach utilizes a fully connected neural network that is
trained to use training samples as its attractors, enhancing its robustness.
This network has the ability to classify inputs and identify OOD samples as
well. To evaluate this method, the network is trained on the MNIST dataset, and
its performance is tested on adversarial examples. The results indicate that
the network maintains its performance even when classifying adversarial
examples, achieving 87.13% accuracy when dealing with highly perturbed MNIST
test data. Furthermore, by using fashion-MNIST and CIFAR-10-bw as OOD samples,
the network can distinguish these samples from MNIST samples with an accuracy
of 98.84% and 99.28%, respectively. In the presence of severe adversarial
attacks, these measures decrease slightly to 98.48% and 98.88%, indicating the
robustness of the proposed method."
Optimization-based Structural Pruning for Large Language Models without Back-Propagation,https://arxiv.org/abs/2406.10576,2024-06-15,2024-06-19,0.0,0.0,"Compared to the moderate size of neural network models, structural weight
pruning on the Large-Language Models (LLMs) imposes a novel challenge on the
efficiency of the pruning algorithms, due to the heavy computation/memory
demands of the LLMs. Recent efficient LLM pruning methods typically operate at
the post-training phase without the expensive weight finetuning, however, their
pruning criteria often rely on heuristically designed metrics, potentially
leading to suboptimal performance. We instead propose a novel
optimization-based structural pruning that learns the pruning masks in a
probabilistic space directly by optimizing the loss of the pruned model. To
preserve the efficiency, our method 1) works at post-training phase} and 2)
eliminates the back-propagation through the LLM per se during the optimization
(i.e., only requires the forward pass of the LLM). We achieve this by learning
an underlying Bernoulli distribution to sample binary pruning masks, where we
decouple the Bernoulli parameters from the LLM loss, thus facilitating an
efficient optimization via a policy gradient estimator without
back-propagation. As a result, our method is able to 1) operate at structural
granularities of channels, heads, and layers, 2) support global and
heterogeneous pruning (i.e., our method automatically determines different
redundancy for different layers), and 3) optionally use a metric-based method
as initialization (of our Bernoulli distributions). Extensive experiments on
LLaMA, LLaMA-2, and Vicuna using the C4 and WikiText2 datasets demonstrate that
our method operates for 2.7 hours with around 35GB memory for the 13B models on
a single A100 GPU, and our pruned models outperform the state-of-the-arts
w.r.t. perplexity. Codes will be released."
Large Language Models Playing Mixed Strategy Nash Equilibrium Games,https://arxiv.org/abs/2406.10574,2024-06-15,2024-06-19,0.0,0.0,"Generative artificial intelligence (Generative AI), and in particular Large
Language Models (LLMs) have gained significant popularity among researchers and
industrial communities, paving the way for integrating LLMs in different
domains, such as robotics, telecom, and healthcare. In this paper, we study the
intersection of game theory and generative artificial intelligence, focusing on
the capabilities of LLMs to find the Nash equilibrium in games with a mixed
strategy Nash equilibrium and no pure strategy Nash equilibrium (that we denote
mixed strategy Nash equilibrium games). The study reveals a significant
enhancement in the performance of LLMs when they are equipped with the
possibility to run code and are provided with a specific prompt to incentivize
them to do so. However, our research also highlights the limitations of LLMs
when the randomization strategy of the game is not easy to deduce. It is
evident that while LLMs exhibit remarkable proficiency in well-known standard
games, their performance dwindles when faced with slight modifications of the
same games. This paper aims to contribute to the growing body of knowledge on
the intersection of game theory and generative artificial intelligence while
providing valuable insights into LLMs strengths and weaknesses. It also
underscores the need for further research to overcome the limitations of LLMs,
particularly in dealing with even slightly more complex scenarios, to harness
their full potential."
"Graph Neural Backdoor - Fundamentals, Methodologies, Applications, and Future Directions",https://arxiv.org/abs/2406.10573,2024-06-15,2024-06-19,0.0,0.0,"Graph Neural Networks (GNNs) have significantly advanced various downstream
graph-relevant tasks, encompassing recommender systems, molecular structure
prediction, social media analysis, etc. Despite the boosts of GNN, recent
research has empirically demonstrated its potential vulnerability to backdoor
attacks, wherein adversaries employ triggers to poison input samples, inducing
GNN to adversary-premeditated malicious outputs. This is typically due to the
controlled training process, or the deployment of untrusted models, such as
delegating model training to third-party service, leveraging external training
sets, and employing pre-trained models from online sources. Although there's an
ongoing increase in research on GNN backdoors, comprehensive investigation into
this field is lacking. To bridge this gap, we propose the first survey
dedicated to GNN backdoors. We begin by outlining the fundamental definition of
GNN, followed by the detailed summarization and categorization of current GNN
backdoor attacks and defenses based on their technical characteristics and
application scenarios. Subsequently, the analysis of the applicability and use
cases of GNN backdoors is undertaken. Finally, the exploration of potential
research directions of GNN backdoors is presented. This survey aims to explore
the principles of graph backdoors, provide insights to defenders, and promote
future security research."
Model Evaluation and Anomaly Detection in Temporal Complex Networks using Deep Learning Methods,https://arxiv.org/abs/2406.11901,2024-06-15,2024-06-19,0.0,0.0,"Modeling complex networks allows us to analyze the characteristics and
discover the basic mechanisms governing phenomena such as disease outbreaks,
information diffusion, transportation efficiency, social influence, and even
human brain function. Consequently, various network generative models (called
temporal network models) have been presented to model how the network
topologies evolve dynamically over time. Temporal network models face the
challenge of results evaluation because common evaluation methods are
appropriate only for static networks. This paper proposes an automatic approach
based on deep learning to handle this issue. In addition to an evaluation
method, the proposed method can also be used for anomaly detection in evolving
networks. The proposed method has been evaluated on five different datasets,
and the evaluations show that it outperforms the alternative methods based on
the error rate measure in different datasets."
MDA - An Interpretable Multi-Modal Fusion with Missing Modalities and Intrinsic Noise,https://arxiv.org/abs/2406.10569,2024-06-15,2024-06-19,0.0,0.0,"Multi-modal fusion is crucial in medical data research, enabling a
comprehensive understanding of diseases and improving diagnostic performance by
combining diverse modalities. However, multi-modal fusion faces challenges,
including capturing interactions between modalities, addressing missing
modalities, handling erroneous modal information, and ensuring
interpretability. Many existing researchers tend to design different solutions
for these problems, often overlooking the commonalities among them. This paper
proposes a novel multi-modal fusion framework that achieves adaptive adjustment
over the weights of each modality by introducing the Modal-Domain Attention
(MDA). It aims to facilitate the fusion of multi-modal information while
allowing for the inclusion of missing modalities or intrinsic noise, thereby
enhancing the representation of multi-modal data. We provide visualizations of
accuracy changes and MDA weights by observing the process of modal fusion,
offering a comprehensive analysis of its interpretability. Extensive
experiments on various gastrointestinal disease benchmarks, the proposed MDA
maintains high accuracy even in the presence of missing modalities and
intrinsic noise. One thing worth mentioning is that the visualization of MDA is
highly consistent with the conclusions of existing clinical studies on the
dependence of different diseases on various modalities. Code and dataset will
be made available."
Privacy-Preserving Heterogeneous Federated Learning for Sensitive Healthcare Data,https://arxiv.org/abs/2406.10563,2024-06-15,2024-06-19,0.0,0.0,"In the realm of healthcare where decentralized facilities are prevalent,
machine learning faces two major challenges concerning the protection of data
and models. The data-level challenge concerns the data privacy leakage when
centralizing data with sensitive personal information. While the model-level
challenge arises from the heterogeneity of local models, which need to be
collaboratively trained while ensuring their confidentiality to address
intellectual property concerns. To tackle these challenges, we propose a new
framework termed Abstention-Aware Federated Voting (AAFV) that can
collaboratively and confidentially train heterogeneous local models while
simultaneously protecting the data privacy. This is achieved by integrating a
novel abstention-aware voting mechanism and a differential privacy mechanism
onto local models' predictions. In particular, the proposed abstention-aware
voting mechanism exploits a threshold-based abstention method to select
high-confidence votes from heterogeneous local models, which not only enhances
the learning utility but also protects model confidentiality. Furthermore, we
implement AAFV on two practical prediction tasks of diabetes and in-hospital
patient mortality. The experiments demonstrate the effectiveness and
confidentiality of AAFV in testing accuracy and privacy protection."
We Care - Multimodal Depression Detection and Knowledge Infused Mental Health Therapeutic Response Generation,https://arxiv.org/abs/2406.10561,2024-06-15,2024-06-19,0.0,0.0,"The detection of depression through non-verbal cues has gained significant
attention. Previous research predominantly centred on identifying depression
within the confines of controlled laboratory environments, often with the
supervision of psychologists or counsellors. Unfortunately, datasets generated
in such controlled settings may struggle to account for individual behaviours
in real-life situations. In response to this limitation, we present the
Extended D-vlog dataset, encompassing a collection of 1, 261 YouTube vlogs.
Additionally, the emergence of large language models (LLMs) like GPT3.5, and
GPT4 has sparked interest in their potential they can act like mental health
professionals. Yet, the readiness of these LLM models to be used in real-life
settings is still a concern as they can give wrong responses that can harm the
users. We introduce a virtual agent serving as an initial contact for mental
health patients, offering Cognitive Behavioral Therapy (CBT)-based responses.
It comprises two core functions: 1. Identifying depression in individuals, and
2. Delivering CBT-based therapeutic responses. Our Mistral model achieved
impressive scores of 70.1% and 30.9% for distortion assessment and
classification, along with a Bert score of 88.7%. Moreover, utilizing the TVLT
model on our Multimodal Extended D-vlog Dataset yielded outstanding results,
with an impressive F1-score of 67.8%"
Facts-and-Feelings - Capturing both Objectivity and Subjectivity in Table-to-Text Generation,https://arxiv.org/abs/2406.10560,2024-06-15,2024-06-19,0.0,0.0,"Table-to-text generation, a long-standing challenge in natural language
generation, has remained unexplored through the lens of subjectivity.
Subjectivity here encompasses the comprehension of information derived from the
table that cannot be described solely by objective data. Given the absence of
pre-existing datasets, we introduce the Ta2TS dataset with 3849 data instances.
We perform the task of fine-tuning sequence-to-sequence models on the
linearized tables and prompting on popular large language models. We analyze
the results from a quantitative and qualitative perspective to ensure the
capture of subjectivity and factual consistency. The analysis shows the
fine-tuned LMs can perform close to the prompted LLMs. Both the models can
capture the tabular data, generating texts with 85.15% BERTScore and 26.28%
Meteor score. To the best of our knowledge, we provide the first-of-its-kind
dataset on tables with multiple genres and subjectivity included and present
the first comprehensive analysis and comparison of different LLM performances
on this task."
Grad-Instructor - Universal Backpropagation with Explainable Evaluation Neural Networks for Meta-learning and AutoML,https://arxiv.org/abs/2406.10559,2024-06-15,2024-06-19,0.0,0.0,"This paper presents a novel method for autonomously enhancing deep neural
network training. My approach employs an Evaluation Neural Network (ENN)
trained via deep reinforcement learning to predict the performance of the
target network. The ENN then works as an additional evaluation function during
backpropagation. Computational experiments with Multi-Layer Perceptrons (MLPs)
demonstrate the method's effectiveness. By processing input data at 0.15^2
times its original resolution, the ENNs facilitated efficient inference.
Results indicate that MLPs trained with the proposed method achieved a mean
test accuracy of 93.02%, which is 2.8% higher than those trained solely with
conventional backpropagation or with L1 regularization. The proposed method's
test accuracy is comparable to networks initialized with He initialization
while reducing the difference between test and training errors. These
improvements are achieved without increasing the number of epochs, thus
avoiding the risk of overfitting. Additionally, the proposed method dynamically
adjusts gradient magnitudes according to the training stage. The optimal ENN
for enhancing MLPs can be predicted, reducing the time spent exploring optimal
training methodologies. The explainability of ENNs is also analyzed using
Grad-CAM, demonstrating their ability to visualize evaluation bases and
supporting the Strong Lottery Ticket hypothesis."
Explain the Black Box for the Sake of Science - Revisiting the Scientific Method in the Era of Generative Artificial Intelligence,https://arxiv.org/abs/2406.10557,2024-06-15,2024-06-19,0.0,0.0,"The scientific method is the cornerstone of human progress across all
branches of the natural and applied sciences, from understanding the human body
to explaining how the universe works. The scientific method is based on
identifying systematic rules or principles that describe the phenomenon of
interest in a reproducible way that can be validated through experimental
evidence. In the era of artificial intelligence (AI), there are discussions on
how AI systems may discover new knowledge. We argue that human complex
reasoning for scientific discovery remains of vital importance, at least before
the advent of artificial general intelligence. Yet, AI can be leveraged for
scientific discovery via explainable AI. More specifically, knowing what data
AI systems deemed important to make decisions can be a point of contact with
domain experts and scientists, that can lead to divergent or convergent views
on a given scientific problem. Divergent views may spark further scientific
investigations leading to new scientific knowledge."
Multi-User Semantic Fusion for Semantic Communications over Degraded Broadcast Channels,https://arxiv.org/abs/2406.10556,2024-06-15,2024-06-19,0.0,0.0,"Degraded broadcast channels (DBC) are a typical multiuser communication
scenario, Semantic communications over DBC still lack in-depth research. In
this paper, we design a semantic communications approach based on multi-user
semantic fusion for wireless image transmission over DBC. In the proposed
method, the transmitter extracts semantic features for two users separately. It
then effectively fuses these semantic features for broadcasting by leveraging
semantic similarity. Unlike traditional allocation of time, power, or
bandwidth, the semantic fusion scheme can dynamically control the weight of the
semantic features of the two users to balance the performance between the two
users. Considering the different channel state information (CSI) of both users
over DBC, a DBC-Aware method is developed that embeds the CSI of both users
into the joint source-channel coding encoder and fusion module to adapt to the
channel. Experimental results show that the proposed system outperforms the
traditional broadcasting schemes."
Horizon-wise Learning Paradigm Promotes Gene Splicing Identification,https://arxiv.org/abs/2406.11900,2024-06-15,2024-06-19,0.0,0.0,"Identifying gene splicing is a core and significant task confronted in modern
collaboration between artificial intelligence and bioinformatics. Past decades
have witnessed great efforts on this concern, such as the bio-plausible
splicing pattern AT-CG and the famous SpliceAI. In this paper, we propose a
novel framework for the task of gene splicing identification, named
Horizon-wise Gene Splicing Identification (H-GSI). The proposed H-GSI follows
the horizon-wise identification paradigm and comprises four components: the
pre-processing procedure transforming string data into tensors, the sliding
window technique handling long sequences, the SeqLab model, and the predictor.
In contrast to existing studies that process gene information with a truncated
fixed-length sequence, H-GSI employs a horizon-wise identification paradigm in
which all positions in a sequence are predicted with only one forward
computation, improving accuracy and efficiency. The experiments conducted on
the real-world Human dataset show that our proposed H-GSI outperforms SpliceAI
and achieves the best accuracy of 97.20\%. The source code is available from
this link."
Large Language Model Enhanced Clustering for News Event Detection,https://arxiv.org/abs/2406.10552,2024-06-15,2024-06-19,0.0,0.0,"The news landscape is continuously evolving, with an ever-increasing volume
of information from around the world. Automated event detection within this
vast data repository is essential for monitoring, identifying, and categorizing
significant news occurrences across diverse platforms. This paper presents an
event detection framework that leverages Large Language Models (LLMs) combined
with clustering analysis to detect news events from the Global Database of
Events, Language, and Tone (GDELT). The framework enhances event clustering
through both pre-event detection tasks (keyword extraction and text embedding)
and post-event detection tasks (event summarization and topic labelling). We
also evaluate the impact of various textual embeddings on the quality of
clustering outcomes, ensuring robust news categorization. Additionally, we
introduce a novel Cluster Stability Assessment Index (CSAI) to assess the
validity and robustness of clustering results. CSAI utilizes multiple feature
vectors to provide a new way of measuring clustering quality. Our experiments
indicate that the use of LLM embedding in the event detection framework has
significantly improved the results, demonstrating greater robustness in terms
of CSAI scores. Moreover, post-event detection tasks generate meaningful
insights, facilitating effective interpretation of event clustering results.
Overall, our experimental results indicate that the proposed framework offers
valuable insights and could enhance the accuracy in news analysis and
reporting."
Lightweight Audio Segmentation for Long-form Speech Translation,https://arxiv.org/abs/2406.10549,2024-06-15,2024-06-19,0.0,0.0,"Speech segmentation is an essential part of speech translation (ST) systems
in real-world scenarios. Since most ST models are designed to process speech
segments, long-form audio must be partitioned into shorter segments before
translation. Recently, data-driven approaches for the speech segmentation task
have been developed. Although the approaches improve overall translation
quality, a performance gap exists due to a mismatch between the models and ST
systems. In addition, the prior works require large self-supervised speech
models, which consume significant computational resources. In this work, we
propose a segmentation model that achieves better speech translation quality
with a small model size. We propose an ASR-with-punctuation task as an
effective pre-training strategy for the segmentation model. We also show that
proper integration of the speech segmentation model into the underlying ST
system is critical to improve overall translation quality at inference time."
NeRFDeformer - NeRF Transformation from a Single View via 3D Scene Flows,https://arxiv.org/abs/2406.10543,2024-06-15,2024-06-19,0.0,0.0,"We present a method for automatically modifying a NeRF representation based
on a single observation of a non-rigid transformed version of the original
scene. Our method defines the transformation as a 3D flow, specifically as a
weighted linear blending of rigid transformations of 3D anchor points that are
defined on the surface of the scene. In order to identify anchor points, we
introduce a novel correspondence algorithm that first matches RGB-based pairs,
then leverages multi-view information and 3D reprojection to robustly filter
false positives in two steps. We also introduce a new dataset for exploring the
problem of modifying a NeRF scene through a single observation. Our dataset (
https://github.com/nerfdeformer/nerfdeformer ) contains 113 synthetic scenes
leveraging 47 3D assets. We show that our proposed method outperforms NeRF
editing methods as well as diffusion-based methods, and we also explore
different methods for filtering correspondences."
Generating and Evolving Reward Functions for Highway Driving with Large Language Models,https://arxiv.org/abs/2406.10540,2024-06-15,2024-06-19,0.0,0.0,"Reinforcement Learning (RL) plays a crucial role in advancing autonomous
driving technologies by maximizing reward functions to achieve the optimal
policy. However, crafting these reward functions has been a complex, manual
process in many practices. To reduce this complexity, we introduce a novel
framework that integrates Large Language Models (LLMs) with RL to improve
reward function design in autonomous driving. This framework utilizes the
coding capabilities of LLMs, proven in other areas, to generate and evolve
reward functions for highway scenarios. The framework starts with instructing
LLMs to create an initial reward function code based on the driving environment
and task descriptions. This code is then refined through iterative cycles
involving RL training and LLMs' reflection, which benefits from their ability
to review and improve the output. We have also developed a specific prompt
template to improve LLMs' understanding of complex driving simulations,
ensuring the generation of effective and error-free code. Our experiments in a
highway driving simulator across three traffic configurations show that our
method surpasses expert handcrafted reward functions, achieving a 22% higher
average success rate. This not only indicates safer driving but also suggests
significant gains in development productivity."
Large Reasoning Models for 3D Floorplanning in EDA - Learning from Imperfections,https://arxiv.org/abs/2406.10538,2024-06-15,2024-06-19,0.0,0.0,"In this paper, we introduce Dreamweaver, which belongs to a new class of
auto-regressive decision-making models known as large reasoning models (LRMs).
Dreamweaver is designed to improve 3D floorplanning in electronic design
automation (EDA) via an architecture that melds advancements in
sequence-to-sequence reinforcement learning algorithms. A significant advantage
of our approach is its ability to effectively reason over large discrete action
spaces, which is essential for handling the numerous potential positions for
various functional blocks in floorplanning. Additionally, Dreamweaver
demonstrates strong performance even when trained on entirely random
trajectories, showcasing its capacity to leverage sub-optimal or non-expert
trajectories to enhance its results. This innovative approach contributes to
streamlining the integrated circuit (IC) design flow and reducing the high
computational costs typically associated with floorplanning. We evaluate its
performance against a current state-of-the-art method, highlighting notable
improvements."
Scalable Differentiable Causal Discovery in the Presence of Latent Confounders with Skeleton Posterior (Extended Version),https://arxiv.org/abs/2406.10537,2024-06-15,2024-06-19,0.0,0.0,"Differentiable causal discovery has made significant advancements in the
learning of directed acyclic graphs. However, its application to real-world
datasets remains restricted due to the ubiquity of latent confounders and the
requirement to learn maximal ancestral graphs (MAGs). To date, existing
differentiable MAG learning algorithms have been limited to small datasets and
failed to scale to larger ones (e.g., with more than 50 variables).
  The key insight in this paper is that the causal skeleton, which is the
undirected version of the causal graph, has potential for improving accuracy
and reducing the search space of the optimization procedure, thereby enhancing
the performance of differentiable causal discovery. Therefore, we seek to
address a two-fold challenge to harness the potential of the causal skeleton
for differentiable causal discovery in the presence of latent confounders: (1)
scalable and accurate estimation of skeleton and (2) universal integration of
skeleton estimation with differentiable causal discovery.
  To this end, we propose SPOT (Skeleton Posterior-guided OpTimization), a
two-phase framework that harnesses skeleton posterior for differentiable causal
discovery in the presence of latent confounders. On the contrary to a
``point-estimation'', SPOT seeks to estimate the posterior distribution of
skeletons given the dataset. It first formulates the posterior inference as an
instance of amortized inference problem and concretizes it with a supervised
causal learning (SCL)-enabled solution to estimate the skeleton posterior. To
incorporate the skeleton posterior with differentiable causal discovery, SPOT
then features a skeleton posterior-guided stochastic optimization procedure to
guide the optimization of MAGs. [abridged due to length limit]"
A Finite Difference Informed Graph Network for Solving Steady-State Incompressible Flows on Block-Structured Grids,https://arxiv.org/abs/2406.10534,2024-06-15,2024-06-19,0.0,0.0,"Recently, advancements in deep learning have enabled physics-informed neural
networks (PINNs) to solve partial differential equations (PDEs). Numerical
differentiation (ND) using the finite difference (FD) method is efficient in
physics-constrained designs, even in parameterized settings, often employing
body-fitted block-structured grids for complex flow cases. However, convolution
operators in CNNs for finite differences are typically limited to single-block
grids. To address this, we use graphs and graph networks (GNs) to learn flow
representations across multi-block structured grids. We propose a graph
convolution-based finite difference method (GC-FDM) to train GNs in a
physics-constrained manner, enabling differentiable finite difference
operations on graph unstructured outputs. Our goal is to solve parametric
steady incompressible Navier-Stokes equations for flows around a
backward-facing step, a circular cylinder, and double cylinders, using
multi-block structured grids. Comparing our method to a CFD solver under
various boundary conditions, we demonstrate improved training efficiency and
accuracy, achieving a minimum relative error of $10^{-3}$ in velocity field
prediction and a 20\% reduction in training cost compared to PINNs."
A Theory of Interpretable Approximations,https://arxiv.org/abs/2406.10529,2024-06-15,2024-06-19,0.0,0.0,"Can a deep neural network be approximated by a small decision tree based on
simple features? This question and its variants are behind the growing demand
for machine learning models that are *interpretable* by humans. In this work we
study such questions by introducing *interpretable approximations*, a notion
that captures the idea of approximating a target concept $c$ by a small
aggregation of concepts from some base class $\mathcal{H}$. In particular, we
consider the approximation of a binary concept $c$ by decision trees based on a
simple class $\mathcal{H}$ (e.g., of bounded VC dimension), and use the tree
depth as a measure of complexity. Our primary contribution is the following
remarkable trichotomy. For any given pair of $\mathcal{H}$ and $c$, exactly one
of these cases holds: (i) $c$ cannot be approximated by $\mathcal{H}$ with
arbitrary accuracy; (ii) $c$ can be approximated by $\mathcal{H}$ with
arbitrary accuracy, but there exists no universal rate that bounds the
complexity of the approximations as a function of the accuracy; or (iii) there
exists a constant $\kappa$ that depends only on $\mathcal{H}$ and $c$ such
that, for *any* data distribution and *any* desired accuracy level, $c$ can be
approximated by $\mathcal{H}$ with a complexity not exceeding $\kappa$. This
taxonomy stands in stark contrast to the landscape of supervised
classification, which offers a complex array of distribution-free and
universally learnable scenarios. We show that, in the case of interpretable
approximations, even a slightly nontrivial a-priori guarantee on the complexity
of approximations implies approximations with constant (distribution-free and
accuracy-free) complexity. We extend our trichotomy to classes $\mathcal{H}$ of
unbounded VC dimension and give characterizations of interpretability based on
the algebra generated by $\mathcal{H}$."
Memory Faults in Activation-sparse Quantized Deep Neural Networks - Analysis and Mitigation using Sharpness-aware Training,https://arxiv.org/abs/2406.10528,2024-06-15,2024-06-19,0.0,0.0,"Improving the hardware efficiency of deep neural network (DNN) accelerators
with techniques such as quantization and sparsity enhancement have shown an
immense promise. However, their inference accuracy in non-ideal real-world
settings (such as in the presence of hardware faults) is yet to be
systematically analyzed. In this work, we investigate the impact of memory
faults on activation-sparse quantized DNNs (AS QDNNs). We show that a high
level of activation sparsity comes at the cost of larger vulnerability to
faults, with AS QDNNs exhibiting up to 11.13% lower accuracy than the standard
QDNNs. We establish that the degraded accuracy correlates with a sharper minima
in the loss landscape for AS QDNNs, which makes them more sensitive to
perturbations in the weight values due to faults. Based on this observation, we
employ sharpness-aware quantization (SAQ) training to mitigate the impact of
memory faults. The AS and standard QDNNs trained with SAQ have up to 19.50% and
15.82% higher inference accuracy, respectively compared to their conventionally
trained equivalents. Moreover, we show that SAQ-trained AS QDNNs show higher
accuracy in faulty settings than standard QDNNs trained conventionally. Thus,
sharpness-aware training can be instrumental in achieving sparsity-related
latency benefits without compromising on fault tolerance."
Humor in AI - Massive Scale Crowd-Sourced Preferences and Benchmarks for Cartoon Captioning,https://arxiv.org/abs/2406.10522,2024-06-15,2024-06-19,0.0,0.0,"We present a novel multimodal preference dataset for creative tasks,
consisting of over 250 million human ratings on more than 2.2 million captions,
collected through crowdsourcing rating data for The New Yorker's weekly cartoon
caption contest over the past eight years. This unique dataset supports the
development and evaluation of multimodal large language models and
preference-based fine-tuning algorithms for humorous caption generation. We
propose novel benchmarks for judging the quality of model-generated captions,
utilizing both GPT4 and human judgments to establish ranking-based evaluation
strategies. Our experimental results highlight the limitations of current
fine-tuning methods, such as RLHF and DPO, when applied to creative tasks.
Furthermore, we demonstrate that even state-of-the-art models like GPT4 and
Claude currently underperform top human contestants in generating humorous
captions. As we conclude this extensive data collection effort, we release the
entire preference dataset to the research community, fostering further
advancements in AI humor generation and evaluation."
MALLM-GAN - Multi-Agent Large Language Model as Generative Adversarial Network for Synthesizing Tabular Data,https://arxiv.org/abs/2406.10521,2024-06-15,2024-06-19,0.0,0.0,"In the era of big data, access to abundant data is crucial for driving
research forward. However, such data is often inaccessible due to privacy
concerns or high costs, particularly in healthcare domain. Generating synthetic
(tabular) data can address this, but existing models typically require
substantial amounts of data to train effectively, contradicting our objective
to solve data scarcity. To address this challenge, we propose a novel framework
to generate synthetic tabular data, powered by large language models (LLMs)
that emulates the architecture of a Generative Adversarial Network (GAN). By
incorporating data generation process as contextual information and utilizing
LLM as the optimizer, our approach significantly enhance the quality of
synthetic data generation in common scenarios with small sample sizes. Our
experimental results on public and private datasets demonstrate that our model
outperforms several state-of-art models regarding generating higher quality
synthetic data for downstream tasks while keeping privacy of the real data."
Self Pre-training with Topology- and Spatiality-aware Masked Autoencoders for 3D Medical Image Segmentation,https://arxiv.org/abs/2406.10519,2024-06-15,2024-06-19,0.0,0.0,"Masked Autoencoders (MAEs) have been shown to be effective in pre-training
Vision Transformers (ViTs) for natural and medical image analysis problems. By
reconstructing missing pixel/voxel information in visible patches, a ViT
encoder can aggregate contextual information for downstream tasks. But,
existing MAE pre-training methods, which were specifically developed with the
ViT architecture, lack the ability to capture geometric shape and spatial
information, which is critical for medical image segmentation tasks. In this
paper, we propose a novel extension of known MAEs for self pre-training (i.e.,
models pre-trained on the same target dataset) for 3D medical image
segmentation. (1) We propose a new topological loss to preserve geometric shape
information by computing topological signatures of both the input and
reconstructed volumes, learning geometric shape information. (2) We introduce a
pre-text task that predicts the positions of the centers and eight corners of
3D crops, enabling the MAE to aggregate spatial information. (3) We extend the
MAE pre-training strategy to a hybrid state-of-the-art (SOTA) medical image
segmentation architecture and co-pretrain it alongside the ViT. (4) We develop
a fine-tuned model for downstream segmentation tasks by complementing the
pre-trained ViT encoder with our pre-trained SOTA model. Extensive experiments
on five public 3D segmentation datasets show the effectiveness of our new
approach."
ADSNet - Cross-Domain LTV Prediction with an Adaptive Siamese Network in Advertising,https://arxiv.org/abs/2406.10517,2024-06-15,2024-06-19,0.0,0.0,"Advertising platforms have evolved in estimating Lifetime Value (LTV) to
better align with advertisers' true performance metric. However, the sparsity
of real-world LTV data presents a significant challenge to LTV predictive
model(i.e., pLTV), severely limiting the their capabilities. Therefore, we
propose to utilize external data, in addition to the internal data of
advertising platform, to expand the size of purchase samples and enhance the
LTV prediction model of the advertising platform. To tackle the issue of data
distribution shift between internal and external platforms, we introduce an
Adaptive Difference Siamese Network (ADSNet), which employs cross-domain
transfer learning to prevent negative transfer. Specifically, ADSNet is
designed to learn information that is beneficial to the target domain. We
introduce a gain evaluation strategy to calculate information gain, aiding the
model in learning helpful information for the target domain and providing the
ability to reject noisy samples, thus avoiding negative transfer. Additionally,
we also design a Domain Adaptation Module as a bridge to connect different
domains, reduce the distribution distance between them, and enhance the
consistency of representation space distribution. We conduct extensive offline
experiments and online A/B tests on a real advertising platform. Our proposed
ADSNet method outperforms other methods, improving GINI by 2$\%$. The ablation
study highlights the importance of the gain evaluation strategy in negative
gain sample rejection and improving model performance. Additionally, ADSNet
significantly improves long-tail prediction. The online A/B tests confirm
ADSNet's efficacy, increasing online LTV by 3.47$\%$ and GMV by 3.89$\%$."
"Reactor Mk.1 performances - MMLU, HumanEval and BBH test results",https://arxiv.org/abs/2406.10515,2024-06-15,2024-06-19,0.0,0.0,"The paper presents the performance results of Reactor Mk.1, ARCs flagship
large language model, through a benchmarking process analysis. The model
utilizes the Lychee AI engine and possesses less than 100 billion parameters,
resulting in a combination of efficiency and potency. The Reactor Mk.1
outperformed models such as GPT-4o, Claude Opus, and Llama 3, with achieved
scores of 92% on the MMLU dataset, 91% on HumanEval dataset, and 88% on BBH
dataset. It excels in both managing difficult jobs and reasoning, establishing
as a prominent AI solution in the present cutting-edge AI technology."
Articulatory Phonetics Informed Controllable Expressive Speech Synthesis,https://arxiv.org/abs/2406.10514,2024-06-15,2024-06-19,0.0,0.0,"Expressive speech synthesis aims to generate speech that captures a wide
range of para-linguistic features, including emotion and articulation, though
current research primarily emphasizes emotional aspects over the nuanced
articulatory features mastered by professional voice actors. Inspired by this,
we explore expressive speech synthesis through the lens of articulatory
phonetics. Specifically, we define a framework with three dimensions:
Glottalization, Tenseness, and Resonance (GTR), to guide the synthesis at the
voice production level. With this framework, we record a high-quality speech
dataset named GTR-Voice, featuring 20 Chinese sentences articulated by a
professional voice actor across 125 distinct GTR combinations. We verify the
framework and GTR annotations through automatic classification and listening
tests, and demonstrate precise controllability along the GTR dimensions on two
fine-tuned expressive TTS models. We open-source the dataset and TTS models."
Lift Your Molecules - Molecular Graph Generation in Latent Euclidean Space,https://arxiv.org/abs/2406.10513,2024-06-15,2024-06-19,0.0,0.0,"We introduce a new framework for molecular graph generation with 3D molecular
generative models. Our Synthetic Coordinate Embedding (SyCo) framework maps
molecular graphs to Euclidean point clouds via synthetic conformer coordinates
and learns the inverse map using an E(n)-Equivariant Graph Neural Network
(EGNN). The induced point cloud-structured latent space is well-suited to apply
existing 3D molecular generative models. This approach simplifies the graph
generation problem - without relying on molecular fragments nor autoregressive
decoding - into a point cloud generation problem followed by node and edge
classification tasks. Further, we propose a novel similarity-constrained
optimization scheme for 3D diffusion models based on inpainting and guidance.
As a concrete implementation of our framework, we develop EDM-SyCo based on the
E(3) Equivariant Diffusion Model (EDM). EDM-SyCo achieves state-of-the-art
performance in distribution learning of molecular graphs, outperforming the
best non-autoregressive methods by more than 30% on ZINC250K and 16% on the
large-scale GuacaMol dataset while improving conditional generation by up to
3.9 times."
Benchmarking Children's ASR with Supervised and Self-supervised Speech Foundation Models,https://arxiv.org/abs/2406.10507,2024-06-15,2024-06-19,0.0,0.0,"Speech foundation models (SFMs) have achieved state-of-the-art results for
various speech tasks in supervised (e.g. Whisper) or self-supervised systems
(e.g. WavLM). However, the performance of SFMs for child ASR has not been
systematically studied. In addition, there is no benchmark for child ASR with
standard evaluations, making the comparisons of novel ideas difficult. In this
paper, we initiate and present a comprehensive benchmark on several child
speech databases based on various SFMs (Whisper, Wav2vec2.0, HuBERT, and
WavLM). Moreover, we investigate finetuning strategies by comparing various
data augmentation and parameter-efficient finetuning (PEFT) methods. We observe
that the behaviors of these methods are different when the model size
increases. For example, PEFT matches the performance of full finetuning for
large models but worse for small models. To stabilize finetuning using
augmented data, we propose a perturbation invariant finetuning (PIF) loss as a
regularization."
CroPrompt - Cross-task Interactive Prompting for Zero-shot Spoken Language Understanding,https://arxiv.org/abs/2406.10505,2024-06-15,2024-06-19,0.0,0.0,"Slot filling and intent detection are two highly correlated tasks in spoken
language understanding (SLU). Recent SLU research attempts to explore zero-shot
prompting techniques in large language models to alleviate the data scarcity
problem. Nevertheless, the existing prompting work ignores the cross-task
interaction information for SLU, which leads to sub-optimal performance. To
solve this problem, we present the pioneering work of Cross-task Interactive
Prompting (CroPrompt) for SLU, which enables the model to interactively
leverage the information exchange across the correlated tasks in SLU.
Additionally, we further introduce a multi-task self-consistency mechanism to
mitigate the error propagation caused by the intent information injection. We
conduct extensive experiments on the standard SLU benchmark and the results
reveal that CroPrompt consistently outperforms the existing prompting
approaches. In addition, the multi-task self-consistency mechanism can
effectively ease the error propagation issue, thereby enhancing the
performance. We hope this work can inspire more research on cross-task
prompting for SLU."
Task Facet Learning - A Structured Approach to Prompt Optimization,https://arxiv.org/abs/2406.10504,2024-06-15,2024-06-19,0.0,0.0,"Given a task in the form of a basic description and its training examples,
prompt optimization is the problem of synthesizing the given information into a
text prompt for a large language model (LLM). Humans solve this problem by also
considering the different facets that define a task (e.g., counter-examples,
explanations, analogies) and including them in the prompt. However, it is
unclear whether existing algorithmic approaches, based on iteratively editing a
given prompt or automatically selecting a few in-context examples, can cover
the multiple facets required to solve a complex task. In this work, we view
prompt optimization as that of learning multiple facets of a task from a set of
training examples. We identify and exploit structure in the prompt optimization
problem -- first, we find that prompts can be broken down into loosely coupled
semantic sections that have a relatively independent effect on the prompt's
performance; second, we cluster the input space and use clustered batches so
that the optimization procedure can learn the different facets of a task across
batches. The resulting algorithm, UniPrompt, consists of a generative model to
generate initial candidates for each prompt section; and a feedback mechanism
that aggregates suggested edits from multiple mini-batches into a conceptual
description for the section. Empirical evaluation on multiple datasets and a
real-world task shows that prompts generated using UniPrompt obtain higher
accuracy than human-tuned prompts and those from state-of-the-art methods. In
particular, our algorithm can generate long, complex prompts that existing
methods are unable to generate. Code for UniPrompt will be available at
\url{https://aka.ms/uniprompt}."
Candidate Pseudolabel Learning - Enhancing Vision-Language Models by Prompt Tuning with Unlabeled Data,https://arxiv.org/abs/2406.10502,2024-06-15,2024-06-19,0.0,0.0,"Fine-tuning vision-language models (VLMs) with abundant unlabeled data
recently has attracted increasing attention. Existing methods that resort to
the pseudolabeling strategy would suffer from heavily incorrect hard
pseudolabels when VLMs exhibit low zero-shot performance in downstream tasks.
To alleviate this issue, we propose a Candidate Pseudolabel Learning method,
termed CPL, to fine-tune VLMs with suitable candidate pseudolabels of unlabeled
data in downstream tasks. The core of our method lies in the generation
strategy of candidate pseudolabels, which progressively generates refined
candidate pseudolabels by both intra- and inter-instance label selection, based
on a confidence score matrix for all unlabeled data. This strategy can result
in better performance in true label inclusion and class-balanced instance
selection. In this way, we can directly apply existing loss functions to learn
with generated candidate psueudolabels. Extensive experiments on nine benchmark
datasets with three learning paradigms demonstrate the effectiveness of our
method. Our code can be found at https://github.com/vanillaer/CPL-ICML2024."
Geodesic Distance Between Graphs - A Spectral Metric for Assessing the Stability of Graph Neural Networks,https://arxiv.org/abs/2406.10500,2024-06-15,2024-06-19,0.0,0.0,"This paper presents a spectral framework for assessing the generalization and
stability of Graph Neural Networks (GNNs) by introducing a Graph Geodesic
Distance (GGD) metric. For two different graphs with the same number of nodes,
our framework leverages a spectral graph matching procedure to find node
correspondence so that the geodesic distance between them can be subsequently
computed by solving a generalized eigenvalue problem associated with their
Laplacian matrices. For graphs with different sizes, a resistance-based
spectral graph coarsening scheme is introduced to reduce the size of the bigger
graph while preserving the original spectral properties. We show that the
proposed GGD metric can effectively quantify dissimilarities between two graphs
by encapsulating their differences in key structural (spectral) properties,
such as effective resistances between nodes, cuts, the mixing time of random
walks, etc. Through extensive experiments comparing with the state-of-the-art
metrics, such as the latest Tree-Mover's Distance (TMD) metric, the proposed
GGD metric shows significantly improved performance for stability evaluation of
GNNs especially when only partial node features are available."
A Unified Graph Selective Prompt Learning for Graph Neural Networks,https://arxiv.org/abs/2406.10498,2024-06-15,2024-06-19,0.0,0.0,"In recent years, graph prompt learning/tuning has garnered increasing
attention in adapting pre-trained models for graph representation learning. As
a kind of universal graph prompt learning method, Graph Prompt Feature (GPF)
has achieved remarkable success in adapting pre-trained models for Graph Neural
Networks (GNNs). By fixing the parameters of a pre-trained GNN model, the aim
of GPF is to modify the input graph data by adding some (learnable) prompt
vectors into graph node features to better align with the downstream tasks on
the smaller dataset. However, existing GPFs generally suffer from two main
limitations. First, GPFs generally focus on node prompt learning which ignore
the prompting for graph edges. Second, existing GPFs generally conduct the
prompt learning on all nodes equally which fails to capture the importances of
different nodes and may perform sensitively w.r.t noisy nodes in aligning with
the downstream tasks. To address these issues, in this paper, we propose a new
unified Graph Selective Prompt Feature learning (GSPF) for GNN fine-tuning. The
proposed GSPF integrates the prompt learning on both graph node and edge
together, which thus provides a unified prompt model for the graph data.
Moreover, it conducts prompt learning selectively on nodes and edges by
concentrating on the important nodes and edges for prompting which thus make
our model be more reliable and compact. Experimental results on many benchmark
datasets demonstrate the effectiveness and advantages of the proposed GSPF
method."
Large Language Models as Event Forecasters,https://arxiv.org/abs/2406.10492,2024-06-15,2024-06-19,0.0,0.0,"Key elements of human events are extracted as quadruples that consist of
subject, relation, object, and timestamp. This representation can be extended
to a quintuple by adding a fifth element: a textual summary that briefly
describes the event. These quadruples or quintuples, when organized within a
specific domain, form a temporal knowledge graph (TKG). Current learning
frameworks focus on a few TKG-related tasks, such as predicting an object given
a subject and a relation or forecasting the occurrences of multiple types of
events (i.e., relation) in the next time window. They typically rely on complex
structural and sequential models like graph neural networks (GNNs) and
recurrent neural networks (RNNs) to update intermediate embeddings. However,
these methods often neglect the contextual information inherent in each
quintuple, which can be effectively captured through concise textual
descriptions. In this paper, we investigate how large language models (LLMs)
can streamline the design of TKG learning frameworks while maintaining
competitive accuracy in prediction and forecasting tasks. We develop multiple
prompt templates to frame the object prediction (OP) task as a standard
question-answering (QA) task, suitable for instruction fine-tuning with an
encoder-decoder generative LLM. For multi-event forecasting (MEF), we design
simple yet effective prompt templates for each TKG quintuple. This novel
approach removes the need for GNNs and RNNs, instead utilizing an encoder-only
LLM to generate fixed intermediate embeddings, which are subsequently processed
by a prediction head with a self-attention mechanism to forecast potential
future relations. Extensive experiments on multiple real-world datasets using
various evaluation metrics validate the effectiveness and robustness of our
approach."
"Active, anytime-valid risk controlling prediction sets",https://arxiv.org/abs/2406.10490,2024-06-15,2024-06-19,0.0,0.0,"Rigorously establishing the safety of black-box machine learning models
concerning critical risk measures is important for providing guarantees about
model behavior. Recently, Bates et. al. (JACM '24) introduced the notion of a
risk controlling prediction set (RCPS) for producing prediction sets that are
statistically guaranteed low risk from machine learning models. Our method
extends this notion to the sequential setting, where we provide guarantees even
when the data is collected adaptively, and ensures that the risk guarantee is
anytime-valid, i.e., simultaneously holds at all time steps. Further, we
propose a framework for constructing RCPSes for active labeling, i.e., allowing
one to use a labeling policy that chooses whether to query the true label for
each received data point and ensures that the expected proportion of data
points whose labels are queried are below a predetermined label budget. We also
describe how to use predictors (i.e., the machine learning model for which we
provide risk control guarantees) to further improve the utility of our RCPSes
by estimating the expected risk conditioned on the covariates. We characterize
the optimal choices of label policy and predictor under a fixed label budget
and show a regret result that relates the estimation error of the optimal
labeling policy and predictor to the wealth process that underlies our RCPSes.
Lastly, we present practical ways of formulating label policies and empirically
show that our label policies use fewer labels to reach higher utility than
naive baseline labeling strategies (e.g., labeling all points, randomly
labeling points) on both simulations and real data."
A Label is Worth a Thousand Images in Dataset Distillation,https://arxiv.org/abs/2406.10485,2024-06-15,2024-06-19,0.0,0.0,"Data $\textit{quality}$ is a crucial factor in the performance of machine
learning models, a principle that dataset distillation methods exploit by
compressing training datasets into much smaller counterparts that maintain
similar downstream performance. Understanding how and why data distillation
methods work is vital not only for improving these methods but also for
revealing fundamental characteristics of ""good"" training data. However, a major
challenge in achieving this goal is the observation that distillation
approaches, which rely on sophisticated but mostly disparate methods to
generate synthetic data, have little in common with each other. In this work,
we highlight a largely overlooked aspect common to most of these methods: the
use of soft (probabilistic) labels. Through a series of ablation experiments,
we study the role of soft labels in depth. Our results reveal that the main
factor explaining the performance of state-of-the-art distillation methods is
not the specific techniques used to generate synthetic data but rather the use
of soft labels. Furthermore, we demonstrate that not all soft labels are
created equal; they must contain $\textit{structured information}$ to be
beneficial. We also provide empirical scaling laws that characterize the
effectiveness of soft labels as a function of images-per-class in the distilled
dataset and establish an empirical Pareto frontier for data-efficient learning.
Combined, our findings challenge conventional wisdom in dataset distillation,
underscore the importance of soft labels in learning, and suggest new
directions for improving distillation methods. Code for all experiments is
available at https://github.com/sunnytqin/no-distillation."
DCDILP - a distributed learning method for large-scale causal structure learning,https://arxiv.org/abs/2406.10481,2024-06-15,2024-06-19,0.0,0.0,"This paper presents a novel approach to causal discovery through a
divide-and-conquer framework. By decomposing the problem into smaller
subproblems defined on Markov blankets, the proposed DCDILP method first
explores in parallel the local causal graphs of these subproblems. However,
this local discovery phase encounters systematic challenges due to the presence
of hidden confounders (variables within each Markov blanket may be influenced
by external variables). Moreover, aggregating these local causal graphs in a
consistent global graph defines a large size combinatorial optimization
problem. DCDILP addresses these challenges by: i) restricting the local
subgraphs to causal links only related with the central variable of the Markov
blanket; ii) formulating the reconciliation of local causal graphs as an
integer linear programming method. The merits of the approach, in both terms of
causal discovery accuracy and scalability in the size of the problem, are
showcased by experiments and comparisons with the state of the art."
Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning,https://arxiv.org/abs/2406.10479,2024-06-15,2024-06-19,0.0,0.0,"Large language models (LLMs) have demonstrated impressive task-solving
capabilities, achieved through either prompting techniques or system designs.
However, concerns have arisen regarding their proficiency in planning tasks, as
they often struggle to generate valid plans. This paper investigates the impact
of fine-tuning on LLMs' planning capabilities. Our findings indicate that LLMs
can achieve good performance in planning through substantial (thousands of
specific examples) fine-tuning. However, fine-tuning is associated with
significant economic and computational costs. To address this challenge, we
propose the Maximum Diversity Fine-Tuning (MDFT) strategy to improve the sample
efficiency of fine-tuning in the planning domain. Specifically, our algorithm,
referred to as MDFT-g, encodes the planning task instances with their graph
representations and selects a subset of samples in the vector space that
maximizes data diversity. We empirically demonstrate that MDFT-g consistently
outperforms existing baselines at various scales across multiple benchmark
domains."
From Words to Worlds - Transforming One-line Prompt into Immersive Multi-modal Digital Stories with Communicative LLM Agent,https://arxiv.org/abs/2406.10478,2024-06-15,2024-06-19,0.0,0.0,"Digital storytelling, essential in entertainment, education, and marketing,
faces challenges in production scalability and flexibility. The StoryAgent
framework, introduced in this paper, utilizes Large Language Models and
generative tools to automate and refine digital storytelling. Employing a
top-down story drafting and bottom-up asset generation approach, StoryAgent
tackles key issues such as manual intervention, interactive scene
orchestration, and narrative consistency. This framework enables efficient
production of interactive and consistent narratives across multiple modalities,
democratizing content creation and enhancing engagement. Our results
demonstrate the framework's capability to produce coherent digital stories
without reference videos, marking a significant advancement in automated
digital storytelling."
Personalized Pieces - Efficient Personalized Large Language Models through Collaborative Efforts,https://arxiv.org/abs/2406.10471,2024-06-15,2024-06-19,0.0,0.0,"Personalized large language models (LLMs) aim to tailor interactions,
content, and recommendations to individual user preferences. While
parameter-efficient fine-tuning (PEFT) methods excel in performance and
generalization, they are costly and limit communal benefits when used
individually. To this end, we introduce Personalized Pieces (Per-Pcs), a
framework that allows users to safely share and assemble personalized PEFT
efficiently with collaborative efforts. Per-Pcs involves selecting sharers,
breaking their PEFT into pieces, and training gates for each piece. These
pieces are added to a pool, from which target users can select and assemble
personalized PEFT using their history data. This approach preserves privacy and
enables fine-grained user modeling without excessive storage and computation
demands. Experimental results show Per-Pcs outperforms non-personalized and
PEFT retrieval baselines, offering performance comparable to OPPU with
significantly lower resource use across six tasks. Further analysis highlights
Per-Pcs's robustness concerning sharer count and selection strategy, pieces
sharing ratio, and scalability in computation time and storage space. Per-Pcs's
modularity promotes safe sharing, making LLM personalization more efficient,
effective, and widely accessible through collaborative efforts."
The data augmentation algorithm,https://arxiv.org/abs/2406.10464,2024-06-15,2024-06-19,0.0,0.0,"The data augmentation (DA) algorithms are popular Markov chain Monte Carlo
(MCMC) algorithms often used for sampling from intractable probability
distributions. This review article comprehensively surveys DA MCMC algorithms,
highlighting their theoretical foundations, methodological implementations, and
diverse applications in frequentist and Bayesian statistics. The article
discusses tools for studying the convergence properties of DA algorithms.
Furthermore, it contains various strategies for accelerating the speed of
convergence of the DA algorithms, different extensions of DA algorithms and
outlines promising directions for future research. This paper aims to serve as
a resource for researchers and practitioners seeking to leverage data
augmentation techniques in MCMC algorithms by providing key insights and
synthesizing recent developments."
Improving Ab-Initio Cryo-EM Reconstruction with Semi-Amortized Pose Inference,https://arxiv.org/abs/2406.10455,2024-06-15,2024-06-19,0.0,0.0,"Cryo-Electron Microscopy (cryo-EM) is an increasingly popular experimental
technique for estimating the 3D structure of macromolecular complexes such as
proteins based on 2D images. These images are notoriously noisy, and the pose
of the structure in each image is unknown \textit{a priori}. Ab-initio 3D
reconstruction from 2D images entails estimating the pose in addition to the
structure. In this work, we propose a new approach to this problem. We first
adopt a multi-head architecture as a pose encoder to infer multiple plausible
poses per-image in an amortized fashion. This approach mitigates the high
uncertainty in pose estimation by encouraging exploration of pose space early
in reconstruction. Once uncertainty is reduced, we refine poses in an
auto-decoding fashion. In particular, we initialize with the most likely pose
and iteratively update it for individual images using stochastic gradient
descent (SGD). Through evaluation on synthetic datasets, we demonstrate that
our method is able to handle multi-modal pose distributions during the
amortized inference stage, while the later, more flexible stage of direct pose
optimization yields faster and more accurate convergence of poses compared to
baselines. Finally, on experimental data, we show that our approach is faster
than state-of-the-art cryoAI and achieves higher-resolution reconstruction."
TokenRec - Learning to Tokenize ID for LLM-based Generative Recommendation,https://arxiv.org/abs/2406.10450,2024-06-15,2024-06-19,0.0,0.0,"There is a growing interest in utilizing large-scale language models (LLMs)
to advance next-generation Recommender Systems (RecSys), driven by their
outstanding language understanding and in-context learning capabilities. In
this scenario, tokenizing (i.e., indexing) users and items becomes essential
for ensuring a seamless alignment of LLMs with recommendations. While several
studies have made progress in representing users and items through textual
contents or latent representations, challenges remain in efficiently capturing
high-order collaborative knowledge into discrete tokens that are compatible
with LLMs. Additionally, the majority of existing tokenization approaches often
face difficulties in generalizing effectively to new/unseen users or items that
were not in the training corpus. To address these challenges, we propose a
novel framework called TokenRec, which introduces not only an effective ID
tokenization strategy but also an efficient retrieval paradigm for LLM-based
recommendations. Specifically, our tokenization strategy, Masked
Vector-Quantized (MQ) Tokenizer, involves quantizing the masked user/item
representations learned from collaborative filtering into discrete tokens, thus
achieving a smooth incorporation of high-order collaborative knowledge and a
generalizable tokenization of users and items for LLM-based RecSys. Meanwhile,
our generative retrieval paradigm is designed to efficiently recommend top-$K$
items for users to eliminate the need for the time-consuming auto-regressive
decoding and beam search processes used by LLMs, thus significantly reducing
inference time. Comprehensive experiments validate the effectiveness of the
proposed methods, demonstrating that TokenRec outperforms competitive
benchmarks, including both traditional recommender systems and emerging
LLM-based recommender systems."
Learning Temporal Logic Predicates from Data with Statistical Guarantees,https://arxiv.org/abs/2406.10449,2024-06-15,2024-06-19,0.0,0.0,"Temporal logic rules are often used in control and robotics to provide
structured, human-interpretable descriptions of high-dimensional trajectory
data. These rules have numerous applications including safety validation using
formal methods, constraining motion planning among autonomous agents, and
classifying data. However, existing methods for learning temporal logic
predicates from data provide no assurances about the correctness of the
resulting predicate. We present a novel method to learn temporal logic
predicates from data with finite-sample correctness guarantees. Our approach
leverages expression optimization and conformal prediction to learn predicates
that correctly describe future trajectories under mild assumptions with a
user-defined confidence level. We provide experimental results showing the
performance of our approach on a simulated trajectory dataset and perform
ablation studies to understand how each component of our algorithm contributes
to its performance."
Optimal Reward Labeling - Bridging Offline Preference and Reward-Based Reinforcement Learning,https://arxiv.org/abs/2406.10445,2024-06-14,2024-06-19,0.0,0.0,"Offline reinforcement learning has become one of the most practical RL
settings. A recent success story has been RLHF, offline preference-based RL
(PBRL) with preference from humans. However, most existing works on offline RL
focus on the standard setting with scalar reward feedback. It remains unknown
how to universally transfer the existing rich understanding of offline RL from
the reward-based to the preference-based setting. In this work, we propose a
general framework to bridge this gap. Our key insight is transforming
preference feedback to scalar rewards via optimal reward labeling (ORL), and
then any reward-based offline RL algorithms can be applied to the dataset with
the reward labels. We theoretically show the connection between several recent
PBRL techniques and our framework combined with specific offline RL algorithms
in terms of how they utilize the preference signals. By combining reward
labeling with different algorithms, our framework can lead to new and
potentially more efficient offline PBRL algorithms. We empirically test our
framework on preference datasets based on the standard D4RL benchmark. When
combined with a variety of efficient reward-based offline RL algorithms, the
learning result achieved under our framework is comparable to training the same
algorithm on the dataset with actual rewards in many cases and better than the
recent PBRL baselines in most cases."
Domain-Specific Shorthand for Generation Based on Context-Free Grammar,https://arxiv.org/abs/2406.10442,2024-06-14,2024-06-19,0.0,0.0,"The generation of structured data in formats such as JSON, YAML and XML is a
critical task in Generative AI (GenAI) applications. These formats, while
widely used, contain many redundant constructs that lead to inflated token
usage. This inefficiency is particularly evident when employing large language
models (LLMs) like GPT-4, where generating extensive structured data incurs
increased latency and operational costs. We introduce a domain-specific
shorthand (DSS) format, underpinned by a context-free grammar (CFG), and
demonstrate its usage to reduce the number of tokens required for structured
data generation. The method involves creating a shorthand notation that
captures essential elements of the output schema with fewer tokens, ensuring it
can be unambiguously converted to and from its verbose form. It employs a CFG
to facilitate efficient shorthand generation by the LLM, and to create parsers
to translate the shorthand back into standard structured formats. The
application of our approach to data visualization with LLMs demonstrates a
significant (3x to 5x) reduction in generated tokens, leading to significantly
lower latency and cost. This paper outlines the development of the DSS and the
accompanying CFG, and the implications of this approach for GenAI applications,
presenting a scalable solution to the token inefficiency problem in structured
data generation."
Differentiable Predictive Control for Large-Scale Urban Road Networks,https://arxiv.org/abs/2406.10433,2024-06-14,2024-06-19,0.0,0.0,"Transportation is a major contributor to CO2 emissions, making it essential
to optimize traffic networks to reduce energy-related emissions. This paper
presents a novel approach to traffic network control using Differentiable
Predictive Control (DPC), a physics-informed machine learning methodology. We
base our model on the Macroscopic Fundamental Diagram (MFD) and the Networked
Macroscopic Fundamental Diagram (NMFD), offering a simplified representation of
citywide traffic networks. Our approach ensures compliance with system
constraints by construction. In empirical comparisons with existing
state-of-the-art Model Predictive Control (MPC) methods, our approach
demonstrates a 4 order of magnitude reduction in computation time and an up to
37% improvement in traffic performance. Furthermore, we assess the robustness
of our controller to scenario shifts and find that it adapts well to changes in
traffic patterns. This work proposes more efficient traffic control methods,
particularly in large-scale urban networks, and aims to mitigate emissions and
alleviate congestion in the future."
Enhancing In-Context Learning with Semantic Representations for Relation Extraction,https://arxiv.org/abs/2406.10432,2024-06-14,2024-06-19,0.0,0.0,"Existing in-context learning (ICL) methods for relation extraction (RE) often
prioritize language similarity over structural similarity, which can lead to
overlooking entity relationships. To address this, we propose an AMR-enhanced
retrieval-based ICL method for RE. Our model retrieves in-context examples
based on semantic structure similarity between task inputs and training
samples. Evaluations on four standard English RE datasets show that our model
outperforms baselines in the unsupervised setting across all datasets. In the
supervised setting, it achieves state-of-the-art results on three datasets and
competitive results on the fourth."
Challenging the Machine - Contestability in Government AI Systems,https://arxiv.org/abs/2406.10430,2024-06-14,2024-06-19,0.0,0.0,"In an October 2023 executive order (EO), President Biden issued a detailed
but largely aspirational road map for the safe and responsible development and
use of artificial intelligence (AI). The challenge for the January 24-25, 2024
workshop was to transform those aspirations regarding one specific but crucial
issue -- the ability of individuals to challenge government decisions made
about themselves -- into actionable guidance enabling agencies to develop,
procure, and use genuinely contestable advanced automated decision-making
systems. While the Administration has taken important steps since the October
2023 EO, the insights garnered from our workshop remain highly relevant, as the
requirements for contestability of advanced decision-making systems are not yet
fully defined or implemented.
  The workshop brought together technologists, members of government agencies
and civil society organizations, litigators, and researchers in an intensive
two-day meeting that examined the challenges that users, developers, and
agencies faced in enabling contestability in light of advanced automated
decision-making systems. To ensure a free and open flow of discussion, the
meeting was held under a modified version of the Chatham House rule.
Participants were free to use any information or details that they learned, but
they may not attribute any remarks made at the meeting by the identity or the
affiliation of the speaker. Thus, the workshop summary that follows anonymizes
speakers and their affiliation. Where an identification of an agency, company,
or organization is made, it is done from a public, identified resource and does
not necessarily reflect statements made by participants at the workshop.
  This document is a report of that workshop, along with recommendations and
explanatory material."
Consistency-diversity-realism Pareto fronts of conditional image generative models,https://arxiv.org/abs/2406.10429,2024-06-14,2024-06-19,0.0,0.0,"Building world models that accurately and comprehensively represent the real
world is the utmost aspiration for conditional image generative models as it
would enable their use as world simulators. For these models to be successful
world models, they should not only excel at image quality and prompt-image
consistency but also ensure high representation diversity. However, current
research in generative models mostly focuses on creative applications that are
predominantly concerned with human preferences of image quality and aesthetics.
We note that generative models have inference time mechanisms - or knobs - that
allow the control of generation consistency, quality, and diversity. In this
paper, we use state-of-the-art text-to-image and image-and-text-to-image models
and their knobs to draw consistency-diversity-realism Pareto fronts that
provide a holistic view on consistency-diversity-realism multi-objective. Our
experiments suggest that realism and consistency can both be improved
simultaneously; however there exists a clear tradeoff between
realism/consistency and diversity. By looking at Pareto optimal points, we note
that earlier models are better at representation diversity and worse in
consistency/realism, and more recent models excel in consistency/realism while
decreasing significantly the representation diversity. By computing Pareto
fronts on a geodiverse dataset, we find that the first version of latent
diffusion models tends to perform better than more recent models in all axes of
evaluation, and there exist pronounced consistency-diversity-realism
disparities between geographical regions. Overall, our analysis clearly shows
that there is no best model and the choice of model should be determined by the
downstream application. With this analysis, we invite the research community to
consider Pareto fronts as an analytical tool to measure progress towards world
models."
Adaptive Randomized Smoothing - Certifying Multi-Step Defences against Adversarial Examples,https://arxiv.org/abs/2406.10427,2024-06-14,2024-06-19,0.0,0.0,"We propose Adaptive Randomized Smoothing (ARS) to certify the predictions of
our test-time adaptive models against adversarial examples. ARS extends the
analysis of randomized smoothing using f-Differential Privacy to certify the
adaptive composition of multiple steps. For the first time, our theory covers
the sound adaptive composition of general and high-dimensional functions of
noisy input. We instantiate ARS on deep image classification to certify
predictions against adversarial examples of bounded $L_{\infty}$ norm. In the
$L_{\infty}$ threat model, our flexibility enables adaptation through
high-dimensional input-dependent masking. We design adaptivity benchmarks,
based on CIFAR-10 and CelebA, and show that ARS improves accuracy by $2$ to
$5\%$ points. On ImageNet, ARS improves accuracy by $1$ to $3\%$ points over
standard RS without adaptivity."
Towards Neural Scaling Laws for Foundation Models on Temporal Graphs,https://arxiv.org/abs/2406.10426,2024-06-14,2024-06-19,0.0,0.0,"The field of temporal graph learning aims to learn from evolving network data
to forecast future interactions. Given a collection of observed temporal
graphs, is it possible to predict the evolution of an unseen network from the
same domain? To answer this question, we first present the Temporal Graph
Scaling (TGS) dataset, a large collection of temporal graphs consisting of
eighty-four ERC20 token transaction networks collected from 2017 to 2023. Next,
we evaluate the transferability of Temporal Graph Neural Networks (TGNNs) for
the temporal graph property prediction task by pre-training on a collection of
up to sixty-four token transaction networks and then evaluating the downstream
performance on twenty unseen token networks. We find that the neural scaling
law observed in NLP and Computer Vision also applies in temporal graph
learning, where pre-training on greater number of networks leads to improved
downstream performance. To the best of our knowledge, this is the first
empirical demonstration of the transferability of temporal graphs learning. On
downstream token networks, the largest pre-trained model outperforms single
model TGNNs on thirteen unseen test networks. Therefore, we believe that this
is a promising first step towards building foundation models for temporal
graphs."
Multi-source Unsupervised Domain Adaptation on Graphs with Transferability Modeling,https://arxiv.org/abs/2406.10425,2024-06-14,2024-06-19,0.0,0.0,"In this paper, we tackle a new problem of \textit{multi-source unsupervised
domain adaptation (MSUDA) for graphs}, where models trained on annotated source
domains need to be transferred to the unsupervised target graph for node
classification. Due to the discrepancy in distribution across domains, the key
challenge is how to select good source instances and how to adapt the model.
Diverse graph structures further complicate this problem, rendering previous
MSUDA approaches less effective. In this work, we present the framework
Selective Multi-source Adaptation for Graph ({\method}), with a
graph-modeling-based domain selector, a sub-graph node selector, and a bi-level
alignment objective for the adaptation. Concretely, to facilitate the
identification of informative source data, the similarity across graphs is
disentangled and measured with the transferability of a graph-modeling task
set, and we use it as evidence for source domain selection. A node selector is
further incorporated to capture the variation in transferability of nodes
within the same source domain. To learn invariant features for adaptation, we
align the target domain to selected source data both at the embedding space by
minimizing the optimal transport distance and at the classification level by
distilling the label function. Modules are explicitly learned to select
informative source data and conduct the alignment in virtual training splits
with a meta-learning strategy. Experimental results on five graph datasets show
the effectiveness of the proposed method."
What is the Visual Cognition Gap between Humans and Multimodal LLMs?,https://arxiv.org/abs/2406.10424,2024-06-14,2024-06-19,0.0,0.0,"Recently, Multimodal Large Language Models (MLLMs) have shown great promise
in language-guided perceptual tasks such as recognition, segmentation, and
object detection. However, their effectiveness in addressing visual cognition
problems that require high-level reasoning is not well-established. One such
challenge is abstract visual reasoning (AVR) -- the cognitive ability to
discern relationships among patterns in a set of images and extrapolate to
predict subsequent patterns. This skill is crucial during the early
neurodevelopmental stages of children. Inspired by the AVR tasks in Raven's
Progressive Matrices (RPM) and Wechsler Intelligence Scale for Children (WISC),
we propose a new dataset MaRs-VQA and a new benchmark VCog-Bench containing
three datasets to evaluate the zero-shot AVR capability of MLLMs and compare
their performance with existing human intelligent investigation. Our
comparative experiments with different open-source and closed-source MLLMs on
the VCog-Bench revealed a gap between MLLMs and human intelligence,
highlighting the visual cognitive limitations of current MLLMs. We believe that
the public release of VCog-Bench, consisting of MaRs-VQA, and the inference
pipeline will drive progress toward the next generation of MLLMs with
human-like visual cognition abilities."
SciEx - Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading,https://arxiv.org/abs/2406.10421,2024-06-14,2024-06-19,0.0,0.0,"With the rapid development of Large Language Models (LLMs), it is crucial to
have benchmarks which can evaluate the ability of LLMs on different domains.
One common use of LLMs is performing tasks on scientific topics, such as
writing algorithms, querying databases or giving mathematical proofs. Inspired
by the way university students are evaluated on such tasks, in this paper, we
propose SciEx - a benchmark consisting of university computer science exam
questions, to evaluate LLMs ability on solving scientific tasks. SciEx is (1)
multilingual, containing both English and German exams, and (2) multi-modal,
containing questions that involve images, and (3) contains various types of
freeform questions with different difficulty levels, due to the nature of
university exams. We evaluate the performance of various state-of-the-art LLMs
on our new benchmark. Since SciEx questions are freeform, it is not
straightforward to evaluate LLM performance. Therefore, we provide human expert
grading of the LLM outputs on SciEx. We show that the free-form exams in SciEx
remain challenging for the current LLMs, where the best LLM only achieves
59.4\% exam grade on average. We also provide detailed comparisons between LLM
performance and student performance on SciEx. To enable future evaluation of
new LLMs, we propose using LLM-as-a-judge to grade the LLM answers on SciEx.
Our experiments show that, although they do not perform perfectly on solving
the exams, LLMs are decent as graders, achieving 0.948 Pearson correlation with
expert grading."
Learning Flexible Time-windowed Granger Causality Integrating Heterogeneous Interventional Time Series Data,https://arxiv.org/abs/2406.10419,2024-06-14,2024-06-19,0.0,0.0,"Granger causality, commonly used for inferring causal structures from time
series data, has been adopted in widespread applications across various fields
due to its intuitive explainability and high compatibility with emerging deep
neural network prediction models. To alleviate challenges in better deciphering
causal structures unambiguously from time series, the use of interventional
data has become a practical approach. However, existing methods have yet to be
explored in the context of imperfect interventions with unknown targets, which
are more common and often more beneficial in a wide range of real-world
applications. Additionally, the identifiability issues of Granger causality
with unknown interventional targets in complex network models remain unsolved.
Our work presents a theoretically-grounded method that infers Granger causal
structure and identifies unknown targets by leveraging heterogeneous
interventional time series data. We further illustrate that learning Granger
causal structure and recovering interventional targets can mutually promote
each other. Comparative experiments demonstrate that our method outperforms
several robust baseline methods in learning Granger causal structure from
interventional time series data."
Byzantine-Robust Decentralized Federated Learning,https://arxiv.org/abs/2406.10416,2024-06-14,2024-06-19,0.0,0.0,"Federated learning (FL) enables multiple clients to collaboratively train
machine learning models without revealing their private training data. In
conventional FL, the system follows the server-assisted architecture
(server-assisted FL), where the training process is coordinated by a central
server. However, the server-assisted FL framework suffers from poor scalability
due to a communication bottleneck at the server, and trust dependency issues.
To address challenges, decentralized federated learning (DFL) architecture has
been proposed to allow clients to train models collaboratively in a serverless
and peer-to-peer manner. However, due to its fully decentralized nature, DFL is
highly vulnerable to poisoning attacks, where malicious clients could
manipulate the system by sending carefully-crafted local models to their
neighboring clients. To date, only a limited number of Byzantine-robust DFL
methods have been proposed, most of which are either communication-inefficient
or remain vulnerable to advanced poisoning attacks. In this paper, we propose a
new algorithm called BALANCE (Byzantine-robust averaging through local
similarity in decentralization) to defend against poisoning attacks in DFL. In
BALANCE, each client leverages its own local model as a similarity reference to
determine if the received model is malicious or benign. We establish the
theoretical convergence guarantee for BALANCE under poisoning attacks in both
strongly convex and non-convex settings. Furthermore, the convergence rate of
BALANCE under poisoning attacks matches those of the state-of-the-art
counterparts in Byzantine-free settings. Extensive experiments also demonstrate
that BALANCE outperforms existing DFL methods and effectively defends against
poisoning attacks."
PRISM - A Design Framework for Open-Source Foundation Model Safety,https://arxiv.org/abs/2406.10415,2024-06-14,2024-06-19,0.0,0.0,"The rapid advancement of open-source foundation models has brought
transparency and accessibility to this groundbreaking technology. However, this
openness has also enabled the development of highly-capable, unsafe models, as
exemplified by recent instances such as WormGPT and FraudGPT, which are
specifically designed to facilitate criminal activity. As the capabilities of
open foundation models continue to grow, potentially outpacing those of
closed-source models, the risk of misuse by bad actors poses an increasingly
serious threat to society. This paper addresses the critical question of how
open foundation model developers should approach model safety in light of these
challenges. Our analysis reveals that open-source foundation model companies
often provide less restrictive acceptable use policies (AUPs) compared to their
closed-source counterparts, likely due to the inherent difficulties in
enforcing such policies once the models are released. To tackle this issue, we
introduce PRISM, a design framework for open-source foundation model safety
that emphasizes Private, Robust, Independent Safety measures, at Minimal
marginal cost of compute. The PRISM framework proposes the use of modular
functions that moderate prompts and outputs independently of the core language
model, offering a more adaptable and resilient approach to safety compared to
the brittle reinforcement learning methods currently used for value alignment.
By focusing on identifying AUP violations and engaging the developer community
in establishing consensus around safety design decisions, PRISM aims to create
a safer open-source ecosystem that maximizes the potential of these powerful
technologies while minimizing the risks to individuals and society as a whole."
Tree Search for Simultaneous Move Games via Equilibrium Approximation,https://arxiv.org/abs/2406.10411,2024-06-14,2024-06-19,0.0,0.0,"Neural network supported tree-search has shown strong results in a variety of
perfect information multi-agent tasks. However, the performance of these
methods on partial information games has generally been below competing
approaches. Here we study the class of simultaneous-move games, which are a
subclass of partial information games which are most similar to perfect
information games: both agents know the game state with the exception of the
opponent's move, which is revealed only after each agent makes its own move.
Simultaneous move games include popular benchmarks such as Google Research
Football and Starcraft.
  In this study we answer the question: can we take tree search algorithms
trained through self-play from perfect information settings and adapt them to
simultaneous move games without significant loss of performance? We answer this
question by deriving a practical method that attempts to approximate a coarse
correlated equilibrium as a subroutine within a tree search. Our algorithm
works on cooperative, competitive, and mixed tasks. Our results are better than
the current best MARL algorithms on a wide range of accepted baseline
environments."
Towards Better Benchmark Datasets for Inductive Knowledge Graph Completion,https://arxiv.org/abs/2406.11898,2024-06-14,2024-06-19,0.0,0.0,"Knowledge Graph Completion (KGC) attempts to predict missing facts in a
Knowledge Graph (KG). Recently, there's been an increased focus on designing
KGC methods that can excel in the {\it inductive setting}, where a portion or
all of the entities and relations seen in inference are unobserved during
training. Numerous benchmark datasets have been proposed for inductive KGC, all
of which are subsets of existing KGs used for transductive KGC. However, we
find that the current procedure for constructing inductive KGC datasets
inadvertently creates a shortcut that can be exploited even while disregarding
the relational information. Specifically, we observe that the Personalized
PageRank (PPR) score can achieve strong or near SOTA performance on most
inductive datasets. In this paper, we study the root cause of this problem.
Using these insights, we propose an alternative strategy for constructing
inductive KGC datasets that helps mitigate the PPR shortcut. We then benchmark
multiple popular methods using the newly constructed datasets and analyze their
performance. The new benchmark datasets help promote a better understanding of
the capabilities and challenges of inductive KGC by removing any shortcuts that
obfuscate performance."
Suboptimality bounds for trace-bounded SDPs enable a faster and scalable low-rank SDP solver SDPLR+,https://arxiv.org/abs/2406.10407,2024-06-14,2024-06-19,0.0,0.0,"Semidefinite programs (SDPs) and their solvers are powerful tools with many
applications in machine learning and data science. Designing scalable SDP
solvers is challenging because by standard the positive semidefinite decision
variable is an $n \times n$ dense matrix, even though the input is often $n
\times n$ sparse matrices. However, the information in the solution may not
correspond to a full-rank dense matrix as shown by Barvinok and Pataki. Two
decades ago, Burer and Monteiro developed an SDP solver $\texttt{SDPLR}$ that
optimizes over a low-rank factorization instead of the full matrix. This
greatly decreases the storage cost and works well for many problems. The
original solver $\texttt{SDPLR}$ tracks only the primal infeasibility of the
solution, limiting the technique's flexibility to produce moderate accuracy
solutions. We use a suboptimality bound for trace-bounded SDP problems that
enables us to track the progress better and perform early termination. We then
develop $\texttt{SDPLR+}$, which starts the optimization with an extremely
low-rank factorization and dynamically updates the rank based on the primal
infeasibility and suboptimality. This further speeds up the computation and
saves the storage cost. Numerical experiments on Max Cut, Minimum Bisection,
Cut Norm, and Lov\'{a}sz Theta problems with many recent memory-efficient
scalable SDP solvers demonstrate its scalability up to problems with
million-by-million decision variables and it is often the fastest solver to a
moderate accuracy of $10^{-2}$."
Determination of the Number of Topics Intrinsically - Is It Possible?,https://arxiv.org/abs/2406.10402,2024-06-14,2024-06-19,0.0,0.0,"The number of topics might be the most important parameter of a topic model.
The topic modelling community has developed a set of various procedures to
estimate the number of topics in a dataset, but there has not yet been a
sufficiently complete comparison of existing practices. This study attempts to
partially fill this gap by investigating the performance of various methods
applied to several topic models on a number of publicly available corpora.
Further analysis demonstrates that intrinsic methods are far from being
reliable and accurate tools. The number of topics is shown to be a method- and
a model-dependent quantity, as opposed to being an absolute property of a
particular corpus. We conclude that other methods for dealing with this problem
should be developed and suggest some promising directions for further research."
Evaluating Speaker Identity Coding in Self-supervised Models and Humans,https://arxiv.org/abs/2406.10401,2024-06-14,2024-06-19,0.0,0.0,"Speaker identity plays a significant role in human communication and is being
increasingly used in societal applications, many through advances in machine
learning. Speaker identity perception is an essential cognitive phenomenon that
can be broadly reduced to two main tasks: recognizing a voice or discriminating
between voices. Several studies have attempted to identify acoustic correlates
of identity perception to pinpoint salient parameters for such a task. Unlike
other communicative social signals, most efforts have yielded inefficacious
conclusions. Furthermore, current neurocognitive models of voice identity
processing consider the bases of perception as acoustic dimensions such as
fundamental frequency, harmonics-to-noise ratio, and formant dispersion.
However, these findings do not account for naturalistic speech and
within-speaker variability. Representational spaces of current self-supervised
models have shown significant performance in various speech-related tasks. In
this work, we demonstrate that self-supervised representations from different
families (e.g., generative, contrastive, and predictive models) are
significantly better for speaker identification over acoustic representations.
We also show that such a speaker identification task can be used to better
understand the nature of acoustic information representation in different
layers of these powerful networks. By evaluating speaker identification
accuracy across acoustic, phonemic, prosodic, and linguistic variants, we
report similarity between model performance and human identity perception. We
further examine these similarities by juxtaposing the encoding spaces of models
and humans and challenging the use of distance metrics as a proxy for speaker
proximity. Lastly, we show that some models can predict brain responses in
Auditory and Language regions during naturalistic stimuli."
Self-Reflection Outcome is Sensitive to Prompt Construction,https://arxiv.org/abs/2406.10400,2024-06-14,2024-06-19,0.0,0.0,"Large language models (LLMs) demonstrate impressive zero-shot and few-shot
reasoning capabilities. Some propose that such capabilities can be improved
through self-reflection, i.e., letting LLMs reflect on their own output to
identify and correct mistakes in the initial responses. However, despite some
evidence showing the benefits of self-reflection, recent studies offer mixed
results. Here, we aim to reconcile these conflicting findings by first
demonstrating that the outcome of self-reflection is sensitive to prompt
wording; e.g., LLMs are more likely to conclude that it has made a mistake when
explicitly prompted to find mistakes. Consequently, idiosyncrasies in
reflection prompts may lead LLMs to change correct responses unnecessarily. We
show that most prompts used in the self-reflection literature are prone to this
bias. We then propose different ways of constructing prompts that are
conservative in identifying mistakes and show that self-reflection using such
prompts results in higher accuracy. Our findings highlight the importance of
prompt engineering in self-reflection tasks. We release our code at
https://github.com/Michael98Liu/mixture-of-prompts."
A Benchmark for Maximum Cut - Towards Standardization of the Evaluation of Learned Heuristics for Combinatorial Optimization,https://arxiv.org/abs/2406.11897,2024-06-14,2024-06-19,0.0,0.0,"Recently, there has been much work on the design of general heuristics for
graph-based, combinatorial optimization problems via the incorporation of Graph
Neural Networks (GNNs) to learn distribution-specific solution
structures.However, there is a lack of consistency in the evaluation of these
heuristics, in terms of the baselines and instances chosen, which makes it
difficult to assess the relative performance of the algorithms. In this paper,
we propose an open-source benchmark suite MaxCut-Bench dedicated to the NP-hard
Maximum Cut problem in both its weighted and unweighted variants, based on a
careful selection of instances curated from diverse graph datasets. The suite
offers a unified interface to various heuristics, both traditional and machine
learning-based. Next, we use the benchmark in an attempt to systematically
corroborate or reproduce the results of several, popular learning-based
approaches, including S2V-DQN [31], ECO-DQN [4], among others, in terms of
three dimensions: objective value, generalization, and scalability. Our
empirical results show that several of the learned heuristics fail to
outperform a naive greedy algorithm, and that only one of them consistently
outperforms Tabu Search, a simple, general heuristic based upon local search.
Furthermore, we find that the performance of ECO-DQN remains the same or is
improved if the GNN is replaced by a simple linear regression on a subset of
the features that are related to Tabu Search. Code, data, and pretrained models
are available at: \url{https://github.com/ankurnath/MaxCut-Bench}."
EWEK-QA - Enhanced Web and Efficient Knowledge Graph Retrieval for Citation-based Question Answering Systems,https://arxiv.org/abs/2406.10393,2024-06-14,2024-06-19,0.0,0.0,"The emerging citation-based QA systems are gaining more attention especially
in generative AI search applications. The importance of extracted knowledge
provided to these systems is vital from both accuracy (completeness of
information) and efficiency (extracting the information in a timely manner). In
this regard, citation-based QA systems are suffering from two shortcomings.
First, they usually rely only on web as a source of extracted knowledge and
adding other external knowledge sources can hamper the efficiency of the
system. Second, web-retrieved contents are usually obtained by some simple
heuristics such as fixed length or breakpoints which might lead to splitting
information into pieces. To mitigate these issues, we propose our enhanced web
and efficient knowledge graph (KG) retrieval solution (EWEK-QA) to enrich the
content of the extracted knowledge fed to the system. This has been done
through designing an adaptive web retriever and incorporating KGs triples in an
efficient manner. We demonstrate the effectiveness of EWEK-QA over the
open-source state-of-the-art (SoTA) web-based and KG baseline models using a
comprehensive set of quantitative and human evaluation experiments. Our model
is able to: first, improve the web-retriever baseline in terms of extracting
more relevant passages (>20\%), the coverage of answer span (>25\%) and self
containment (>35\%); second, obtain and integrate KG triples into its pipeline
very efficiently (by avoiding any LLM calls) to outperform the web-only and
KG-only SoTA baselines significantly in 7 quantitative QA tasks and our human
evaluation."
BEACON - Benchmark for Comprehensive RNA Tasks and Language Models,https://arxiv.org/abs/2406.10391,2024-06-14,2024-06-19,0.0,0.0,"RNA plays a pivotal role in translating genetic instructions into functional
outcomes, underscoring its importance in biological processes and disease
mechanisms. Despite the emergence of numerous deep learning approaches for RNA,
particularly universal RNA language models, there remains a significant lack of
standardized benchmarks to assess the effectiveness of these methods. In this
study, we introduce the first comprehensive RNA benchmark BEACON
(\textbf{BE}nchm\textbf{A}rk for \textbf{CO}mprehensive R\textbf{N}A Task and
Language Models). First, BEACON comprises 13 distinct tasks derived from
extensive previous work covering structural analysis, functional studies, and
engineering applications, enabling a comprehensive assessment of the
performance of methods on various RNA understanding tasks. Second, we examine a
range of models, including traditional approaches like CNNs, as well as
advanced RNA foundation models based on language models, offering valuable
insights into the task-specific performances of these models. Third, we
investigate the vital RNA language model components from the tokenizer and
positional encoding aspects. Notably, our findings emphasize the superiority of
single nucleotide tokenization and the effectiveness of Attention with Linear
Biases (ALiBi) over traditional positional encoding methods. Based on these
insights, a simple yet strong baseline called BEACON-B is proposed, which can
achieve outstanding performance with limited data and computational resources.
The datasets and source code of our benchmark are available at
https://github.com/terry-r123/RNABenchmark."
A Benchmark Suite for Systematically Evaluating Reasoning Shortcuts,https://arxiv.org/abs/2406.10368,2024-06-14,2024-06-19,0.0,0.0,"The advent of powerful neural classifiers has increased interest in problems
that require both learning and reasoning. These problems are critical for
understanding important properties of models, such as trustworthiness,
generalization, interpretability, and compliance to safety and structural
constraints. However, recent research observed that tasks requiring both
learning and reasoning on background knowledge often suffer from reasoning
shortcuts (RSs): predictors can solve the downstream reasoning task without
associating the correct concepts to the high-dimensional data. To address this
issue, we introduce rsbench, a comprehensive benchmark suite designed to
systematically evaluate the impact of RSs on models by providing easy access to
highly customizable tasks affected by RSs. Furthermore, rsbench implements
common metrics for evaluating concept quality and introduces novel formal
verification procedures for assessing the presence of RSs in learning tasks.
Using rsbench, we highlight that obtaining high quality concepts in both purely
neural and neuro-symbolic models is a far-from-solved problem. rsbench is
available at: https://unitn-sml.github.io/rsbench."
Improving the Validity and Practical Usefulness of AI/ML Evaluations Using an Estimands Framework,https://arxiv.org/abs/2406.10366,2024-06-14,2024-06-19,0.0,0.0,"Commonly, AI or machine learning (ML) models are evaluated on benchmark
datasets. This practice supports innovative methodological research, but
benchmark performance can be poorly correlated with performance in real-world
applications -- a construct validity issue. To improve the validity and
practical usefulness of evaluations, we propose using an estimands framework
adapted from international clinical trials guidelines. This framework provides
a systematic structure for inference and reporting in evaluations, emphasizing
the importance of a well-defined estimation target. We illustrate our proposal
on examples of commonly used evaluation methodologies - involving
cross-validation, clustering evaluation, and LLM benchmarking - that can lead
to incorrect rankings of competing models (rank reversals) with high
probability, even when performance differences are large. We demonstrate how
the estimands framework can help uncover underlying issues, their causes, and
potential solutions. Ultimately, we believe this framework can improve the
validity of evaluations through better-aligned inference, and help
decision-makers and model users interpret reported results more effectively."
SigDiffusions - Score-Based Diffusion Models for Long Time Series via Log-Signature Embeddings,https://arxiv.org/abs/2406.10354,2024-06-14,2024-06-19,0.0,0.0,"Score-based diffusion models have recently emerged as state-of-the-art
generative models for a variety of data modalities. Nonetheless, it remains
unclear how to adapt these models to generate long multivariate time series.
Viewing a time series as the discretization of an underlying continuous
process, we introduce SigDiffusion, a novel diffusion model operating on
log-signature embeddings of the data. The forward and backward processes
gradually perturb and denoise log-signatures preserving their algebraic
structure. To recover a signal from its log-signature, we provide new
closed-form inversion formulae expressing the coefficients obtained by
expanding the signal in a given basis (e.g. Fourier or orthogonal polynomials)
as explicit polynomial functions of the log-signature. Finally, we show that
combining SigDiffusion with these inversion formulae results in highly
realistic time series generation, competitive with the current state-of-the-art
on various datasets of synthetic and real-world examples."
Quantifying Variance in Evaluation Benchmarks,https://arxiv.org/abs/2406.10229,2024-06-14,2024-06-19,0.0,0.0,"Evaluation benchmarks are the cornerstone of measuring capabilities of large
language models (LLMs), as well as driving progress in said capabilities.
Originally designed to make claims about capabilities (or lack thereof) in
fully pretrained models, evaluation benchmarks are now also extensively used to
decide between various training choices. Despite this widespread usage, we
rarely quantify the variance in our evaluation benchmarks, which dictates
whether differences in performance are meaningful. Here, we define and measure
a range of metrics geared towards measuring variance in evaluation benchmarks,
including seed variance across initialisations, and monotonicity during
training. By studying a large number of models -- both openly available and
pretrained from scratch -- we provide empirical estimates for a variety of
variance metrics, with considerations and recommendations for practitioners. We
also evaluate the utility and tradeoffs of continuous versus discrete
performance measures and explore options for better understanding and reducing
this variance. We find that simple changes, such as framing choice tasks (like
MMLU) as completion tasks, can often reduce variance for smaller scale
($\sim$7B) models, while more involved methods inspired from human testing
literature (such as item analysis and item response theory) struggle to
meaningfully reduce variance. Overall, our work provides insights into variance
in evaluation benchmarks, suggests LM-specific techniques to reduce variance,
and more generally encourages practitioners to carefully factor in variance
when comparing models."
From Pixels to Prose - A Large Dataset of Dense Image Captions,https://arxiv.org/abs/2406.10328,2024-06-14,2024-06-19,0.0,0.0,"Training large vision-language models requires extensive, high-quality
image-text pairs. Existing web-scraped datasets, however, are noisy and lack
detailed image descriptions. To bridge this gap, we introduce PixelProse, a
comprehensive dataset of over 16M (million) synthetically generated captions,
leveraging cutting-edge vision-language models for detailed and accurate
descriptions. To ensure data integrity, we rigorously analyze our dataset for
problematic content, including child sexual abuse material (CSAM), personally
identifiable information (PII), and toxicity. We also provide valuable metadata
such as watermark presence and aesthetic scores, aiding in further dataset
filtering. We hope PixelProse will be a valuable resource for future
vision-language research. PixelProse is available at
https://huggingface.co/datasets/tomg-group-umd/pixelprose"
VEGA - Learning Interleaved Image-Text Comprehension in Vision-Language Large Models,https://arxiv.org/abs/2406.10228,2024-06-14,2024-06-19,0.0,0.0,"The swift progress of Multi-modal Large Models (MLLMs) has showcased their
impressive ability to tackle tasks blending vision and language. Yet, most
current models and benchmarks cater to scenarios with a narrow scope of visual
and textual contexts. These models often fall short when faced with complex
comprehension tasks, which involve navigating through a plethora of irrelevant
and potentially misleading information in both text and image forms. To bridge
this gap, we introduce a new, more demanding task known as Interleaved
Image-Text Comprehension (IITC). This task challenges models to discern and
disregard superfluous elements in both images and text to accurately answer
questions and to follow intricate instructions to pinpoint the relevant image.
In support of this task, we further craft a new VEGA dataset, tailored for the
IITC task on scientific content, and devised a subtask, Image-Text Association
(ITA), to refine image-text correlation skills. Our evaluation of four leading
closed-source models, as well as various open-source models using VEGA,
underscores the rigorous nature of IITC. Even the most advanced models, such as
Gemini-1.5-pro and GPT4V, only achieved modest success. By employing a
multi-task, multi-scale post-training strategy, we have set a robust baseline
for MLLMs on the IITC task, attaining an $85.8\%$ accuracy rate in image
association and a $0.508$ Rouge score. These results validate the effectiveness
of our dataset in improving MLLMs capabilities for nuanced image-text
comprehension."
Analysing Multi-Task Regression via Random Matrix Theory with Application to Time Series Forecasting,https://arxiv.org/abs/2406.10327,2024-06-14,2024-06-19,0.0,0.0,"In this paper, we introduce a novel theoretical framework for multi-task
regression, applying random matrix theory to provide precise performance
estimations, under high-dimensional, non-Gaussian data distributions. We
formulate a multi-task optimization problem as a regularization technique to
enable single-task models to leverage multi-task learning information. We
derive a closed-form solution for multi-task optimization in the context of
linear models. Our analysis provides valuable insights by linking the
multi-task learning performance to various model statistics such as raw data
covariances, signal-generating hyperplanes, noise levels, as well as the size
and number of datasets. We finally propose a consistent estimation of training
and testing errors, thereby offering a robust foundation for hyperparameter
optimization in multi-task regression scenarios. Experimental validations on
both synthetic and real-world datasets in regression and multivariate time
series forecasting demonstrate improvements on univariate models, incorporating
our method into the training loss and thus leveraging multivariate information."
VideoGUI - A Benchmark for GUI Automation from Instructional Videos,https://arxiv.org/abs/2406.10227,2024-06-14,2024-06-19,0.0,0.0,"Graphical User Interface (GUI) automation holds significant promise for
enhancing human productivity by assisting with computer tasks. Existing task
formulations primarily focus on simple tasks that can be specified by a single,
language-only instruction, such as ""Insert a new slide."" In this work, we
introduce VideoGUI, a novel multi-modal benchmark designed to evaluate GUI
assistants on visual-centric GUI tasks. Sourced from high-quality web
instructional videos, our benchmark focuses on tasks involving professional and
novel software (e.g., Adobe Photoshop or Stable Diffusion WebUI) and complex
activities (e.g., video editing). VideoGUI evaluates GUI assistants through a
hierarchical process, allowing for identification of the specific levels at
which they may fail: (i) high-level planning: reconstruct procedural subtasks
from visual conditions without language descriptions; (ii) middle-level
planning: generate sequences of precise action narrations based on visual state
(i.e., screenshot) and goals; (iii) atomic action execution: perform specific
actions such as accurately clicking designated elements. For each level, we
design evaluation metrics across individual dimensions to provide clear
signals, such as individual performance in clicking, dragging, typing, and
scrolling for atomic action execution. Our evaluation on VideoGUI reveals that
even the SoTA large multimodal model GPT4o performs poorly on visual-centric
GUI tasks, especially for high-level planning."
Enhancing Multilingual Voice Toxicity Detection with Speech-Text Alignment,https://arxiv.org/abs/2406.10325,2024-06-14,2024-06-19,0.0,0.0,"Toxicity classification for voice heavily relies on the semantic content of
speech. We propose a novel framework that utilizes cross-modal learning to
integrate the semantic embedding of text into a multilabel speech toxicity
classifier during training. This enables us to incorporate textual information
during training while still requiring only audio during inference. We evaluate
this classifier on large-scale datasets with real-world characteristics to
validate the effectiveness of this framework. Through ablation studies, we
demonstrate that general-purpose semantic text embeddings are rich and aligned
with speech for toxicity classification purposes. Conducting experiments across
multiple languages at scale, we show improvements in voice toxicity
classification across five languages and different toxicity categories."
Diffusion Synthesizer for Efficient Multilingual Speech to Speech Translation,https://arxiv.org/abs/2406.10223,2024-06-14,2024-06-19,0.0,0.0,"We introduce DiffuseST, a low-latency, direct speech-to-speech translation
system capable of preserving the input speaker's voice zero-shot while
translating from multiple source languages into English. We experiment with the
synthesizer component of the architecture, comparing a Tacotron-based
synthesizer to a novel diffusion-based synthesizer. We find the diffusion-based
synthesizer to improve MOS and PESQ audio quality metrics by 23\% each and
speaker similarity by 5\% while maintaining comparable BLEU scores. Despite
having more than double the parameter count, the diffusion synthesizer has
lower latency, allowing the entire model to run more than 5$\times$ faster than
real-time."
Short Film Dataset (SFD) - A Benchmark for Story-Level Video Understanding,https://arxiv.org/abs/2406.10221,2024-06-14,2024-06-19,0.0,0.0,"Recent advances in vision-language models have significantly propelled video
understanding. Existing datasets and tasks, however, have notable limitations.
Most datasets are confined to short videos with limited events and narrow
narratives. For example, datasets with instructional and egocentric videos
often document the activities of one person in a single scene. Although some
movie datasets offer richer content, they are often limited to short-term
tasks, lack publicly available videos and frequently encounter data leakage
given the use of movie forums and other resources in LLM training. To address
the above limitations, we propose the Short Film Dataset (SFD) with 1,078
publicly available amateur movies, a wide variety of genres and minimal data
leakage issues. SFD offers long-term story-oriented video tasks in the form of
multiple-choice and open-ended question answering. Our extensive experiments
emphasize the need for long-term reasoning to solve SFD tasks. Notably, we find
strong signals in movie transcripts leading to the on-par performance of people
and LLMs. We also show significantly lower performance of current models
compared to people when using vision data alone."
Semantic Membership Inference Attack against Large Language Models,https://arxiv.org/abs/2406.10218,2024-06-14,2024-06-19,0.0,0.0,"Membership Inference Attacks (MIAs) determine whether a specific data point
was included in the training set of a target model. In this paper, we introduce
the Semantic Membership Inference Attack (SMIA), a novel approach that enhances
MIA performance by leveraging the semantic content of inputs and their
perturbations. SMIA trains a neural network to analyze the target model's
behavior on perturbed inputs, effectively capturing variations in output
probability distributions between members and non-members. We conduct
comprehensive evaluations on the Pythia and GPT-Neo model families using the
Wikipedia dataset. Our results show that SMIA significantly outperforms
existing MIAs; for instance, SMIA achieves an AUC-ROC of 67.39% on Pythia-12B,
compared to 58.90% by the second-best attack."
L4GM - Large 4D Gaussian Reconstruction Model,https://arxiv.org/abs/2406.10324,2024-06-14,2024-06-19,0.0,0.0,"We present L4GM, the first 4D Large Reconstruction Model that produces
animated objects from a single-view video input -- in a single feed-forward
pass that takes only a second. Key to our success is a novel dataset of
multiview videos containing curated, rendered animated objects from Objaverse.
This dataset depicts 44K diverse objects with 110K animations rendered in 48
viewpoints, resulting in 12M videos with a total of 300M frames. We keep our
L4GM simple for scalability and build directly on top of LGM, a pretrained 3D
Large Reconstruction Model that outputs 3D Gaussian ellipsoids from multiview
image input. L4GM outputs a per-frame 3D Gaussian Splatting representation from
video frames sampled at a low fps and then upsamples the representation to a
higher fps to achieve temporal smoothness. We add temporal self-attention
layers to the base LGM to help it learn consistency across time, and utilize a
per-timestep multiview rendering loss to train the model. The representation is
upsampled to a higher framerate by training an interpolation model which
produces intermediate 3D Gaussian representations. We showcase that L4GM that
is only trained on synthetic data generalizes extremely well on in-the-wild
videos, producing high quality animated 3D assets."
Regularizing Hidden States Enables Learning Generalizable Reward Model for LLMs,https://arxiv.org/abs/2406.10216,2024-06-14,2024-06-19,0.0,0.0,"Reward models trained on human preference data have been proven to be
effective for aligning Large Language Models (LLMs) with human intent within
the reinforcement learning from human feedback (RLHF) framework. However, the
generalization capabilities of current reward models to unseen prompts and
responses are limited. This limitation can lead to an unexpected phenomenon
known as reward over-optimization, where excessive optimization of rewards
results in a decline in actual performance. While previous research has
advocated for constraining policy optimization, our study proposes a novel
approach to enhance the reward model's generalization ability against
distribution shifts by regularizing the hidden states. Specifically, we retain
the base model's language model head and incorporate a suite of text-generation
losses to preserve the hidden states' text generation capabilities, while
concurrently learning a reward head behind the same hidden states. Our
experimental results demonstrate that the introduced regularization technique
markedly improves the accuracy of learned reward models across a variety of
out-of-distribution (OOD) tasks and effectively alleviate the over-optimization
issue in RLHF, offering a more reliable and robust preference learning
paradigm."
DigiRL - Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning,https://arxiv.org/abs/2406.11896,2024-06-14,2024-06-19,0.0,0.0,"Training corpuses for vision language models (VLMs) typically lack sufficient
amounts of decision-centric data. This renders off-the-shelf VLMs sub-optimal
for decision-making tasks such as in-the-wild device control through graphical
user interfaces (GUIs). While training with static demonstrations has shown
some promise, we show that such methods fall short for controlling real GUIs
due to their failure to deal with real-world stochasticity and non-stationarity
not captured in static observational data. This paper introduces a novel
autonomous RL approach, called DigiRL, for training in-the-wild device control
agents through fine-tuning a pre-trained VLM in two stages: offline RL to
initialize the model, followed by offline-to-online RL. To do this, we build a
scalable and parallelizable Android learning environment equipped with a
VLM-based evaluator and develop a simple yet effective RL approach for learning
in this domain. Our approach runs advantage-weighted RL with advantage
estimators enhanced to account for stochasticity along with an automatic
curriculum for deriving maximal learning signal. We demonstrate the
effectiveness of DigiRL using the Android-in-the-Wild (AitW) dataset, where our
1.3B VLM trained with RL achieves a 49.5% absolute improvement -- from 17.7 to
67.2% success rate -- over supervised fine-tuning with static human
demonstration data. These results significantly surpass not only the prior best
agents, including AppAgent with GPT-4V (8.3% success rate) and the 17B CogAgent
trained with AitW data (38.5%), but also the prior best autonomous RL approach
based on filtered behavior cloning (57.8%), thereby establishing a new
state-of-the-art for digital agents for in-the-wild device control."
DevBench - A multimodal developmental benchmark for language learning,https://arxiv.org/abs/2406.10215,2024-06-14,2024-06-19,0.0,0.0,"How (dis)similar are the learning trajectories of vision-language models and
children? Recent modeling work has attempted to understand the gap between
models' and humans' data efficiency by constructing models trained on less
data, especially multimodal naturalistic data. However, such models are often
evaluated on adult-level benchmarks, with limited breadth in language abilities
tested, and without direct comparison to behavioral data. We introduce
DevBench, a multimodal benchmark comprising seven language evaluation tasks
spanning the domains of lexical, syntactic, and semantic ability, with
behavioral data from both children and adults. We evaluate a set of
vision-language models on these tasks, comparing models and humans not only on
accuracy but on their response patterns. Across tasks, models exhibit variation
in their closeness to human response patterns, and models that perform better
on a task also more closely resemble human behavioral responses. We also
examine the developmental trajectory of OpenCLIP over training, finding that
greater training results in closer approximations to adult response patterns.
DevBench thus provides a benchmark for comparing models to human language
development. These comparisons highlight ways in which model and human language
learning processes diverge, providing insight into entry points for improving
language models."
Universal randomised signatures for generative time series modelling,https://arxiv.org/abs/2406.10214,2024-06-14,2024-06-19,0.0,0.0,"Randomised signature has been proposed as a flexible and easily implementable
alternative to the well-established path signature. In this article, we employ
randomised signature to introduce a generative model for financial time series
data in the spirit of reservoir computing. Specifically, we propose a novel
Wasserstein-type distance based on discrete-time randomised signatures. This
metric on the space of probability measures captures the distance between
(conditional) distributions. Its use is justified by our novel universal
approximation results for randomised signatures on the space of continuous
functions taking the underlying path as an input. We then use our metric as the
loss function in a non-adversarial generator model for synthetic time series
data based on a reservoir neural stochastic differential equation. We compare
the results of our model to benchmarks from the existing literature."
Selecting Interpretability Techniques for Healthcare Machine Learning models,https://arxiv.org/abs/2406.10213,2024-06-14,2024-06-19,0.0,0.0,"In healthcare there is a pursuit for employing interpretable algorithms to
assist healthcare professionals in several decision scenarios. Following the
Predictive, Descriptive and Relevant (PDR) framework, the definition of
interpretable machine learning as a machine-learning model that explicitly and
in a simple frame determines relationships either contained in data or learned
by the model that are relevant for its functioning and the categorization of
models by post-hoc, acquiring interpretability after training, or model-based,
being intrinsically embedded in the algorithm design. We overview a selection
of eight algorithms, both post-hoc and model-based, that can be used for such
purposes."
Predicting User Perception of Move Brilliance in Chess,https://arxiv.org/abs/2406.11895,2024-06-14,2024-06-19,0.0,0.0,"AI research in chess has been primarily focused on producing stronger agents
that can maximize the probability of winning. However, there is another aspect
to chess that has largely gone unexamined: its aesthetic appeal. Specifically,
there exists a category of chess moves called ``brilliant"" moves. These moves
are appreciated and admired by players for their high intellectual aesthetics.
We demonstrate the first system for classifying chess moves as brilliant. The
system uses a neural network, using the output of a chess engine as well as
features that describe the shape of the game tree. The system achieves an
accuracy of 79% (with 50% base-rate), a PPV of 83%, and an NPV of 75%. We
demonstrate that what humans perceive as ``brilliant"" moves is not merely the
best possible move. We show that a move is more likely to be predicted as
brilliant, all things being equal, if a weaker engine considers it
lower-quality (for the same rating by a stronger engine). Our system opens the
avenues for computer chess engines to (appear to) display human-like
brilliance, and, hence, creativity."
Make It Count - Text-to-Image Generation with an Accurate Number of Objects,https://arxiv.org/abs/2406.10210,2024-06-14,2024-06-19,0.0,0.0,"Despite the unprecedented success of text-to-image diffusion models,
controlling the number of depicted objects using text is surprisingly hard.
This is important for various applications from technical documents, to
children's books to illustrating cooking recipes. Generating object-correct
counts is fundamentally challenging because the generative model needs to keep
a sense of separate identity for every instance of the object, even if several
objects look identical or overlap, and then carry out a global computation
implicitly during generation. It is still unknown if such representations
exist. To address count-correct generation, we first identify features within
the diffusion model that can carry the object identity information. We then use
them to separate and count instances of objects during the denoising process
and detect over-generation and under-generation. We fix the latter by training
a model that predicts both the shape and location of a missing object, based on
the layout of existing ones, and show how it can be used to guide denoising
with correct object count. Our approach, CountGen, does not depend on external
source to determine object layout, but rather uses the prior from the diffusion
model itself, creating prompt-dependent and seed-dependent layouts. Evaluated
on two benchmark datasets, we find that CountGen strongly outperforms the
count-accuracy of existing baselines."
"Be like a Goldfish, Don't Memorize! Mitigating Memorization in Generative LLMs",https://arxiv.org/abs/2406.10209,2024-06-14,2024-06-19,0.0,0.0,"Large language models can memorize and repeat their training data, causing
privacy and copyright risks. To mitigate memorization, we introduce a subtle
modification to the next-token training objective that we call the goldfish
loss. During training, a randomly sampled subset of tokens are excluded from
the loss computation. These dropped tokens are not memorized by the model,
which prevents verbatim reproduction of a complete chain of tokens from the
training set. We run extensive experiments training billion-scale Llama-2
models, both pre-trained and trained from scratch, and demonstrate significant
reductions in extractable memorization with little to no impact on downstream
benchmarks."
LieRE - Generalizing Rotary Position Encodings,https://arxiv.org/abs/2406.10322,2024-06-14,2024-06-19,0.0,0.0,"While Rotary Position Embeddings (RoPE) for natural language performs well
and has become widely adopted, its adoption for other modalities has been
slower. Here, we introduce Lie group Relative position Encodings (LieRE) that
goes beyond RoPE in supporting higher dimensional inputs. We evaluate the
performance of LieRE on 2D and 3D image classification tasks and observe that
LieRE leads to marked improvements in performance (up to 6%), training
efficiency (3.5x reduction), data efficiency (30%) compared to the baselines of
RoFormer, DeiT III, RoPE-Mixed and Vision-Llama"
A Fundamental Trade-off in Aligned Language Models and its Relation to Sampling Adaptors,https://arxiv.org/abs/2406.10203,2024-06-14,2024-06-19,0.0,0.0,"The relationship between the quality of a string, as judged by a human
reader, and its probability, $p(\boldsymbol{y})$ under a language model
undergirds the development of better language models. For example, many popular
algorithms for sampling from a language model have been conceived with the goal
of manipulating $p(\boldsymbol{y})$ to place higher probability on strings that
humans deem of high quality. In this article, we examine the
probability--quality relationship in language models explicitly aligned to
human preferences, e.g., through reinforcement learning through human feedback.
We show that, when sampling corpora from an aligned language model, there
exists a trade-off between the strings' average reward and average
log-likelihood under the prior language model, i.e., the same model before
alignment with human preferences. We provide a formal treatment of this
phenomenon and demonstrate how a choice of sampling adaptor allows for a
selection of how much likelihood we exchange for the reward."
Crafting Parts for Expressive Object Composition,https://arxiv.org/abs/2406.10197,2024-06-14,2024-06-19,0.0,0.0,"Text-to-image generation from large generative models like Stable Diffusion,
DALLE-2, etc., have become a common base for various tasks due to their
superior quality and extensive knowledge bases. As image composition and
generation are creative processes the artists need control over various parts
of the images being generated. We find that just adding details about parts in
the base text prompt either leads to an entirely different image (e.g.,
missing/incorrect identity) or the extra part details simply being ignored. To
mitigate these issues, we introduce PartCraft, which enables image generation
based on fine-grained part-level details specified for objects in the base text
prompt. This allows more control for artists and enables novel object
compositions by combining distinctive object parts. PartCraft first localizes
object parts by denoising the object region from a specific diffusion process.
This enables each part token to be localized to the right object region. After
obtaining part masks, we run a localized diffusion process in each of the part
regions based on fine-grained part descriptions and combine them to produce the
final image. All the stages of PartCraft are based on repurposing a pre-trained
diffusion model, which enables it to generalize across various domains without
training. We demonstrate the effectiveness of part-level control provided by
PartCraft qualitatively through visual examples and quantitatively in
comparison to the contemporary baselines."
TRIP-PAL - Travel Planning with Guarantees by Combining Large Language Models and Automated Planners,https://arxiv.org/abs/2406.10196,2024-06-14,2024-06-19,0.0,0.0,"Travel planning is a complex task that involves generating a sequence of
actions related to visiting places subject to constraints and maximizing some
user satisfaction criteria. Traditional approaches rely on problem formulation
in a given formal language, extracting relevant travel information from web
sources, and use an adequate problem solver to generate a valid solution. As an
alternative, recent Large Language Model (LLM) based approaches directly output
plans from user requests using language. Although LLMs possess extensive travel
domain knowledge and provide high-level information like points of interest and
potential routes, current state-of-the-art models often generate plans that
lack coherence, fail to satisfy constraints fully, and do not guarantee the
generation of high-quality solutions. We propose TRIP-PAL, a hybrid method that
combines the strengths of LLMs and automated planners, where (i) LLMs get and
translate travel information and user information into data structures that can
be fed into planners; and (ii) automated planners generate travel plans that
guarantee constraint satisfaction and optimize for users' utility. Our
experiments across various travel scenarios show that TRIP-PAL outperforms an
LLM when generating travel plans."
CHIRON - Rich Character Representations in Long-Form Narratives,https://arxiv.org/abs/2406.10190,2024-06-14,2024-06-19,0.0,0.0,"Characters are integral to long-form narratives, but are poorly understood by
existing story analysis and generation systems. While prior work has simplified
characters via graph-based methods and brief character descriptions, we aim to
better tackle the problem of representing complex characters by taking
inspiration from advice given to professional writers. We propose CHIRON, a new
`character sheet' based representation that organizes and filters textual
information about characters. We construct CHIRON sheets in two steps: a
Generation Module that prompts an LLM for character information via
question-answering and a Validation Module that uses automated reasoning and a
domain-specific entailment model to eliminate false facts about a character. We
validate CHIRON via the downstream task of masked-character prediction, where
our experiments show CHIRON is better and more flexible than comparable
summary-based baselines. We also show that metrics derived from CHIRON can be
used to automatically infer character-centricity in stories, and that these
metrics align with human judgments."
Out of style - Misadventures with LLMs and code style transfer,https://arxiv.org/abs/2406.10320,2024-06-14,2024-06-19,0.0,0.0,"Like text, programs have styles, and certain programming styles are more
desirable than others for program readability, maintainability, and
performance. Code style transfer, however, is difficult to automate except for
trivial style guidelines such as limits on line length. Inspired by the success
of using language models for text style transfer, we investigate if code
language models can perform code style transfer. Code style transfer, unlike
text transfer, has rigorous requirements: the system needs to identify lines of
code to change, change them correctly, and leave the rest of the program
untouched. We designed CSB (Code Style Benchmark), a benchmark suite of code
style transfer tasks across five categories including converting for-loops to
list comprehensions, eliminating duplication in code, adding decorators to
methods, etc. We then used these tests to see if large pre-trained code
language models or fine-tuned models perform style transfer correctly, based on
rigorous metrics to test that the transfer did occur, and the code still passes
functional tests. Surprisingly, language models failed to perform all of the
tasks, suggesting that they perform poorly on tasks that require code
understanding. We will make available the large-scale corpora to help the
community build better code models."
Practical offloading for fine-tuning LLM on commodity GPU via learned subspace projectors,https://arxiv.org/abs/2406.10181,2024-06-14,2024-06-19,0.0,0.0,"Fine-tuning large language models (LLMs) requires significant memory, often
exceeding the capacity of a single GPU. A common solution to this memory
challenge is offloading compute and data from the GPU to the CPU. However, this
approach is hampered by the limited bandwidth of commodity hardware, which
constrains communication between the CPU and GPU.
  In this paper, we present an offloading framework, LSP_Offload, that enables
near-native speed LLM fine-tuning on commodity hardware through learned
subspace projectors. Our data-driven approach involves learning an efficient
sparse compressor that minimizes communication with minimal precision loss.
Additionally, we introduce a novel layer-wise communication schedule to
maximize parallelism between communication and computation. As a result, our
framework can fine-tune a 1.3 billion parameter model on a 4GB laptop GPU and a
7 billion parameter model on an NVIDIA RTX 4090 GPU with 24GB memory, achieving
only a 31% slowdown compared to fine-tuning with unlimited memory. Compared to
state-of-the-art offloading frameworks, our approach increases fine-tuning
throughput by up to 3.33 times and reduces end-to-end fine-tuning time by
33.1%~62.5% when converging to the same accuracy."
Inclusive ASR for Disfluent Speech - Cascaded Large-Scale Self-Supervised Learning with Targeted Fine-Tuning and Data Augmentation,https://arxiv.org/abs/2406.10177,2024-06-14,2024-06-19,0.0,0.0,"Automatic speech recognition (ASR) systems often falter while processing
stuttering-related disfluencies -- such as involuntary blocks and word
repetitions -- yielding inaccurate transcripts. A critical barrier to progress
is the scarcity of large, annotated disfluent speech datasets. Therefore, we
present an inclusive ASR design approach, leveraging large-scale
self-supervised learning on standard speech followed by targeted fine-tuning
and data augmentation on a smaller, curated dataset of disfluent speech. Our
data augmentation technique enriches training datasets with various
disfluencies, enhancing ASR processing of these speech patterns. Results show
that fine-tuning wav2vec 2.0 with even a relatively small, labeled dataset,
alongside data augmentation, can significantly reduce word error rates for
disfluent speech. Our approach not only advances ASR inclusivity for people who
stutter, but also paves the way for ASRs that can accommodate wider speech
variations."
Let the Poem Hit the Rhythm - Using a Byte-Based Transformer for Beat-Aligned Poetry Generation,https://arxiv.org/abs/2406.10174,2024-06-14,2024-06-19,0.0,0.0,"The intersection between poetry and music provides an interesting case for
computational creativity, yet remains relatively unexplored. This paper
explores the integration of poetry and music through the lens of beat patterns,
investigating whether a byte-based language model can generate words that fit
specific beat patterns within the context of poetry. Drawing on earlier
studies, we developed a method to train a byte-based transformer model, ByT5,
to align poems with beat patterns. The results demonstrate a high level of beat
alignment while maintaining semantic coherence. Future work will aim to improve
the model's ability to create complete beat-aligned poems."
Creating a Lens of Chinese Culture - A Multimodal Dataset for Chinese Pun Rebus Art Understanding,https://arxiv.org/abs/2406.10318,2024-06-14,2024-06-19,0.0,0.0,"Large vision-language models (VLMs) have demonstrated remarkable abilities in
understanding everyday content. However, their performance in the domain of
art, particularly culturally rich art forms, remains less explored. As a pearl
of human wisdom and creativity, art encapsulates complex cultural narratives
and symbolism. In this paper, we offer the Pun Rebus Art Dataset, a multimodal
dataset for art understanding deeply rooted in traditional Chinese culture. We
focus on three primary tasks: identifying salient visual elements, matching
elements with their symbolic meanings, and explanations for the conveyed
messages. Our evaluation reveals that state-of-the-art VLMs struggle with these
tasks, often providing biased and hallucinated explanations and showing limited
improvement through in-context learning. By releasing the Pun Rebus Art
Dataset, we aim to facilitate the development of VLMs that can better
understand and interpret culturally specific content, promoting greater
inclusiveness beyond English-based corpora."
IntentionQA - A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce,https://arxiv.org/abs/2406.10173,2024-06-14,2024-06-19,0.0,0.0,"Enhancing Language Models' (LMs) ability to understand purchase intentions in
E-commerce scenarios is crucial for their effective assistance in various
downstream tasks. However, previous approaches that distill intentions from LMs
often fail to generate meaningful and human-centric intentions applicable in
real-world E-commerce contexts. This raises concerns about the true
comprehension and utilization of purchase intentions by LMs. In this paper, we
present IntentionQA, a double-task multiple-choice question answering benchmark
to evaluate LMs' comprehension of purchase intentions in E-commerce.
Specifically, LMs are tasked to infer intentions based on purchased products
and utilize them to predict additional purchases. IntentionQA consists of 4,360
carefully curated problems across three difficulty levels, constructed using an
automated pipeline to ensure scalability on large E-commerce platforms. Human
evaluations demonstrate the high quality and low false-negative rate of our
benchmark. Extensive experiments across 19 language models show that they still
struggle with certain scenarios, such as understanding products and intentions
accurately, jointly reasoning with products and intentions, and more, in which
they fall far behind human performances. Our code and data are publicly
available at https://github.com/HKUST-KnowComp/IntentionQA."
Datasets for Multilingual Answer Sentence Selection,https://arxiv.org/abs/2406.10172,2024-06-14,2024-06-19,0.0,0.0,"Answer Sentence Selection (AS2) is a critical task for designing effective
retrieval-based Question Answering (QA) systems. Most advancements in AS2 focus
on English due to the scarcity of annotated datasets for other languages. This
lack of resources prevents the training of effective AS2 models in different
languages, creating a performance gap between QA systems in English and other
locales. In this paper, we introduce new high-quality datasets for AS2 in five
European languages (French, German, Italian, Portuguese, and Spanish), obtained
through supervised Automatic Machine Translation (AMT) of existing English AS2
datasets such as ASNQ, WikiQA, and TREC-QA using a Large Language Model (LLM).
We evaluated our approach and the quality of the translated datasets through
multiple experiments with different Transformer architectures. The results
indicate that our datasets are pivotal in producing robust and powerful
multilingual AS2 models, significantly contributing to closing the performance
gap between English and other languages."
Misam - Using ML in Dataflow Selection of Sparse-Sparse Matrix Multiplication,https://arxiv.org/abs/2406.10166,2024-06-14,2024-06-19,0.0,0.0,"Sparse matrix-matrix multiplication (SpGEMM) is a critical operation in
numerous fields, including scientific computing, graph analytics, and deep
learning. These applications exploit the sparsity of matrices to reduce storage
and computational demands. However, the irregular structure of sparse matrices
poses significant challenges for performance optimization. Traditional hardware
accelerators are tailored for specific sparsity patterns with fixed dataflow
schemes - inner, outer, and row-wise but often perform suboptimally when the
actual sparsity deviates from these predetermined patterns. As the use of
SpGEMM expands across various domains, each with distinct sparsity
characteristics, the demand for hardware accelerators that can efficiently
handle a range of sparsity patterns is increasing. This paper presents a
machine learning based approach for adaptively selecting the most appropriate
dataflow scheme for SpGEMM tasks with diverse sparsity patterns. By employing
decision trees and deep reinforcement learning, we explore the potential of
these techniques to surpass heuristic-based methods in identifying optimal
dataflow schemes. We evaluate our models by comparing their performance with
that of a heuristic, highlighting the strengths and weaknesses of each
approach. Our findings suggest that using machine learning for dynamic dataflow
selection in hardware accelerators can provide upto 28 times gains."
MeshAnything - Artist-Created Mesh Generation with Autoregressive Transformers,https://arxiv.org/abs/2406.10163,2024-06-14,2024-06-19,0.0,0.0,"Recently, 3D assets created via reconstruction and generation have matched
the quality of manually crafted assets, highlighting their potential for
replacement. However, this potential is largely unrealized because these assets
always need to be converted to meshes for 3D industry applications, and the
meshes produced by current mesh extraction methods are significantly inferior
to Artist-Created Meshes (AMs), i.e., meshes created by human artists.
Specifically, current mesh extraction methods rely on dense faces and ignore
geometric features, leading to inefficiencies, complicated post-processing, and
lower representation quality. To address these issues, we introduce
MeshAnything, a model that treats mesh extraction as a generation problem,
producing AMs aligned with specified shapes. By converting 3D assets in any 3D
representation into AMs, MeshAnything can be integrated with various 3D asset
production methods, thereby enhancing their application across the 3D industry.
The architecture of MeshAnything comprises a VQ-VAE and a shape-conditioned
decoder-only transformer. We first learn a mesh vocabulary using the VQ-VAE,
then train the shape-conditioned decoder-only transformer on this vocabulary
for shape-conditioned autoregressive mesh generation. Our extensive experiments
show that our method generates AMs with hundreds of times fewer faces,
significantly improving storage, rendering, and simulation efficiencies, while
achieving precision comparable to previous methods."
Sycophancy to Subterfuge - Investigating Reward-Tampering in Large Language Models,https://arxiv.org/abs/2406.10162,2024-06-14,2024-06-19,0.0,0.0,"In reinforcement learning, specification gaming occurs when AI systems learn
undesired behaviors that are highly rewarded due to misspecified training
goals. Specification gaming can range from simple behaviors like sycophancy to
sophisticated and pernicious behaviors like reward-tampering, where a model
directly modifies its own reward mechanism. However, these more pernicious
behaviors may be too complex to be discovered via exploration. In this paper,
we study whether Large Language Model (LLM) assistants which find easily
discovered forms of specification gaming will generalize to perform rarer and
more blatant forms, up to and including reward-tampering. We construct a
curriculum of increasingly sophisticated gameable environments and find that
training on early-curriculum environments leads to more specification gaming on
remaining environments. Strikingly, a small but non-negligible proportion of
the time, LLM assistants trained on the full curriculum generalize zero-shot to
directly rewriting their own reward function. Retraining an LLM not to game
early-curriculum environments mitigates, but does not eliminate,
reward-tampering in later environments. Moreover, adding harmlessness training
to our gameable environments does not prevent reward-tampering. These results
demonstrate that LLMs can generalize from common forms of specification gaming
to more pernicious reward tampering and that such behavior may be nontrivial to
remove."
On the Computability of Robust PAC Learning,https://arxiv.org/abs/2406.10161,2024-06-14,2024-06-19,0.0,0.0,"We initiate the study of computability requirements for adversarially robust
learning. Adversarially robust PAC-type learnability is by now an established
field of research. However, the effects of computability requirements in
PAC-type frameworks are only just starting to emerge. We introduce the problem
of robust computable PAC (robust CPAC) learning and provide some simple
sufficient conditions for this. We then show that learnability in this setup is
not implied by the combination of its components: classes that are both CPAC
and robustly PAC learnable are not necessarily robustly CPAC learnable.
Furthermore, we show that the novel framework exhibits some surprising effects:
for robust CPAC learnability it is not required that the robust loss is
computably evaluable! Towards understanding characterizing properties, we
introduce a novel dimension, the computable robust shattering dimension. We
prove that its finiteness is necessary, but not sufficient for robust CPAC
learnability. This might yield novel insights for the corresponding phenomenon
in the context of robust PAC learnability, where insufficiency of the robust
shattering dimension for learnability has been conjectured, but so far a
resolution has remained elusive."
One-pass Multiple Conformer and Foundation Speech Systems Compression and Quantization Using An All-in-one Neural Model,https://arxiv.org/abs/2406.10160,2024-06-14,2024-06-19,0.0,0.0,"We propose a novel one-pass multiple ASR systems joint compression and
quantization approach using an all-in-one neural model. A single compression
cycle allows multiple nested systems with varying Encoder depths, widths, and
quantization precision settings to be simultaneously constructed without the
need to train and store individual target systems separately. Experiments
consistently demonstrate the multiple ASR systems compressed in a single
all-in-one model produced a word error rate (WER) comparable to, or lower by up
to 1.01\% absolute (6.98\% relative) than individually trained systems of equal
complexity. A 3.4x overall system compression and training time speed-up was
achieved. Maximum model size compression ratios of 12.8x and 3.93x were
obtained over the baseline Switchboard-300hr Conformer and LibriSpeech-100hr
fine-tuned wav2vec2.0 models, respectively, incurring no statistically
significant WER increase."
RoboGolf - Mastering Real-World Minigolf with a Reflective Multi-Modality Vision-Language Model,https://arxiv.org/abs/2406.10157,2024-06-14,2024-06-19,0.0,0.0,"Minigolf is an exemplary real-world game for examining embodied intelligence,
requiring challenging spatial and kinodynamic understanding to putt the ball.
Additionally, reflective reasoning is required if the feasibility of a
challenge is not ensured. We introduce RoboGolf, a VLM-based framework that
combines dual-camera perception with closed-loop action refinement, augmented
by a reflective equilibrium loop. The core of both loops is powered by
finetuned VLMs. We analyze the capabilities of the framework in an offline
inference setting, relying on an extensive set of recorded trajectories.
Exemplary demonstrations of the analyzed problem domain are available at
https://jity16.github.io/RoboGolf/"
Automated Design of Linear Bounding Functions for Sigmoidal Nonlinearities in Neural Networks,https://arxiv.org/abs/2406.10154,2024-06-14,2024-06-19,0.0,0.0,"The ubiquity of deep learning algorithms in various applications has
amplified the need for assuring their robustness against small input
perturbations such as those occurring in adversarial attacks. Existing complete
verification techniques offer provable guarantees for all robustness queries
but struggle to scale beyond small neural networks. To overcome this
computational intractability, incomplete verification methods often rely on
convex relaxation to over-approximate the nonlinearities in neural networks.
Progress in tighter approximations has been achieved for piecewise linear
functions. However, robustness verification of neural networks for general
activation functions (e.g., Sigmoid, Tanh) remains under-explored and poses new
challenges. Typically, these networks are verified using convex relaxation
techniques, which involve computing linear upper and lower bounds of the
nonlinear activation functions. In this work, we propose a novel parameter
search method to improve the quality of these linear approximations.
Specifically, we show that using a simple search method, carefully adapted to
the given verification problem through state-of-the-art algorithm configuration
techniques, improves the average global lower bound by 25% on average over the
current state of the art on several commonly used local robustness verification
benchmarks."
BABILong - Testing the Limits of LLMs with Long Context Reasoning-in-a-Haystack,https://arxiv.org/abs/2406.10149,2024-06-14,2024-06-19,0.0,0.0,"In recent years, the input context sizes of large language models (LLMs) have
increased dramatically. However, existing evaluation methods have not kept
pace, failing to comprehensively assess the efficiency of models in handling
long contexts. To bridge this gap, we introduce the BABILong benchmark,
designed to test language models' ability to reason across facts distributed in
extremely long documents. BABILong includes a diverse set of 20 reasoning
tasks, including fact chaining, simple induction, deduction, counting, and
handling lists/sets. These tasks are challenging on their own, and even more
demanding when the required facts are scattered across long natural text. Our
evaluations show that popular LLMs effectively utilize only 10-20\% of the
context and their performance declines sharply with increased reasoning
complexity. Among alternatives to in-context reasoning, Retrieval-Augmented
Generation methods achieve a modest 60\% accuracy on single-fact question
answering, independent of context length. Among context extension methods, the
highest performance is demonstrated by recurrent memory transformers, enabling
the processing of lengths up to 11 million tokens. The BABILong benchmark is
extendable to any length to support the evaluation of new upcoming models with
increased capabilities, and we provide splits up to 1 million token lengths."
A Primal-Dual-Assisted Penalty Approach to Bilevel Optimization with Coupled Constraints,https://arxiv.org/abs/2406.10148,2024-06-14,2024-06-19,0.0,0.0,"Interest in bilevel optimization has grown in recent years, partially due to
its applications to tackle challenging machine-learning problems. Several
exciting recent works have been centered around developing efficient
gradient-based algorithms that can solve bilevel optimization problems with
provable guarantees. However, the existing literature mainly focuses on bilevel
problems either without constraints, or featuring only simple constraints that
do not couple variables across the upper and lower levels, excluding a range of
complex applications. Our paper studies this challenging but less explored
scenario and develops a (fully) first-order algorithm, which we term BLOCC, to
tackle BiLevel Optimization problems with Coupled Constraints. We establish
rigorous convergence theory for the proposed algorithm and demonstrate its
effectiveness on two well-known real-world applications - hyperparameter
selection in support vector machine (SVM) and infrastructure planning in
transportation networks using the real data from the city of Seville."
Improving rule mining via embedding-based link prediction,https://arxiv.org/abs/2406.10144,2024-06-14,2024-06-19,0.0,0.0,"Rule mining on knowledge graphs allows for explainable link prediction.
Contrarily, embedding-based methods for link prediction are well known for
their generalization capabilities, but their predictions are not interpretable.
Several approaches combining the two families have been proposed in recent
years. The majority of the resulting hybrid approaches are usually trained
within a unified learning framework, which often leads to convergence issues
due to the complexity of the learning task. In this work, we propose a new way
to combine the two families of approaches. Specifically, we enrich a given
knowledge graph by means of its pre-trained entity and relation embeddings
before applying rule mining systems on the enriched knowledge graph. To
validate our approach, we conduct extensive experiments on seven benchmark
datasets. An analysis of the results generated by our approach suggests that we
discover new valuable rules on the enriched graphs. We provide an open source
implementation of our approach as well as pretrained models and datasets at
https://github.com/Jean-KOUAGOU/EnhancedRuleLearning"
The Rise and Fall(?) of Software Engineering,https://arxiv.org/abs/2406.10141,2024-06-14,2024-06-19,0.0,0.0,"Over the last ten years, the realm of Artificial Intelligence (AI) has
experienced an explosion of revolutionary breakthroughs, transforming what
seemed like a far-off dream into a reality that is now deeply embedded in our
everyday lives. AI's widespread impact is revolutionizing virtually all aspects
of human life, and software engineering (SE) is no exception.
  As we explore this changing landscape, we are faced with questions about what
the future holds for SE and how AI will reshape the roles, duties, and
methodologies within the field. The introduction of these groundbreaking
technologies highlights the inevitable shift towards a new paradigm, suggesting
a future where AI's capabilities may redefine the boundaries of SE, potentially
even more than human input.
  In this paper, we aim at outlining the key elements that, based on our
expertise, are vital for the smooth integration of AI into SE, all while
preserving the intrinsic human creativity that has been the driving force
behind the field. First, we provide a brief description of SE and AI evolution.
Afterward, we delve into the intricate interplay between AI-driven automation
and human innovation, exploring how these two components can work together to
advance SE practices to new methods and standards."
Compressed Sensor Caching and Collaborative Sparse Data Recovery with Anchor Alignment,https://arxiv.org/abs/2406.10137,2024-06-14,2024-06-19,0.0,0.0,"This work examines the compressed sensor caching problem in wireless sensor
networks and devises efficient distributed sparse data recovery algorithms to
enable collaboration among multiple caches. In this problem, each cache is only
allowed to access measurements from a small subset of sensors within its
vicinity to reduce both cache size and data acquisition overhead. To enable
reliable data recovery with limited access to measurements, we propose a
distributed sparse data recovery method, called the collaborative sparse
recovery by anchor alignment (CoSR-AA) algorithm, where collaboration among
caches is enabled by aligning their locally recovered data at a few anchor
nodes. The proposed algorithm is based on the consensus alternating direction
method of multipliers (ADMM) algorithm but with message exchange that is
reduced by considering the proposed anchor alignment strategy. Then, by the
deep unfolding of the ADMM iterations, we further propose the Deep CoSR-AA
algorithm that can be used to significantly reduce the number of iterations. We
obtain a graph neural network architecture where message exchange is done more
efficiently by an embedded autoencoder. Simulations are provided to demonstrate
the effectiveness of the proposed collaborative recovery algorithms in terms of
the improved reconstruction quality and the reduced communication overhead due
to anchor alignment."
Linear Contextual Bandits with Hybrid Payoff - Revisited,https://arxiv.org/abs/2406.10131,2024-06-14,2024-06-19,0.0,0.0,"We study the Linear Contextual Bandit problem in the hybrid reward setting.
In this setting every arm's reward model contains arm specific parameters in
addition to parameters shared across the reward models of all the arms. We can
reduce this setting to two closely related settings (a) Shared - no arm
specific parameters, and (b) Disjoint - only arm specific parameters, enabling
the application of two popular state of the art algorithms - $\texttt{LinUCB}$
and $\texttt{DisLinUCB}$ (Algorithm 1 in (Li et al. 2010)). When the arm
features are stochastic and satisfy a popular diversity condition, we provide
new regret analyses for both algorithms, significantly improving on the known
regret guarantees of these algorithms. Our novel analysis critically exploits
the hybrid reward structure and the diversity condition. Moreover, we introduce
a new algorithm $\texttt{HyLinUCB}$ that crucially modifies $\texttt{LinUCB}$
(using a new exploration coefficient) to account for sparsity in the hybrid
setting. Under the same diversity assumptions, we prove that
$\texttt{HyLinUCB}$ also incurs only $O(\sqrt{T})$ regret for $T$ rounds. We
perform extensive experiments on synthetic and real-world datasets
demonstrating strong empirical performance of $\texttt{HyLinUCB}$.For number of
arm specific parameters much larger than the number of shared parameters, we
observe that $\texttt{DisLinUCB}$ incurs the lowest regret. In this case,
regret of $\texttt{HyLinUCB}$ is the second best and extremely competitive to
$\texttt{DisLinUCB}$. In all other situations, including our real-world
dataset, $\texttt{HyLinUCB}$ has significantly lower regret than
$\texttt{LinUCB}$, $\texttt{DisLinUCB}$ and other SOTA baselines we considered.
We also empirically observe that the regret of $\texttt{HyLinUCB}$ grows much
slower with the number of arms compared to baselines, making it suitable even
for very large action spaces."
The Devil is in the Neurons - Interpreting and Mitigating Social Biases in Pre-trained Language Models,https://arxiv.org/abs/2406.10130,2024-06-14,2024-06-19,0.0,0.0,"Pre-trained Language models (PLMs) have been acknowledged to contain harmful
information, such as social biases, which may cause negative social impacts or
even bring catastrophic results in application. Previous works on this problem
mainly focused on using black-box methods such as probing to detect and
quantify social biases in PLMs by observing model outputs. As a result,
previous debiasing methods mainly finetune or even pre-train language models on
newly constructed anti-stereotypical datasets, which are high-cost. In this
work, we try to unveil the mystery of social bias inside language models by
introducing the concept of {\sc Social Bias Neurons}. Specifically, we propose
{\sc Integrated Gap Gradients (IG$^2$)} to accurately pinpoint units (i.e.,
neurons) in a language model that can be attributed to undesirable behavior,
such as social bias. By formalizing undesirable behavior as a distributional
property of language, we employ sentiment-bearing prompts to elicit classes of
sensitive words (demographics) correlated with such sentiments. Our IG$^2$ thus
attributes the uneven distribution for different demographics to specific
Social Bias Neurons, which track the trail of unwanted behavior inside PLM
units to achieve interoperability. Moreover, derived from our interpretable
technique, {\sc Bias Neuron Suppression (BNS)} is further proposed to mitigate
social biases. By studying BERT, RoBERTa, and their attributable differences
from debiased FairBERTa, IG$^2$ allows us to locate and suppress identified
neurons, and further mitigate undesired behaviors. As measured by prior metrics
from StereoSet, our model achieves a higher degree of fairness while
maintaining language modeling ability with low cost."
Exploration by Learning Diverse Skills through Successor State Measures,https://arxiv.org/abs/2406.10127,2024-06-14,2024-06-19,0.0,0.0,"The ability to perform different skills can encourage agents to explore. In
this work, we aim to construct a set of diverse skills which uniformly cover
the state space. We propose a formalization of this search for diverse skills,
building on a previous definition based on the mutual information between
states and skills. We consider the distribution of states reached by a policy
conditioned on each skill and leverage the successor state measure to maximize
the difference between these skill distributions. We call this approach LEADS:
Learning Diverse Skills through Successor States. We demonstrate our approach
on a set of maze navigation and robotic control tasks which show that our
method is capable of constructing a diverse set of skills which exhaustively
cover the state space without relying on reward or exploration bonuses. Our
findings demonstrate that this new formalization promotes more robust and
efficient exploration by combining mutual information maximization and
exploration bonuses."
Data Ethics in the Era of Healthcare Artificial Intelligence in Africa - An Ubuntu Philosophy Perspective,https://arxiv.org/abs/2406.10121,2024-06-14,2024-06-19,0.0,0.0,"Data are essential in developing healthcare artificial intelligence (AI)
systems. However, patient data collection, access, and use raise ethical
concerns, including informed consent, data bias, data protection and privacy,
data ownership, and benefit sharing. Various ethical frameworks have been
proposed to ensure the ethical use of healthcare data and AI, however, these
frameworks often align with Western cultural values, social norms, and
institutional contexts emphasizing individual autonomy and well-being. Ethical
guidelines must reflect political and cultural settings to account for cultural
diversity, inclusivity, and historical factors such as colonialism. Thus, this
paper discusses healthcare data ethics in the AI era in Africa from the Ubuntu
philosophy perspective. It focuses on the contrast between individualistic and
communitarian approaches to data ethics. The proposed framework could inform
stakeholders, including AI developers, healthcare providers, the public, and
policy-makers about healthcare data ethical usage in AI in Africa."
Trustworthy Artificial Intelligence in the Context of Metrology,https://arxiv.org/abs/2406.10117,2024-06-14,2024-06-19,0.0,0.0,"We review research at the National Physical Laboratory (NPL) in the area of
trustworthy artificial intelligence (TAI), and more specifically trustworthy
machine learning (TML), in the context of metrology, the science of
measurement. We describe three broad themes of TAI: technical, socio-technical
and social, which play key roles in ensuring that the developed models are
trustworthy and can be relied upon to make responsible decisions. From a
metrology perspective we emphasise uncertainty quantification (UQ), and its
importance within the framework of TAI to enhance transparency and trust in the
outputs of AI systems. We then discuss three research areas within TAI that we
are working on at NPL, and examine the certification of AI systems in terms of
adherence to the characteristics of TAI."
Shelf-Supervised Multi-Modal Pre-Training for 3D Object Detection,https://arxiv.org/abs/2406.10115,2024-06-14,2024-06-19,0.0,0.0,"State-of-the-art 3D object detectors are often trained on massive labeled
datasets. However, annotating 3D bounding boxes remains prohibitively expensive
and time-consuming, particularly for LiDAR. Instead, recent works demonstrate
that self-supervised pre-training with unlabeled data can improve detection
accuracy with limited labels. Contemporary methods adapt best-practices for
self-supervised learning from the image domain to point clouds (such as
contrastive learning). However, publicly available 3D datasets are considerably
smaller and less diverse than those used for image-based self-supervised
learning, limiting their effectiveness. We do note, however, that such data is
naturally collected in a multimodal fashion, often paired with images. Rather
than pre-training with only self-supervised objectives, we argue that it is
better to bootstrap point cloud representations using image-based foundation
models trained on internet-scale image data. Specifically, we propose a
shelf-supervised approach (e.g. supervised with off-the-shelf image foundation
models) for generating zero-shot 3D bounding boxes from paired RGB and LiDAR
data. Pre-training 3D detectors with such pseudo-labels yields significantly
better semi-supervised detection accuracy than prior self-supervised pretext
tasks. Importantly, we show that image-based shelf-supervision is helpful for
training LiDAR-only and multi-modal (RGB + LiDAR) detectors. We demonstrate the
effectiveness of our approach on nuScenes and WOD, significantly improving over
prior work in limited data settings. Our code is available at
https://github.com/meharkhurana03/cm3d"
Precipitation Nowcasting Using Physics Informed Discriminator Generative Models,https://arxiv.org/abs/2406.10108,2024-06-14,2024-06-19,0.0,0.0,"Nowcasting leverages real-time atmospheric conditions to forecast weather
over short periods. State-of-the-art models, including PySTEPS, encounter
difficulties in accurately forecasting extreme weather events because of their
unpredictable distribution patterns. In this study, we design a
physics-informed neural network to perform precipitation nowcasting using the
precipitation and meteorological data from the Royal Netherlands Meteorological
Institute (KNMI). This model draws inspiration from the novel Physics-Informed
Discriminator GAN (PID-GAN) formulation, directly integrating physics-based
supervision within the adversarial learning framework. The proposed model
adopts a GAN structure, featuring a Vector Quantization Generative Adversarial
Network (VQ-GAN) and a Transformer as the generator, with a temporal
discriminator serving as the discriminator. Our findings demonstrate that the
PID-GAN model outperforms numerical and SOTA deep generative models in terms of
precipitation nowcasting downstream metrics."
SkySenseGPT - A Fine-Grained Instruction Tuning Dataset and Model for Remote Sensing Vision-Language Understanding,https://arxiv.org/abs/2406.10100,2024-06-14,2024-06-19,0.0,0.0,"Remote Sensing Large Multi-Modal Models (RSLMMs) are developing rapidly and
showcase significant capabilities in remote sensing imagery (RSI)
comprehension. However, due to the limitations of existing datasets, RSLMMs
have shortcomings in understanding the rich semantic relations among objects in
complex remote sensing scenes. To unlock RSLMMs' complex comprehension ability,
we propose a large-scale instruction tuning dataset FIT-RS, containing
1,800,851 instruction samples. FIT-RS covers common interpretation tasks and
innovatively introduces several complex comprehension tasks of escalating
difficulty, ranging from relation reasoning to image-level scene graph
generation. Based on FIT-RS, we build the FIT-RSFG benchmark. Furthermore, we
establish a new benchmark to evaluate the fine-grained relation comprehension
capabilities of LMMs, named FIT-RSRC. Based on combined instruction data, we
propose SkySenseGPT, which achieves outstanding performance on both public
datasets and FIT-RSFG, surpassing existing RSLMMs. We hope the FIT-RS dataset
can enhance the relation comprehension capability of RSLMMs and provide a
large-scale fine-grained data source for the remote sensing community. The
dataset will be available at https://github.com/Luo-Z13/SkySenseGPT"
Know the Unknown - An Uncertainty-Sensitive Method for LLM Instruction Tuning,https://arxiv.org/abs/2406.10099,2024-06-14,2024-06-19,0.0,0.0,"Large language models (LLMs) have demonstrated remarkable capabilities across
various tasks but still face challenges such as hallucinations. One potential
reason for hallucinations is the lack of relevant knowledge or context. Thus, a
promising solution to mitigate this issue involves instructing LLMs to respond
with ""I do not know"" when a question falls outside their knowledge domain or
the provided context. However, in this work, we observed that LLMs struggle to
admit their lack of knowledge, primarily due to existing instruction datasets
designed to encourage specific answers. To improve large language models'
capability to recognize the boundaries of their knowledge, we propose a novel
approach called uncertainty-sensitive tuning. This method involves two-stage
training designed for uncertainty recognition and prompt-sensitive activation.
In the first stage, we guide the LLM to reject unknown questions. In the second
stage, we recover the decreased performance in QA tasks by incorporating
designed causal instructions. By leveraging this method, we aim to enhance the
model's ability to identify areas of uncertainty. The experimental results
demonstrate that our proposed uncertainty-sensitive tuning method significantly
improves the performance of the Llama2-chat-7B model. Specifically, it achieves
a substantial 34.7% improvement in handling questions involving knowledge gaps
compared to the original model. Moreover, our approach outperforms GPT-4,
exhibiting a 9.4% increase in overall performance. We open-source the model and
code on GitHub."
ECGMamba - Towards Efficient ECG Classification with BiSSM,https://arxiv.org/abs/2406.10098,2024-06-14,2024-06-19,0.0,0.0,"Electrocardiogram (ECG) signal analysis represents a pivotal technique in the
diagnosis of cardiovascular diseases. Although transformer-based models have
made significant progress in ECG classification, they exhibit inefficiencies in
the inference phase. The issue is primarily attributable to the secondary
computational complexity of Transformer's self-attention mechanism.
particularly when processing lengthy sequences. To address this issue, we
propose a novel model, ECGMamba, which employs a bidirectional state-space
model (BiSSM) to enhance classification efficiency. ECGMamba is based on the
innovative Mamba-based block, which incorporates a range of time series
modeling techniques to enhance performance while maintaining the efficiency of
inference. The experimental results on two publicly available ECG datasets
demonstrate that ECGMamba effectively balances the effectiveness and efficiency
of classification, achieving competitive performance. This study not only
contributes to the body of knowledge in the field of ECG classification but
also provides a new research path for efficient and accurate ECG signal
analysis. This is of guiding significance for the development of diagnostic
models for cardiovascular diseases."
BiKC - Keypose-Conditioned Consistency Policy for Bimanual Robotic Manipulation,https://arxiv.org/abs/2406.10093,2024-06-14,2024-06-19,0.0,0.0,"Bimanual manipulation tasks typically involve multiple stages which require
efficient interactions between two arms, posing step-wise and stage-wise
challenges for imitation learning systems. Specifically, failure and delay of
one step will broadcast through time, hinder success and efficiency of each
sub-stage task, and thereby overall task performance. Although recent works
have made strides in addressing certain challenges, few approaches explicitly
consider the multi-stage nature of bimanual tasks while simultaneously
emphasizing the importance of inference speed. In this paper, we introduce a
novel keypose-conditioned consistency policy tailored for bimanual
manipulation. It is a hierarchical imitation learning framework that consists
of a high-level keypose predictor and a low-level trajectory generator. The
predicted keyposes provide guidance for trajectory generation and also mark the
completion of one sub-stage task. The trajectory generator is designed as a
consistency model trained from scratch without distillation, which generates
action sequences conditioning on current observations and predicted keyposes
with fast inference speed. Simulated and real-world experimental results
demonstrate that the proposed approach surpasses baseline methods in terms of
success rate and operational efficiency. Codes are available at
https://github.com/ManUtdMoon/BiKC."
Exploring the Correlation between Human and Machine Evaluation of Simultaneous Speech Translation,https://arxiv.org/abs/2406.10091,2024-06-14,2024-06-19,0.0,0.0,"Assessing the performance of interpreting services is a complex task, given
the nuanced nature of spoken language translation, the strategies that
interpreters apply, and the diverse expectations of users. The complexity of
this task become even more pronounced when automated evaluation methods are
applied. This is particularly true because interpreted texts exhibit less
linearity between the source and target languages due to the strategies
employed by the interpreter.
  This study aims to assess the reliability of automatic metrics in evaluating
simultaneous interpretations by analyzing their correlation with human
evaluations. We focus on a particular feature of interpretation quality, namely
translation accuracy or faithfulness. As a benchmark we use human assessments
performed by language experts, and evaluate how well sentence embeddings and
Large Language Models correlate with them. We quantify semantic similarity
between the source and translated texts without relying on a reference
translation. The results suggest GPT models, particularly GPT-3.5 with direct
prompting, demonstrate the strongest correlation with human judgment in terms
of semantic similarity between source and target texts, even when evaluating
short textual segments. Additionally, the study reveals that the size of the
context window has a notable impact on this correlation."
Over-parameterization and Adversarial Robustness in Neural Networks - An Overview and Empirical Analysis,https://arxiv.org/abs/2406.10090,2024-06-14,2024-06-19,0.0,0.0,"Thanks to their extensive capacity, over-parameterized neural networks
exhibit superior predictive capabilities and generalization. However, having a
large parameter space is considered one of the main suspects of the neural
networks' vulnerability to adversarial example -- input samples crafted ad-hoc
to induce a desired misclassification. Relevant literature has claimed
contradictory remarks in support of and against the robustness of
over-parameterized networks. These contradictory findings might be due to the
failure of the attack employed to evaluate the networks' robustness. Previous
research has demonstrated that depending on the considered model, the algorithm
employed to generate adversarial examples may not function properly, leading to
overestimating the model's robustness. In this work, we empirically study the
robustness of over-parameterized networks against adversarial examples.
However, unlike the previous works, we also evaluate the considered attack's
reliability to support the results' veracity. Our results show that
over-parameterized networks are robust against adversarial attacks as opposed
to their under-parameterized counterparts."
Discovering influential text using convolutional neural networks,https://arxiv.org/abs/2406.10086,2024-06-14,2024-06-19,0.0,0.0,"Experimental methods for estimating the impacts of text on human evaluation
have been widely used in the social sciences. However, researchers in
experimental settings are usually limited to testing a small number of
pre-specified text treatments. While efforts to mine unstructured texts for
features that causally affect outcomes have been ongoing in recent years, these
models have primarily focused on the topics or specific words of text, which
may not always be the mechanism of the effect. We connect these efforts with
NLP interpretability techniques and present a method for flexibly discovering
clusters of similar text phrases that are predictive of human reactions to
texts using convolutional neural networks. When used in an experimental
setting, this method can identify text treatments and their effects under
certain assumptions. We apply the method to two datasets. The first enables
direct validation of the model's ability to detect phrases known to cause the
outcome. The second demonstrates its ability to flexibly discover text
treatments with varying textual structures. In both cases, the model learns a
greater variety of text treatments compared to benchmark methods, and these
text features quantitatively meet or exceed the ability of benchmark methods to
predict the outcome."
Enhancing Question Answering on Charts Through Effective Pre-training Tasks,https://arxiv.org/abs/2406.10085,2024-06-14,2024-06-19,0.0,0.0,"To completely understand a document, the use of textual information is not
enough. Understanding visual cues, such as layouts and charts, is also
required. While the current state-of-the-art approaches for document
understanding (both OCR-based and OCR-free) work well, a thorough analysis of
their capabilities and limitations has not yet been performed. Therefore, in
this work, we addresses the limitation of current VisualQA models when applied
to charts and plots. To investigate shortcomings of the state-of-the-art
models, we conduct a comprehensive behavioral analysis, using ChartQA as a case
study. Our findings indicate that existing models particularly underperform in
answering questions related to the chart's structural and visual context, as
well as numerical information. To address these issues, we propose three simple
pre-training tasks that enforce the existing model in terms of both
structural-visual knowledge, as well as its understanding of numerical
questions. We evaluate our pre-trained model (called MatCha-v2) on three chart
datasets - both extractive and abstractive question datasets - and observe that
it achieves an average improvement of 1.7% over the baseline model."
Development and Validation of a Machine Learning Algorithm for Clinical Wellness Visit Classification in Cats and Dogs,https://arxiv.org/abs/2406.10314,2024-06-14,2024-06-19,0.0,0.0,"Early disease detection in veterinary care relies on identifying subclinical
abnormalities in asymptomatic animals during wellness visits. This study
introduces an algorithm designed to distinguish between wellness and other
veterinary visits.The purpose of this study is to validate the use of a visit
classification algorithm compared to manual classification of veterinary visits
by three board-certified veterinarians. Using a dataset of 11,105 clinical
visits from 2012 to 2017 involving 655 animals (85.3% canines and 14.7%
felines) across 544 U.S. veterinary establishments, the model was trained using
a Gradient Boosting Machine model. Three validators were tasked with
classifying 400 visits, including both wellness and other types of visits,
selected randomly from the same database used for initial algorithm training,
aiming to maintain consistency and relevance between the training and
application phases; visit classifications were subsequently categorized into
""wellness"" or ""other"" based on majority consensus among validators to assess
the algorithm's performance in identifying wellness visits. The algorithm
demonstrated a specificity of 0.94 (95% CI: 0.91 to 0.96), implying its
accuracy in distinguishing non-wellness visits. The algorithm had a sensitivity
of 0.86 (95% CI: 0.80 to 0.92), indicating its ability to correctly identify
wellness visits as compared to the annotations provided by veterinary experts.
The balanced accuracy, calculated as 0.90 (95% CI: 0.87 to 0.93), further
confirms the algorithm's overall effectiveness. The algorithm exhibits strong
specificity and sensitivity, ensuring accurate identification of a high
proportion of wellness visits. Overall, this algorithm holds promise for
advancing research on preventive care's role in subclinical disease
identification, but prospective studies are needed for validation."
On the Evaluation of Speech Foundation Models for Spoken Language Understanding,https://arxiv.org/abs/2406.10083,2024-06-14,2024-06-19,0.0,0.0,"The Spoken Language Understanding Evaluation (SLUE) suite of benchmark tasks
was recently introduced to address the need for open resources and benchmarking
of complex spoken language understanding (SLU) tasks, including both
classification and sequence generation tasks, on natural speech. The benchmark
has demonstrated preliminary success in using pre-trained speech foundation
models (SFM) for these SLU tasks. However, the community still lacks a
fine-grained understanding of the comparative utility of different SFMs.
Inspired by this, we ask: which SFMs offer the most benefits for these complex
SLU tasks, and what is the most effective approach for incorporating these
SFMs? To answer this, we perform an extensive evaluation of multiple supervised
and self-supervised SFMs using several evaluation protocols: (i) frozen SFMs
with a lightweight prediction head, (ii) frozen SFMs with a complex prediction
head, and (iii) fine-tuned SFMs with a lightweight prediction head. Although
the supervised SFMs are pre-trained on much more speech recognition data (with
labels), they do not always outperform self-supervised SFMs; the latter tend to
perform at least as well as, and sometimes better than, supervised SFMs,
especially on the sequence generation tasks in SLUE. While there is no
universally optimal way of incorporating SFMs, the complex prediction head
gives the best performance for most tasks, although it increases the inference
time. We also introduce an open-source toolkit and performance leaderboard,
SLUE-PERB, for these tasks and modeling strategies."
Localizing Events in Videos with Multimodal Queries,https://arxiv.org/abs/2406.10079,2024-06-14,2024-06-19,0.0,0.0,"Video understanding is a pivotal task in the digital era, yet the dynamic and
multievent nature of videos makes them labor-intensive and computationally
demanding to process. Thus, localizing a specific event given a semantic query
has gained importance in both user-oriented applications like video search and
academic research into video foundation models. A significant limitation in
current research is that semantic queries are typically in natural language
that depicts the semantics of the target event. This setting overlooks the
potential for multimodal semantic queries composed of images and texts. To
address this gap, we introduce a new benchmark, ICQ, for localizing events in
videos with multimodal queries, along with a new evaluation dataset
ICQ-Highlight. Our new benchmark aims to evaluate how well models can localize
an event given a multimodal semantic query that consists of a reference image,
which depicts the event, and a refinement text to adjust the images' semantics.
To systematically benchmark model performance, we include 4 styles of reference
images and 5 types of refinement texts, allowing us to explore model
performance across different domains. We propose 3 adaptation methods that
tailor existing models to our new setting and evaluate 10 SOTA models, ranging
from specialized to large-scale foundation models. We believe this benchmark is
an initial step toward investigating multimodal queries in video event
localization."
D-NPC - Dynamic Neural Point Clouds for Non-Rigid View Synthesis from Monocular Video,https://arxiv.org/abs/2406.10078,2024-06-14,2024-06-19,0.0,0.0,"Dynamic reconstruction and spatiotemporal novel-view synthesis of non-rigidly
deforming scenes recently gained increased attention. While existing work
achieves impressive quality and performance on multi-view or teleporting camera
setups, most methods fail to efficiently and faithfully recover motion and
appearance from casual monocular captures. This paper contributes to the field
by introducing a new method for dynamic novel view synthesis from monocular
video, such as casual smartphone captures.
  Our approach represents the scene as a $\textit{dynamic neural point cloud}$,
an implicit time-conditioned point distribution that encodes local geometry and
appearance in separate hash-encoded neural feature grids for static and dynamic
regions. By sampling a discrete point cloud from our model, we can efficiently
render high-quality novel views using a fast differentiable rasterizer and
neural rendering network. Similar to recent work, we leverage advances in
neural scene analysis by incorporating data-driven priors like monocular depth
estimation and object segmentation to resolve motion and depth ambiguities
originating from the monocular captures. In addition to guiding the
optimization process, we show that these priors can be exploited to explicitly
initialize our scene representation to drastically improve optimization speed
and final image quality. As evidenced by our experimental evaluation, our
dynamic point cloud model not only enables fast optimization and real-time
frame rates for interactive applications, but also achieves competitive image
quality on monocular benchmark sequences.
  Our project page is available at
https://moritzkappel.github.io/projects/dnpc."
Detecting the terminality of speech-turn boundary for spoken interactions in French TV and Radio content,https://arxiv.org/abs/2406.10073,2024-06-14,2024-06-19,0.0,0.0,"Transition Relevance Places are defined as the end of an utterance where the
interlocutor may take the floor without interrupting the current speaker
--i.e., a place where the turn is terminal. Analyzing turn terminality is
useful to study the dynamic of turn-taking in spontaneous conversations. This
paper presents an automatic classification of spoken utterances as Terminal or
Non-Terminal in multi-speaker settings. We compared audio, text, and fusions of
both approaches on a French corpus of TV and Radio extracts annotated with
turn-terminality information at each speaker change. Our models are based on
pre-trained self-supervised representations. We report results for different
fusion strategies and varying context sizes. This study also questions the
problem of performance variability by analyzing the differences in results for
multiple training runs with random initialization. The measured accuracy would
allow the use of these models for large-scale analysis of turn-taking."
TACCO - Task-guided Co-clustering of Clinical Concepts and Patient Visits for Disease Subtyping based on EHR Data,https://arxiv.org/abs/2406.10061,2024-06-14,2024-06-19,0.0,0.0,"The growing availability of well-organized Electronic Health Records (EHR)
data has enabled the development of various machine learning models towards
disease risk prediction. However, existing risk prediction methods overlook the
heterogeneity of complex diseases, failing to model the potential disease
subtypes regarding their corresponding patient visits and clinical concept
subgroups. In this work, we introduce TACCO, a novel framework that jointly
discovers clusters of clinical concepts and patient visits based on a
hypergraph modeling of EHR data. Specifically, we develop a novel
self-supervised co-clustering framework that can be guided by the risk
prediction task of specific diseases. Furthermore, we enhance the hypergraph
model of EHR data with textual embeddings and enforce the alignment between the
clusters of clinical concepts and patient visits through a contrastive
objective. Comprehensive experiments conducted on the public MIMIC-III dataset
and Emory internal CRADLE dataset over the downstream clinical tasks of
phenotype classification and cardiovascular risk prediction demonstrate an
average 31.25% performance improvement compared to traditional ML baselines and
a 5.26% improvement on top of the vanilla hypergraph model without our
co-clustering mechanism. In-depth model analysis, clustering results analysis,
and clinical case studies further validate the improved utilities and
insightful interpretations delivered by TACCO. Code is available at
https://github.com/PericlesHat/TACCO."
PRIMER - Perception-Aware Robust Learning-based Multiagent Trajectory Planner,https://arxiv.org/abs/2406.10060,2024-06-14,2024-06-19,0.0,0.0,"In decentralized multiagent trajectory planners, agents need to communicate
and exchange their positions to generate collision-free trajectories. However,
due to localization errors/uncertainties, trajectory deconfliction can fail
even if trajectories are perfectly shared between agents. To address this
issue, we first present PARM and PARM*, perception-aware, decentralized,
asynchronous multiagent trajectory planners that enable a team of agents to
navigate uncertain environments while deconflicting trajectories and avoiding
obstacles using perception information. PARM* differs from PARM as it is less
conservative, using more computation to find closer-to-optimal solutions. While
these methods achieve state-of-the-art performance, they suffer from high
computational costs as they need to solve large optimization problems onboard,
making it difficult for agents to replan at high rates. To overcome this
challenge, we present our second key contribution, PRIMER, a learning-based
planner trained with imitation learning (IL) using PARM* as the expert
demonstrator. PRIMER leverages the low computational requirements at deployment
of neural networks and achieves a computation speed up to 5500 times faster
than optimization-based approaches."
First Multi-Dimensional Evaluation of Flowchart Comprehension for Multimodal Large Language Models,https://arxiv.org/abs/2406.10057,2024-06-14,2024-06-19,0.0,0.0,"With the development of Multimodal Large Language Models (MLLMs) technology,
its general capabilities are increasingly powerful. To evaluate the various
abilities of MLLMs, numerous evaluation systems have emerged. But now there is
still a lack of a comprehensive method to evaluate MLLMs in the tasks related
to flowcharts, which are very important in daily life and work. We propose the
first comprehensive method, FlowCE, to assess MLLMs across various dimensions
for tasks related to flowcharts. It encompasses evaluating MLLMs' abilities in
Reasoning, Localization Recognition, Information Extraction, Logical
Verification, and Summarization on flowcharts. However, we find that even the
GPT4o model achieves only a score of 56.63. Among open-source models,
Phi-3-Vision obtained the highest score of 49.97. We hope that FlowCE can
contribute to future research on MLLMs for tasks based on flowcharts.
\url{https://github.com/360AILAB-NLP/FlowCE} \end{abstract}"
Simul-Whisper - Attention-Guided Streaming Whisper with Truncation Detection,https://arxiv.org/abs/2406.10052,2024-06-14,2024-06-19,0.0,0.0,"As a robust and large-scale multilingual speech recognition model, Whisper
has demonstrated impressive results in many low-resource and
out-of-distribution scenarios. However, its encoder-decoder structure hinders
its application to streaming speech recognition. In this paper, we introduce
Simul-Whisper, which uses the time alignment embedded in Whisper's
cross-attention to guide auto-regressive decoding and achieve chunk-based
streaming ASR without any fine-tuning of the pre-trained model. Furthermore, we
observe the negative effect of the truncated words at the chunk boundaries on
the decoding results and propose an integrate-and-fire-based truncation
detection model to address this issue. Experiments on multiple languages and
Whisper architectures show that Simul-Whisper achieves an average absolute word
error rate degradation of only 1.46% at a chunk size of 1 second, which
significantly outperforms the current state-of-the-art baseline."
Comparison of fine-tuning strategies for transfer learning in medical image classification,https://arxiv.org/abs/2406.10050,2024-06-14,2024-06-19,0.0,0.0,"In the context of medical imaging and machine learning, one of the most
pressing challenges is the effective adaptation of pre-trained models to
specialized medical contexts. Despite the availability of advanced pre-trained
models, their direct application to the highly specialized and diverse field of
medical imaging often falls short due to the unique characteristics of medical
data. This study provides a comprehensive analysis on the performance of
various fine-tuning methods applied to pre-trained models across a spectrum of
medical imaging domains, including X-ray, MRI, Histology, Dermoscopy, and
Endoscopic surgery. We evaluated eight fine-tuning strategies, including
standard techniques such as fine-tuning all layers or fine-tuning only the
classifier layers, alongside methods such as gradually unfreezing layers,
regularization based fine-tuning and adaptive learning rates. We selected three
well-established CNN architectures (ResNet-50, DenseNet-121, and VGG-19) to
cover a range of learning and feature extraction scenarios. Although our
results indicate that the efficacy of these fine-tuning methods significantly
varies depending on both the architecture and the medical imaging type,
strategies such as combining Linear Probing with Full Fine-tuning resulted in
notable improvements in over 50% of the evaluated cases, demonstrating general
effectiveness across medical domains. Moreover, Auto-RGN, which dynamically
adjusts learning rates, led to performance enhancements of up to 11% for
specific modalities. Additionally, the DenseNet architecture showed more
pronounced benefits from alternative fine-tuning approaches compared to
traditional full fine-tuning. This work not only provides valuable insights for
optimizing pre-trained models in medical image analysis but also suggests the
potential for future research into more advanced architectures and fine-tuning
methods."
FZI-WIM at SemEval-2024 Task 2 - Self-Consistent CoT for Complex NLI in Biomedical Domain,https://arxiv.org/abs/2406.10040,2024-06-14,2024-06-19,0.0,0.0,"This paper describes the inference system of FZI-WIM at the SemEval-2024 Task
2: Safe Biomedical Natural Language Inference for Clinical Trials. Our system
utilizes the chain of thought (CoT) paradigm to tackle this complex reasoning
problem and further improves the CoT performance with self-consistency. Instead
of greedy decoding, we sample multiple reasoning chains with the same prompt
and make the final verification with majority voting. The self-consistent CoT
system achieves a baseline F1 score of 0.80 (1st), faithfulness score of 0.90
(3rd), and consistency score of 0.73 (12th). We release the code and data
publicly https://github.com/jens5588/FZI-WIM-NLI4CT."
Towards Effective and Efficient Non-autoregressive Decoding Using Block-based Attention Mask,https://arxiv.org/abs/2406.10034,2024-06-14,2024-06-19,0.0,0.0,"This paper proposes a novel non-autoregressive (NAR) block-based Attention
Mask Decoder (AMD) that flexibly balances performance-efficiency trade-offs for
Conformer ASR systems. AMD performs parallel NAR inference within contiguous
blocks of output labels that are concealed using attention masks, while
conducting left-to-right AR prediction and history context amalgamation between
blocks. A beam search algorithm is designed to leverage a dynamic fusion of
CTC, AR Decoder, and AMD probabilities. Experiments on the LibriSpeech-100hr
corpus suggest the tripartite Decoder incorporating the AMD module produces a
maximum decoding speed-up ratio of 1.73x over the baseline CTC+AR decoding,
while incurring no statistically significant word error rate (WER) increase on
the test sets. When operating with the same decoding real time factors,
statistically significant WER reductions of up to 0.7% and 0.3% absolute (5.3%
and 6.1% relative) were obtained over the CTC+AR baseline."
Intepretative Deep Learning using Domain Adaptation for Fluorescence Spectroscopy,https://arxiv.org/abs/2406.10031,2024-06-14,2024-06-19,0.0,0.0,"Fluorescence spectroscopy is a fundamental tool in life sciences and
chemistry, widely used for applications such as environmental monitoring, food
quality control, and biomedical diagnostics. However, analysis of spectroscopic
data with deep learning, in particular of fluorescence excitation-emission
matrices (EEMs), presents significant challenges due to the typically small and
sparse datasets available. Furthermore, the analysis of EEMs is difficult due
to their high dimensionality and overlapping spectral features. This study
proposes a new approach that exploits domain adaptation with pretrained vision
models, alongside a novel interpretability algorithm to address these
challenges. Thanks to specialised feature engineering of the neural networks
described in this work, we are now able to provide deeper insights into the
physico-chemical processes underlying the data. The proposed approach is
demonstrated through the analysis of the oxidation process in extra virgin
olive oil (EVOO) during ageing, showing its effectiveness in predicting quality
indicators and identifying the spectral bands, and thus the molecules involved
in the process. This work describes a significantly innovative approach in the
use of deep learning for spectroscopy, transforming it from a black box into a
tool for understanding complex biological and chemical processes."
Off-Policy Evaluation from Logged Human Feedback,https://arxiv.org/abs/2406.10030,2024-06-14,2024-06-19,0.0,0.0,"Learning from human feedback has been central to recent advances in
artificial intelligence and machine learning. Since the collection of human
feedback is costly, a natural question to ask is if the new feedback always
needs to collected. Or could we evaluate a new model with the human feedback on
responses of another model? This motivates us to study off-policy evaluation
from logged human feedback. We formalize the problem, propose both model-based
and model-free estimators for policy values, and show how to optimize them. We
analyze unbiasedness of our estimators and evaluate them empirically. Our
estimators can predict the absolute values of evaluated policies, rank them,
and be optimized."
ProtoS-ViT - Visual foundation models for sparse self-explainable classifications,https://arxiv.org/abs/2406.10025,2024-06-14,2024-06-19,0.0,0.0,"Prototypical networks aim to build intrinsically explainable models based on
the linear summation of concepts. However, important challenges remain in the
transparency, compactness, and meaningfulness of the explanations provided by
these models. This work demonstrates how frozen pre-trained ViT backbones can
be effectively turned into prototypical models for both general and
domain-specific tasks, in our case biomedical image classifiers. By leveraging
strong spatial features combined with a novel prototypical head, ProtoS-ViT
surpasses existing prototypical models showing strong performance in terms of
accuracy, compactness, and explainability. Model explainability is evaluated
through an extensive set of quantitative and qualitative metrics which serve as
a general benchmark for the development of prototypical models. Code is
available at https://github.com/hturbe/protosvit."
Deep Bayesian Active Learning for Preference Modeling in Large Language Models,https://arxiv.org/abs/2406.10023,2024-06-14,2024-06-19,0.0,0.0,"Leveraging human preferences for steering the behavior of Large Language
Models (LLMs) has demonstrated notable success in recent years. Nonetheless,
data selection and labeling are still a bottleneck for these systems,
particularly at large scale. Hence, selecting the most informative points for
acquiring human feedback may considerably reduce the cost of preference
labeling and unleash the further development of LLMs. Bayesian Active Learning
provides a principled framework for addressing this challenge and has
demonstrated remarkable success in diverse settings. However, previous attempts
to employ it for Preference Modeling did not meet such expectations. In this
work, we identify that naive epistemic uncertainty estimation leads to the
acquisition of redundant samples. We address this by proposing the Bayesian
Active Learner for Preference Modeling (BAL-PM), a novel stochastic acquisition
policy that not only targets points of high epistemic uncertainty according to
the preference model but also seeks to maximize the entropy of the acquired
prompt distribution in the feature space spanned by the employed LLM. Notably,
our experiments demonstrate that BAL-PM requires 33% to 68% fewer preference
labels in two popular human preference datasets and exceeds previous stochastic
Bayesian acquisition policies."
Group and Shuffle - Efficient Structured Orthogonal Parametrization,https://arxiv.org/abs/2406.10019,2024-06-14,2024-06-19,0.0,0.0,"The increasing size of neural networks has led to a growing demand for
methods of efficient fine-tuning. Recently, an orthogonal fine-tuning paradigm
was introduced that uses orthogonal matrices for adapting the weights of a
pretrained model. In this paper, we introduce a new class of structured
matrices, which unifies and generalizes structured classes from previous works.
We examine properties of this class and build a structured orthogonal
parametrization upon it. We then use this parametrization to modify the
orthogonal fine-tuning framework, improving parameter and computational
efficiency. We empirically validate our method on different domains, including
adapting of text-to-image diffusion models and downstream task fine-tuning in
language modeling. Additionally, we adapt our construction for orthogonal
convolutions and conduct experiments with 1-Lipschitz neural networks."
Tilt and Average  - Geometric Adjustment of the Last Layer for Recalibration,https://arxiv.org/abs/2406.10017,2024-06-14,2024-06-19,0.0,0.0,"After the revelation that neural networks tend to produce overconfident
predictions, the problem of calibration, which aims to align confidence with
accuracy to enhance the reliability of predictions, has gained significant
importance. Several solutions based on calibration maps have been proposed to
address the problem of recalibrating a trained classifier using additional
datasets. In this paper, we offer an algorithm that transforms the weights of
the last layer of the classifier, distinct from the calibration-map-based
approach. We concentrate on the geometry of the final linear layer,
specifically its angular aspect, and adjust the weights of the corresponding
layer. We name the method Tilt and Average(\textsc{Tna}), and validate the
calibration effect empirically and theoretically. Through this, we demonstrate
that our approach, in addition to the existing calibration-map-based
techniques, can yield improved calibration performance. Code available :
https://github.com/GYYYYYUUUUU/TNA_Angular_Scaling."
Gradient-based Learning in State-based Potential Games for Self-Learning Production Systems,https://arxiv.org/abs/2406.10015,2024-06-14,2024-06-19,0.0,0.0,"In this paper, we introduce novel gradient-based optimization methods for
state-based potential games (SbPGs) within self-learning distributed production
systems. SbPGs are recognised for their efficacy in enabling self-optimizing
distributed multi-agent systems and offer a proven convergence guarantee, which
facilitates collaborative player efforts towards global objectives. Our study
strives to replace conventional ad-hoc random exploration-based learning in
SbPGs with contemporary gradient-based approaches, which aim for faster
convergence and smoother exploration dynamics, thereby shortening training
duration while upholding the efficacy of SbPGs. Moreover, we propose three
distinct variants for estimating the objective function of gradient-based
learning, each developed to suit the unique characteristics of the systems
under consideration. To validate our methodology, we apply it to a laboratory
testbed, namely Bulk Good Laboratory Plant, which represents a smart and
flexible distributed multi-agent production system. The incorporation of
gradient-based learning in SbPGs reduces training times and achieves more
optimal policies than its baseline."
Beyond Slow Signs in High-fidelity Model Extraction,https://arxiv.org/abs/2406.10011,2024-06-14,2024-06-19,0.0,0.0,"Deep neural networks, costly to train and rich in intellectual property
value, are increasingly threatened by model extraction attacks that compromise
their confidentiality. Previous attacks have succeeded in reverse-engineering
model parameters up to a precision of float64 for models trained on random data
with at most three hidden layers using cryptanalytical techniques. However, the
process was identified to be very time consuming and not feasible for larger
and deeper models trained on standard benchmarks. Our study evaluates the
feasibility of parameter extraction methods of Carlini et al. [1] further
enhanced by Canales-Mart\'inez et al. [2] for models trained on standard
benchmarks. We introduce a unified codebase that integrates previous methods
and reveal that computational tools can significantly influence performance. We
develop further optimisations to the end-to-end attack and improve the
efficiency of extracting weight signs by up to 14.8 times compared to former
methods through the identification of easier and harder to extract neurons.
Contrary to prior assumptions, we identify extraction of weights, not
extraction of weight signs, as the critical bottleneck. With our improvements,
a 16,721 parameter model with 2 hidden layers trained on MNIST is extracted
within only 98 minutes compared to at least 150 minutes previously. Finally,
addressing methodological deficiencies observed in previous studies, we propose
new ways of robust benchmarking for future model extraction attacks."
An elementary proof of a universal approximation theorem,https://arxiv.org/abs/2406.10002,2024-06-14,2024-06-19,0.0,0.0,"In this short note, we give an elementary proof of a universal approximation
theorem for neural networks with three hidden layers and increasing,
continuous, bounded activation function. The result is weaker than the best
known results, but the proof is elementary in the sense that no machinery
beyond undergraduate analysis is used."
Understanding Pedestrian Movement Using Urban Sensing Technologies - The Promise of Audio-based Sensors,https://arxiv.org/abs/2406.09998,2024-06-14,2024-06-19,0.0,0.0,"While various sensors have been deployed to monitor vehicular flows, sensing
pedestrian movement is still nascent. Yet walking is a significant mode of
travel in many cities, especially those in Europe, Africa, and Asia.
Understanding pedestrian volumes and flows is essential for designing safer and
more attractive pedestrian infrastructure and for controlling periodic
overcrowding. This study discusses a new approach to scale up urban sensing of
people with the help of novel audio-based technology. It assesses the benefits
and limitations of microphone-based sensors as compared to other forms of
pedestrian sensing. A large-scale dataset called ASPED is presented, which
includes high-quality audio recordings along with video recordings used for
labeling the pedestrian count data. The baseline analyses highlight the promise
of using audio sensors for pedestrian tracking, although algorithmic and
technological improvements to make the sensors practically usable continue.
This study also demonstrates how the data can be leveraged to predict
pedestrian trajectories. Finally, it discusses the use cases and scenarios
where audio-based pedestrian sensing can support better urban and
transportation planning."
Towards Scalable and Versatile Weight Space Learning,https://arxiv.org/abs/2406.09997,2024-06-14,2024-06-19,0.0,0.0,"Learning representations of well-trained neural network models holds the
promise to provide an understanding of the inner workings of those models.
However, previous work has either faced limitations when processing larger
networks or was task-specific to either discriminative or generative tasks.
This paper introduces the SANE approach to weight-space learning. SANE
overcomes previous limitations by learning task-agnostic representations of
neural networks that are scalable to larger models of varying architectures and
that show capabilities beyond a single task. Our method extends the idea of
hyper-representations towards sequential processing of subsets of neural
network weights, thus allowing one to embed larger neural networks as a set of
tokens into the learned representation space. SANE reveals global model
information from layer-wise embeddings, and it can sequentially generate unseen
neural network models, which was unattainable with previous
hyper-representation learning methods. Extensive empirical evaluation
demonstrates that SANE matches or exceeds state-of-the-art performance on
several weight representation learning benchmarks, particularly in
initialization for new tasks and larger ResNet architectures."
"Precision Empowers, Excess Distracts - Visual Question Answering With Dynamically Infused Knowledge In Language Models",https://arxiv.org/abs/2406.09994,2024-06-14,2024-06-19,0.0,0.0,"In the realm of multimodal tasks, Visual Question Answering (VQA) plays a
crucial role by addressing natural language questions grounded in visual
content. Knowledge-Based Visual Question Answering (KBVQA) advances this
concept by adding external knowledge along with images to respond to questions.
We introduce an approach for KBVQA, augmenting the existing vision-language
transformer encoder-decoder (OFA) model. Our main contribution involves
enhancing questions by incorporating relevant external knowledge extracted from
knowledge graphs, using a dynamic triple extraction method. We supply a
flexible number of triples from the knowledge graph as context, tailored to
meet the requirements for answering the question. Our model, enriched with
knowledge, demonstrates an average improvement of 4.75\% in Exact Match Score
over the state-of-the-art on three different KBVQA datasets. Through
experiments and analysis, we demonstrate that furnishing variable triples for
each question improves the reasoning capabilities of the language model in
contrast to supplying a fixed number of triples. This is illustrated even for
recent large language models. Additionally, we highlight the model's
generalization capability by showcasing its SOTA-beating performance on a small
dataset, achieved through straightforward fine-tuning."
Details Make a Difference - Object State-Sensitive Neurorobotic Task Planning,https://arxiv.org/abs/2406.09988,2024-06-14,2024-06-19,0.0,0.0,"The state of an object reflects its current status or condition and is
important for a robot's task planning and manipulation. However, detecting an
object's state and generating a state-sensitive plan for robots is challenging.
Recently, pre-trained Large Language Models (LLMs) and Vision-Language Models
(VLMs) have shown impressive capabilities in generating plans. However, to the
best of our knowledge, there is hardly any investigation on whether LLMs or
VLMs can also generate object state-sensitive plans. To study this, we
introduce an Object State-Sensitive Agent (OSSA), a task-planning agent
empowered by pre-trained neural networks. We propose two methods for OSSA: (i)
a modular model consisting of a pre-trained vision processing module (dense
captioning model, DCM) and a natural language processing model (LLM), and (ii)
a monolithic model consisting only of a VLM. To quantitatively evaluate the
performances of the two methods, we use tabletop scenarios where the task is to
clear the table. We contribute a multimodal benchmark dataset that takes object
states into consideration. Our results show that both methods can be used for
object state-sensitive tasks, but the monolithic approach outperforms the
modular approach. The code for OSSA is available at
\url{https://github.com/Xiao-wen-Sun/OSSA}"
CNVSRC 2023 - The First Chinese Continuous Visual Speech Recognition Challenge,https://arxiv.org/abs/2406.10313,2024-06-14,2024-06-19,0.0,0.0,"The first Chinese Continuous Visual Speech Recognition Challenge aimed to
probe the performance of Large Vocabulary Continuous Visual Speech Recognition
(LVC-VSR) on two tasks: (1) Single-speaker VSR for a particular speaker and (2)
Multi-speaker VSR for a set of registered speakers. The challenge yielded
highly successful results, with the best submission significantly outperforming
the baseline, particularly in the single-speaker task. This paper
comprehensively reviews the challenge, encompassing the data profile, task
specifications, and baseline system construction. It also summarises the
representative techniques employed by the submitted systems, highlighting the
most effective approaches. Additional information and resources about this
challenge can be accessed through the official website at
http://cnceleb.org/competition."
HIRO - Hierarchical Information Retrieval Optimization,https://arxiv.org/abs/2406.09979,2024-06-14,2024-06-19,0.0,0.0,"Retrieval-Augmented Generation (RAG) has revolutionized natural language
processing by dynamically integrating external knowledge into Large Language
Models (LLMs), addressing their limitation of static training datasets. Recent
implementations of RAG leverage hierarchical data structures, which organize
documents at various levels of summarization and information density. This
complexity, however, can cause LLMs to ""choke"" on information overload,
necessitating more sophisticated querying mechanisms. In this context, we
introduce Hierarchical Information Retrieval Optimization (HIRO), a novel
querying approach that employs a Depth-First Search (DFS)-based recursive
similarity score calculation and branch pruning. This method uniquely minimizes
the context delivered to the LLM without informational loss, effectively
managing the challenge of excessive data. HIRO's refined approach is validated
by a 10.85% improvement in performance on the NarrativeQA dataset."
Disentangling Dialect from Social Bias via Multitask Learning to Improve Fairness,https://arxiv.org/abs/2406.09977,2024-06-14,2024-06-19,0.0,0.0,"Dialects introduce syntactic and lexical variations in language that occur in
regional or social groups. Most NLP methods are not sensitive to such
variations. This may lead to unfair behavior of the methods, conveying negative
bias towards dialect speakers. While previous work has studied dialect-related
fairness for aspects like hate speech, other aspects of biased language, such
as lewdness, remain fully unexplored. To fill this gap, we investigate
performance disparities between dialects in the detection of five aspects of
biased language and how to mitigate them. To alleviate bias, we present a
multitask learning approach that models dialect language as an auxiliary task
to incorporate syntactic and lexical variations. In our experiments with
African-American English dialect, we provide empirical evidence that
complementing common learning approaches with dialect modeling improves their
fairness. Furthermore, the results suggest that multitask learning achieves
state-of-the-art performance and helps to detect properties of biased language
more reliably."
In-depth analysis of recall initiators of medical devices with a Machine Learning-Natural language Processing workflow,https://arxiv.org/abs/2406.10312,2024-06-14,2024-06-19,0.0,0.0,"Recall initiator identification and assessment are the preliminary steps to
prevent medical device recall. Conventional analysis tools are inappropriate
for processing massive and multi-formatted data comprehensively and completely
to meet the higher expectations of delicacy management with the increasing
overall data volume and textual data format. This study presents a
bigdata-analytics-based machine learning-natural language processing work tool
to address the shortcomings in dealing efficiency and data process versatility
of conventional tools in the practical context of big data volume and muti data
format. This study identified, assessed and analysed the medical device recall
initiators according to the public medical device recall database from 2018 to
2024 with the ML-NLP tool. The results suggest that the unsupervised
Density-Based Spatial Clustering of Applications with Noise (DBSCAN) clustering
algorithm can present each single recall initiator in a specific manner,
therefore helping practitioners to identify the recall reasons comprehensively
and completely within a short time frame. This is then followed by text
similarity-based textual classification to assist practitioners in controlling
the group size of recall initiators and provide managerial insights from the
operational to the tactical and strategical levels. This ML-NLP work tool can
not only capture specific details of each recall initiator but also interpret
the inner connection of each existing initiator and can be implemented for risk
identification and assessment in the forward SC. Finally, this paper suggests
some concluding remarks and presents future works. More proactive practices and
control solutions for medical device recalls are expected in the future."
Robust Model-Based Reinforcement Learning with an Adversarial Auxiliary Model,https://arxiv.org/abs/2406.09976,2024-06-14,2024-06-19,0.0,0.0,"Reinforcement learning has demonstrated impressive performance in various
challenging problems such as robotics, board games, and classical arcade games.
However, its real-world applications can be hindered by the absence of
robustness and safety in the learned policies. More specifically, an RL agent
that trains in a certain Markov decision process (MDP) often struggles to
perform well in nearly identical MDPs. To address this issue, we employ the
framework of Robust MDPs (RMDPs) in a model-based setting and introduce a novel
learned transition model. Our method specifically incorporates an auxiliary
pessimistic model, updated adversarially, to estimate the worst-case MDP within
a Kullback-Leibler uncertainty set. In comparison to several existing works,
our work does not impose any additional conditions on the training environment,
such as the need for a parametric simulator. To test the effectiveness of the
proposed pessimistic model in enhancing policy robustness, we integrate it into
a practical RL algorithm, called Robust Model-Based Policy Optimization
(RMBPO). Our experimental results indicate a notable improvement in policy
robustness on high-dimensional MuJoCo control tasks, with the auxiliary model
enhancing the performance of the learned policy in distorted MDPs. We further
explore the learned deviation between the proposed auxiliary world model and
the nominal model, to examine how pessimism is achieved. By learning a
pessimistic world model and demonstrating its role in improving policy
robustness, our research contributes towards making (model-based) RL more
robust."
A Better LLM Evaluator for Text Generation - The Impact of Prompt Output Sequencing and Optimization,https://arxiv.org/abs/2406.09972,2024-06-14,2024-06-19,0.0,0.0,"This research investigates prompt designs of evaluating generated texts using
large language models (LLMs). While LLMs are increasingly used for scoring
various inputs, creating effective prompts for open-ended text evaluation
remains challenging due to model sensitivity and subjectivity in evaluation of
text generation. Our study experimented with different prompt structures,
altering the sequence of output instructions and including explanatory reasons.
We found that the order of presenting reasons and scores significantly
influences LLMs' scoring, with a different level of rule understanding in the
prompt. An additional optimization may enhance scoring alignment if sufficient
data is available. This insight is crucial for improving the accuracy and
consistency of LLM-based evaluations."
Impact of Speech Mode in Automatic Pathological Speech Detection,https://arxiv.org/abs/2406.09968,2024-06-14,2024-06-19,0.0,0.0,"Automatic pathological speech detection approaches yield promising results in
identifying various pathologies. These approaches are typically designed and
evaluated for phonetically-controlled speech scenarios, where speakers are
prompted to articulate identical phonetic content. While gathering controlled
speech recordings can be laborious, spontaneous speech can be conveniently
acquired as potential patients navigate their daily routines. Further,
spontaneous speech can be valuable in detecting subtle and abstract cues of
pathological speech. Nonetheless, the efficacy of automatic pathological speech
detection for spontaneous speech remains unexplored. This paper analyzes the
influence of speech mode on pathological speech detection approaches, examining
two distinct categories of approaches, i.e., classical machine learning and
deep learning. Results indicate that classical approaches may struggle to
capture pathology-discriminant cues in spontaneous speech. In contrast, deep
learning approaches demonstrate superior performance, managing to extract
additional cues that were previously inaccessible in non-spontaneous speech"
Bag of Lies - Robustness in Continuous Pre-training BERT,https://arxiv.org/abs/2406.09967,2024-06-14,2024-06-19,0.0,0.0,"This study aims to acquire more insights into the continuous pre-training
phase of BERT regarding entity knowledge, using the COVID-19 pandemic as a case
study. Since the pandemic emerged after the last update of BERT's pre-training
data, the model has little to no entity knowledge about COVID-19. Using
continuous pre-training, we control what entity knowledge is available to the
model. We compare the baseline BERT model with the further pre-trained variants
on the fact-checking benchmark Check-COVID. To test the robustness of
continuous pre-training, we experiment with several adversarial methods to
manipulate the input data, such as training on misinformation and shuffling the
word order until the input becomes nonsensical. Surprisingly, our findings
reveal that these methods do not degrade, and sometimes even improve, the
model's downstream performance. This suggests that continuous pre-training of
BERT is robust against misinformation. Furthermore, we are releasing a new
dataset, consisting of original texts from academic publications in the
LitCovid repository and their AI-generated false counterparts."
Outlier detection in maritime environments using AIS data and deep recurrent architectures,https://arxiv.org/abs/2406.09966,2024-06-14,2024-06-19,0.0,0.0,"A methodology based on deep recurrent models for maritime surveillance, over
publicly available Automatic Identification System (AIS) data, is presented in
this paper. The setup employs a deep Recurrent Neural Network (RNN)-based
model, for encoding and reconstructing the observed ships' motion patterns. Our
approach is based on a thresholding mechanism, over the calculated errors
between observed and reconstructed motion patterns of maritime vessels.
Specifically, a deep-learning framework, i.e. an encoder-decoder architecture,
is trained using the observed motion patterns, enabling the models to learn and
predict the expected trajectory, which will be compared to the effective ones.
Our models, particularly the bidirectional GRU with recurrent dropouts,
showcased superior performance in capturing the temporal dynamics of maritime
data, illustrating the potential of deep learning to enhance maritime
surveillance capabilities. Our work lays a solid foundation for future research
in this domain, highlighting a path toward improved maritime safety through the
innovative application of technology."
ChartMimic - Evaluating LMM's Cross-Modal Reasoning Capability via Chart-to-Code Generation,https://arxiv.org/abs/2406.09961,2024-06-14,2024-06-19,0.0,0.0,"We introduce a new benchmark, ChartMimic, aimed at assessing the
visually-grounded code generation capabilities of large multimodal models
(LMMs). ChartMimic utilizes information-intensive visual charts and textual
instructions as inputs, requiring LMMs to generate the corresponding code for
chart rendering. ChartMimic includes 1,000 human-curated (figure, instruction,
code) triplets, which represent the authentic chart use cases found in
scientific papers across various domains(e.g., Physics, Computer Science,
Economics, etc). These charts span 18 regular types and 4 advanced types,
diversifying into 191 subcategories. Furthermore, we propose multi-level
evaluation metrics to provide an automatic and thorough assessment of the
output code and the rendered charts. Unlike existing code generation
benchmarks, ChartMimic places emphasis on evaluating LMMs' capacity to
harmonize a blend of cognitive capabilities, encompassing visual understanding,
code generation, and cross-modal reasoning. The evaluation of 3 proprietary
models and 11 open-weight models highlights the substantial challenges posed by
ChartMimic. Even the advanced GPT-4V, Claude-3-opus only achieve an average
score of 73.2 and 53.7, respectively, indicating significant room for
improvement. We anticipate that ChartMimic will inspire the development of
LMMs, advancing the pursuit of artificial general intelligence."
H-Fac - Memory-Efficient Optimization with Factorized Hamiltonian Descent,https://arxiv.org/abs/2406.09958,2024-06-14,2024-06-19,0.0,0.0,"In this study, we introduce a novel adaptive optimizer, H-Fac, which
incorporates a factorized approach to momentum and scaling parameters. Our
algorithm demonstrates competitive performances on both ResNets and Vision
Transformers, while achieving sublinear memory costs through the use of rank-1
parameterizations for moment estimators. We develop our algorithms based on
principles derived from Hamiltonian dynamics, providing robust theoretical
underpinnings. These optimization algorithms are designed to be both
straightforward and adaptable, facilitating easy implementation in diverse
settings."
Rule Based Learning with Dynamic (Graph) Neural Networks,https://arxiv.org/abs/2406.09954,2024-06-14,2024-06-19,0.0,0.0,"A common problem of classical neural network architectures is that additional
information or expert knowledge cannot be naturally integrated into the
learning process. To overcome this limitation, we propose a two-step approach
consisting of (1) generating rule functions from knowledge and (2) using these
rules to define rule based layers -- a new type of dynamic neural network
layer. The focus of this work is on the second step, i.e., rule based layers
that are designed to dynamically arrange learnable parameters in the weight
matrices and bias vectors depending on the input samples. Indeed, we prove that
our approach generalizes classical feed-forward layers such as fully connected
and convolutional layers by choosing appropriate rules. As a concrete
application we present rule based graph neural networks (RuleGNNs) that
overcome some limitations of ordinary graph neural networks. Our experiments
show that the predictive performance of RuleGNNs is comparable to
state-of-the-art graph classifiers using simple rules based on Weisfeiler-Leman
labeling and pattern counting. Moreover, we introduce new synthetic benchmark
graph datasets to show how to integrate expert knowledge into RuleGNNs making
them more powerful than ordinary graph neural networks."
DAG-Plan - Generating Directed Acyclic Dependency Graphs for Dual-Arm Cooperative Planning,https://arxiv.org/abs/2406.09953,2024-06-14,2024-06-19,0.0,0.0,"Dual-arm robots offer enhanced versatility and efficiency over single-arm
counterparts by enabling concurrent manipulation of multiple objects or
cooperative execution of tasks using both arms. However, effectively
coordinating the two arms for complex long-horizon tasks remains a significant
challenge. Existing task planning methods predominantly focus on single-arm
robots or rely on predefined bimanual operations, failing to fully leverage the
capabilities of dual-arm systems. To address this limitation, we introduce
DAG-Plan, a structured task planning framework tailored for dual-arm robots.
DAG-Plan harnesses large language models (LLMs) to decompose intricate tasks
into actionable sub-tasks represented as nodes within a directed acyclic graph
(DAG). Critically, DAG-Plan dynamically assigns these sub-tasks to the
appropriate arm based on real-time environmental observations, enabling
parallel and adaptive execution. We evaluate DAG-Plan on the novel Dual-Arm
Kitchen Benchmark, comprising 9 sequential tasks with 78 sub-tasks and 26
objects. Extensive experiments demonstrate the superiority of DAG-Plan over
directly using LLM to generate plans, achieving nearly 50% higher efficiency
compared to the single-arm task planning baseline and nearly double the success
rate of the dual-arm task planning baseline."
BiVLC - Extending Vision-Language Compositionality Evaluation with Text-to-Image Retrieval,https://arxiv.org/abs/2406.09952,2024-06-14,2024-06-19,0.0,0.0,"Existing Vision-Language Compositionality (VLC) benchmarks like SugarCrepe
are formulated as image-to-text retrieval problems, where, given an image, the
models need to select between the correct textual description and a synthetic
hard negative text. In this work we present the Bidirectional Vision-Language
Compositionality (BiVLC) dataset. The novelty of BiVLC is to add a synthetic
hard negative image generated from the synthetic text, resulting in two
image-to-text retrieval examples (one for each image) and, more importantly,
two text-to-image retrieval examples (one for each text). Human annotators
filter out ill-formed examples ensuring the validity of the benchmark. The
experiments on BiVLC uncover a weakness of current multimodal models, as they
perform poorly in the text-to-image direction. In fact, when considering both
retrieval directions, the conclusions obtained in previous works change
significantly. In addition to the benchmark, we show that a contrastive model
trained using synthetic images and texts improves the state of the art in
SugarCrepe and in BiVLC for both retrieval directions. The gap to human
performance in BiVLC confirms that Vision-Language Compositionality is still a
challenging problem. BiVLC and code are available at
https://imirandam.github.io/BiVLC_project_page."
An efficient text augmentation approach for contextualized Mandarin speech recognition,https://arxiv.org/abs/2406.09950,2024-06-14,2024-06-19,0.0,0.0,"Although contextualized automatic speech recognition (ASR) systems are
commonly used to improve the recognition of uncommon words, their effectiveness
is hindered by the inherent limitations of speech-text data availability. To
address this challenge, our study proposes to leverage extensive text-only
datasets and contextualize pre-trained ASR models using a straightforward
text-augmentation (TA) technique, all while keeping computational costs
minimal. In particular, to contextualize a pre-trained CIF-based ASR, we
construct a codebook using limited speech-text data. By utilizing a simple
codebook lookup process, we convert available text-only data into latent text
embeddings. These embeddings then enhance the inputs for the contextualized
ASR. Our experiments on diverse Mandarin test sets demonstrate that our TA
approach significantly boosts recognition performance. The top-performing
system shows relative CER improvements of up to 30% on rare words and 15%
across all words in general."
Neural Concept Binder,https://arxiv.org/abs/2406.09949,2024-06-14,2024-06-19,0.0,0.0,"The challenge in object-based visual reasoning lies in generating descriptive
yet distinct concept representations. Moreover, doing this in an unsupervised
fashion requires human users to understand a model's learned concepts and
potentially revise false concepts. In addressing this challenge, we introduce
the Neural Concept Binder, a new framework for deriving discrete concept
representations resulting in what we term ""concept-slot encodings"". These
encodings leverage both ""soft binding"" via object-centric block-slot encodings
and ""hard binding"" via retrieval-based inference. The Neural Concept Binder
facilitates straightforward concept inspection and direct integration of
external knowledge, such as human input or insights from other AI models like
GPT-4. Additionally, we demonstrate that incorporating the hard binding
mechanism does not compromise performance; instead, it enables seamless
integration into both neural and symbolic modules for intricate reasoning
tasks, as evidenced by evaluations on our newly introduced CLEVR-Sudoku
dataset."
Finite-Time Analysis of Simultaneous Double Q-learning,https://arxiv.org/abs/2406.09946,2024-06-14,2024-06-19,0.0,0.0,"$Q$-learning is one of the most fundamental reinforcement learning (RL)
algorithms. Despite its widespread success in various applications, it is prone
to overestimation bias in the $Q$-learning update. To address this issue,
double $Q$-learning employs two independent $Q$-estimators which are randomly
selected and updated during the learning process. This paper proposes a
modified double $Q$-learning, called simultaneous double $Q$-learning (SDQ),
with its finite-time analysis. SDQ eliminates the need for random selection
between the two $Q$-estimators, and this modification allows us to analyze
double $Q$-learning through the lens of a novel switching system framework
facilitating efficient finite-time analysis. Empirical studies demonstrate that
SDQ converges faster than double $Q$-learning while retaining the ability to
mitigate the maximization bias. Finally, we derive a finite-time expected error
bound for SDQ."
Implementing engrams from a machine learning perspective - XOR as a basic motif,https://arxiv.org/abs/2406.09940,2024-06-14,2024-06-19,0.0,0.0,"We have previously presented the idea of how complex multimodal information
could be represented in our brains in a compressed form, following mechanisms
similar to those employed in machine learning tools, like autoencoders. In this
short comment note we reflect, mainly with a didactical purpose, upon the basic
question for a biological implementation: what could be the mechanism working
as a loss function, and how it could be connected to a neuronal network
providing the required feedback to build a simple training configuration. We
present our initial ideas based on a basic motif that implements an XOR switch,
using few excitatory and inhibitory neurons. Such motif is guided by a
principle of homeostasis, and it implements a loss function that could provide
feedback to other neuronal structures, establishing a control system. We
analyse the presence of this XOR motif in the connectome of C.Elegans, and
indicate the relationship with the well-known lateral inhibition motif. We then
explore how to build a basic biological neuronal structure with learning
capacity integrating this XOR motif. Guided by the computational analogy, we
show an initial example that indicates the feasibility of this approach,
applied to learning binary sequences, like it is the case for simple melodies.
In summary, we provide didactical examples exploring the parallelism between
biological and computational learning mechanisms, identifying basic motifs and
training procedures, and how an engram encoding a melody could be built using a
simple recurrent network involving both excitatory and inhibitory neurons."
Experiments in News Bias Detection with Pre-Trained Neural Transformers,https://arxiv.org/abs/2406.09938,2024-06-14,2024-06-19,0.0,0.0,"The World Wide Web provides unrivalled access to information globally,
including factual news reporting and commentary. However, state actors and
commercial players increasingly spread biased (distorted) or fake (non-factual)
information to promote their agendas. We compare several large, pre-trained
language models on the task of sentence-level news bias detection and sub-type
classification, providing quantitative and qualitative results."
Forgetting Order of Continual Learning - Examples That are Learned First are Forgotten Last,https://arxiv.org/abs/2406.09935,2024-06-14,2024-06-19,0.0,0.0,"Catastrophic forgetting poses a significant challenge in continual learning,
where models often forget previous tasks when trained on new data. Our
empirical analysis reveals a strong correlation between catastrophic forgetting
and the learning speed of examples: examples learned early are rarely
forgotten, while those learned later are more susceptible to forgetting. We
demonstrate that replay-based continual learning methods can leverage this
phenomenon by focusing on mid-learned examples for rehearsal. We introduce
Goldilocks, a novel replay buffer sampling method that filters out examples
learned too quickly or too slowly, keeping those learned at an intermediate
speed. Goldilocks improves existing continual learning algorithms, leading to
state-of-the-art performance across several image classification tasks."
What Does it Take to Generalize SER Model Across Datasets? A Comprehensive Benchmark,https://arxiv.org/abs/2406.09933,2024-06-14,2024-06-19,0.0,0.0,"Speech emotion recognition (SER) is essential for enhancing human-computer
interaction in speech-based applications. Despite improvements in specific
emotional datasets, there is still a research gap in SER's capability to
generalize across real-world situations. In this paper, we investigate
approaches to generalize the SER system across different emotion datasets. In
particular, we incorporate 11 emotional speech datasets and illustrate a
comprehensive benchmark on the SER task. We also address the challenge of
imbalanced data distribution using over-sampling methods when combining SER
datasets for training. Furthermore, we explore various evaluation protocols for
adeptness in the generalization of SER. Building on this, we explore the
potential of Whisper for SER, emphasizing the importance of thorough
evaluation. Our approach is designed to advance SER technology by integrating
speaker-independent methods."
SCKansformer - Fine-Grained Classification of Bone Marrow Cells via Kansformer Backbone and Hierarchical Attention Mechanisms,https://arxiv.org/abs/2406.09931,2024-06-14,2024-06-19,0.0,0.0,"The incidence and mortality rates of malignant tumors, such as acute
leukemia, have risen significantly. Clinically, hospitals rely on cytological
examination of peripheral blood and bone marrow smears to diagnose malignant
tumors, with accurate blood cell counting being crucial. Existing automated
methods face challenges such as low feature expression capability, poor
interpretability, and redundant feature extraction when processing
high-dimensional microimage data. We propose a novel fine-grained
classification model, SCKansformer, for bone marrow blood cells, which
addresses these challenges and enhances classification accuracy and efficiency.
The model integrates the Kansformer Encoder, SCConv Encoder, and Global-Local
Attention Encoder. The Kansformer Encoder replaces the traditional MLP layer
with the KAN, improving nonlinear feature representation and interpretability.
The SCConv Encoder, with its Spatial and Channel Reconstruction Units, enhances
feature representation and reduces redundancy. The Global-Local Attention
Encoder combines Multi-head Self-Attention with a Local Part module to capture
both global and local features. We validated our model using the Bone Marrow
Blood Cell Fine-Grained Classification Dataset (BMCD-FGCD), comprising over
10,000 samples and nearly 40 classifications, developed with a partner
hospital. Comparative experiments on our private dataset, as well as the
publicly available PBC and ALL-IDB datasets, demonstrate that SCKansformer
outperforms both typical and advanced microcell classification methods across
all datasets. Our source code and private BMCD-FGCD dataset are available at
https://github.com/JustlfC03/SCKansformer."
Personalized Speech Enhancement Without a Separate Speaker Embedding Model,https://arxiv.org/abs/2406.09928,2024-06-14,2024-06-19,0.0,0.0,"Personalized speech enhancement (PSE) models can improve the audio quality of
teleconferencing systems by adapting to the characteristics of a speaker's
voice. However, most existing methods require a separate speaker embedding
model to extract a vector representation of the speaker from enrollment audio,
which adds complexity to the training and deployment process. We propose to use
the internal representation of the PSE model itself as the speaker embedding,
thereby avoiding the need for a separate model. We show that our approach
performs equally well or better than the standard method of using a pre-trained
speaker embedding model on noise suppression and echo cancellation tasks.
Moreover, our approach surpasses the ICASSP 2023 Deep Noise Suppression
Challenge winner by 0.15 in Mean Opinion Score."
POWN - Prototypical Open-World Node Classification,https://arxiv.org/abs/2406.09926,2024-06-14,2024-06-19,0.0,0.0,"We consider the problem of \textit{true} open-world semi-supervised node
classification, in which nodes in a graph either belong to known or new
classes, with the latter not present during training. Existing methods detect
and reject new classes but fail to distinguish between different new classes.
We adapt existing methods and show they do not solve the problem sufficiently.
We introduce a novel end-to-end approach for classification into known classes
and new classes based on class prototypes, which we call Prototypical
Open-World Learning for Node Classification (POWN). Our method combines graph
semi-supervised learning, self-supervised learning, and pseudo-labeling to
learn prototype representations of new classes in a zero-shot way. In contrast
to existing solutions from the vision domain, POWN does not require data
augmentation techniques for node classification. Experiments on benchmark
datasets demonstrate the effectiveness of POWN, where it outperforms baselines
by up to $20\%$ accuracy on the small and up to $30\%$ on the large datasets.
Source code is available at https://github.com/Bobowner/POWN."
"Fundamental operating regimes, hyper-parameter fine-tuning and glassiness - towards an interpretable replica-theory for trained restricted Boltzmann machines",https://arxiv.org/abs/2406.09924,2024-06-14,2024-06-19,0.0,0.0,"We consider restricted Boltzmann machines with a binary visible layer and a
Gaussian hidden layer trained by an unlabelled dataset composed of noisy
realizations of a single ground pattern. We develop a statistical mechanics
framework to describe the network generative capabilities, by exploiting the
replica trick and assuming self-averaging of the underlying order parameters
(i.e., replica symmetry). In particular, we outline the effective control
parameters (e.g., the relative number of weights to be trained, the
regularization parameter), whose tuning can yield qualitatively-different
operative regimes. Further, we provide analytical and numerical evidence for
the existence of a sub-region in the space of the hyperparameters where
replica-symmetry breaking occurs."
"CliBench - Multifaceted Evaluation of Large Language Models in Clinical Decisions on Diagnoses, Procedures, Lab Tests Orders and Prescriptions",https://arxiv.org/abs/2406.09923,2024-06-14,2024-06-19,0.0,0.0,"The integration of Artificial Intelligence (AI), especially Large Language
Models (LLMs), into the clinical diagnosis process offers significant potential
to improve the efficiency and accessibility of medical care. While LLMs have
shown some promise in the medical domain, their application in clinical
diagnosis remains underexplored, especially in real-world clinical practice,
where highly sophisticated, patient-specific decisions need to be made. Current
evaluations of LLMs in this field are often narrow in scope, focusing on
specific diseases or specialties and employing simplified diagnostic tasks. To
bridge this gap, we introduce CliBench, a novel benchmark developed from the
MIMIC IV dataset, offering a comprehensive and realistic assessment of LLMs'
capabilities in clinical diagnosis. This benchmark not only covers diagnoses
from a diverse range of medical cases across various specialties but also
incorporates tasks of clinical significance: treatment procedure
identification, lab test ordering and medication prescriptions. Supported by
structured output ontologies, CliBench enables a precise and multi-granular
evaluation, offering an in-depth understanding of LLM's capability on diverse
clinical tasks of desired granularity. We conduct a zero-shot evaluation of
leading LLMs to assess their proficiency in clinical decision-making. Our
preliminary results shed light on the potential and limitations of current LLMs
in clinical settings, providing valuable insights for future advancements in
LLM-powered healthcare."
Knowledge Editing in Language Models via Adapted Direct Preference Optimization,https://arxiv.org/abs/2406.09920,2024-06-14,2024-06-19,0.0,0.0,"Large Language Models (LLMs) can become outdated over time as they may lack
updated world knowledge, leading to factual knowledge errors and gaps.
Knowledge Editing (KE) aims to overcome this challenge using weight updates
that do not require expensive retraining. We propose treating KE as an LLM
alignment problem. Toward this goal, we introduce Knowledge Direct Preference
Optimization (KDPO), a variation of the Direct Preference Optimization (DPO)
that is more effective for knowledge modifications. Our method is based on an
online approach that continually updates the knowledge stored in the model. We
use the current knowledge as a negative sample and the new knowledge we want to
introduce as a positive sample in a process called DPO. We also use
teacher-forcing for negative sample generation and optimize using the positive
sample, which helps maintain localized changes. We tested our KE method on
various datasets and models, comparing it to several cutting-edge methods, with
100 and 500 sequential edits. Additionally, we conducted an ablation study
comparing our method to the standard DPO approach. Our experimental results
show that our modified DPO method allows for more refined KE, achieving similar
or better performance compared to previous methods."
What Does Softmax Probability Tell Us about Classifiers Ranking Across Diverse Test Conditions?,https://arxiv.org/abs/2406.09908,2024-06-14,2024-06-19,0.0,0.0,"This work aims to develop a measure that can accurately rank the performance
of various classifiers when they are tested on unlabeled data from
out-of-distribution (OOD) distributions. We commence by demonstrating that
conventional uncertainty metrics, notably the maximum Softmax prediction
probability, possess inherent utility in forecasting model generalization
across certain OOD contexts. Building on this insight, we introduce a new
measure called Softmax Correlation (SoftmaxCorr). It calculates the cosine
similarity between a class-class correlation matrix, constructed from Softmax
output vectors across an unlabeled test dataset, and a predefined reference
matrix that embodies ideal class correlations. A high resemblance of
predictions to the reference matrix signals that the model delivers confident
and uniform predictions across all categories, reflecting minimal uncertainty
and confusion. Through rigorous evaluation across a suite of datasets,
including ImageNet, CIFAR-10, and WILDS, we affirm the predictive validity of
SoftmaxCorr in accurately forecasting model performance within both
in-distribution (ID) and OOD settings. Furthermore, we discuss the limitations
of our proposed measure and suggest avenues for future research."
QQQ - Quality Quattuor-Bit Quantization for Large Language Models,https://arxiv.org/abs/2406.09904,2024-06-14,2024-06-19,0.0,0.0,"Quantization is a proven effective method for compressing large language
models. Although popular techniques like W8A8 and W4A16 effectively maintain
model performance, they often fail to concurrently speed up the prefill and
decoding stages of inference. W4A8 is a promising strategy to accelerate both
of them while usually leads to a significant performance degradation. To
address these issues, we present QQQ, a Quality Quattuor-bit Quantization
method with 4-bit weights and 8-bit activations. QQQ employs adaptive smoothing
and Hessian-based compensation, significantly enhancing the performance of
quantized models without extensive training. Furthermore, we meticulously
engineer W4A8 GEMM kernels to increase inference speed. Our specialized
per-channel W4A8 GEMM and per-group W4A8 GEMM achieve impressive speed
increases of 3.67$\times$ and 3.29 $\times$ over FP16 GEMM. Our extensive
experiments show that QQQ achieves performance on par with existing
state-of-the-art LLM quantization methods while significantly accelerating
inference, achieving speed boosts up to 2.24 $\times$, 2.10$\times$, and
1.25$\times$ compared to FP16, W8A8, and W4A16, respectively."
GEB-1.3B - Open Lightweight Large Language Model,https://arxiv.org/abs/2406.09900,2024-06-14,2024-06-19,0.0,0.0,"Recently developed large language models (LLMs) such as ChatGPT, Claude, and
Llama have demonstrated impressive abilities, and even surpass human-level
performance in several tasks. Despite their success, the resource-intensive
demands of these models, requiring significant computational power for both
training and inference, limit their deployment to high-performance servers.
Additionally, the extensive calculation requirements of the models often lead
to increased latency in response times. With the increasing need for LLMs to
operate efficiently on CPUs, research about lightweight models that are
optimized for CPU inference has emerged. In this work, we introduce GEB-1.3B, a
lightweight LLM trained on 550 billion tokens in both Chinese and English
languages. We employ novel training techniques, including ROPE,
Group-Query-Attention, and FlashAttention-2, to accelerate training while
maintaining model performance. Additionally, we fine-tune the model using 10
million samples of instruction data to enhance alignment. GEB-1.3B exhibits
outstanding performance on general benchmarks such as MMLU, C-Eval, and CMMLU,
outperforming comparative models such as MindLLM-1.3B and TinyLLaMA-1.1B.
Notably, the FP32 version of GEB-1.3B achieves commendable inference times on
CPUs, with ongoing efforts to further enhance speed through advanced
quantization techniques. The release of GEB-1.3B as an open-source model marks
a significant contribution to the development of lightweight LLMs, promising to
foster further research and innovation in the field."
Learning Solution-Aware Transformers for Efficiently Solving Quadratic Assignment Problem,https://arxiv.org/abs/2406.09899,2024-06-14,2024-06-19,0.0,0.0,"Recently various optimization problems, such as Mixed Integer Linear
Programming Problems (MILPs), have undergone comprehensive investigation,
leveraging the capabilities of machine learning. This work focuses on
learning-based solutions for efficiently solving the Quadratic Assignment
Problem (QAPs), which stands as a formidable challenge in combinatorial
optimization. While many instances of simpler problems admit fully
polynomial-time approximate solution (FPTAS), QAP is shown to be strongly
NP-hard. Even finding a FPTAS for QAP is difficult, in the sense that the
existence of a FPTAS implies $P = NP$. Current research on QAPs suffer from
limited scale and computational inefficiency. To attack the aforementioned
issues, we here propose the first solution of its kind for QAP in the
learn-to-improve category. This work encodes facility and location nodes
separately, instead of forming computationally intensive association graphs
prevalent in current approaches. This design choice enables scalability to
larger problem sizes. Furthermore, a \textbf{S}olution \textbf{AW}are
\textbf{T}ransformer (SAWT) architecture integrates the incumbent solution
matrix with the attention score to effectively capture higher-order information
of the QAPs. Our model's effectiveness is validated through extensive
experiments on self-generated QAP instances of varying sizes and the QAPLIB
benchmark."
Positive-Unlabelled Learning for Identifying New Candidate Dietary Restriction-related Genes among Ageing-related Genes,https://arxiv.org/abs/2406.09898,2024-06-14,2024-06-19,0.0,0.0,"Dietary Restriction (DR) is one of the most popular anti-ageing
interventions, prompting exhaustive research into genes associated with its
mechanisms. Recently, Machine Learning (ML) has been explored to identify
potential DR-related genes among ageing-related genes, aiming to minimize
costly wet lab experiments needed to expand our knowledge on DR. However, to
train a model from positive (DR-related) and negative (non-DR-related)
examples, existing ML methods naively label genes without known DR relation as
negative examples, assuming that lack of DR-related annotation for a gene
represents evidence of absence of DR-relatedness, rather than absence of
evidence; this hinders the reliability of the negative examples (non-DR-related
genes) and the method's ability to identify novel DR-related genes. This work
introduces a novel gene prioritization method based on the two-step
Positive-Unlabelled (PU) Learning paradigm: using a similarity-based,
KNN-inspired approach, our method first selects reliable negative examples
among the genes without known DR associations. Then, these reliable negatives
and all known positives are used to train a classifier that effectively
differentiates DR-related and non-DR-related genes, which is finally employed
to generate a more reliable ranking of promising genes for novel
DR-relatedness. Our method significantly outperforms the existing
state-of-the-art non-PU approach for DR-relatedness prediction in three
relevant performance metrics. In addition, curation of existing literature
finds support for the top-ranked candidate DR-related genes identified by our
model."
3D-RPE - Enhancing Long-Context Modeling Through 3D Rotary Position Encoding,https://arxiv.org/abs/2406.09897,2024-06-14,2024-06-19,0.0,0.0,"Inspired by the Bloch Sphere representation, we propose a novel rotary
position encoding on a three-dimensional sphere, named 3D Rotary Position
Encoding (3D-RPE). 3D-RPE is an advanced version of the widely used 2D Rotary
Position Encoding (RoPE), with two major advantages for modeling long contexts:
controllable long-term decay and improved position resolution. For controllable
long-term decay, 3D-RPE allows for the regulation of long-term decay within the
chunk size, ensuring the modeling of relative positional information between
tokens at a distant relative position. For enhanced position resolution, 3D-RPE
can mitigate the degradation of position resolution caused by position
interpolation on RoPE. We have conducted experiments on long-context Natural
Language Understanding (NLU) and long-sequence Language Modeling (LM) tasks.
From the experimental results, 3D-RPE achieved performance improvements over
RoPE, especially in long-context NLU tasks."
Benchmarking Generative Models on Computational Thinking Tests in Elementary Visual Programming,https://arxiv.org/abs/2406.09891,2024-06-14,2024-06-19,0.0,0.0,"Generative models have demonstrated human-level proficiency in various
benchmarks across domains like programming, natural sciences, and general
knowledge. Despite these promising results on competitive benchmarks, they
still struggle with seemingly simple problem-solving tasks typically carried
out by elementary-level students. How do state-of-the-art models perform on
standardized tests designed to assess computational thinking and
problem-solving skills at schools? In this paper, we curate a novel benchmark
involving computational thinking tests grounded in elementary visual
programming domains. Our initial results show that state-of-the-art models like
GPT-4o and Llama3 barely match the performance of an average school student. To
further boost the performance of these models, we fine-tune them using a novel
synthetic data generation methodology. The key idea is to develop a
comprehensive dataset using symbolic methods that capture different skill
levels, ranging from recognition of visual elements to multi-choice quizzes to
synthesis-style tasks. We showcase how various aspects of symbolic information
in synthetic data help improve fine-tuned models' performance. We will release
the full implementation and datasets to facilitate further research on
enhancing computational thinking in generative models."
Harm Mitigation in Recommender Systems under User Preference Dynamics,https://arxiv.org/abs/2406.09882,2024-06-14,2024-06-19,0.0,0.0,"We consider a recommender system that takes into account the interplay
between recommendations, the evolution of user interests, and harmful content.
We model the impact of recommendations on user behavior, particularly the
tendency to consume harmful content. We seek recommendation policies that
establish a tradeoff between maximizing click-through rate (CTR) and mitigating
harm. We establish conditions under which the user profile dynamics have a
stationary point, and propose algorithms for finding an optimal recommendation
policy at stationarity. We experiment on a semi-synthetic movie recommendation
setting initialized with real data and observe that our policies outperform
baselines at simultaneously maximizing CTR and mitigating harm."
A Unified Data Augmentation Framework for Low-Resource Multi-Domain Dialogue Generation,https://arxiv.org/abs/2406.09881,2024-06-14,2024-06-19,0.0,0.0,"Current state-of-the-art dialogue systems heavily rely on extensive training
datasets. However, challenges arise in domains where domain-specific training
datasets are insufficient or entirely absent. To tackle this challenge, we
propose a novel data \textbf{A}ugmentation framework for
\textbf{M}ulti-\textbf{D}omain \textbf{D}ialogue \textbf{G}eneration, referred
to as \textbf{AMD$^2$G}. The AMD$^2$G framework consists of a data augmentation
process and a two-stage training approach: domain-agnostic training and domain
adaptation training. We posit that domain corpora are a blend of
domain-agnostic and domain-specific features, with certain representation
patterns shared among diverse domains. Domain-agnostic training aims to enable
models to learn these common expressive patterns. To construct domain-agnostic
dialogue corpora, we employ a \textit{\textbf{de-domaining}} data processing
technique used to remove domain-specific features. By mitigating the effects of
domain-specific features, the model trained on the de-domained corpora can
effectively learn common expression patterns in different domains.
Subsequently, we adapt the learned domain-agnostic features to the target
domain through domain adaptation training. We conduct experiments on Chinese
dialogue datasets from five different domains and show that AMD$^2$G achieves
superior performance compared to both direct training on the target domain
corpus and collective training on all five domain corpora. Our work underscores
AMD$^2$G as a viable alternative solution for low-resource multi-domain
dialogue generation. Code and data associated with our work are available on
GitHub repository$^{\text 1}$."
Federated Learning with Flexible Architectures,https://arxiv.org/abs/2406.09877,2024-06-14,2024-06-19,0.0,0.0,"Traditional federated learning (FL) methods have limited support for clients
with varying computational and communication abilities, leading to
inefficiencies and potential inaccuracies in model training. This limitation
hinders the widespread adoption of FL in diverse and resource-constrained
environments, such as those with client devices ranging from powerful servers
to mobile devices. To address this need, this paper introduces Federated
Learning with Flexible Architectures (FedFA), an FL training algorithm that
allows clients to train models of different widths and depths. Each client can
select a network architecture suitable for its resources, with shallower and
thinner networks requiring fewer computing resources for training. Unlike prior
work in this area, FedFA incorporates the layer grafting technique to align
clients' local architectures with the largest network architecture in the FL
system during model aggregation. Layer grafting ensures that all client
contributions are uniformly integrated into the global model, thereby
minimizing the risk of any individual client's data skewing the model's
parameters disproportionately and introducing security benefits. Moreover,
FedFA introduces the scalable aggregation method to manage scale variations in
weights among different network architectures. Experimentally, FedFA
outperforms previous width and depth flexible aggregation strategies.
Furthermore, FedFA demonstrates increased robustness against performance
degradation in backdoor attack scenarios compared to earlier strategies."
Sailing in high-dimensional spaces - Low-dimensional embeddings through angle preservation,https://arxiv.org/abs/2406.09876,2024-06-14,2024-06-19,0.0,0.0,"Low-dimensional embeddings (LDEs) of high-dimensional data are ubiquitous in
science and engineering. They allow us to quickly understand the main
properties of the data, identify outliers and processing errors, and inform the
next steps of data analysis. As such, LDEs have to be faithful to the original
high-dimensional data, i.e., they should represent the relationships that are
encoded in the data, both at a local as well as global scale. The current
generation of LDE approaches focus on reconstructing local distances between
any pair of samples correctly, often out-performing traditional approaches
aiming at all distances. For these approaches, global relationships are,
however, usually strongly distorted, often argued to be an inherent trade-off
between local and global structure learning for embeddings. We suggest a new
perspective on LDE learning, reconstructing angles between data points. We show
that this approach, Mercat, yields good reconstruction across a diverse set of
experiments and metrics, and preserve structures well across all scales.
Compared to existing work, our approach also has a simple formulation,
facilitating future theoretical analysis and algorithmic improvements."
Perceiver-Prompt - Flexible Speaker Adaptation in Whisper for Chinese Disordered Speech Recognition,https://arxiv.org/abs/2406.09873,2024-06-14,2024-06-19,0.0,0.0,"Disordered speech recognition profound implications for improving the quality
of life for individuals afflicted with, for example, dysarthria. Dysarthric
speech recognition encounters challenges including limited data, substantial
dissimilarities between dysarthric and non-dysarthric speakers, and significant
speaker variations stemming from the disorder. This paper introduces
Perceiver-Prompt, a method for speaker adaptation that utilizes P-Tuning on the
Whisper large-scale model. We first fine-tune Whisper using LoRA and then
integrate a trainable Perceiver to generate fixed-length speaker prompts from
variable-length inputs, to improve model recognition of Chinese dysarthric
speech. Experimental results from our Chinese dysarthric speech dataset
demonstrate consistent improvements in recognition performance with
Perceiver-Prompt. Relative reduction up to 13.04% in CER is obtained over the
fine-tuned Whisper."
IGL-Bench - Establishing the Comprehensive Benchmark for Imbalanced Graph Learning,https://arxiv.org/abs/2406.09870,2024-06-14,2024-06-19,0.0,0.0,"Deep graph learning has gained grand popularity over the past years due to
its versatility and success in representing graph data across a wide range of
domains. However, the pervasive issue of imbalanced graph data distributions,
where certain parts exhibit disproportionally abundant data while others remain
sparse, undermines the efficacy of conventional graph learning algorithms,
leading to biased outcomes. To address this challenge, Imbalanced Graph
Learning (IGL) has garnered substantial attention, enabling more balanced data
distributions and better task performance. Despite the proliferation of IGL
algorithms, the absence of consistent experimental protocols and fair
performance comparisons pose a significant barrier to comprehending
advancements in this field. To bridge this gap, we introduce IGL-Bench, a
foundational comprehensive benchmark for imbalanced graph learning, embarking
on 16 diverse graph datasets and 24 distinct IGL algorithms with uniform data
processing and splitting strategies. Specifically, IGL-Bench systematically
investigates state-of-the-art IGL algorithms in terms of effectiveness,
robustness, and efficiency on node-level and graph-level tasks, with the scope
of class-imbalance and topology-imbalance. Extensive experiments demonstrate
the potential benefits of IGL algorithms on various imbalanced conditions,
offering insights and opportunities in the IGL field. Further, we have
developed an open-sourced and unified package to facilitate reproducible
evaluation and inspire further innovative research, which is available at
https://github.com/RingBDStack/IGL-Bench."
LUMA - A Benchmark Dataset for Learning from Uncertain and Multimodal Data,https://arxiv.org/abs/2406.09864,2024-06-14,2024-06-19,0.0,0.0,"Multimodal Deep Learning enhances decision-making by integrating diverse
information sources, such as texts, images, audio, and videos. To develop
trustworthy multimodal approaches, it is essential to understand how
uncertainty impacts these models. We propose LUMA, a unique benchmark dataset,
featuring audio, image, and textual data from 50 classes, for learning from
uncertain and multimodal data. It extends the well-known CIFAR 10/100 dataset
with audio samples extracted from three audio corpora, and text data generated
using the Gemma-7B Large Language Model (LLM). The LUMA dataset enables the
controlled injection of varying types and degrees of uncertainty to achieve and
tailor specific experiments and benchmarking initiatives. LUMA is also
available as a Python package including the functions for generating multiple
variants of the dataset with controlling the diversity of the data, the amount
of noise for each modality, and adding out-of-distribution samples. A baseline
pre-trained model is also provided alongside three uncertainty quantification
methods: Monte-Carlo Dropout, Deep Ensemble, and Reliable Conflictive
Multi-View Learning. This comprehensive dataset and its benchmarking tools are
intended to promote and support the development, evaluation, and benchmarking
of trustworthy and robust multimodal deep learning approaches. We anticipate
that the LUMA dataset will help the ICLR community to design more trustworthy
and robust machine learning approaches for safety critical applications."
Dataset Condensation with Latent Quantile Matching,https://arxiv.org/abs/2406.09860,2024-06-14,2024-06-19,0.0,0.0,"Dataset condensation (DC) methods aim to learn a smaller synthesized dataset
with informative data records to accelerate the training of machine learning
models. Current distribution matching (DM) based DC methods learn a synthesized
dataset by matching the mean of the latent embeddings between the synthetic and
the real dataset. However two distributions with the same mean can still be
vastly different. In this work we demonstrate the shortcomings of using Maximum
Mean Discrepancy to match latent distributions i.e. the weak matching power and
lack of outlier regularization. To alleviate these shortcomings we propose our
new method: Latent Quantile Matching (LQM) which matches the quantiles of the
latent embeddings to minimize the goodness of fit test statistic between two
distributions. Empirical experiments on both image and graph-structured
datasets show that LQM matches or outperforms previous state of the art in
distribution matching based DC. Moreover we show that LQM improves the
performance in continual graph learning (CGL) setting where memory efficiency
and privacy can be important. Our work sheds light on the application of DM
based DC for CGL."
Learning Multi-view Molecular Representations with Structured and Unstructured Knowledge,https://arxiv.org/abs/2406.09841,2024-06-14,2024-06-19,0.0,0.0,"Capturing molecular knowledge with representation learning approaches holds
significant potential in vast scientific fields such as chemistry and life
science. An effective and generalizable molecular representation is expected to
capture the consensus and complementary molecular expertise from diverse views
and perspectives. However, existing works fall short in learning multi-view
molecular representations, due to challenges in explicitly incorporating view
information and handling molecular knowledge from heterogeneous sources. To
address these issues, we present MV-Mol, a molecular representation learning
model that harvests multi-view molecular expertise from chemical structures,
unstructured knowledge from biomedical texts, and structured knowledge from
knowledge graphs. We utilize text prompts to model view information and design
a fusion architecture to extract view-based molecular representations. We
develop a two-stage pre-training procedure, exploiting heterogeneous data of
varying quality and quantity. Through extensive experiments, we show that
MV-Mol provides improved representations that substantially benefit molecular
property prediction. Additionally, MV-Mol exhibits state-of-the-art performance
in multi-modal comprehension of molecular structures and texts. Code and data
are available at https://github.com/PharMolix/OpenBioMed."
Rapport-Driven Virtual Agent - Rapport Building Dialogue Strategy for Improving User Experience at First Meeting,https://arxiv.org/abs/2406.09839,2024-06-14,2024-06-19,0.0,0.0,"Rapport is known as a conversational aspect focusing on relationship
building, which influences outcomes in collaborative tasks. This study aims to
establish human-agent rapport through small talk by using a rapport-building
strategy. We implemented this strategy for the virtual agents based on dialogue
strategies by prompting a large language model (LLM). In particular, we
utilized two dialogue strategies-predefined sequence and free-form-to guide the
dialogue generation framework. We conducted analyses based on human
evaluations, examining correlations between total turn, utterance characters,
rapport score, and user experience variables: naturalness, satisfaction,
interest, engagement, and usability. We investigated correlations between
rapport score and naturalness, satisfaction, engagement, and conversation flow.
Our experimental results also indicated that using free-form to prompt the
rapport-building strategy performed the best in subjective scores."
Vision-Language Models Meet Meteorology - Developing Models for Extreme Weather Events Detection with Heatmaps,https://arxiv.org/abs/2406.09838,2024-06-14,2024-06-19,0.0,0.0,"Real-time detection and prediction of extreme weather protect human lives and
infrastructure. Traditional methods rely on numerical threshold setting and
manual interpretation of weather heatmaps with Geographic Information Systems
(GIS), which can be slow and error-prone. Our research redefines Extreme
Weather Events Detection (EWED) by framing it as a Visual Question Answering
(VQA) problem, thereby introducing a more precise and automated solution.
Leveraging Vision-Language Models (VLM) to simultaneously process visual and
textual data, we offer an effective aid to enhance the analysis process of
weather heatmaps. Our initial assessment of general-purpose VLMs (e.g.,
GPT-4-Vision) on EWED revealed poor performance, characterized by low accuracy
and frequent hallucinations due to inadequate color differentiation and
insufficient meteorological knowledge. To address these challenges, we
introduce ClimateIQA, the first meteorological VQA dataset, which includes
8,760 wind gust heatmaps and 254,040 question-answer pairs covering four
question types, both generated from the latest climate reanalysis data. We also
propose Sparse Position and Outline Tracking (SPOT), an innovative technique
that leverages OpenCV and K-Means clustering to capture and depict color
contours in heatmaps, providing ClimateIQA with more accurate color spatial
location information. Finally, we present Climate-Zoo, the first meteorological
VLM collection, which adapts VLMs to meteorological applications using the
ClimateIQA dataset. Experiment results demonstrate that models from Climate-Zoo
substantially outperform state-of-the-art general VLMs, achieving an accuracy
increase from 0% to over 90% in EWED verification. The datasets and models in
this study are publicly available for future climate science research:
https://github.com/AlexJJJChen/Climate-Zoo."
TabularFM - An Open Framework For Tabular Foundational Models,https://arxiv.org/abs/2406.09837,2024-06-14,2024-06-19,0.0,0.0,"Foundational models (FMs), pretrained on extensive datasets using
self-supervised techniques, are capable of learning generalized patterns from
large amounts of data. This reduces the need for extensive labeled datasets for
each new task, saving both time and resources by leveraging the broad knowledge
base established during pretraining. Most research on FMs has primarily focused
on unstructured data, such as text and images, or semi-structured data, like
time-series. However, there has been limited attention to structured data, such
as tabular data, which, despite its prevalence, remains under-studied due to a
lack of clean datasets and insufficient research on the transferability of FMs
for various tabular data tasks. In response to this gap, we introduce a
framework called TabularFM, which incorporates state-of-the-art methods for
developing FMs specifically for tabular data. This includes variations of
neural architectures such as GANs, VAEs, and Transformers. We have curated a
million of tabular datasets and released cleaned versions to facilitate the
development of tabular FMs. We pretrained FMs on this curated data, benchmarked
various learning methods on these datasets, and released the pretrained models
along with leaderboards for future comparative studies. Our fully open-sourced
system provides a comprehensive analysis of the transferability of tabular FMs.
By releasing these datasets, pretrained models, and leaderboards, we aim to
enhance the validity and usability of tabular FMs in the near future."
Robustness-Inspired Defense Against Backdoor Attacks on Graph Neural Networks,https://arxiv.org/abs/2406.09836,2024-06-14,2024-06-19,0.0,0.0,"Graph Neural Networks (GNNs) have achieved promising results in tasks such as
node classification and graph classification. However, recent studies reveal
that GNNs are vulnerable to backdoor attacks, posing a significant threat to
their real-world adoption. Despite initial efforts to defend against specific
graph backdoor attacks, there is no work on defending against various types of
backdoor attacks where generated triggers have different properties. Hence, we
first empirically verify that prediction variance under edge dropping is a
crucial indicator for identifying poisoned nodes. With this observation, we
propose using random edge dropping to detect backdoors and theoretically show
that it can efficiently distinguish poisoned nodes from clean ones.
Furthermore, we introduce a novel robust training strategy to efficiently
counteract the impact of the triggers. Extensive experiments on real-world
datasets show that our framework can effectively identify poisoned nodes,
significantly degrade the attack success rate, and maintain clean accuracy when
defending against various types of graph backdoor attacks with different
properties."
I Know How - Combining Prior Policies to Solve New Tasks,https://arxiv.org/abs/2406.09835,2024-06-14,2024-06-19,0.0,0.0,"Multi-Task Reinforcement Learning aims at developing agents that are able to
continually evolve and adapt to new scenarios. However, this goal is
challenging to achieve due to the phenomenon of catastrophic forgetting and the
high demand of computational resources. Learning from scratch for each new task
is not a viable or sustainable option, and thus agents should be able to
collect and exploit prior knowledge while facing new problems. While several
methodologies have attempted to address the problem from different
perspectives, they lack a common structure. In this work, we propose a new
framework, I Know How (IKH), which provides a common formalization. Our
methodology focuses on modularity and compositionality of knowledge in order to
achieve and enhance agent's ability to learn and adapt efficiently to dynamic
environments. To support our framework definition, we present a simple
application of it in a simulated driving environment and compare its
performance with that of state-of-the-art approaches."
SHMamba - Structured Hyperbolic State Space Model for Audio-Visual Question Answering,https://arxiv.org/abs/2406.09833,2024-06-14,2024-06-19,0.0,0.0,"The Audio-Visual Question Answering (AVQA) task holds significant potential
for applications. Compared to traditional unimodal approaches, the multi-modal
input of AVQA makes feature extraction and fusion processes more challenging.
Euclidean space is difficult to effectively represent multi-dimensional
relationships of data. Especially when extracting and processing data with a
tree structure or hierarchical structure, Euclidean space is not suitable as an
embedding space. Additionally, the self-attention mechanism in Transformers is
effective in capturing the dynamic relationships between elements in a
sequence. However, the self-attention mechanism's limitations in window
modeling and quadratic computational complexity reduce its effectiveness in
modeling long sequences. To address these limitations, we propose SHMamba:
Structured Hyperbolic State Space Model to integrate the advantages of
hyperbolic geometry and state space models. Specifically, SHMamba leverages the
intrinsic properties of hyperbolic space to represent hierarchical structures
and complex relationships in audio-visual data. Meanwhile, the state space
model captures dynamic changes over time by globally modeling the entire
sequence. Furthermore, we introduce an adaptive curvature hyperbolic alignment
module and a cross fusion block to enhance the understanding of hierarchical
structures and the dynamic exchange of cross-modal information, respectively.
Extensive experiments demonstrate that SHMamba outperforms previous methods
with fewer parameters and computational costs. Our learnable parameters are
reduced by 78.12\%, while the average performance improves by 2.53\%.
Experiments show that our method demonstrates superiority among all current
major methods and is more suitable for practical application scenarios."
Federated Learning driven Large Language Models for Swarm Intelligence - A Survey,https://arxiv.org/abs/2406.09831,2024-06-14,2024-06-19,0.0,0.0,"Federated learning (FL) offers a compelling framework for training large
language models (LLMs) while addressing data privacy and decentralization
challenges. This paper surveys recent advancements in the federated learning of
large language models, with a particular focus on machine unlearning, a crucial
aspect for complying with privacy regulations like the Right to be Forgotten.
Machine unlearning in the context of federated LLMs involves systematically and
securely removing individual data contributions from the learned model without
retraining from scratch. We explore various strategies that enable effective
unlearning, such as perturbation techniques, model decomposition, and
incremental learning, highlighting their implications for maintaining model
performance and data privacy. Furthermore, we examine case studies and
experimental results from recent literature to assess the effectiveness and
efficiency of these approaches in real-world scenarios. Our survey reveals a
growing interest in developing more robust and scalable federated unlearning
methods, suggesting a vital area for future research in the intersection of AI
ethics and distributed machine learning technologies."
HiP Attention - Sparse Sub-Quadratic Attention with Hierarchical Attention Pruning,https://arxiv.org/abs/2406.09827,2024-06-14,2024-06-19,0.0,0.0,"In modern large language models (LLMs), increasing sequence lengths is a
crucial challenge for enhancing their comprehension and coherence in handling
complex tasks such as multi-modal question answering. However, handling long
context sequences with LLMs is prohibitively costly due to the conventional
attention mechanism's quadratic time and space complexity, and the context
window size is limited by the GPU memory. Although recent works have proposed
linear and sparse attention mechanisms to address this issue, their real-world
applicability is often limited by the need to re-train pre-trained models. In
response, we propose a novel approach, Hierarchically Pruned Attention (HiP),
which simultaneously reduces the training and inference time complexity from
$O(T^2)$ to $O(T \log T)$ and the space complexity from $O(T^2)$ to $O(T)$. To
this end, we devise a dynamic sparse attention mechanism that generates an
attention mask through a novel tree-search-like algorithm for a given query on
the fly. HiP is training-free as it only utilizes the pre-trained attention
scores to spot the positions of the top-$k$ most significant elements for each
query. Moreover, it ensures that no token is overlooked, unlike the sliding
window-based sub-quadratic attention methods, such as StreamingLLM. Extensive
experiments on diverse real-world benchmarks demonstrate that HiP significantly
reduces prompt (i.e., prefill) and decoding latency and memory usage while
maintaining high generation performance with little or no degradation. As HiP
allows pretrained LLMs to scale to millions of tokens on commodity GPUs with no
additional engineering due to its easy plug-and-play deployment, we believe
that our work will have a large practical impact, opening up the possibility to
many long-context LLM applications previously infeasible."
Unraveling Anomalies in Time - Unsupervised Discovery and Isolation of Anomalous Behavior in Bio-regenerative Life Support System Telemetry,https://arxiv.org/abs/2406.09825,2024-06-14,2024-06-19,0.0,0.0,"The detection of abnormal or critical system states is essential in condition
monitoring. While much attention is given to promptly identifying anomalies, a
retrospective analysis of these anomalies can significantly enhance our
comprehension of the underlying causes of observed undesired behavior. This
aspect becomes particularly critical when the monitored system is deployed in a
vital environment. In this study, we delve into anomalies within the domain of
Bio-Regenerative Life Support Systems (BLSS) for space exploration and analyze
anomalies found in telemetry data stemming from the EDEN ISS space greenhouse
in Antarctica. We employ time series clustering on anomaly detection results to
categorize various types of anomalies in both uni- and multivariate settings.
We then assess the effectiveness of these methods in identifying systematic
anomalous behavior. Additionally, we illustrate that the anomaly detection
methods MDI and DAMP produce complementary results, as previously indicated by
research."
An I2I Inpainting Approach for Efficient Channel Knowledge Map Construction,https://arxiv.org/abs/2406.09822,2024-06-14,2024-06-19,0.0,0.0,"Channel knowledge map (CKM) has received widespread attention as an emerging
enabling technology for environment-aware wireless communications. It involves
the construction of databases containing location-specific channel knowledge,
which are then leveraged to facilitate channel state information (CSI)
acquisition and transceiver design. In this context, a fundamental challenge
lies in efficiently constructing the CKM based on a given wireless propagation
environment. Most existing methods are based on stochastic modeling and
sequence prediction, which do not fully exploit the inherent physical
characteristics of the propagation environment, resulting in low accuracy and
high computational complexity. To address these limitations, we propose a
Laplacian pyramid (LP)-based CKM construction scheme to predict the channel
knowledge at arbitrary locations in a targeted area. Specifically, we first
view the channel knowledge as a 2-D image and transform the CKM construction
problem into an image-to-image (I2I) inpainting task, which predicts the
channel knowledge at a specific location by recovering the corresponding pixel
value in the image matrix. Then, inspired by the reversible and closed-form
structure of the LP, we show its natural suitability for our task in designing
a fast I2I mapping network. For different frequency components of LP
decomposition, we design tailored networks accordingly. Besides, to encode the
global structural information of the propagation environment, we introduce
self-attention and cross-covariance attention mechanisms in different layers,
respectively. Finally, experimental results show that the proposed scheme
outperforms the benchmark, achieving higher reconstruction accuracy while with
lower computational complexity. Moreover, the proposed approach has a strong
generalization ability and can be implemented in different wireless
communication scenarios."
A Zeroth-Order Proximal Algorithm for Consensus Optimization,https://arxiv.org/abs/2406.09816,2024-06-14,2024-06-19,0.0,0.0,"This paper considers a consensus optimization problem, where all the nodes in
a network, with access to the zeroth-order information of its local objective
function only, attempt to cooperatively achieve a common minimizer of the sum
of their local objectives. To address this problem, we develop ZoPro, a
zeroth-order proximal algorithm, which incorporates a zeroth-order oracle for
approximating Hessian and gradient into a recently proposed, high-performance
distributed second-order proximal algorithm. We show that the proposed ZoPro
algorithm, equipped with a dynamic stepsize, converges linearly to a
neighborhood of the optimum in expectation, provided that each local objective
function is strongly convex and smooth. Extensive simulations demonstrate that
ZoPro converges faster than several state-of-the-art distributed zeroth-order
algorithms and outperforms a few distributed second-order algorithms in terms
of running time for reaching given accuracy."
Retrieval Augmented Fact Verification by Synthesizing Contrastive Arguments,https://arxiv.org/abs/2406.09815,2024-06-14,2024-06-19,0.0,0.0,"The rapid propagation of misinformation poses substantial risks to public
interest. To combat misinformation, large language models (LLMs) are adapted to
automatically verify claim credibility. Nevertheless, existing methods heavily
rely on the embedded knowledge within LLMs and / or black-box APIs for evidence
collection, leading to subpar performance with smaller LLMs or upon unreliable
context. In this paper, we propose retrieval augmented fact verification
through the synthesis of contrasting arguments (RAFTS). Upon input claims,
RAFTS starts with evidence retrieval, where we design a retrieval pipeline to
collect and re-rank relevant documents from verifiable sources. Then, RAFTS
forms contrastive arguments (i.e., supporting or refuting) conditioned on the
retrieved evidence. In addition, RAFTS leverages an embedding model to identify
informative demonstrations, followed by in-context prompting to generate the
prediction and explanation. Our method effectively retrieves relevant documents
as evidence and evaluates arguments from varying perspectives, incorporating
nuanced information for fine-grained decision-making. Combined with informative
in-context examples as prior, RAFTS achieves significant improvements to
supervised and LLM baselines without complex prompts. We demonstrate the
effectiveness of our method through extensive experiments, where RAFTS can
outperform GPT-based methods with a significantly smaller 7B LLM."
DeltaPhi - Learning Physical Trajectory Residual for PDE Solving,https://arxiv.org/abs/2406.09795,2024-06-14,2024-06-19,0.0,0.0,"Although neural operator networks theoretically approximate any operator
mapping, the limited generalization capability prevents them from learning
correct physical dynamics when potential data biases exist, particularly in the
practical PDE solving scenario where the available data amount is restricted or
the resolution is extremely low. To address this issue, we propose and
formulate the Physical Trajectory Residual Learning (DeltaPhi), which learns to
predict the physical residuals between the pending solved trajectory and a
known similar auxiliary trajectory. First, we transform the direct operator
mapping between input-output function fields in original training data to
residual operator mapping between input function pairs and output function
residuals. Next, we learn the surrogate model for the residual operator mapping
based on existing neural operator networks. Additionally, we design helpful
customized auxiliary inputs for efficient optimization. Through extensive
experiments, we conclude that, compared to direct learning, physical residual
learning is preferred for PDE solving."
Pcc-tuning - Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity,https://arxiv.org/abs/2406.09790,2024-06-14,2024-06-19,0.0,0.0,"Semantic Textual Similarity (STS) constitutes a critical research direction
in computational linguistics and serves as a key indicator of the encoding
capabilities of embedding models. Driven by advances in pre-trained language
models and contrastive learning techniques, leading sentence representation
methods can already achieved average Spearman's correlation scores of
approximately 86 across seven STS benchmarks in SentEval. However, further
improvements have become increasingly marginal, with no existing method
attaining an average score higher than 87 on these tasks. This paper conducts
an in-depth analysis of this phenomenon and concludes that the upper limit for
Spearman's correlation scores using contrastive learning is 87.5. To transcend
this ceiling, we propose an innovative approach termed Pcc-tuning, which
employs Pearson's correlation coefficient as a loss function to refine model
performance beyond contrastive learning. Experimental results demonstrate that
Pcc-tuning markedly surpasses previous state-of-the-art strategies, raising the
Spearman's correlation score to above 90."
OSPC - Detecting Harmful Memes with Large Language Model as a Catalyst,https://arxiv.org/abs/2406.09779,2024-06-14,2024-06-19,0.0,0.0,"Memes, which rapidly disseminate personal opinions and positions across the
internet, also pose significant challenges in propagating social bias and
prejudice. This study presents a novel approach to detecting harmful memes,
particularly within the multicultural and multilingual context of Singapore.
Our methodology integrates image captioning, Optical Character Recognition
(OCR), and Large Language Model (LLM) analysis to comprehensively understand
and classify harmful memes. Utilizing the BLIP model for image captioning,
PP-OCR and TrOCR for text recognition across multiple languages, and the Qwen
LLM for nuanced language understanding, our system is capable of identifying
harmful content in memes created in English, Chinese, Malay, and Tamil. To
enhance the system's performance, we fine-tuned our approach by leveraging
additional data labeled using GPT-4V, aiming to distill the understanding
capability of GPT-4V for harmful memes to our system. Our framework achieves
top-1 at the public leaderboard of the Online Safety Prize Challenge hosted by
AI Singapore, with the AUROC as 0.7749 and accuracy as 0.7087, significantly
ahead of the other teams. Notably, our approach outperforms previous
benchmarks, with FLAVA achieving an AUROC of 0.5695 and VisualBERT an AUROC of
0.5561."
Research on Edge Detection of LiDAR Images Based on Artificial Intelligence Technology,https://arxiv.org/abs/2406.09773,2024-06-14,2024-06-19,0.0,0.0,"With the widespread application of Light Detection and Ranging (LiDAR)
technology in fields such as autonomous driving, robot navigation, and terrain
mapping, the importance of edge detection in LiDAR images has become
increasingly prominent. Traditional edge detection methods often face
challenges in accuracy and computational complexity when processing LiDAR
images. To address these issues, this study proposes an edge detection method
for LiDAR images based on artificial intelligence technology. This paper first
reviews the current state of research on LiDAR technology and image edge
detection, introducing common edge detection algorithms and their applications
in LiDAR image processing. Subsequently, a deep learning-based edge detection
model is designed and implemented, optimizing the model training process
through preprocessing and enhancement of the LiDAR image dataset. Experimental
results indicate that the proposed method outperforms traditional methods in
terms of detection accuracy and computational efficiency, showing significant
practical application value. Finally, improvement strategies are proposed for
the current method's shortcomings, and the improvements are validated through
experiments."
Towards Efficient Pareto Set Approximation via Mixture of Experts Based Model Fusion,https://arxiv.org/abs/2406.09770,2024-06-14,2024-06-19,0.0,0.0,"Solving multi-objective optimization problems for large deep neural networks
is a challenging task due to the complexity of the loss landscape and the
expensive computational cost of training and evaluating models. Efficient
Pareto front approximation of large models enables multi-objective optimization
for various tasks such as multi-task learning and trade-off analysis. Existing
algorithms for learning Pareto set, including (1) evolutionary, hypernetworks,
and hypervolume-maximization methods, are computationally expensive and have
restricted scalability to large models; (2) Scalarization algorithms, where a
separate model is trained for each objective ray, which is inefficient for
learning the entire Pareto set and fails to capture the objective trade-offs
effectively. Inspired by the recent success of model merging, we propose a
practical and scalable approach to Pareto set learning problem via mixture of
experts (MoE) based model fusion. By ensembling the weights of specialized
single-task models, the MoE module can effectively capture the trade-offs
between multiple objectives and closely approximate the entire Pareto set of
large neural networks. Once the routers are learned and a preference vector is
set, the MoE module can be unloaded, thus no additional computational cost is
introduced during inference. We conduct extensive experiments on vision and
language tasks using large-scale models such as CLIP-ViT and GPT-2. The
experimental results demonstrate that our method efficiently approximates the
entire Pareto front of large models. Using only hundreds of trainable
parameters of the MoE routers, our method even has lower memory usage compared
to linear scalarization and algorithms that learn a single Pareto optimal
solution, and are scalable to both the number of objectives and the size of the
model."
Bayesian Conditioned Diffusion Models for Inverse Problems,https://arxiv.org/abs/2406.09768,2024-06-14,2024-06-19,0.0,0.0,"Diffusion models have recently been shown to excel in many image
reconstruction tasks that involve inverse problems based on a forward
measurement operator. A common framework uses task-agnostic unconditional
models that are later post-conditioned for reconstruction, an approach that
typically suffers from suboptimal task performance. While task-specific
conditional models have also been proposed, current methods heuristically
inject measured data as a naive input channel that elicits sampling
inaccuracies. Here, we address the optimal conditioning of diffusion models for
solving challenging inverse problems that arise during image reconstruction.
Specifically, we propose a novel Bayesian conditioning technique for diffusion
models, BCDM, based on score-functions associated with the conditional
distribution of desired images given measured data. We rigorously derive the
theory to express and train the conditional score-function. Finally, we show
state-of-the-art performance in image dealiasing, deblurring, super-resolution,
and inpainting with the proposed technique."
Application of Natural Language Processing in Financial Risk Detection,https://arxiv.org/abs/2406.09765,2024-06-14,2024-06-19,0.0,0.0,"This paper explores the application of Natural Language Processing (NLP) in
financial risk detection. By constructing an NLP-based financial risk detection
model, this study aims to identify and predict potential risks in financial
documents and communications. First, the fundamental concepts of NLP and its
theoretical foundation, including text mining methods, NLP model design
principles, and machine learning algorithms, are introduced. Second, the
process of text data preprocessing and feature extraction is described.
Finally, the effectiveness and predictive performance of the model are
validated through empirical research. The results show that the NLP-based
financial risk detection model performs excellently in risk identification and
prediction, providing effective risk management tools for financial
institutions. This study offers valuable references for the field of financial
risk management, utilizing advanced NLP techniques to improve the accuracy and
efficiency of financial risk detection."
Towards Full Integration of Artificial Intelligence in Colon Capsule Endoscopy's Pathway,https://arxiv.org/abs/2406.09761,2024-06-14,2024-06-19,0.0,0.0,"Despite recent surge of interest in deploying colon capsule endoscopy (CCE)
for early diagnosis of colorectal diseases, there remains a large gap between
the current state of CCE in clinical practice, and the state of its counterpart
optical colonoscopy (OC). Our study is aimed at closing this gap, by focusing
on the full integration of AI in CCE's pathway, where image processing steps
linked to the detection, localization and characterisation of important
findings are carried out autonomously using various AI algorithms. We developed
a recognition network, that with an impressive sensitivity of 99.9%, a
specificity of 99.4%, and a negative predictive value (NPV) of 99.8%, detected
colorectal polyps. After recognising a polyp within a sequence of images, only
those images containing polyps were fed into two parallel independent networks
for characterisation, and estimation of the size of those important findings.
The characterisation network reached a sensitivity of 82% and a specificity of
80% in classifying polyps to two groups, namely neoplastic vs. non-neoplastic.
The size estimation network reached an accuracy of 88% in correctly segmenting
the polyps. By automatically incorporating this crucial information into CCE's
pathway, we moved a step closer towards the full integration of AI in CCE's
routine clinical practice."
Bootstrapping Language Models with DPO Implicit Rewards,https://arxiv.org/abs/2406.09760,2024-06-14,2024-06-19,0.0,0.0,"Human alignment in large language models (LLMs) is an active area of
research. A recent groundbreaking work, direct preference optimization (DPO),
has greatly simplified the process from past work in reinforcement learning
from human feedback (RLHF) by bypassing the reward learning stage in RLHF. DPO,
after training, provides an implicit reward model. In this work, we make a
novel observation that this implicit reward model can by itself be used in a
bootstrapping fashion to further align the LLM. Our approach is to use the
rewards from a current LLM model to construct a preference dataset, which is
then used in subsequent DPO rounds. We incorporate refinements that debias the
length of the responses and improve the quality of the preference dataset to
further improve our approach. Our approach, named self-alignment with DPO
ImpliCit rEwards (DICE), shows great improvements in alignment and achieves
superior performance than Gemini Pro on AlpacaEval 2, reaching 27.55%
length-controlled win rate against GPT-4 Turbo, but with only 8B parameters and
no external feedback. Our code is available at https://github.com/sail-sg/dice."
Evaluating LLM-driven User-Intent Formalization for Verification-Aware Languages,https://arxiv.org/abs/2406.09757,2024-06-14,2024-06-19,0.0,0.0,"Verification-aware programming languages such as Dafny and F* provide means
to formally specify and prove properties of programs. Although the problem of
checking an implementation against a specification can be defined mechanically,
there is no algorithmic way of ensuring the correctness of the user-intent
formalization for programs -- that a specification adheres to the user's intent
behind the program. The intent or requirement is expressed informally in
natural language and the specification is a formal artefact. The advent of
large language models (LLMs) has made strides bridging the gap between informal
intent and formal program implementations recently, driven in large parts due
to benchmarks and automated metrics for evaluation.
  Recent work has proposed evaluating {\it user-intent formalization} problem
for mainstream programming languages~\cite{endres-fse24}. However, such an
approach does not readily extend to verification-aware languages that support
rich specifications (containing quantifiers and ghost variables) that cannot be
evaluated through dynamic execution. Previous work also required generating
program mutants using LLMs to create the benchmark. We advocate an alternate
approach of {\it symbolically testing specifications} to provide an intuitive
metric for evaluating the quality of specifications for verification-aware
languages. We demonstrate that our automated metric agrees closely with mostly
GPT-4 generated and human-labeled dataset of roughly 150 Dafny specifications
for the popular MBPP code-generation benchmark, yet demonstrates cases where
the human labeling is not perfect. We believe our work provides a stepping
stone to enable the establishment of a benchmark and research agenda for the
problem of user-intent formalization for programs."
CHiSafetyBench - A Chinese Hierarchical Safety Benchmark for Large Language Models,https://arxiv.org/abs/2406.10311,2024-06-14,2024-06-19,0.0,0.0,"With the profound development of large language models(LLMs), their safety
concerns have garnered increasing attention. However, there is a scarcity of
Chinese safety benchmarks for LLMs, and the existing safety taxonomies are
inadequate, lacking comprehensive safety detection capabilities in authentic
Chinese scenarios. In this work, we introduce CHiSafetyBench, a dedicated
safety benchmark for evaluating LLMs' capabilities in identifying risky content
and refusing answering risky questions in Chinese contexts. CHiSafetyBench
incorporates a dataset that covers a hierarchical Chinese safety taxonomy
consisting of 5 risk areas and 31 categories. This dataset comprises two types
of tasks: multiple-choice questions and question-answering, evaluating LLMs
from the perspectives of risk content identification and the ability to refuse
answering risky questions respectively. Utilizing this benchmark, we validate
the feasibility of automatic evaluation as a substitute for human evaluation
and conduct comprehensive automatic safety assessments on mainstream Chinese
LLMs. Our experiments reveal the varying performance of different models across
various safety domains, indicating that all models possess considerable
potential for improvement in Chinese safety capabilities. Our dataset is
publicly available at
https://github.com/UnicomAI/UnicomBenchmark/tree/main/CHiSafetyBench."
ControlVAR - Exploring Controllable Visual Autoregressive Modeling,https://arxiv.org/abs/2406.09750,2024-06-14,2024-06-19,0.0,0.0,"Conditional visual generation has witnessed remarkable progress with the
advent of diffusion models (DMs), especially in tasks like control-to-image
generation. However, challenges such as expensive computational cost, high
inference latency, and difficulties of integration with large language models
(LLMs) have necessitated exploring alternatives to DMs. This paper introduces
ControlVAR, a novel framework that explores pixel-level controls in visual
autoregressive (VAR) modeling for flexible and efficient conditional
generation. In contrast to traditional conditional models that learn the
conditional distribution, ControlVAR jointly models the distribution of image
and pixel-level conditions during training and imposes conditional controls
during testing. To enhance the joint modeling, we adopt the next-scale AR
prediction paradigm and unify control and image representations. A
teacher-forcing guidance strategy is proposed to further facilitate
controllable generation with joint modeling. Extensive experiments demonstrate
the superior efficacy and flexibility of ControlVAR across various conditional
generation tasks against popular conditional DMs, \eg, ControlNet and
T2I-Adaptor. Code: \url{https://github.com/lxa9867/ControlVAR}."
How Does Distribution Matching Help Domain Generalization - An Information-theoretic Analysis,https://arxiv.org/abs/2406.09745,2024-06-14,2024-06-19,0.0,0.0,"Domain generalization aims to learn invariance across multiple training
domains, thereby enhancing generalization against out-of-distribution data.
While gradient or representation matching algorithms have achieved remarkable
success, these methods generally lack generalization guarantees or depend on
strong assumptions, leaving a gap in understanding the underlying mechanism of
distribution matching. In this work, we formulate domain generalization from a
novel probabilistic perspective, ensuring robustness while avoiding overly
conservative solutions. Through comprehensive information-theoretic analysis,
we provide key insights into the roles of gradient and representation matching
in promoting generalization. Our results reveal the complementary relationship
between these two components, indicating that existing works focusing solely on
either gradient or representation alignment are insufficient to solve the
domain generalization problem. In light of these theoretical findings, we
introduce IDM to simultaneously align the inter-domain gradients and
representations. Integrated with the proposed PDM method for complex
distribution matching, IDM achieves superior performance over various baseline
methods."
TEG-DB - A Comprehensive Dataset and Benchmark of Textual-Edge Graphs,https://arxiv.org/abs/2406.10310,2024-06-14,2024-06-19,0.0,0.0,"Text-Attributed Graphs (TAGs) augment graph structures with natural language
descriptions, facilitating detailed depictions of data and their
interconnections across various real-world settings. However, existing TAG
datasets predominantly feature textual information only at the nodes, with
edges typically represented by mere binary or categorical attributes. This lack
of rich textual edge annotations significantly limits the exploration of
contextual relationships between entities, hindering deeper insights into
graph-structured data. To address this gap, we introduce Textual-Edge Graphs
Datasets and Benchmark (TEG-DB), a comprehensive and diverse collection of
benchmark textual-edge datasets featuring rich textual descriptions on nodes
and edges. The TEG-DB datasets are large-scale and encompass a wide range of
domains, from citation networks to social networks. In addition, we conduct
extensive benchmark experiments on TEG-DB to assess the extent to which current
techniques, including pre-trained language models, graph neural networks, and
their combinations, can utilize textual node and edge information. Our goal is
to elicit advancements in textual-edge graph research, specifically in
developing methodologies that exploit rich textual node and edge descriptions
to enhance graph analysis and provide deeper insights into complex real-world
networks. The entire TEG-DB project is publicly accessible as an open-source
repository on Github, accessible at
https://github.com/Zhuofeng-Li/TEG-Benchmark."
Deep Symbolic Optimization for Combinatorial Optimization - Accelerating Node Selection by Discovering Potential Heuristics,https://arxiv.org/abs/2406.09740,2024-06-14,2024-06-19,0.0,0.0,"Combinatorial optimization (CO) is one of the most fundamental mathematical
models in real-world applications. Traditional CO solvers, such as
Branch-and-Bound (B&B) solvers, heavily rely on expert-designed heuristics,
which are reliable but require substantial manual tuning. Recent studies have
leveraged deep learning (DL) models as an alternative to capture rich feature
patterns for improved performance on GPU machines. Nonetheless, the drawbacks
of high training and inference costs, as well as limited interpretability,
severely hinder the adoption of DL methods in real-world applications. To
address these challenges, we propose a novel deep symbolic optimization
learning framework that combines their advantages. Specifically, we focus on
the node selection module within B&B solvers -- namely, deep symbolic
optimization for node selection (Dso4NS). With data-driven approaches, Dso4NS
guides the search for mathematical expressions within the high-dimensional
discrete symbolic space and then incorporates the highest-performing
mathematical expressions into a solver. The data-driven model captures the rich
feature information in the input data and generates symbolic expressions, while
the expressions deployed in solvers enable fast inference with high
interpretability. Experiments demonstrate the effectiveness of Dso4NS in
learning high-quality expressions, outperforming existing approaches on a CPU
machine. Encouragingly, the learned CPU-based policies consistently achieve
performance comparable to state-of-the-art GPU-based approaches."
PixRO - Pixel-Distributed Rotational Odometry with Gaussian Belief Propagation,https://arxiv.org/abs/2406.09726,2024-06-14,2024-06-19,0.0,0.0,"Visual sensors are not only becoming better at capturing high-quality images
but also they have steadily increased their capabilities in processing data on
their own on-chip. Yet the majority of VO pipelines rely on the transmission
and processing of full images in a centralized unit (e.g. CPU or GPU), which
often contain much redundant and low-quality information for the task. In this
paper, we address the task of frame-to-frame rotational estimation but, instead
of reasoning about relative motion between frames using the full images,
distribute the estimation at pixel-level. In this paradigm, each pixel produces
an estimate of the global motion by only relying on local information and local
message-passing with neighbouring pixels. The resulting per-pixel estimates can
then be communicated to downstream tasks, yielding higher-level, informative
cues instead of the original raw pixel-readings. We evaluate the proposed
approach on real public datasets, where we offer detailed insights about this
novel technique and open-source our implementation for the future benefit of
the community."
When Will Gradient Regularization Be Harmful?,https://arxiv.org/abs/2406.09723,2024-06-14,2024-06-19,0.0,0.0,"Gradient regularization (GR), which aims to penalize the gradient norm atop
the loss function, has shown promising results in training modern
over-parameterized deep neural networks. However, can we trust this powerful
technique? This paper reveals that GR can cause performance degeneration in
adaptive optimization scenarios, particularly with learning rate warmup. Our
empirical and theoretical analyses suggest this is due to GR inducing
instability and divergence in gradient statistics of adaptive optimizers at the
initial training stage. Inspired by the warmup heuristic, we propose three GR
warmup strategies, each relaxing the regularization effect to a certain extent
during the warmup course to ensure the accurate and stable accumulation of
gradients. With experiments on Vision Transformer family, we confirm the three
GR warmup strategies can effectively circumvent these issues, thereby largely
improving the model performance. Meanwhile, we note that scalable models tend
to rely more on the GR warmup, where the performance can be improved by up to
3\% on Cifar10 compared to baseline GR. Code is available at
\href{https://github.com/zhaoyang-0204/gnp}{https://github.com/zhaoyang-0204/gnp}."
Cross-view geo-localization - a survey,https://arxiv.org/abs/2406.09722,2024-06-14,2024-06-19,0.0,0.0,"Cross-view geo-localization has garnered notable attention in the realm of
computer vision, spurred by the widespread availability of copious geotagged
datasets and the advancements in machine learning techniques. This paper
provides a thorough survey of cutting-edge methodologies, techniques, and
associated challenges that are integral to this domain, with a focus on
feature-based and deep learning strategies. Feature-based methods capitalize on
unique features to establish correspondences across disparate viewpoints,
whereas deep learning-based methodologies deploy convolutional neural networks
to embed view-invariant attributes. This work also delineates the multifaceted
challenges encountered in cross-view geo-localization, such as variations in
viewpoints and illumination, the occurrence of occlusions, and it elucidates
innovative solutions that have been formulated to tackle these issues.
Furthermore, we delineate benchmark datasets and relevant evaluation metrics,
and also perform a comparative analysis of state-of-the-art techniques.
Finally, we conclude the paper with a discussion on prospective avenues for
future research and the burgeoning applications of cross-view geo-localization
in an intricately interconnected global landscape."
Self-Knowledge Distillation for Learning Ambiguity,https://arxiv.org/abs/2406.09719,2024-06-14,2024-06-19,0.0,0.0,"Recent language models have shown remarkable performance on natural language
understanding (NLU) tasks. However, they are often sub-optimal when faced with
ambiguous samples that can be interpreted in multiple ways, over-confidently
predicting a single label without consideration for its correctness. To address
this issue, we propose a novel self-knowledge distillation method that enables
models to learn label distributions more accurately by leveraging knowledge
distilled from their lower layers. This approach also includes a learning phase
that re-calibrates the unnecessarily strengthened confidence for training
samples judged as extremely ambiguous based on the distilled distribution
knowledge. We validate our method on diverse NLU benchmark datasets and the
experimental results demonstrate its effectiveness in producing better label
distributions. Particularly, through the process of re-calibrating the
confidence for highly ambiguous samples, the issue of over-confidence when
predictions for unseen samples do not match with their ground-truth labels has
been significantly alleviated. This has been shown to contribute to generating
better distributions than the existing state-of-the-art method. Moreover, our
method is more efficient in training the models compared to the existing
method, as it does not involve additional training processes to refine label
distributions."
UniBridge - A Unified Approach to Cross-Lingual Transfer Learning for Low-Resource Languages,https://arxiv.org/abs/2406.09717,2024-06-14,2024-06-19,0.0,0.0,"In this paper, we introduce UniBridge (Cross-Lingual Transfer Learning with
Optimized Embeddings and Vocabulary), a comprehensive approach developed to
improve the effectiveness of Cross-Lingual Transfer Learning, particularly in
languages with limited resources. Our approach tackles two essential elements
of a language model: the initialization of embeddings and the optimal
vocabulary size. Specifically, we propose a novel embedding initialization
method that leverages both lexical and semantic alignment for a language. In
addition, we present a method for systematically searching for the optimal
vocabulary size, ensuring a balance between model complexity and linguistic
coverage. Our experiments across multilingual datasets show that our approach
greatly improves the F1-Score in several languages. UniBridge is a robust and
adaptable solution for cross-lingual systems in various languages, highlighting
the significance of initializing embeddings and choosing the right vocabulary
size in cross-lingual environments."
What is the best model? Application-driven Evaluation for Large Language Models,https://arxiv.org/abs/2406.10307,2024-06-14,2024-06-19,0.0,0.0,"General large language models enhanced with supervised fine-tuning and
reinforcement learning from human feedback are increasingly popular in academia
and industry as they generalize foundation models to various practical tasks in
a prompt manner. To assist users in selecting the best model in practical
application scenarios, i.e., choosing the model that meets the application
requirements while minimizing cost, we introduce A-Eval, an application-driven
LLMs evaluation benchmark for general large language models. First, we
categorize evaluation tasks into five main categories and 27 sub-categories
from a practical application perspective. Next, we construct a dataset
comprising 678 question-and-answer pairs through a process of collecting,
annotating, and reviewing. Then, we design an objective and effective
evaluation method and evaluate a series of LLMs of different scales on A-Eval.
Finally, we reveal interesting laws regarding model scale and task difficulty
level and propose a feasible method for selecting the best model. Through
A-Eval, we provide clear empirical and engineer guidance for selecting the best
model, reducing barriers to selecting and using LLMs and promoting their
application and development. Our benchmark is publicly available at
https://github.com/UnicomAI/DataSet/tree/main/TestData/GeneralAbility."
Speed-up of Data Analysis with Kernel Trick in Encrypted Domain,https://arxiv.org/abs/2406.09716,2024-06-14,2024-06-19,0.0,0.0,"Homomorphic encryption (HE) is pivotal for secure computation on encrypted
data, crucial in privacy-preserving data analysis. However, efficiently
processing high-dimensional data in HE, especially for machine learning and
statistical (ML/STAT) algorithms, poses a challenge. In this paper, we present
an effective acceleration method using the kernel method for HE schemes,
enhancing time performance in ML/STAT algorithms within encrypted domains. This
technique, independent of underlying HE mechanisms and complementing existing
optimizations, notably reduces costly HE multiplications, offering near
constant time complexity relative to data dimension. Aimed at accessibility,
this method is tailored for data scientists and developers with limited
cryptography background, facilitating advanced data analysis in secure
environments."
Large language model validity via enhanced conformal prediction methods,https://arxiv.org/abs/2406.09714,2024-06-14,2024-06-19,0.0,0.0,"We develop new conformal inference methods for obtaining validity guarantees
on the output of large language models (LLMs). Prior work in conformal language
modeling identifies a subset of the text that satisfies a high-probability
guarantee of correctness. These methods work by filtering claims from the LLM's
original response if a scoring function evaluated on the claim fails to exceed
a threshold calibrated via split conformal prediction. Existing methods in this
area suffer from two deficiencies. First, the guarantee stated is not
conditionally valid. The trustworthiness of the filtering step may vary based
on the topic of the response. Second, because the scoring function is
imperfect, the filtering step can remove many valuable and accurate claims. We
address both of these challenges via two new conformal methods. First, we
generalize the conditional conformal procedure of Gibbs et al. (2023) in order
to adaptively issue weaker guarantees when they are required to preserve the
utility of the output. Second, we show how to systematically improve the
quality of the scoring function via a novel algorithm for differentiating
through the conditional conformal procedure. We demonstrate the efficacy of our
approach on both synthetic and real-world datasets."
Meta-Learning Loss Functions for Deep Neural Networks,https://arxiv.org/abs/2406.09713,2024-06-14,2024-06-19,0.0,0.0,"Humans can often quickly and efficiently solve complex new learning tasks
given only a small set of examples. In contrast, modern artificially
intelligent systems often require thousands or millions of observations in
order to solve even the most basic tasks. Meta-learning aims to resolve this
issue by leveraging past experiences from similar learning tasks to embed the
appropriate inductive biases into the learning system. Historically methods for
meta-learning components such as optimizers, parameter initializations, and
more have led to significant performance increases. This thesis aims to explore
the concept of meta-learning to improve performance, through the
often-overlooked component of the loss function. The loss function is a vital
component of a learning system, as it represents the primary learning
objective, where success is determined and quantified by the system's ability
to optimize for that objective successfully."
Fine-Grained Urban Flow Inference with Multi-scale Representation Learning,https://arxiv.org/abs/2406.09710,2024-06-14,2024-06-19,0.0,0.0,"Fine-grained urban flow inference (FUFI) is a crucial transportation service
aimed at improving traffic efficiency and safety. FUFI can infer fine-grained
urban traffic flows based solely on observed coarse-grained data. However, most
of existing methods focus on the influence of single-scale static geographic
information on FUFI, neglecting the interactions and dynamic information
between different-scale regions within the city. Different-scale geographical
features can capture redundant information from the same spatial areas. In
order to effectively learn multi-scale information across time and space, we
propose an effective fine-grained urban flow inference model called UrbanMSR,
which uses self-supervised contrastive learning to obtain dynamic multi-scale
representations of neighborhood-level and city-level geographic information,
and fuses multi-scale representations to improve fine-grained accuracy. The
fusion of multi-scale representations enhances fine-grained. We validate the
performance through extensive experiments on three real-world datasets. The
resutls compared with state-of-the-art methods demonstrate the superiority of
the proposed model."
"A Simple, Solid, and Reproducible Baseline for Bridge Bidding AI",https://arxiv.org/abs/2406.10306,2024-06-14,2024-06-19,0.0,0.0,"Contract bridge, a cooperative game characterized by imperfect information
and multi-agent dynamics, poses significant challenges and serves as a critical
benchmark in artificial intelligence (AI) research. Success in this domain
requires agents to effectively cooperate with their partners. This study
demonstrates that an appropriate combination of existing methods can perform
surprisingly well in bridge bidding against WBridge5, a leading benchmark in
the bridge bidding system and a multiple-time World Computer-Bridge
Championship winner. Our approach is notably simple, yet it outperforms the
current state-of-the-art methodologies in this field. Furthermore, we have made
our code and models publicly available as open-source software. This initiative
provides a strong starting foundation for future bridge AI research,
facilitating the development and verification of new strategies and
advancements in the field."
Detecting Response Generation Not Requiring Factual Judgment,https://arxiv.org/abs/2406.09702,2024-06-14,2024-06-19,0.0,0.0,"With the remarkable development of large language models (LLMs), ensuring the
factuality of output has become a challenge. However, having all the contents
of the response with given knowledge or facts is not necessarily a good thing
in dialogues. This study aimed to achieve both attractiveness and factuality in
a dialogue response for which a task was set to predict sentences that do not
require factual correctness judgment such as agreeing, or personal
opinions/feelings. We created a dataset, dialogue dataset annotated with
fact-check-needed label (DDFC), for this task via crowdsourcing, and
classification tasks were performed on several models using this dataset. The
model with the highest classification accuracy could yield about 88% accurate
classification results."
Differentiable Programming for Differential Equations - A Review,https://arxiv.org/abs/2406.09699,2024-06-14,2024-06-19,0.0,0.0,"The differentiable programming paradigm is a cornerstone of modern scientific
computing. It refers to numerical methods for computing the gradient of a
numerical model's output. Many scientific models are based on differential
equations, where differentiable programming plays a crucial role in calculating
model sensitivities, inverting model parameters, and training hybrid models
that combine differential equations with data-driven approaches. Furthermore,
recognizing the strong synergies between inverse methods and machine learning
offers the opportunity to establish a coherent framework applicable to both
fields. Differentiating functions based on the numerical solution of
differential equations is non-trivial. Numerous methods based on a wide variety
of paradigms have been proposed in the literature, each with pros and cons
specific to the type of problem investigated. Here, we provide a comprehensive
review of existing techniques to compute derivatives of numerical solutions of
differential equations. We first discuss the importance of gradients of
solutions of differential equations in a variety of scientific domains. Second,
we lay out the mathematical foundations of the various approaches and compare
them with each other. Third, we cover the computational considerations and
explore the solutions available in modern scientific software. Last but not
least, we provide best-practices and recommendations for practitioners. We hope
that this work accelerates the fusion of scientific models and data, and
fosters a modern approach to scientific modelling."
"ED-sKWS - Early-Decision Spiking Neural Networks for Rapid,and Energy-Efficient Keyword Spotting",https://arxiv.org/abs/2406.12726,2024-06-14,2024-06-19,0.0,0.0,"Keyword Spotting (KWS) is essential in edge computing requiring rapid and
energy-efficient responses. Spiking Neural Networks (SNNs) are well-suited for
KWS for their efficiency and temporal capacity for speech. To further reduce
the latency and energy consumption, this study introduces ED-sKWS, an SNN-based
KWS model with an early-decision mechanism that can stop speech processing and
output the result before the end of speech utterance. Furthermore, we introduce
a Cumulative Temporal (CT) loss that can enhance prediction accuracy at both
the intermediate and final timesteps. To evaluate early-decision performance,
we present the SC-100 dataset including 100 speech commands with beginning and
end timestamp annotation. Experiments on the Google Speech Commands v2 and our
SC-100 datasets show that ED-sKWS maintains competitive accuracy with 61%
timesteps and 52% energy consumption compared to SNN models without
early-decision mechanism, ensuring rapid response and energy efficiency."
An Efficient Approach to Regression Problems with Tensor Neural Networks,https://arxiv.org/abs/2406.09694,2024-06-14,2024-06-19,0.0,0.0,"This paper introduces a tensor neural network (TNN) to address nonparametric
regression problems, leveraging its distinct sub-network structure to
effectively facilitate variable separation and enhance the approximation of
complex, high-dimensional functions. The TNN demonstrates superior performance
compared to conventional Feed-Forward Networks (FFN) and Radial Basis Function
Networks (RBN) in terms of both approximation accuracy and generalization
capacity, even with a comparable number of parameters. A significant innovation
in our approach is the integration of statistical regression and numerical
integration within the TNN framework. This allows for efficient computation of
high-dimensional integrals associated with the regression function and provides
detailed insights into the underlying data structure. Furthermore, we employ
gradient and Laplacian analysis on the regression outputs to identify key
dimensions influencing the predictions, thereby guiding the design of
subsequent experiments. These advancements make TNN a powerful tool for
applications requiring precise high-dimensional data analysis and predictive
modeling."
Unraveling the Mechanics of Learning-Based Demonstration Selection for In-Context Learning,https://arxiv.org/abs/2406.11890,2024-06-14,2024-06-19,0.0,0.0,"Large Language Models (LLMs) have demonstrated impressive in-context learning
(ICL) capabilities from few-shot demonstration exemplars. While recent
learning-based demonstration selection methods have proven beneficial to ICL by
choosing more useful exemplars, their underlying mechanisms are opaque,
hindering efforts to address limitations such as high training costs and poor
generalization across tasks. These methods generally assume the selection
process captures similarities between the exemplar and the target instance,
however, it remains unknown what kinds of similarities are captured and vital
to performing ICL. To dive into this question, we analyze the working
mechanisms of the learning-based demonstration selection methods and
empirically identify two important factors related to similarity measurement:
1) The ability to integrate different levels of task-agnostic text similarities
between the input of exemplars and test cases enhances generalization power
across different tasks. 2) Incorporating task-specific labels when measuring
the similarities significantly improves the performance on each specific task.
We validate these two findings through extensive quantitative and qualitative
analyses across ten datasets and various LLMs. Based on our findings, we
introduce two effective yet simplified exemplar selection methods catering to
task-agnostic and task-specific demands, eliminating the costly LLM inference
overhead."
FreeCtrl - Constructing Control Centers with Feedforward Layers for Learning-Free Controllable Text Generation,https://arxiv.org/abs/2406.09688,2024-06-14,2024-06-19,0.0,0.0,"Controllable text generation (CTG) seeks to craft texts adhering to specific
attributes, traditionally employing learning-based techniques such as training,
fine-tuning, or prefix-tuning with attribute-specific datasets. These
approaches, while effective, demand extensive computational and data resources.
In contrast, some proposed learning-free alternatives circumvent learning but
often yield inferior results, exemplifying the fundamental machine learning
trade-off between computational expense and model efficacy. To overcome these
limitations, we propose FreeCtrl, a learning-free approach that dynamically
adjusts the weights of selected feedforward neural network (FFN) vectors to
steer the outputs of large language models (LLMs). FreeCtrl hinges on the
principle that the weights of different FFN vectors influence the likelihood of
different tokens appearing in the output. By identifying and adaptively
adjusting the weights of attribute-related FFN vectors, FreeCtrl can control
the output likelihood of attribute keywords in the generated content. Extensive
experiments on single- and multi-attribute control reveal that the
learning-free FreeCtrl outperforms other learning-free and learning-based
methods, successfully resolving the dilemma between learning costs and model
performance."
Explainable AI for Comparative Analysis of Intrusion Detection Models,https://arxiv.org/abs/2406.09684,2024-06-14,2024-06-19,0.0,0.0,"Explainable Artificial Intelligence (XAI) has become a widely discussed
topic, the related technologies facilitate better understanding of conventional
black-box models like Random Forest, Neural Networks and etc. However,
domain-specific applications of XAI are still insufficient. To fill this gap,
this research analyzes various machine learning models to the tasks of binary
and multi-class classification for intrusion detection from network traffic on
the same dataset using occlusion sensitivity. The models evaluated include
Linear Regression, Logistic Regression, Linear Support Vector Machine (SVM),
K-Nearest Neighbors (KNN), Random Forest, Decision Trees, and Multi-Layer
Perceptrons (MLP). We trained all models to the accuracy of 90\% on the
UNSW-NB15 Dataset. We found that most classifiers leverage only less than three
critical features to achieve such accuracies, indicating that effective feature
engineering could actually be far more important for intrusion detection than
applying complicated models. We also discover that Random Forest provides the
best performance in terms of accuracy, time efficiency and robustness. Data and
code available at https://github.com/pcwhy/XML-IntrusionDetection.git"
Heterogeneous Federated Learning with Convolutional and Spiking Neural Networks,https://arxiv.org/abs/2406.09680,2024-06-14,2024-06-19,0.0,0.0,"Federated learning (FL) has emerged as a promising paradigm for training
models on decentralized data while safeguarding data privacy. Most existing FL
systems, however, assume that all machine learning models are of the same type,
although it becomes more likely that different edge devices adopt different
types of AI models, including both conventional analogue artificial neural
networks (ANNs) and biologically more plausible spiking neural networks (SNNs).
This diversity empowers the efficient handling of specific tasks and
requirements, showcasing the adaptability and versatility of edge computing
platforms. One main challenge of such heterogeneous FL system lies in
effectively aggregating models from the local devices in a privacy-preserving
manner. To address the above issue, this work benchmarks FL systems containing
both convoluntional neural networks (CNNs) and SNNs by comparing various
aggregation approaches, including federated CNNs, federated SNNs, federated
CNNs for SNNs, federated SNNs for CNNs, and federated CNNs with SNN fusion.
Experimental results demonstrate that the CNN-SNN fusion framework exhibits the
best performance among the above settings on the MNIST dataset. Additionally,
intriguing phenomena of competitive suppression are noted during the
convergence process of multi-model FL."
Optimizing Byte-level Representation for End-to-end ASR,https://arxiv.org/abs/2406.09676,2024-06-14,2024-06-19,0.0,0.0,"We propose a novel approach to optimizing a byte-level representation for
end-to-end automatic speech recognition (ASR). Byte-level representation is
often used by large scale multilingual ASR systems when the character set of
the supported languages is large. The compactness and universality of
byte-level representation allow the ASR models to use smaller output
vocabularies and therefore, provide more flexibility. UTF-8 is a commonly used
byte-level representation for multilingual ASR, but it is not designed to
optimize machine learning tasks directly. By using auto-encoder and vector
quantization, we show that we can optimize a byte-level representation for ASR
and achieve better accuracy. Our proposed framework can incorporate information
from different modalities, and provides an error correction mechanism. In an
English/Mandarin dictation task, we show that a bilingual ASR model built with
this approach can outperform UTF-8 representation by 5% relative in error rate."
Benchmarking Spectral Graph Neural Networks - A Comprehensive Study on Effectiveness and Efficiency,https://arxiv.org/abs/2406.09675,2024-06-14,2024-06-19,0.0,0.0,"With the recent advancements in graph neural networks (GNNs), spectral GNNs
have received increasing popularity by virtue of their specialty in capturing
graph signals in the frequency domain, demonstrating promising capability in
specific tasks. However, few systematic studies have been conducted on
assessing their spectral characteristics. This emerging family of models also
varies in terms of designs and settings, leading to difficulties in comparing
their performance and deciding on the suitable model for specific scenarios,
especially for large-scale tasks. In this work, we extensively benchmark
spectral GNNs with a focus on the frequency perspective. We analyze and
categorize over 30 GNNs with 27 corresponding filters. Then, we implement these
spectral models under a unified framework with dedicated graph computations and
efficient training schemes. Thorough experiments are conducted on the spectral
models with inclusive metrics on effectiveness and efficiency, offering
practical guidelines on evaluating and selecting spectral GNNs with desirable
performance. Our implementation enables application on larger graphs with
comparable performance and less overhead, which is available at:
https://github.com/gdmnl/Spectral-GNN-Benchmark."
Evaluating ChatGPT-4 Vision on Brazil's National Undergraduate Computer Science Exam,https://arxiv.org/abs/2406.09671,2024-06-14,2024-06-19,0.0,0.0,"The recent integration of visual capabilities into Large Language Models
(LLMs) has the potential to play a pivotal role in science and technology
education, where visual elements such as diagrams, charts, and tables are
commonly used to improve the learning experience. This study investigates the
performance of ChatGPT-4 Vision, OpenAI's most advanced visual model at the
time the study was conducted, on the Bachelor in Computer Science section of
Brazil's 2021 National Undergraduate Exam (ENADE). By presenting the model with
the exam's open and multiple-choice questions in their original image format
and allowing for reassessment in response to differing answer keys, we were
able to evaluate the model's reasoning and self-reflecting capabilities in a
large-scale academic assessment involving textual and visual content. ChatGPT-4
Vision significantly outperformed the average exam participant, positioning
itself within the top 10 best score percentile. While it excelled in questions
that incorporated visual elements, it also encountered challenges with question
interpretation, logical reasoning, and visual acuity. The involvement of an
independent expert panel to review cases of disagreement between the model and
the answer key revealed some poorly constructed questions containing vague or
ambiguous statements, calling attention to the critical need for improved
question design in future exams. Our findings suggest that while ChatGPT-4
Vision shows promise in multimodal academic evaluations, human oversight
remains crucial for verifying the model's accuracy and ensuring the fairness of
high-stakes educational exams. The paper's research materials are publicly
available at https://github.com/nabormendonca/gpt-4v-enade-cs-2021."
"A Survey on Large Language Models from General Purpose to Medical Applications - Datasets, Methodologies, and Evaluations",https://arxiv.org/abs/2406.10303,2024-06-14,2024-06-19,0.0,0.0,"Large Language Models (LLMs) have demonstrated surprising performance across
various natural language processing tasks. Recently, medical LLMs enhanced with
domain-specific knowledge have exhibited excellent capabilities in medical
consultation and diagnosis. These models can smoothly simulate doctor-patient
dialogues and provide professional medical advice. Most medical LLMs are
developed through continued training of open-source general LLMs, which require
significantly fewer computational resources than training LLMs from scratch.
Additionally, this approach offers better patient privacy protection than
API-based solutions. Given the above advantages, this survey systematically
summarizes how to train medical LLMs based on open-source general LLMs from a
more fine-grained perspective. It covers (a) how to acquire training corpus and
construct customized medical training sets, (b) how to choose an appropriate
training paradigm, (c) how to choose a suitable evaluation benchmark, and (d)
existing challenges and promising research directions are discussed. This
survey can provide guidance for the development of LLMs focused on various
medical applications, such as medical education, diagnostic planning, and
clinical assistants. Related resources and supplemental information can be
found on the GitHub repository."
New algorithms for sampling and diffusion models,https://arxiv.org/abs/2406.09665,2024-06-14,2024-06-19,0.0,0.0,"Drawing from the theory of stochastic differential equations, we introduce a
novel sampling method for known distributions and a new algorithm for diffusion
generative models with unknown distributions. Our approach is inspired by the
concept of the reverse diffusion process, widely adopted in diffusion
generative models. Additionally, we derive the explicit convergence rate based
on the smooth ODE flow. For diffusion generative models and sampling, we
establish a dimension-free particle approximation convergence result. Numerical
experiments demonstrate the effectiveness of our method. Notably, unlike the
traditional Langevin method, our sampling method does not require any
regularity assumptions about the density function of the target distribution.
Furthermore, we also apply our method to optimization problems."
Temporal Planning via Interval Logic Satisfiability for Autonomous Systems,https://arxiv.org/abs/2406.09661,2024-06-14,2024-06-19,0.0,0.0,"Many automated planning methods and formulations rely on suitably designed
abstractions or simplifications of the constrained dynamics associated with
agents to attain computational scalability. We consider formulations of
temporal planning where intervals are associated with both action and fluent
atoms, and relations between these are given as sentences in Allen's Interval
Logic. We propose a notion of planning graphs that can account for complex
concurrency relations between actions and fluents as a Constraint Programming
(CP) model. We test an implementation of our algorithm on a state-of-the-art
framework for CP and compare it with PDDL 2.1 planners that capture plans
requiring complex concurrent interactions between agents. We demonstrate our
algorithm outperforms existing PDDL 2.1 planners in the case studies. Still,
scalability remains challenging when plans must comply with intricate
concurrent interactions and the sequencing of actions."
Learning Language Structures through Grounding,https://arxiv.org/abs/2406.09662,2024-06-14,2024-06-19,0.0,0.0,"Language is highly structured, with syntactic and semantic structures, to
some extent, agreed upon by speakers of the same language. With implicit or
explicit awareness of such structures, humans can learn and use language
efficiently and generalize to sentences that contain unseen words. Motivated by
human language learning, in this dissertation, we consider a family of machine
learning tasks that aim to learn language structures through grounding. We seek
distant supervision from other data sources (i.e., grounds), including but not
limited to other modalities (e.g., vision), execution results of programs, and
other languages.
  We demonstrate the potential of this task formulation and advocate for its
adoption through three schemes. In Part I, we consider learning syntactic
parses through visual grounding. We propose the task of visually grounded
grammar induction, present the first models to induce syntactic structures from
visually grounded text and speech, and find that the visual grounding signals
can help improve the parsing quality over language-only models. As a side
contribution, we propose a novel evaluation metric that enables the evaluation
of speech parsing without text or automatic speech recognition systems
involved. In Part II, we propose two execution-aware methods to map sentences
into corresponding semantic structures (i.e., programs), significantly
improving compositional generalization and few-shot program synthesis. In Part
III, we propose methods that learn language structures from annotations in
other languages. Specifically, we propose a method that sets a new state of the
art on cross-lingual word alignment. We then leverage the learned word
alignments to improve the performance of zero-shot cross-lingual dependency
parsing, by proposing a novel substructure-based projection method that
preserves structural knowledge learned from the source language."
ScaLES - Scalable Latent Exploration Score for Pre-Trained Generative Networks,https://arxiv.org/abs/2406.09657,2024-06-14,2024-06-19,0.0,0.0,"We develop Scalable Latent Exploration Score (ScaLES) to mitigate
over-exploration in Latent Space Optimization (LSO), a popular method for
solving black-box discrete optimization problems. LSO utilizes continuous
optimization within the latent space of a Variational Autoencoder (VAE) and is
known to be susceptible to over-exploration, which manifests in unrealistic
solutions that reduce its practicality. ScaLES is an exact and theoretically
motivated method leveraging the trained decoder's approximation of the data
distribution. ScaLES can be calculated with any existing decoder, e.g. from a
VAE, without additional training, architectural changes, or access to the
training data. Our evaluation across five LSO benchmark tasks and three VAE
architectures demonstrates that ScaLES enhances the quality of the solutions
while maintaining high objective values, leading to improvements over existing
solutions. We believe that new avenues to LSO will be opened by ScaLES ability
to identify out of distribution areas, differentiability, and computational
tractability. Open source code for ScaLES is available at
https://github.com/OmerRonen/scales."
RSEND - Retinex-based Squeeze and Excitation Network with Dark Region Detection for Efficient Low Light Image Enhancement,https://arxiv.org/abs/2406.09656,2024-06-14,2024-06-19,0.0,0.0,"Images captured under low-light scenarios often suffer from low quality.
Previous CNN-based deep learning methods often involve using Retinex theory.
Nevertheless, most of them cannot perform well in more complicated datasets
like LOL-v2 while consuming too much computational resources. Besides, some of
these methods require sophisticated training at different stages, making the
procedure even more time-consuming and tedious. In this paper, we propose a
more accurate, concise, and one-stage Retinex theory based framework, RSEND.
RSEND first divides the low-light image into the illumination map and
reflectance map, then captures the important details in the illumination map
and performs light enhancement. After this step, it refines the enhanced
gray-scale image and does element-wise matrix multiplication with the
reflectance map. By denoising the output it has from the previous step, it
obtains the final result. In all the steps, RSEND utilizes Squeeze and
Excitation network to better capture the details. Comprehensive quantitative
and qualitative experiments show that our Efficient Retinex model significantly
outperforms other CNN-based models, achieving a PSNR improvement ranging from
0.44 dB to 4.2 dB in different datasets and even outperforms transformer-based
models in the LOL-v2-real dataset."
Coralai - Intrinsic Evolution of Embodied Neural Cellular Automata Ecosystems,https://arxiv.org/abs/2406.09654,2024-06-14,2024-06-19,0.0,0.0,"This paper presents Coralai, a framework for exploring diverse ecosystems of
Neural Cellular Automata (NCA). Organisms in Coralai utilize modular,
GPU-accelerated Taichi kernels to interact, enact environmental changes, and
evolve through local survival, merging, and mutation operations implemented
with HyperNEAT and PyTorch. We provide an exploratory experiment implementing
physics inspired by slime mold behavior showcasing the emergence of competition
between sessile and mobile organisms, cycles of resource depletion and
recovery, and symbiosis between diverse organisms. We conclude by outlining
future work to discover simulation parameters through measures of multi-scale
complexity and diversity. Code for Coralai is available at
https://github.com/aidanbx/coralai , video demos are available at
https://www.youtube.com/watch?v=NL8IZQY02-8 ."
An Intrinsic Vector Heat Network,https://arxiv.org/abs/2406.09648,2024-06-14,2024-06-19,0.0,0.0,"Vector fields are widely used to represent and model flows for many science
and engineering applications. This paper introduces a novel neural network
architecture for learning tangent vector fields that are intrinsically defined
on manifold surfaces embedded in 3D. Previous approaches to learning vector
fields on surfaces treat vectors as multi-dimensional scalar fields, using
traditional scalar-valued architectures to process channels individually, thus
fail to preserve fundamental intrinsic properties of the vector field. The core
idea of this work is to introduce a trainable vector heat diffusion module to
spatially propagate vector-valued feature data across the surface, which we
incorporate into our proposed architecture that consists of vector-valued
neurons. Our architecture is invariant to rigid motion of the input, isometric
deformation, and choice of local tangent bases, and is robust to
discretizations of the surface. We evaluate our Vector Heat Network on triangle
meshes, and empirically validate its invariant properties. We also demonstrate
the effectiveness of our method on the useful industrial application of
quadrilateral mesh generation."
A Survey of Video Datasets for Grounded Event Understanding,https://arxiv.org/abs/2406.09646,2024-06-14,2024-06-19,0.0,0.0,"While existing video benchmarks largely consider specialized downstream tasks
like retrieval or question-answering (QA), contemporary multimodal AI systems
must be capable of well-rounded common-sense reasoning akin to human visual
understanding. A critical component of human temporal-visual perception is our
ability to identify and cognitively model ""things happening"", or events.
Historically, video benchmark tasks have implicitly tested for this ability
(e.g., video captioning, in which models describe visual events with natural
language), but they do not consider video event understanding as a task in
itself. Recent work has begun to explore video analogues to textual event
extraction but consists of competing task definitions and datasets limited to
highly specific event types. Therefore, while there is a rich domain of
event-centric video research spanning the past 10+ years, it is unclear how
video event understanding should be framed and what resources we have to study
it. In this paper, we survey 105 video datasets that require event
understanding capability, consider how they contribute to the study of robust
event understanding in video, and assess proposed video event extraction tasks
in the context of this body of research. We propose suggestions informed by
this survey for dataset curation and task framing, with an emphasis on the
uniquely temporal nature of video events and ambiguity in visual content."
Reinforced Decoder - Towards Training Recurrent Neural Networks for Time Series Forecasting,https://arxiv.org/abs/2406.09643,2024-06-14,2024-06-19,0.0,0.0,"Recurrent neural network-based sequence-to-sequence models have been
extensively applied for multi-step-ahead time series forecasting. These models
typically involve a decoder trained using either its previous forecasts or the
actual observed values as the decoder inputs. However, relying on
self-generated predictions can lead to the rapid accumulation of errors over
multiple steps, while using the actual observations introduces exposure bias as
these values are unavailable during the extrapolation stage. In this regard,
this study proposes a novel training approach called reinforced decoder, which
introduces auxiliary models to generate alternative decoder inputs that remain
accessible when extrapolating. Additionally, a reinforcement learning algorithm
is utilized to dynamically select the optimal inputs to improve accuracy.
Comprehensive experiments demonstrate that our approach outperforms
representative training methods over several datasets. Furthermore, the
proposed approach also exhibits promising performance when generalized to
self-attention-based sequence-to-sequence forecasting models."
TGB 2.0 - A Benchmark for Learning on Temporal Knowledge Graphs and Heterogeneous Graphs,https://arxiv.org/abs/2406.09639,2024-06-14,2024-06-19,0.0,0.0,"Multi-relational temporal graphs are powerful tools for modeling real-world
data, capturing the evolving and interconnected nature of entities over time.
Recently, many novel models are proposed for ML on such graphs intensifying the
need for robust evaluation and standardized benchmark datasets. However, the
availability of such resources remains scarce and evaluation faces added
complexity due to reproducibility issues in experimental protocols. To address
these challenges, we introduce Temporal Graph Benchmark 2.0 (TGB 2.0), a novel
benchmarking framework tailored for evaluating methods for predicting future
links on Temporal Knowledge Graphs and Temporal Heterogeneous Graphs with a
focus on large-scale datasets, extending the Temporal Graph Benchmark. TGB 2.0
facilitates comprehensive evaluations by presenting eight novel datasets
spanning five domains with up to 53 million edges. TGB 2.0 datasets are
significantly larger than existing datasets in terms of number of nodes, edges,
or timestamps. In addition, TGB 2.0 provides a reproducible and realistic
evaluation pipeline for multi-relational temporal graphs. Through extensive
experimentation, we observe that 1) leveraging edge-type information is crucial
to obtain high performance, 2) simple heuristic baselines are often competitive
with more complex methods, 3) most methods fail to run on our largest datasets,
highlighting the need for research on more scalable methods."
RASPNet - A Benchmark Dataset for Radar Adaptive Signal Processing Applications,https://arxiv.org/abs/2406.09638,2024-06-14,2024-06-19,0.0,0.0,"This work presents a large-scale dataset for radar adaptive signal processing
(RASP) applications, aimed at supporting the development of data-driven models
within the radar community. The dataset, called RASPNet, consists of 100
realistic scenarios compiled over a variety of topographies and land types from
across the contiguous United States, designed to reflect a diverse array of
real-world environments. Within each scenario, RASPNet consists of 10,000
clutter realizations from an airborne radar setting, which can be utilized for
radar algorithm development and evaluation. RASPNet intends to fill a prominent
gap in the availability of a large-scale, realistic dataset that standardizes
the evaluation of adaptive radar processing techniques. We describe its
construction, organization, and several potential applications, which includes
a transfer learning example to demonstrate how RASPNet can be leveraged for
realistic adaptive radar processing scenarios."
Muharaf - Manuscripts of Handwritten Arabic Dataset for Cursive Text Recognition,https://arxiv.org/abs/2406.09630,2024-06-13,2024-06-19,0.0,0.0,"We present the Manuscripts of Handwritten Arabic~(Muharaf) dataset, which is
a machine learning dataset consisting of more than 1,600 historic handwritten
page images transcribed by experts in archival Arabic. Each document image is
accompanied by spatial polygonal coordinates of its text lines as well as basic
page elements. This dataset was compiled to advance the state of the art in
handwritten text recognition (HTR), not only for Arabic manuscripts but also
for cursive text in general. The Muharaf dataset includes diverse handwriting
styles and a wide range of document types, including personal letters, diaries,
notes, poems, church records, and legal correspondences. In this paper, we
describe the data acquisition pipeline, notable dataset features, and
statistics. We also provide a preliminary baseline result achieved by training
convolutional neural networks using this data."
RobustSAM - Segment Anything Robustly on Degraded Images,https://arxiv.org/abs/2406.09627,2024-06-13,2024-06-19,0.0,0.0,"Segment Anything Model (SAM) has emerged as a transformative approach in
image segmentation, acclaimed for its robust zero-shot segmentation
capabilities and flexible prompting system. Nonetheless, its performance is
challenged by images with degraded quality. Addressing this limitation, we
propose the Robust Segment Anything Model (RobustSAM), which enhances SAM's
performance on low-quality images while preserving its promptability and
zero-shot generalization. Our method leverages the pre-trained SAM model with
only marginal parameter increments and computational requirements. The
additional parameters of RobustSAM can be optimized within 30 hours on eight
GPUs, demonstrating its feasibility and practicality for typical research
laboratories. We also introduce the Robust-Seg dataset, a collection of 688K
image-mask pairs with different degradations designed to train and evaluate our
model optimally. Extensive experiments across various segmentation tasks and
datasets confirm RobustSAM's superior performance, especially under zero-shot
conditions, underscoring its potential for extensive real-world application.
Additionally, our method has been shown to effectively improve the performance
of SAM-based downstream tasks such as single image dehazing and deblurring."
Multi-Modal Retrieval For Large Language Model Based Speech Recognition,https://arxiv.org/abs/2406.09618,2024-06-13,2024-06-19,0.0,0.0,"Retrieval is a widely adopted approach for improving language models
leveraging external information. As the field moves towards multi-modal large
language models, it is important to extend the pure text based methods to
incorporate other modalities in retrieval as well for applications across the
wide spectrum of machine learning tasks and data types. In this work, we
propose multi-modal retrieval with two approaches: kNN-LM and cross-attention
techniques. We demonstrate the effectiveness of our retrieval approaches
empirically by applying them to automatic speech recognition tasks with access
to external information. Under this setting, we show that speech-based
multi-modal retrieval outperforms text based retrieval, and yields up to 50 %
improvement in word error rate over the multi-modal language model baseline.
Furthermore, we achieve state-of-the-art recognition results on the
Spoken-Squad question answering dataset."
Multimodal Large Language Models with Fusion Low Rank Adaptation for Device Directed Speech Detection,https://arxiv.org/abs/2406.09617,2024-06-13,2024-06-19,0.0,0.0,"Although Large Language Models (LLMs) have shown promise for human-like
conversations, they are primarily pre-trained on text data. Incorporating audio
or video improves performance, but collecting large-scale multimodal data and
pre-training multimodal LLMs is challenging. To this end, we propose a Fusion
Low Rank Adaptation (FLoRA) technique that efficiently adapts a pre-trained
unimodal LLM to consume new, previously unseen modalities via low rank
adaptation. For device-directed speech detection, using FLoRA, the multimodal
LLM achieves 22% relative reduction in equal error rate (EER) over the
text-only approach and attains performance parity with its full fine-tuning
(FFT) counterpart while needing to tune only a fraction of its parameters.
Furthermore, with the newly introduced adapter dropout, FLoRA is robust to
missing data, improving over FFT by 20% lower EER and 56% lower false accept
rate. The proposed approach scales well for model sizes from 16M to 3B
parameters."
Trainability issues in quantum policy gradients,https://arxiv.org/abs/2406.09614,2024-06-13,2024-06-19,0.0,0.0,"This research explores the trainability of Parameterized Quantum
circuit-based policies in Reinforcement Learning, an area that has recently
seen a surge in empirical exploration. While some studies suggest improved
sample complexity using quantum gradient estimation, the efficient trainability
of these policies remains an open question. Our findings reveal significant
challenges, including standard Barren Plateaus with exponentially small
gradients and gradient explosion. These phenomena depend on the type of
basis-state partitioning and mapping these partitions onto actions. For a
polynomial number of actions, a trainable window can be ensured with a
polynomial number of measurements if a contiguous-like partitioning of
basis-states is employed. These results are empirically validated in a
multi-armed bandit environment."
Automated Molecular Concept Generation and Labeling with Large Language Models,https://arxiv.org/abs/2406.09612,2024-06-13,2024-06-19,0.0,0.0,"Artificial intelligence (AI) is significantly transforming scientific
research. Explainable AI methods, such as concept-based models (CMs), are
promising for driving new scientific discoveries because they make predictions
based on meaningful concepts and offer insights into the prediction process. In
molecular science, however, explainable CMs are not as common compared to
black-box models like Graph Neural Networks (GNNs), primarily due to their
requirement for predefined concepts and manual label for each instance, which
demand domain knowledge and can be labor-intensive. This paper introduces a
novel framework for Automated Molecular Concept (AutoMolCo) generation and
labeling. AutoMolCo leverages the knowledge in Large Language Models (LLMs) to
automatically generate predictive molecular concepts and label them for each
molecule. Such procedures are repeated through iterative interactions with LLMs
to refine concepts, enabling simple linear models on the refined concepts to
outperform GNNs and LLM in-context learning on several benchmarks. The whole
AutoMolCo framework is automated without any human knowledge inputs in either
concept generation, labeling, or refinement, thereby surpassing the limitations
of extant CMs while maintaining their explainability and allowing easy
intervention. Through systematic experiments on MoleculeNet and High-Throughput
Experimentation (HTE) datasets, we demonstrate that the AutoMolCo-induced
explainable CMs are beneficial and promising for molecular science research."
Cross-Modality Program Representation Learning for Electronic Design Automation with High-Level Synthesis,https://arxiv.org/abs/2406.09606,2024-06-13,2024-06-19,0.0,0.0,"In recent years, domain-specific accelerators (DSAs) have gained popularity
for applications such as deep learning and autonomous driving. To facilitate
DSA designs, programmers use high-level synthesis (HLS) to compile a high-level
description written in C/C++ into a design with low-level hardware description
languages that eventually synthesize DSAs on circuits. However, creating a
high-quality HLS design still demands significant domain knowledge,
particularly in microarchitecture decisions expressed as \textit{pragmas}.
Thus, it is desirable to automate such decisions with the help of machine
learning for predicting the quality of HLS designs, requiring a deeper
understanding of the program that consists of original code and pragmas.
Naturally, these programs can be considered as sequence data. In addition,
these programs can be compiled and converted into a control data flow graph
(CDFG). But existing works either fail to leverage both modalities or combine
the two in shallow or coarse ways. We propose ProgSG, a model that allows
interaction between the source code sequence modality and the graph modality in
a deep and fine-grained way. To alleviate the scarcity of labeled designs, a
pre-training method is proposed based on a suite of compiler's data flow
analysis tasks. Experimental results show that ProgSG reduces the RMSE of
design performance predictions by up to $22\%$, and identifies designs with an
average of $1.10\times$ and $1.26\times$ (up to $8.17\times$ and $13.31\times$)
performance improvement in design space exploration (DSE) task compared to HARP
and AutoDSE, respectively."
On Value Iteration Convergence in Connected MDPs,https://arxiv.org/abs/2406.09592,2024-06-13,2024-06-19,0.0,0.0,"This paper establishes that an MDP with a unique optimal policy and ergodic
associated transition matrix ensures the convergence of various versions of the
Value Iteration algorithm at a geometric rate that exceeds the discount factor
{\gamma} for both discounted and average-reward criteria."
Color Equivariant Network,https://arxiv.org/abs/2406.09588,2024-06-13,2024-06-19,0.0,0.0,"Group equivariant convolutional neural networks have been designed for a
variety of geometric transformations from 2D and 3D rotation groups, to
semi-groups such as scale. Despite the improved interpretability, accuracy and
generalizability afforded by these architectures, group equivariant networks
have seen limited application in the context of perceptual quantities such as
hue and saturation, even though their variation can lead to significant
reductions in classification performance. In this paper, we introduce
convolutional neural networks equivariant to variations in hue and saturation
by design. To achieve this, we leverage the observation that hue and saturation
transformations can be identified with the 2D rotation and 1D translation
groups respectively. Our hue-, saturation-, and fully color-equivariant
networks achieve equivariance to these perceptual transformations without an
increase in network parameters. We demonstrate the utility of our networks on
synthetic and real world datasets where color and lighting variations are
commonplace."
Hyperdimensional Quantum Factorization,https://arxiv.org/abs/2406.11889,2024-06-13,2024-06-19,0.0,0.0,"This paper presents a quantum algorithm for efficiently decoding
hypervectors, a crucial process in extracting atomic elements from hypervectors
- an essential task in Hyperdimensional Computing (HDC) models for
interpretable learning and information retrieval. HDC employs high-dimensional
vectors and efficient operators to encode and manipulate information,
representing complex objects from atomic concepts. When one attempts to decode
a hypervector that is the product (binding) of multiple hypervectors, the
factorization becomes prohibitively costly with classical optimization-based
methods and specialized recurrent networks, an inherent consequence of the
binding operation. We propose HDQF, an innovative quantum computing approach,
to address this challenge. By exploiting parallels between HDC and quantum
computing and capitalizing on quantum algorithms' speedup capabilities, HDQF
encodes potential factors as a quantum superposition using qubit states and
bipolar vector representation. This yields a quadratic speedup over classical
search methods and effectively mitigates Hypervector Factorization capacity
issues."
A Review of 315 Benchmark and Test Functions for Machine Learning Optimization Algorithms and Metaheuristics with Mathematical and Visual Descriptions,https://arxiv.org/abs/2406.09581,2024-06-13,2024-06-19,0.0,0.0,"In the rapidly evolving optimization and metaheuristics domains, the efficacy
of algorithms is crucially determined by the benchmark (test) functions. While
several functions have been developed and derived over the past decades, little
information is available on the mathematical and visual description, range of
suitability, and applications of many such functions. To bridge this knowledge
gap, this review provides an exhaustive survey of more than 300 benchmark
functions used in the evaluation of optimization and metaheuristics algorithms.
This review first catalogs benchmark and test functions based on their
characteristics, complexity, properties, visuals, and domain implications to
offer a wide view that aids in selecting appropriate benchmarks for various
algorithmic challenges. This review also lists the 25 most commonly used
functions in the open literature and proposes two new, highly dimensional,
dynamic and challenging functions that could be used for testing new
algorithms. Finally, this review identifies gaps in current benchmarking
practices and suggests directions for future research."
Improving Consistency Models with Generator-Induced Coupling,https://arxiv.org/abs/2406.09570,2024-06-13,2024-06-19,0.0,0.0,"Consistency models are promising generative models as they distill the
multi-step sampling of score-based diffusion in a single forward pass of a
neural network. Without access to sampling trajectories of a pre-trained
diffusion model, consistency training relies on proxy trajectories built on an
independent coupling between the noise and data distributions. Refining this
coupling is a key area of improvement to make it more adapted to the task and
reduce the resulting randomness in the training process. In this work, we
introduce a novel coupling associating the input noisy data with their
generated output from the consistency model itself, as a proxy to the
inaccessible diffusion flow output. Our affordable approach exploits the
inherent capacity of consistency models to compute the transport map in a
single step. We provide intuition and empirical evidence of the relevance of
our generator-induced coupling (GC), which brings consistency training closer
to score distillation. Consequently, our method not only accelerates
consistency training convergence by significant amounts but also enhances the
resulting performance. The code is available at:
https://github.com/thibautissenhuth/consistency_GC."
Speech ReaLLM -- Real-time Streaming Speech Recognition with Multimodal LLMs by Teaching the Flow of Time,https://arxiv.org/abs/2406.09569,2024-06-13,2024-06-19,0.0,0.0,"We introduce Speech ReaLLM, a new ASR architecture that marries
""decoder-only"" ASR with the RNN-T to make multimodal LLM architectures capable
of real-time streaming. This is the first ""decoder-only"" ASR architecture
designed to handle continuous audio without explicit end-pointing. Speech
ReaLLM is a special case of the more general ReaLLM (""real-time LLM"") approach,
also introduced here for the first time. The idea is inspired by RNN-T: Instead
of generating a response only at the end of a user prompt, generate after every
input token received in real time (it is often empty). On Librispeech ""test"",
an 80M Speech ReaLLM achieves WERs of 3.0% and 7.4% in real time (without an
external LM or auxiliary loss). This is only slightly above a 3x larger
Attention-Encoder-Decoder baseline. We also show that this way, an LLM
architecture can learn to represent and reproduce the flow of time; and that a
pre-trained 7B LLM can be fine-tuned to do reasonably well on this task."
Causal Fine-Tuning and Effect Calibration of Non-Causal Predictive Models,https://arxiv.org/abs/2406.09567,2024-06-13,2024-06-19,0.0,0.0,"This paper proposes techniques to enhance the performance of non-causal
models for causal inference using data from randomized experiments. In domains
like advertising, customer retention, and precision medicine, non-causal models
that predict outcomes under no intervention are often used to score individuals
and rank them according to the expected effectiveness of an intervention (e.g,
an ad, a retention incentive, a nudge). However, these scores may not perfectly
correspond to intervention effects due to the inherent non-causal nature of the
models. To address this limitation, we propose causal fine-tuning and effect
calibration, two techniques that leverage experimental data to refine the
output of non-causal models for different causal tasks, including effect
estimation, effect ordering, and effect classification. They are underpinned by
two key advantages. First, they can effectively integrate the predictive
capabilities of general non-causal models with the requirements of a causal
task in a specific context, allowing decision makers to support diverse causal
applications with a ""foundational"" scoring model. Second, through simulations
and an empirical example, we demonstrate that they can outperform the
alternative of building a causal-effect model from scratch, particularly when
the available experimental data is limited and the non-causal scores already
capture substantial information about the relative sizes of causal effects.
Overall, this research underscores the practical advantages of combining
experimental data with non-causal models to support causal applications."
Towards Domain Adaptive Neural Contextual Bandits,https://arxiv.org/abs/2406.09564,2024-06-13,2024-06-19,0.0,0.0,"Contextual bandit algorithms are essential for solving real-world decision
making problems. In practice, collecting a contextual bandit's feedback from
different domains may involve different costs. For example, measuring drug
reaction from mice (as a source domain) and humans (as a target domain).
Unfortunately, adapting a contextual bandit algorithm from a source domain to a
target domain with distribution shift still remains a major challenge and
largely unexplored. In this paper, we introduce the first general domain
adaptation method for contextual bandits. Our approach learns a bandit model
for the target domain by collecting feedback from the source domain. Our
theoretical analysis shows that our algorithm maintains a sub-linear regret
bound even adapting across domains. Empirical results show that our approach
outperforms the state-of-the-art contextual bandit algorithms on real-world
datasets."
e-COP  - Episodic Constrained Optimization of Policies,https://arxiv.org/abs/2406.09563,2024-06-13,2024-06-19,0.0,0.0,"In this paper, we present the $\texttt{e-COP}$ algorithm, the first policy
optimization algorithm for constrained Reinforcement Learning (RL) in episodic
(finite horizon) settings. Such formulations are applicable when there are
separate sets of optimization criteria and constraints on a system's behavior.
We approach this problem by first establishing a policy difference lemma for
the episodic setting, which provides the theoretical foundation for the
algorithm. Then, we propose to combine a set of established and novel solution
ideas to yield the $\texttt{e-COP}$ algorithm that is easy to implement and
numerically stable, and provide a theoretical guarantee on optimality under
certain scaling assumptions. Through extensive empirical analysis using
benchmarks in the Safety Gym suite, we show that our algorithm has similar or
better performance than SoTA (non-episodic) algorithms adapted for the episodic
setting. The scalability of the algorithm opens the door to its application in
safety-constrained Reinforcement Learning from Human Feedback for Large
Language or Diffusion Models."
Label Noise Robustness for Domain-Agnostic Fair Corrections via Nearest Neighbors Label Spreading,https://arxiv.org/abs/2406.09561,2024-06-13,2024-06-19,0.0,0.0,"Last-layer retraining methods have emerged as an efficient framework for
correcting existing base models. Within this framework, several methods have
been proposed to deal with correcting models for subgroup fairness with and
without group membership information. Importantly, prior work has demonstrated
that many methods are susceptible to noisy labels. To this end, we propose a
drop-in correction for label noise in last-layer retraining, and demonstrate
that it achieves state-of-the-art worst-group accuracy for a broad range of
symmetric label noise and across a wide variety of datasets exhibiting spurious
correlations. Our proposed approach uses label spreading on a latent nearest
neighbors graph and has minimal computational overhead compared to existing
methods."
Decoding the Diversity - A Review of the Indic AI Research Landscape,https://arxiv.org/abs/2406.09559,2024-06-13,2024-06-19,0.0,0.0,"This review paper provides a comprehensive overview of large language model
(LLM) research directions within Indic languages. Indic languages are those
spoken in the Indian subcontinent, including India, Pakistan, Bangladesh, Sri
Lanka, Nepal, and Bhutan, among others. These languages have a rich cultural
and linguistic heritage and are spoken by over 1.5 billion people worldwide.
With the tremendous market potential and growing demand for natural language
processing (NLP) based applications in diverse languages, generative
applications for Indic languages pose unique challenges and opportunities for
research. Our paper deep dives into the recent advancements in Indic generative
modeling, contributing with a taxonomy of research directions, tabulating 84
recent publications. Research directions surveyed in this paper include LLM
development, fine-tuning existing LLMs, development of corpora, benchmarking
and evaluation, as well as publications around specific techniques, tools, and
applications. We found that researchers across the publications emphasize the
challenges associated with limited data availability, lack of standardization,
and the peculiar linguistic complexities of Indic languages. This work aims to
serve as a valuable resource for researchers and practitioners working in the
field of NLP, particularly those focused on Indic languages, and contributes to
the development of more accurate and efficient LLM applications for these
languages."
$S^3$ -- Semantic Signal Separation,https://arxiv.org/abs/2406.09556,2024-06-13,2024-06-19,0.0,0.0,"Topic models are useful tools for discovering latent semantic structures in
large textual corpora. Topic modeling historically relied on bag-of-words
representations of language. This approach makes models sensitive to the
presence of stop words and noise, and does not utilize potentially useful
contextual information. Recent efforts have been oriented at incorporating
contextual neural representations in topic modeling and have been shown to
outperform classical topic models. These approaches are, however, typically
slow, volatile and still require preprocessing for optimal results. We present
Semantic Signal Separation ($S^3$), a theory-driven topic modeling approach in
neural embedding spaces. $S^3$ conceptualizes topics as independent axes of
semantic space, and uncovers these with blind-source separation. Our approach
provides the most diverse, highly coherent topics, requires no preprocessing,
and is demonstrated to be the fastest contextually sensitive topic model to
date. We offer an implementation of $S^3$, among other approaches, in the
Turftopic Python package."
My Body My Choice - Human-Centric Full-Body Anonymization,https://arxiv.org/abs/2406.09553,2024-06-13,2024-06-19,0.0,0.0,"In an era of increasing privacy concerns for our online presence, we propose
that the decision to appear in a piece of content should only belong to the
owner of the body. Although some automatic approaches for full-body
anonymization have been proposed, human-guided anonymization can adapt to
various contexts, such as cultural norms, personal relations, esthetic
concerns, and security issues. ''My Body My Choice'' (MBMC) enables physical
and adversarial anonymization by removal and swapping approaches aimed for four
tasks, designed by single or multi, ControlNet or GAN modules, combining
several diffusion models. We evaluate anonymization on seven datasets; compare
with SOTA inpainting and anonymization methods; evaluate by image, adversarial,
and generative metrics; and conduct reidentification experiments."
Embedding machine-learnt sub-grid variability improves climate model biases,https://arxiv.org/abs/2406.09551,2024-06-13,2024-06-19,0.0,0.0,"The under-representation of cloud formation is a long-standing bias
associated with climate simulations. Parameterisation schemes are required to
capture cloud processes within current climate models but have known biases. We
overcome these biases by embedding a Multi-Output Gaussian Process (MOGP)
trained on high resolution Unified Model simulations to represent the
variability of temperature and specific humidity within a climate model. A
trained MOGP model is coupled in-situ with a simplified Atmospheric General
Circulation Model named SPEEDY. The temperature and specific humidity profiles
of SPEEDY are perturbed at fixed intervals according to the variability
predicted from the MOGP. Ten-year predictions are generated for both control
and ML-hybrid models. The hybrid model reduces the global precipitation bias by
18\% and over the tropics by 22\%. To further understand the drivers of these
improvements, physical quantities of interest are explored, such as the
distribution of lifted index values and the alteration of the Hadley cell. The
control and hybrid set-ups are also run in a plus 4K sea-surface temperature
experiment to explore the effects of the approach on patterns relating to cloud
cover and precipitation in a warmed climate setting."
Exploring Syntactic Patterns in Urdu - A Deep Dive into Dependency Analysis,https://arxiv.org/abs/2406.09549,2024-06-13,2024-06-19,0.0,0.0,"Parsing is the process of analyzing a sentence's syntactic structure by
breaking it down into its grammatical components. and is critical for various
linguistic applications. Urdu is a low-resource, free word-order language and
exhibits complex morphology. Literature suggests that dependency parsing is
well-suited for such languages. Our approach begins with a basic feature model
encompassing word location, head word identification, and dependency relations,
followed by a more advanced model integrating part-of-speech (POS) tags and
morphological attributes (e.g., suffixes, gender). We manually annotated a
corpus of news articles of varying complexity. Using Maltparser and the
NivreEager algorithm, we achieved a best-labeled accuracy (LA) of 70% and an
unlabeled attachment score (UAS) of 84%, demonstrating the feasibility of
dependency parsing for Urdu."
Between Randomness and Arbitrariness - Some Lessons for Reliable Machine Learning at Scale,https://arxiv.org/abs/2406.09548,2024-06-13,2024-06-19,0.0,0.0,"To develop rigorous knowledge about ML models -- and the systems in which
they are embedded -- we need reliable measurements. But reliable measurement is
fundamentally challenging, and touches on issues of reproducibility,
scalability, uncertainty quantification, epistemology, and more. This
dissertation addresses criteria needed to take reliability seriously: both
criteria for designing meaningful metrics, and for methodologies that ensure
that we can dependably and efficiently measure these metrics at scale and in
practice. In doing so, this dissertation articulates a research vision for a
new field of scholarship at the intersection of machine learning, law, and
policy. Within this frame, we cover topics that fit under three different
themes: (1) quantifying and mitigating sources of arbitrariness in ML, (2)
taming randomness in uncertainty estimation and optimization algorithms, in
order to achieve scalability without sacrificing reliability, and (3) providing
methods for evaluating generative-AI systems, with specific focuses on
quantifying memorization in language models and training latent diffusion
models on open-licensed data. By making contributions in these three themes,
this dissertation serves as an empirical proof by example that research on
reliable measurement for machine learning is intimately and inescapably bound
up with research in law and policy. These different disciplines pose similar
research questions about reliable measurement in machine learning. They are, in
fact, two complementary sides of the same research vision, which, broadly
construed, aims to construct machine-learning systems that cohere with broader
societal values."
FLea - Addressing Data Scarcity and Label Skew in Federated Learning via Privacy-preserving Feature Augmentation,https://arxiv.org/abs/2406.09547,2024-06-13,2024-06-19,0.0,0.0,"Federated Learning (FL) enables model development by leveraging data
distributed across numerous edge devices without transferring local data to a
central server. However, existing FL methods still face challenges when dealing
with scarce and label-skewed data across devices, resulting in local model
overfitting and drift, consequently hindering the performance of the global
model. In response to these challenges, we propose a pioneering framework
called FLea, incorporating the following key components: i) A global feature
buffer that stores activation-target pairs shared from multiple clients to
support local training. This design mitigates local model drift caused by the
absence of certain classes; ii) A feature augmentation approach based on local
and global activation mix-ups for local training. This strategy enlarges the
training samples, thereby reducing the risk of local overfitting; iii) An
obfuscation method to minimize the correlation between intermediate activations
and the source data, enhancing the privacy of shared features. To verify the
superiority of FLea, we conduct extensive experiments using a wide range of
data modalities, simulating different levels of local data scarcity and label
skew. The results demonstrate that FLea consistently outperforms
state-of-the-art FL counterparts (among 13 of the experimented 18 settings, the
improvement is over 5% while concurrently mitigating the privacy
vulnerabilities associated with shared features. Code is available at
https://github.com/XTxiatong/FLea.git."
Neural logic programs and neural nets,https://arxiv.org/abs/2406.11888,2024-06-13,2024-06-19,0.0,0.0,"Neural-symbolic integration aims to combine the connectionist subsymbolic
with the logical symbolic approach to artificial intelligence. In this paper,
we first define the answer set semantics of (boolean) neural nets and then
introduce from first principles a class of neural logic programs and show that
nets and programs are equivalent."
CircuitVAE - Efficient and Scalable Latent Circuit Optimization,https://arxiv.org/abs/2406.09535,2024-06-13,2024-06-19,0.0,0.0,"Automatically designing fast and space-efficient digital circuits is
challenging because circuits are discrete, must exactly implement the desired
logic, and are costly to simulate. We address these challenges with CircuitVAE,
a search algorithm that embeds computation graphs in a continuous space and
optimizes a learned surrogate of physical simulation by gradient descent. By
carefully controlling overfitting of the simulation surrogate and ensuring
diverse exploration, our algorithm is highly sample-efficient, yet gracefully
scales to large problem instances and high sample budgets. We test CircuitVAE
by designing binary adders across a large range of sizes, IO timing
constraints, and sample budgets. Our method excels at designing large circuits,
where other algorithms struggle: compared to reinforcement learning and genetic
algorithms, CircuitVAE typically finds 64-bit adders which are smaller and
faster using less than half the sample budget. We also find CircuitVAE can
design state-of-the-art adders in a real-world chip, demonstrating that our
method can outperform commercial tools in a realistic setting."
FeatNavigator - Automatic Feature Augmentation on Tabular Data,https://arxiv.org/abs/2406.09534,2024-06-13,2024-06-19,0.0,0.0,"Data-centric AI focuses on understanding and utilizing high-quality, relevant
data in training machine learning (ML) models, thereby increasing the
likelihood of producing accurate and useful results. Automatic feature
augmentation, aiming to augment the initial base table with useful features
from other tables, is critical in data preparation as it improves model
performance, robustness, and generalizability. While recent works have
investigated automatic feature augmentation, most of them have limited
capabilities in utilizing all useful features as many of them are in candidate
tables not directly joinable with the base table. Worse yet, with numerous join
paths leading to these distant features, existing solutions fail to fully
exploit them within a reasonable compute budget. We present FeatNavigator, an
effective and efficient framework that explores and integrates high-quality
features in relational tables for ML models. FeatNavigator evaluates a feature
from two aspects: (1) the intrinsic value of a feature towards an ML task
(i.e., feature importance) and (2) the efficacy of a join path connecting the
feature to the base table (i.e., integration quality). FeatNavigator
strategically selects a small set of available features and their corresponding
join paths to train a feature importance estimation model and an integration
quality prediction model. Furthermore, FeatNavigator's search algorithm
exploits both estimated feature importance and integration quality to identify
the optimized feature augmentation plan. Our experimental results show that
FeatNavigator outperforms state-of-the-art solutions on five public datasets by
up to 40.1% in ML model performance."
Differentiable Reasoning about Knowledge Graphs with Region-based Graph Neural Networks,https://arxiv.org/abs/2406.09529,2024-06-13,2024-06-19,0.0,0.0,"Methods for knowledge graph (KG) completion need to capture semantic
regularities and use these regularities to infer plausible knowledge that is
not explicitly stated. Most embedding-based methods are opaque in the kinds of
regularities they can capture, although region-based KG embedding models have
emerged as a more transparent alternative. By modeling relations as geometric
regions in high-dimensional vector spaces, such models can explicitly capture
semantic regularities in terms of the spatial arrangement of these regions.
Unfortunately, existing region-based approaches are severely limited in the
kinds of rules they can capture. We argue that this limitation arises because
the considered regions are defined as the Cartesian product of two-dimensional
regions. As an alternative, in this paper, we propose RESHUFFLE, a simple model
based on ordering constraints that can faithfully capture a much larger class
of rule bases than existing approaches. Moreover, the embeddings in our
framework can be learned by a monotonic Graph Neural Network (GNN), which
effectively acts as a differentiable rule base. This approach has the important
advantage that embeddings can be easily updated as new knowledge is added to
the KG. At the same time, since the resulting representations can be used
similarly to standard KG embeddings, our approach is significantly more
efficient than existing approaches to differentiable reasoning."
A Systematic Review of Generative AI for Teaching and Learning Practice,https://arxiv.org/abs/2406.09520,2024-06-13,2024-06-19,0.0,0.0,"The use of generative artificial intelligence (GenAI) in academia is a
subjective and hotly debated topic. Currently, there are no agreed guidelines
towards the usage of GenAI systems in higher education (HE) and, thus, it is
still unclear how to make effective use of the technology for teaching and
learning practice. This paper provides an overview of the current state of
research on GenAI for teaching and learning in HE. To this end, this study
conducted a systematic review of relevant studies indexed by Scopus, using the
preferred reporting items for systematic reviews and meta-analyses (PRISMA)
guidelines. The search criteria revealed a total of 625 research papers, of
which 355 met the final inclusion criteria. The findings from the review showed
the current state and the future trends in documents, citations, document
sources/authors, keywords, and co-authorship. The research gaps identified
suggest that while some authors have looked at understanding the detection of
AI-generated text, it may be beneficial to understand how GenAI can be
incorporated into supporting the educational curriculum for assessments,
teaching, and learning delivery. Furthermore, there is a need for additional
interdisciplinary, multidimensional studies in HE through collaboration. This
will strengthen the awareness and understanding of students, tutors, and other
stakeholders, which will be instrumental in formulating guidelines, frameworks,
and policies for GenAI usage."
Talking Heads - Understanding Inter-layer Communication in Transformer Language Models,https://arxiv.org/abs/2406.09519,2024-06-13,2024-06-19,0.0,0.0,"Although it is known that transformer language models (LMs) pass features
from early layers to later layers, it is not well understood how this
information is represented and routed by the model. By analyzing particular
mechanism LMs use to accomplish this, we find that it is also used to recall
items from a list, and show that this mechanism can explain an otherwise
arbitrary-seeming sensitivity of the model to the order of items in the prompt.
Specifically, we find that models write into low-rank subspaces of the residual
stream to represent features which are then read out by specific later layers,
forming low-rank communication channels between layers. By decomposing
attention head weight matrices with the Singular Value Decomposition (SVD), we
find that previously described interactions between heads separated by one or
more layers can be predicted via analysis of their weight matrices. We show
that it is possible to manipulate the internal model representations as well as
edit model weights based on the mechanism we discover in order to significantly
improve performance on our synthetic Laundry List task, which requires recall
from a list, often improving task accuracy by over 20%. Our analysis reveals a
surprisingly intricate interpretable structure learned from language model
pretraining, and helps us understand why sophisticated LMs sometimes fail in
simple domains, facilitating future analysis of more complex behaviors."
Fair GLASSO - Estimating Fair Graphical Models with Unbiased Statistical Behavior,https://arxiv.org/abs/2406.09513,2024-06-13,2024-06-19,0.0,0.0,"We propose estimating Gaussian graphical models (GGMs) that are fair with
respect to sensitive nodal attributes. Many real-world models exhibit unfair
discriminatory behavior due to biases in data. Such discrimination is known to
be exacerbated when data is equipped with pairwise relationships encoded in a
graph. Additionally, the effect of biased data on graphical models is largely
underexplored. We thus introduce fairness for graphical models in the form of
two bias metrics to promote balance in statistical similarities across nodal
groups with different sensitive attributes. Leveraging these metrics, we
present Fair GLASSO, a regularized graphical lasso approach to obtain sparse
Gaussian precision matrices with unbiased statistical dependencies across
groups. We also propose an efficient proximal gradient algorithm to obtain the
estimates. Theoretically, we express the tradeoff between fair and accurate
estimated precision matrices. Critically, this includes demonstrating when
accuracy can be preserved in the presence of a fairness regularizer. On top of
this, we study the complexity of Fair GLASSO and demonstrate that our algorithm
enjoys a fast convergence rate. Our empirical validation includes synthetic and
real-world simulations that illustrate the value and effectiveness of our
proposed optimization problem and iterative algorithm."
CleanDiffuser - An Easy-to-use Modularized Library for Diffusion Models in Decision Making,https://arxiv.org/abs/2406.09509,2024-06-13,2024-06-19,0.0,0.0,"Leveraging the powerful generative capability of diffusion models (DMs) to
build decision-making agents has achieved extensive success. However, there is
still a demand for an easy-to-use and modularized open-source library that
offers customized and efficient development for DM-based decision-making
algorithms. In this work, we introduce CleanDiffuser, the first DM library
specifically designed for decision-making algorithms. By revisiting the roles
of DMs in the decision-making domain, we identify a set of essential
sub-modules that constitute the core of CleanDiffuser, allowing for the
implementation of various DM algorithms with simple and flexible building
blocks. To demonstrate the reliability and flexibility of CleanDiffuser, we
conduct comprehensive evaluations of various DM algorithms implemented with
CleanDiffuser across an extensive range of tasks. The analytical experiments
provide a wealth of valuable design choices and insights, reveal opportunities
and challenges, and lay a solid groundwork for future research. CleanDiffuser
will provide long-term support to the decision-making community, enhancing
reproducibility and fostering the development of more robust solutions. The
code and documentation of CleanDiffuser are open-sourced on the
https://github.com/CleanDiffuserTeam/CleanDiffuser."
You are what you eat? Feeding foundation models a regionally diverse food dataset of World Wide Dishes,https://arxiv.org/abs/2406.09496,2024-06-13,2024-06-19,0.0,0.0,"Foundation models are increasingly ubiquitous in our daily lives, used in
everyday tasks such as text-image searches, interactions with chatbots, and
content generation. As use increases, so does concern over the disparities in
performance and fairness of these models for different people in different
parts of the world. To assess these growing regional disparities, we present
World Wide Dishes, a mixed text and image dataset consisting of 765 dishes,
with dish names collected in 131 local languages. World Wide Dishes has been
collected purely through human contribution and decentralised means, by
creating a website widely distributed through social networks. Using the
dataset, we demonstrate a novel means of operationalising capability and
representational biases in foundation models such as language models and
text-to-image generative models. We enrich these studies with a pilot community
review to understand, from a first-person perspective, how these models
generate images for people in five African countries and the United States.
  We find that these models generally do not produce quality text and image
outputs of dishes specific to different regions. This is true even for the US,
which is typically considered to be more well-resourced in training data -
though the generation of US dishes does outperform that of the investigated
African countries. The models demonstrate a propensity to produce outputs that
are inaccurate as well as culturally misrepresentative, flattening, and
insensitive. These failures in capability and representational bias have the
potential to further reinforce stereotypes and disproportionately contribute to
erasure based on region. The dataset and code are available at
https://github.com/oxai/world-wide-dishes/."
An Image is Worth More Than 16x16 Patches - Exploring Transformers on Individual Pixels,https://arxiv.org/abs/2406.09415,2024-06-13,2024-06-19,0.0,0.0,"This work does not introduce a new method. Instead, we present an interesting
finding that questions the necessity of the inductive bias -- locality in
modern computer vision architectures. Concretely, we find that vanilla
Transformers can operate by directly treating each individual pixel as a token
and achieve highly performant results. This is substantially different from the
popular design in Vision Transformer, which maintains the inductive bias from
ConvNets towards local neighborhoods (e.g. by treating each 16x16 patch as a
token). We mainly showcase the effectiveness of pixels-as-tokens across three
well-studied tasks in computer vision: supervised learning for object
classification, self-supervised learning via masked autoencoding, and image
generation with diffusion models. Although directly operating on individual
pixels is less computationally practical, we believe the community must be
aware of this surprising piece of knowledge when devising the next generation
of neural architectures for computer vision."
Rethinking Score Distillation as a Bridge Between Image Distributions,https://arxiv.org/abs/2406.09417,2024-06-13,2024-06-19,0.0,0.0,"Score distillation sampling (SDS) has proven to be an important tool,
enabling the use of large-scale diffusion priors for tasks operating in
data-poor domains. Unfortunately, SDS has a number of characteristic artifacts
that limit its usefulness in general-purpose applications. In this paper, we
make progress toward understanding the behavior of SDS and its variants by
viewing them as solving an optimal-cost transport path from a source
distribution to a target distribution. Under this new interpretation, these
methods seek to transport corrupted images (source) to the natural image
distribution (target). We argue that current methods' characteristic artifacts
are caused by (1) linear approximation of the optimal path and (2) poor
estimates of the source distribution. We show that calibrating the text
conditioning of the source distribution can produce high-quality generation and
translation results with little extra overhead. Our method can be easily
applied across many domains, matching or beating the performance of specialized
methods. We demonstrate its utility in text-to-2D, text-based NeRF
optimization, translating paintings to real images, optical illusion
generation, and 3D sketch-to-real. We compare our method to existing approaches
for score distillation sampling and show that it can produce high-frequency
details with realistic colors."
Interpreting the Weight Space of Customized Diffusion Models,https://arxiv.org/abs/2406.09413,2024-06-13,2024-06-19,0.0,0.0,"We investigate the space of weights spanned by a large collection of
customized diffusion models. We populate this space by creating a dataset of
over 60,000 models, each of which is a base model fine-tuned to insert a
different person's visual identity. We model the underlying manifold of these
weights as a subspace, which we term weights2weights. We demonstrate three
immediate applications of this space -- sampling, editing, and inversion.
First, as each point in the space corresponds to an identity, sampling a set of
weights from it results in a model encoding a novel identity. Next, we find
linear directions in this space corresponding to semantic edits of the identity
(e.g., adding a beard). These edits persist in appearance across generated
samples. Finally, we show that inverting a single image into this space
reconstructs a realistic identity, even if the input image is out of
distribution (e.g., a painting). Our results indicate that the weight space of
fine-tuned diffusion models behaves as an interpretable latent space of
identities."
Explore the Limits of Omni-modal Pretraining at Scale,https://arxiv.org/abs/2406.09412,2024-06-13,2024-06-19,0.0,0.0,"We propose to build omni-modal intelligence, which is capable of
understanding any modality and learning universal representations. In specific,
we propose a scalable pretraining paradigm, named Multimodal Context (MiCo),
which can scale up the numbers of modalities and amount of data, together with
the model parameters, in the pretraining process. With MiCo, the pretrained
models show significant emergent abilities in multimodal learning, which are
evaluated on the following tasks: i) single-modality perception benchmarks of
10 different modalities, ii) 25 cross-modality understanding tasks of
retrieval, question-answering, captioning, and iii) 18 multimodal large
language model benchmarks. Our models establish 37 new records for
state-of-the-art performance. We hope that our research could contribute to the
development of omni-modal intelligence. Code and Models are at
https://github.com/invictus717/MiCo"
MuirBench - A Comprehensive Benchmark for Robust Multi-image Understanding,https://arxiv.org/abs/2406.09411,2024-06-13,2024-06-19,0.0,0.0,"We introduce MuirBench, a comprehensive benchmark that focuses on robust
multi-image understanding capabilities of multimodal LLMs. MuirBench consists
of 12 diverse multi-image tasks (e.g., scene understanding, ordering) that
involve 10 categories of multi-image relations (e.g., multiview, temporal
relations). Comprising 11,264 images and 2,600 multiple-choice questions,
MuirBench is created in a pairwise manner, where each standard instance is
paired with an unanswerable variant that has minimal semantic differences, in
order for a reliable assessment. Evaluated upon 20 recent multi-modal LLMs, our
results reveal that even the best-performing models like GPT-4o and Gemini Pro
find it challenging to solve MuirBench, achieving 68.0% and 49.3% in accuracy.
Open-source multimodal LLMs trained on single images can hardly generalize to
multi-image questions, hovering below 33.3% in accuracy. These results
highlight the importance of MuirBench in encouraging the community to develop
multimodal LLMs that can look beyond a single image, suggesting potential
pathways for future improvements."
Scene Graph Generation in Large-Size VHR Satellite Imagery - A Large-Scale Dataset and A Context-Aware Approach,https://arxiv.org/abs/2406.09410,2024-06-13,2024-06-19,0.0,0.0,"Scene graph generation (SGG) in satellite imagery (SAI) benefits promoting
understanding of geospatial scenarios from perception to cognition. In SAI,
objects exhibit great variations in scales and aspect ratios, and there exist
rich relationships between objects (even between spatially disjoint objects),
which makes it attractive to holistically conduct SGG in large-size
very-high-resolution (VHR) SAI. However, there lack such SGG datasets. Due to
the complexity of large-size SAI, mining triplets <subject, relationship,
object> heavily relies on long-range contextual reasoning. Consequently, SGG
models designed for small-size natural imagery are not directly applicable to
large-size SAI. This paper constructs a large-scale dataset for SGG in
large-size VHR SAI with image sizes ranging from 512 x 768 to 27,860 x 31,096
pixels, named STAR (Scene graph generaTion in lArge-size satellite imageRy),
encompassing over 210K objects and over 400K triplets. To realize SGG in
large-size SAI, we propose a context-aware cascade cognition (CAC) framework to
understand SAI regarding object detection (OBD), pair pruning and relationship
prediction for SGG. We also release a SAI-oriented SGG toolkit with about 30
OBD and 10 SGG methods which need further adaptation by our devised modules on
our challenging STAR dataset. The dataset and toolkit are available at:
https://linlin-dev.github.io/project/STAR."
Data Attribution for Text-to-Image Models by Unlearning Synthesized Images,https://arxiv.org/abs/2406.09408,2024-06-13,2024-06-19,0.0,0.0,"The goal of data attribution for text-to-image models is to identify the
training images that most influence the generation of a new image. We can
define ""influence"" by saying that, for a given output, if a model is retrained
from scratch without that output's most influential images, the model should
then fail to generate that output image. Unfortunately, directly searching for
these influential images is computationally infeasible, since it would require
repeatedly retraining from scratch. We propose a new approach that efficiently
identifies highly-influential images. Specifically, we simulate unlearning the
synthesized image, proposing a method to increase the training loss on the
output image, without catastrophic forgetting of other, unrelated concepts.
Then, we find training images that are forgotten by proxy, identifying ones
with significant loss deviations after the unlearning process, and label these
as influential. We evaluate our method with a computationally intensive but
""gold-standard"" retraining from scratch and demonstrate our method's advantages
over previous methods."
4M-21 - An Any-to-Any Vision Model for Tens of Tasks and Modalities,https://arxiv.org/abs/2406.09406,2024-06-13,2024-06-19,0.0,0.0,"Current multimodal and multitask foundation models like 4M or UnifiedIO show
promising results, but in practice their out-of-the-box abilities to accept
diverse inputs and perform diverse tasks are limited by the (usually rather
small) number of modalities and tasks they are trained on. In this paper, we
expand upon the capabilities of them by training a single model on tens of
highly diverse modalities and by performing co-training on large-scale
multimodal datasets and text corpora. This includes training on several
semantic and geometric modalities, feature maps from recent state of the art
models like DINOv2 and ImageBind, pseudo labels of specialist models like SAM
and 4DHumans, and a range of new modalities that allow for novel ways to
interact with the model and steer the generation, for example image metadata or
color palettes. A crucial step in this process is performing discrete
tokenization on various modalities, whether they are image-like, neural network
feature maps, vectors, structured data like instance segmentation or human
poses, or data that can be represented as text. Through this, we expand on the
out-of-the-box capabilities of multimodal models and specifically show the
possibility of training one model to solve at least 3x more tasks/modalities
than existing ones and doing so without a loss in performance. This enables
more fine-grained and controllable multimodal generation capabilities and
allows us to study the distillation of models trained on diverse data and
objectives into a unified model. We successfully scale the training to a three
billion parameter model using tens of modalities and different datasets. The
resulting models and training code are open sourced at 4m.epfl.ch."
Why Warmup the Learning Rate? Underlying Mechanisms and Improvements,https://arxiv.org/abs/2406.09405,2024-06-13,2024-06-19,0.0,0.0,"It is common in deep learning to warm up the learning rate $\eta$, often by a
linear schedule between $\eta_{\text{init}} = 0$ and a predetermined target
$\eta_{\text{trgt}}$. In this paper, we show through systematic experiments
using SGD and Adam that the overwhelming benefit of warmup arises from allowing
the network to tolerate larger $\eta_{\text{trgt}}$ by forcing the network to
more well-conditioned areas of the loss landscape. The ability to handle larger
$\eta_{\text{trgt}}$ makes hyperparameter tuning more robust while improving
the final performance. We uncover different regimes of operation during the
warmup period, depending on whether training starts off in a progressive
sharpening or sharpness reduction phase, which in turn depends on the
initialization and parameterization. Using these insights, we show how
$\eta_{\text{init}}$ can be properly chosen by utilizing the loss catapult
mechanism, which saves on the number of warmup steps, in some cases completely
eliminating the need for warmup. We also suggest an initialization for the
variance in Adam which provides benefits similar to warmup."
ConsistDreamer - 3D-Consistent 2D Diffusion for High-Fidelity Scene Editing,https://arxiv.org/abs/2406.09404,2024-06-13,2024-06-19,0.0,0.0,"This paper proposes ConsistDreamer - a novel framework that lifts 2D
diffusion models with 3D awareness and 3D consistency, thus enabling
high-fidelity instruction-guided scene editing. To overcome the fundamental
limitation of missing 3D consistency in 2D diffusion models, our key insight is
to introduce three synergetic strategies that augment the input of the 2D
diffusion model to become 3D-aware and to explicitly enforce 3D consistency
during the training process. Specifically, we design surrounding views as
context-rich input for the 2D diffusion model, and generate 3D-consistent,
structured noise instead of image-independent noise. Moreover, we introduce
self-supervised consistency-enforcing training within the per-scene editing
procedure. Extensive evaluation shows that our ConsistDreamer achieves
state-of-the-art performance for instruction-guided scene editing across
various scenes and editing instructions, particularly in complicated
large-scale indoor scenes from ScanNet++, with significantly improved sharpness
and fine-grained textures. Notably, ConsistDreamer stands as the first work
capable of successfully editing complex (e.g., plaid/checkered) patterns. Our
project page is at immortalco.github.io/ConsistDreamer."
Visual Sketchpad - Sketching as a Visual Chain of Thought for Multimodal Language Models,https://arxiv.org/abs/2406.09403,2024-06-13,2024-06-19,0.0,0.0,"Humans draw to facilitate reasoning: we draw auxiliary lines when solving
geometry problems; we mark and circle when reasoning on maps; we use sketches
to amplify our ideas and relieve our limited-capacity working memory. However,
such actions are missing in current multimodal language models (LMs). Current
chain-of-thought and tool-use paradigms only use text as intermediate reasoning
steps. In this work, we introduce Sketchpad, a framework that gives multimodal
LMs a visual sketchpad and tools to draw on the sketchpad. The LM conducts
planning and reasoning according to the visual artifacts it has drawn.
Different from prior work, which uses text-to-image models to enable LMs to
draw, Sketchpad enables LMs to draw with lines, boxes, marks, etc., which is
closer to human sketching and better facilitates reasoning. Sketchpad can also
use specialist vision models during the sketching process (e.g., draw bounding
boxes with object detection models, draw masks with segmentation models), to
further enhance visual perception and reasoning. We experiment with a wide
range of math tasks (including geometry, functions, graphs, and chess) and
complex visual reasoning tasks. Sketchpad substantially improves performance on
all tasks over strong base models with no sketching, yielding an average gain
of 12.7% on math tasks, and 8.6% on vision tasks. GPT-4o with Sketchpad sets a
new state of the art on all tasks, including V*Bench (80.3%), BLINK spatial
reasoning (83.9%), and visual correspondence (80.8%). All codes and data are in
https://visualsketchpad.github.io/."
MMScan - A Multi-Modal 3D Scene Dataset with Hierarchical Grounded Language Annotations,https://arxiv.org/abs/2406.09401,2024-06-13,2024-06-19,0.0,0.0,"With the emergence of LLMs and their integration with other data modalities,
multi-modal 3D perception attracts more attention due to its connectivity to
the physical world and makes rapid progress. However, limited by existing
datasets, previous works mainly focus on understanding object properties or
inter-object spatial relationships in a 3D scene. To tackle this problem, this
paper builds the first largest ever multi-modal 3D scene dataset and benchmark
with hierarchical grounded language annotations, MMScan. It is constructed
based on a top-down logic, from region to object level, from a single target to
inter-target relationships, covering holistic aspects of spatial and attribute
understanding. The overall pipeline incorporates powerful VLMs via carefully
designed prompts to initialize the annotations efficiently and further involve
humans' correction in the loop to ensure the annotations are natural, correct,
and comprehensive. Built upon existing 3D scanning data, the resulting
multi-modal 3D dataset encompasses 1.4M meta-annotated captions on 109k objects
and 7.7k regions as well as over 3.04M diverse samples for 3D visual grounding
and question-answering benchmarks. We evaluate representative baselines on our
benchmarks, analyze their capabilities in different aspects, and showcase the
key problems to be addressed in the future. Furthermore, we use this
high-quality dataset to train state-of-the-art 3D visual grounding and LLMs and
obtain remarkable performance improvement both on existing benchmarks and
in-the-wild evaluation. Codes, datasets, and benchmarks will be available at
https://github.com/OpenRobotLab/EmbodiedScan."
Instruct 4D-to-4D - Editing 4D Scenes as Pseudo-3D Scenes Using 2D Diffusion,https://arxiv.org/abs/2406.09402,2024-06-13,2024-06-19,0.0,0.0,"This paper proposes Instruct 4D-to-4D that achieves 4D awareness and
spatial-temporal consistency for 2D diffusion models to generate high-quality
instruction-guided dynamic scene editing results. Traditional applications of
2D diffusion models in dynamic scene editing often result in inconsistency,
primarily due to their inherent frame-by-frame editing methodology. Addressing
the complexities of extending instruction-guided editing to 4D, our key insight
is to treat a 4D scene as a pseudo-3D scene, decoupled into two sub-problems:
achieving temporal consistency in video editing and applying these edits to the
pseudo-3D scene. Following this, we first enhance the Instruct-Pix2Pix (IP2P)
model with an anchor-aware attention module for batch processing and consistent
editing. Additionally, we integrate optical flow-guided appearance propagation
in a sliding window fashion for more precise frame-to-frame editing and
incorporate depth-based projection to manage the extensive data of pseudo-3D
scenes, followed by iterative editing to achieve convergence. We extensively
evaluate our approach in various scenes and editing instructions, and
demonstrate that it achieves spatially and temporally consistent editing
results, with significantly enhanced detail and sharpness over the prior art.
Notably, Instruct 4D-to-4D is general and applicable to both monocular and
challenging multi-camera scenes. Code and more results are available at
immortalco.github.io/Instruct-4D-to-4D."
Aligning Vision Models with Human Aesthetics in Retrieval - Benchmarks and Algorithms,https://arxiv.org/abs/2406.09397,2024-06-13,2024-06-19,0.0,0.0,"Modern vision models are trained on very large noisy datasets. While these
models acquire strong capabilities, they may not follow the user's intent to
output the desired results in certain aspects, e.g., visual aesthetic,
preferred style, and responsibility. In this paper, we target the realm of
visual aesthetics and aim to align vision models with human aesthetic standards
in a retrieval system. Advanced retrieval systems usually adopt a cascade of
aesthetic models as re-rankers or filters, which are limited to low-level
features like saturation and perform poorly when stylistic, cultural or
knowledge contexts are involved. We find that utilizing the reasoning ability
of large language models (LLMs) to rephrase the search query and extend the
aesthetic expectations can make up for this shortcoming. Based on the above
findings, we propose a preference-based reinforcement learning method that
fine-tunes the vision models to distill the knowledge from both LLMs reasoning
and the aesthetic models to better align the vision models with human
aesthetics. Meanwhile, with rare benchmarks designed for evaluating retrieval
systems, we leverage large multi-modality model (LMM) to evaluate the aesthetic
performance with their strong abilities. As aesthetic assessment is one of the
most subjective tasks, to validate the robustness of LMM, we further propose a
novel dataset named HPIR to benchmark the alignment with human aesthetics.
Experiments demonstrate that our method significantly enhances the aesthetic
behaviors of the vision models, under several metrics. We believe the proposed
algorithm can be a general practice for aligning vision models with human
values."
Improving Autoregressive Training with Dynamic Oracles,https://arxiv.org/abs/2406.09393,2024-06-13,2024-06-19,0.0,0.0,"Many tasks within NLP can be framed as sequential decision problems, ranging
from sequence tagging to text generation. However, for many tasks, the standard
training methods, including maximum likelihood (teacher forcing) and scheduled
sampling, suffer from exposure bias and a mismatch between metrics employed
during training and inference. DAgger provides a solution to mitigate these
problems, yet it requires a metric-specific dynamic oracle algorithm, which
does not exist for many common metrics like span-based F1, ROUGE, and BLEU. In
this paper, we develop these novel dynamic oracles and show they maintain
DAgger's no-regret guarantee for decomposable metrics like span-based F1. We
evaluate the algorithm's performance on named entity recognition (NER), text
summarization, and machine translation (MT). While DAgger with dynamic oracle
yields less favorable results in our MT experiments, it outperforms the
baseline techniques in NER and text summarization."
A More Practical Approach to Machine Unlearning,https://arxiv.org/abs/2406.09391,2024-06-13,2024-06-19,0.0,0.0,"Machine learning models often incorporate vast amounts of data, raising
significant privacy concerns. Machine unlearning, the ability to remove the
influence of specific data points from a trained model, addresses these
concerns. This paper explores practical methods for implementing machine
unlearning, focusing on a first-epoch gradient-ascent approach.
  Key findings include: 1. Single vs. Multi-Epoch Unlearning: First-epoch
gradient unlearning is more effective than multi-epoch gradients. 2.
Layer-Based Unlearning: The embedding layer in GPT-2 is crucial for effective
unlearning. Gradients from the output layers (11 and 12) have no impact.
Efficient unlearning can be achieved using only the embedding layer, halving
space complexity. 3. Influence Functions & Scoring: Techniques like Hessian
Vector Product and the dot product of activations and tensors are used for
quantifying unlearning. 4. Gradient Ascent Considerations: Calibration is
necessary to avoid overexposing the model to specific data points during
unlearning, which could prematurely terminate the process. 5. Fuzzy Matching
vs. Iterative Unlearning: Fuzzy matching techniques shift the model to a new
optimum, while iterative unlearning provides a more complete modality.
  Our empirical evaluation confirms that first-epoch gradient ascent for
machine unlearning is more effective than whole-model gradient ascent. These
results highlight the potential of machine unlearning for enhancing data
privacy and compliance with regulations such as GDPR and CCPA. The study
underscores the importance of formal methods to comprehensively evaluate the
unlearning process."
LLAVIDAL - Benchmarking Large Language Vision Models for Daily Activities of Living,https://arxiv.org/abs/2406.09390,2024-06-13,2024-06-19,0.0,0.0,"Large Language Vision Models (LLVMs) have demonstrated effectiveness in
processing internet videos, yet they struggle with the visually perplexing
dynamics present in Activities of Daily Living (ADL) due to limited pertinent
datasets and models tailored to relevant cues. To this end, we propose a
framework for curating ADL multiview datasets to fine-tune LLVMs, resulting in
the creation of ADL-X, comprising 100K RGB video-instruction pairs, language
descriptions, 3D skeletons, and action-conditioned object trajectories. We
introduce LLAVIDAL, an LLVM capable of incorporating 3D poses and relevant
object trajectories to understand the intricate spatiotemporal relationships
within ADLs. Furthermore, we present a novel benchmark, ADLMCQ, for quantifying
LLVM effectiveness in ADL scenarios. When trained on ADL-X, LLAVIDAL
consistently achieves state-of-the-art performance across all ADL evaluation
metrics. Qualitative analysis reveals LLAVIDAL's temporal reasoning
capabilities in understanding ADL. The link to the dataset is provided at:
https://adl-x.github.io/"
Exploring the Spectrum of Visio-Linguistic Compositionality and Recognition,https://arxiv.org/abs/2406.09388,2024-06-13,2024-06-19,0.0,0.0,"Vision and language models (VLMs) such as CLIP have showcased remarkable
zero-shot recognition abilities yet face challenges in visio-linguistic
compositionality, particularly in linguistic comprehension and fine-grained
image-text alignment. This paper explores the intricate relationship between
compositionality and recognition -- two pivotal aspects of VLM capability. We
conduct a comprehensive evaluation of existing VLMs, covering both pre-training
approaches aimed at recognition and the fine-tuning methods designed to improve
compositionality. Our evaluation employs 12 benchmarks for compositionality,
along with 21 zero-shot classification and two retrieval benchmarks for
recognition. In our analysis from 274 CLIP model checkpoints, we reveal
patterns and trade-offs that emerge between compositional understanding and
recognition accuracy. Ultimately, this necessitates strategic efforts towards
developing models that improve both capabilities, as well as the meticulous
formulation of benchmarks for compositionality. We open our evaluation
framework at https://github.com/ytaek-oh/vl_compo."
Oblivious subspace embeddings for compressed Tucker decompositions,https://arxiv.org/abs/2406.09387,2024-06-13,2024-06-19,0.0,0.0,"Emphasis in the tensor literature on random embeddings (tools for
low-distortion dimension reduction) for the canonical polyadic (CP) tensor
decomposition has left analogous results for the more expressive Tucker
decomposition comparatively lacking. This work establishes general
Johnson-Lindenstrauss (JL) type guarantees for the estimation of Tucker
decompositions when an oblivious random embedding is applied along each mode.
When these embeddings are drawn from a JL-optimal family, the decomposition can
be estimated within $\varepsilon$ relative error under restrictions on the
embedding dimension that are in line with recent CP results. We implement a
higher-order orthogonal iteration (HOOI) decomposition algorithm with random
embeddings to demonstrate the practical benefits of this approach and its
potential to improve the accessibility of otherwise prohibitive tensor
analyses. On moderately large face image and fMRI neuroimaging datasets,
empirical results show that substantial dimension reduction is possible with
minimal increase in reconstruction error relative to traditional HOOI ($\leq$5%
larger error, 50%-60% lower computation time for large models with 50%
dimension reduction along each mode). Especially for large tensors, our method
outperforms traditional higher-order singular value decomposition (HOSVD) and
recently proposed TensorSketch methods."
Reflecting on the State of Rehearsal-free Continual Learning with Pretrained Models,https://arxiv.org/abs/2406.09384,2024-06-13,2024-06-19,0.0,0.0,"With the advent and recent ubiquity of foundation models, continual learning
(CL) has recently shifted from continual training from scratch to the continual
adaptation of pretrained models, seeing particular success on rehearsal-free CL
benchmarks (RFCL). To achieve this, most proposed methods adapt and restructure
parameter-efficient finetuning techniques (PEFT) to suit the continual nature
of the problem. Based most often on input-conditional query-mechanisms or
regularizations on top of prompt- or adapter-based PEFT, these PEFT-style RFCL
(P-RFCL) approaches report peak performances; often convincingly outperforming
existing CL techniques. However, on the other end, critical studies have
recently highlighted competitive results by training on just the first task or
via simple non-parametric baselines. Consequently, questions arise about the
relationship between methodological choices in P-RFCL and their reported high
benchmark scores. In this work, we tackle these questions to better understand
the true drivers behind strong P-RFCL performances, their placement w.r.t.
recent first-task adaptation studies, and their relation to preceding CL
standards such as EWC or SI. In particular, we show: (1) P-RFCL techniques
relying on input-conditional query mechanisms work not because, but rather
despite them by collapsing towards standard PEFT shortcut solutions. (2)
Indeed, we show how most often, P-RFCL techniques can be matched by a simple
and lightweight PEFT baseline. (3) Using this baseline, we identify the
implicit bound on tunable parameters when deriving RFCL approaches from PEFT
methods as a potential denominator behind P-RFCL efficacy. Finally, we (4)
better disentangle continual versus first-task adaptation, and (5) motivate
standard RFCL techniques s.a. EWC or SI in light of recent P-RFCL methods."
Learning conditional distributions on continuous spaces,https://arxiv.org/abs/2406.09375,2024-06-13,2024-06-19,0.0,0.0,"We investigate sample-based learning of conditional distributions on
multi-dimensional unit boxes, allowing for different dimensions of the feature
and target spaces. Our approach involves clustering data near varying query
points in the feature space to create empirical measures in the target space.
We employ two distinct clustering schemes: one based on a fixed-radius ball and
the other on nearest neighbors. We establish upper bounds for the convergence
rates of both methods and, from these bounds, deduce optimal configurations for
the radius and the number of neighbors. We propose to incorporate the nearest
neighbors method into neural network training, as our empirical analysis
indicates it has better performance in practice. For efficiency, our training
process utilizes approximate nearest neighbors search with random binary space
partitioning. Additionally, we employ the Sinkhorn algorithm and a
sparsity-enforced transport plan. Our empirical findings demonstrate that, with
a suitably designed structure, the neural network has the ability to adapt to a
suitable level of Lipschitz continuity locally. For reproducibility, our code
is available at \url{https://github.com/zcheng-a/LCD_kNN}."
Efficient Discrepancy Testing for Learning with Distribution Shift,https://arxiv.org/abs/2406.09373,2024-06-13,2024-06-19,0.0,0.0,"A fundamental notion of distance between train and test distributions from
the field of domain adaptation is discrepancy distance. While in general hard
to compute, here we provide the first set of provably efficient algorithms for
testing localized discrepancy distance, where discrepancy is computed with
respect to a fixed output classifier. These results imply a broad set of new,
efficient learning algorithms in the recently introduced model of Testable
Learning with Distribution Shift (TDS learning) due to Klivans et al. (2023).
  Our approach generalizes and improves all prior work on TDS learning: (1) we
obtain universal learners that succeed simultaneously for large classes of test
distributions, (2) achieve near-optimal error rates, and (3) give exponential
improvements for constant depth circuits. Our methods further extend to
semi-parametric settings and imply the first positive results for
low-dimensional convex sets. Additionally, we separate learning and testing
phases and obtain algorithms that run in fully polynomial time at test time."
LRM-Zero - Training Large Reconstruction Models with Synthesized Data,https://arxiv.org/abs/2406.09371,2024-06-13,2024-06-19,0.0,0.0,"We present LRM-Zero, a Large Reconstruction Model (LRM) trained entirely on
synthesized 3D data, achieving high-quality sparse-view 3D reconstruction. The
core of LRM-Zero is our procedural 3D dataset, Zeroverse, which is
automatically synthesized from simple primitive shapes with random texturing
and augmentations (e.g., height fields, boolean differences, and wireframes).
Unlike previous 3D datasets (e.g., Objaverse) which are often captured or
crafted by humans to approximate real 3D data, Zeroverse completely ignores
realistic global semantics but is rich in complex geometric and texture details
that are locally similar to or even more intricate than real objects. We
demonstrate that our LRM-Zero, trained with our fully synthesized Zeroverse,
can achieve high visual quality in the reconstruction of real-world objects,
competitive with models trained on Objaverse. We also analyze several critical
design choices of Zeroverse that contribute to LRM-Zero's capability and
training stability. Our work demonstrates that 3D reconstruction, one of the
core tasks in 3D vision, can potentially be addressed without the semantics of
real-world objects. The Zeroverse's procedural synthesis code and interactive
visualization are available at: https://desaixie.github.io/lrm-zero/."
Data-dependent and Oracle Bounds on Forgetting in Continual Learning,https://arxiv.org/abs/2406.09370,2024-06-13,2024-06-19,0.0,0.0,"In continual learning, knowledge must be preserved and re-used between tasks,
maintaining good transfer to future tasks and minimizing forgetting of
previously learned ones. While several practical algorithms have been devised
for this setting, there have been few theoretical works aiming to quantify and
bound the degree of Forgetting in general settings. We provide both
data-dependent and oracle upper bounds that apply regardless of model and
algorithm choice, as well as bounds for Gibbs posteriors. We derive an
algorithm inspired by our bounds and demonstrate empirically that our approach
yields improved forward and backward transfer."
Towards an Improved Understanding and Utilization of Maximum Manifold Capacity Representations,https://arxiv.org/abs/2406.09366,2024-06-13,2024-06-19,0.0,0.0,"Maximum Manifold Capacity Representations (MMCR) is a recent multi-view
self-supervised learning (MVSSL) method that matches or surpasses other leading
MVSSL methods. MMCR is intriguing because it does not fit neatly into any of
the commonplace MVSSL lineages, instead originating from a statistical
mechanical perspective on the linear separability of data manifolds. In this
paper, we seek to improve our understanding and our utilization of MMCR. To
better understand MMCR, we leverage tools from high dimensional probability to
demonstrate that MMCR incentivizes alignment and uniformity of learned
embeddings. We then leverage tools from information theory to show that such
embeddings maximize a well-known lower bound on mutual information between
views, thereby connecting the geometric perspective of MMCR to the
information-theoretic perspective commonly discussed in MVSSL. To better
utilize MMCR, we mathematically predict and experimentally confirm
non-monotonic changes in the pretraining loss akin to double descent but with
respect to atypical hyperparameters. We also discover compute scaling laws that
enable predicting the pretraining loss as a function of gradients steps, batch
size, embedding dimension and number of views. We then show that MMCR,
originally applied to image data, is performant on multimodal image-text data.
By more deeply understanding the theoretical and empirical behavior of MMCR,
our work reveals insights on improving MVSSL methods."
ElicitationGPT - Text Elicitation Mechanisms via Language Models,https://arxiv.org/abs/2406.09363,2024-06-13,2024-06-19,0.0,0.0,"Scoring rules evaluate probabilistic forecasts of an unknown state against
the realized state and are a fundamental building block in the incentivized
elicitation of information and the training of machine learning models. This
paper develops mechanisms for scoring elicited text against ground truth text
using domain-knowledge-free queries to a large language model (specifically
ChatGPT) and empirically evaluates their alignment with human preferences. The
empirical evaluation is conducted on peer reviews from a peer-grading dataset
and in comparison to manual instructor scores for the peer reviews."
Understanding Hallucinations in Diffusion Models through Mode Interpolation,https://arxiv.org/abs/2406.09358,2024-06-13,2024-06-19,0.0,0.0,"Colloquially speaking, image generation models based upon diffusion processes
are frequently said to exhibit ""hallucinations,"" samples that could never occur
in the training data. But where do such hallucinations come from? In this
paper, we study a particular failure mode in diffusion models, which we term
mode interpolation. Specifically, we find that diffusion models smoothly
""interpolate"" between nearby data modes in the training set, to generate
samples that are completely outside the support of the original training
distribution; this phenomenon leads diffusion models to generate artifacts that
never existed in real data (i.e., hallucinations). We systematically study the
reasons for, and the manifestation of this phenomenon. Through experiments on
1D and 2D Gaussians, we show how a discontinuous loss landscape in the
diffusion model's decoder leads to a region where any smooth approximation will
cause such hallucinations. Through experiments on artificial datasets with
various shapes, we show how hallucination leads to the generation of
combinations of shapes that never existed. Finally, we show that diffusion
models in fact know when they go out of support and hallucinate. This is
captured by the high variance in the trajectory of the generated sample towards
the final few backward sampling process. Using a simple metric to capture this
variance, we can remove over 95% of hallucinations at generation time while
retaining 96% of in-support samples. We conclude our exploration by showing the
implications of such hallucination (and its removal) on the collapse (and
stabilization) of recursive training on synthetic data with experiments on
MNIST and 2D Gaussians dataset. We release our code at
https://github.com/locuslab/diffusion-model-hallucination."
Advancing Graph Generation through Beta Diffusion,https://arxiv.org/abs/2406.09357,2024-06-13,2024-06-19,0.0,0.0,"Diffusion models have demonstrated effectiveness in generating natural images
and have been extended to generate diverse data types, including graphs. This
new generation of diffusion-based graph generative models has demonstrated
significant performance improvements over methods that rely on variational
autoencoders or generative adversarial networks. It's important to recognize,
however, that most of these models employ Gaussian or categorical diffusion
processes, which can struggle with sparse and long-tailed data distributions.
In our work, we introduce Graph Beta Diffusion (GBD), a diffusion-based
generative model particularly adept at capturing diverse graph structures. GBD
utilizes a beta diffusion process, tailored for the sparse and range-bounded
characteristics of graph adjacency matrices. Furthermore, we have developed a
modulation technique that enhances the realism of the generated graphs by
stabilizing the generation of critical graph structures, while preserving
flexibility elsewhere. The outstanding performance of GBD across three general
graph benchmarks and two biochemical graph benchmarks highlights its capability
to effectively capture the complexities of real-world graph data. The code will
be made available at https://github.com/YH-UtMSB/Graph_Beta_Diffusion"
Enhancing Domain Adaptation through Prompt Gradient Alignment,https://arxiv.org/abs/2406.09353,2024-06-13,2024-06-19,0.0,0.0,"Prior Unsupervised Domain Adaptation (UDA) methods often aim to train a
domain-invariant feature extractor, which may hinder the model from learning
sufficiently discriminative features. To tackle this, a line of works based on
prompt learning leverages the power of large-scale pre-trained vision-language
models to learn both domain-invariant and specific features through a set of
domain-agnostic and domain-specific learnable prompts. Those studies typically
enforce invariant constraints on representation, output, or prompt space to
learn such prompts. Differently, we cast UDA as a multiple-objective
optimization problem in which each objective is represented by a domain loss.
Under this new framework, we propose aligning per-objective gradients to foster
consensus between them. Additionally, to prevent potential overfitting when
fine-tuning this deep learning architecture, we penalize the norm of these
gradients. To achieve these goals, we devise a practical gradient update
procedure that can work under both single-source and multi-source UDA.
Empirically, our method consistently surpasses other prompt-based baselines by
a large margin on different UDA benchmarks"
On the Expressibility of the Reconstructional Color Refinement,https://arxiv.org/abs/2406.09351,2024-06-13,2024-06-19,0.0,0.0,"One of the most basic facts related to the famous Ulam reconstruction
conjecture is that the connectedness of a graph can be determined by the deck
of its vertex-deleted subgraphs, which are considered up to isomorphism. We
strengthen this result by proving that connectedness can still be determined
when the subgraphs in the deck are given up to equivalence under the color
refinement isomorphism test. Consequently, this implies that connectedness is
recognizable by Reconstruction Graph Neural Networks, a recently introduced GNN
architecture inspired by the reconstruction conjecture (Cotta, Morris, Ribeiro
2021)."
Fair Data Generation via Score-based Diffusion Model,https://arxiv.org/abs/2406.09495,2024-06-13,2024-06-19,0.0,0.0,"Fairness-aware domain generalization (FairDG) has emerged as a critical
challenge for deploying trustworthy AI systems, particularly in scenarios
involving distribution shifts. Traditional methods for addressing fairness have
failed in domain generalization due to their lack of consideration for
distribution shifts. Although disentanglement has been used to tackle FairDG,
it is limited by its strong assumptions. To overcome these limitations, we
propose Fairness-aware Classifier-Guided Score-based Diffusion Models (FADE) as
a novel approach to effectively address the FairDG issue. Specifically, we
first pre-train a score-based diffusion model (SDM) and two classifiers to
equip the model with strong generalization capabilities across different
domains. Then, we guide the SDM using these pre-trained classifiers to
effectively eliminate sensitive information from the generated data. Finally,
the generated fair data is used to train downstream classifiers, ensuring
robust performance under new data distributions. Extensive experiments on three
real-world datasets demonstrate that FADE not only enhances fairness but also
improves accuracy in the presence of distribution shifts. Additionally, FADE
outperforms existing methods in achieving the best accuracy-fairness
trade-offs."
The Second DISPLACE Challenge  - DIarization of SPeaker and LAnguage in Conversational Environments,https://arxiv.org/abs/2406.09494,2024-06-13,2024-06-19,0.0,0.0,"The DIarization of SPeaker and LAnguage in Conversational Environments
(DISPLACE) 2024 challenge is the second in the series of DISPLACE challenges,
which involves tasks of speaker diarization (SD) and language diarization (LD)
on a challenging multilingual conversational speech dataset. In the DISPLACE
2024 challenge, we also introduced the task of automatic speech recognition
(ASR) on this dataset. The dataset containing 158 hours of speech, consisting
of both supervised and unsupervised mono-channel far-field recordings, was
released for LD and SD tracks. Further, 12 hours of close-field mono-channel
recordings were provided for the ASR track conducted on 5 Indian languages. The
details of the dataset, baseline systems and the leader board results are
highlighted in this paper. We have also compared our baseline models and the
team's performances on evaluation data of DISPLACE-2023 to emphasize the
advancements made in this second version of the challenge."
Scoreformer - A Surrogate Model For Large-Scale Prediction of Docking Scores,https://arxiv.org/abs/2406.09346,2024-06-13,2024-06-19,0.0,0.0,"In this study, we present ScoreFormer, a novel graph transformer model
designed to accurately predict molecular docking scores, thereby optimizing
high-throughput virtual screening (HTVS) in drug discovery. The architecture
integrates Principal Neighborhood Aggregation (PNA) and Learnable Random Walk
Positional Encodings (LRWPE), enhancing the model's ability to understand
complex molecular structures and their relationship with their respective
docking scores. This approach significantly surpasses traditional HTVS methods
and recent Graph Neural Network (GNN) models in both recovery and efficiency
due to a wider coverage of the chemical space and enhanced performance. Our
results demonstrate that ScoreFormer achieves competitive performance in
docking score prediction and offers a substantial 1.65-fold reduction in
inference time compared to existing models. We evaluated ScoreFormer across
multiple datasets under various conditions, confirming its robustness and
reliability in identifying potential drug candidates rapidly."
DiscreteSLU - A Large Language Model with Self-Supervised Discrete Speech Units for Spoken Language Understanding,https://arxiv.org/abs/2406.09345,2024-06-13,2024-06-19,0.0,0.0,"The integration of pre-trained text-based large language models (LLM) with
speech input has enabled instruction-following capabilities for diverse speech
tasks. This integration requires the use of a speech encoder, a speech adapter,
and an LLM, trained on diverse tasks. We propose the use of discrete speech
units (DSU), rather than continuous-valued speech encoder outputs, that are
converted to the LLM token embedding space using the speech adapter. We
generate DSU using a self-supervised speech encoder followed by k-means
clustering. The proposed model shows robust performance on speech inputs from
seen/unseen domains and instruction-following capability in spoken question
answering. We also explore various types of DSU extracted from different layers
of the self-supervised speech encoder, as well as Mel frequency Cepstral
Coefficients (MFCC). Our findings suggest that the ASR task and datasets are
not crucial in instruction-tuning for spoken question answering tasks."
Learning the Influence Graph of a High-Dimensional Markov Process with Memory,https://arxiv.org/abs/2406.09338,2024-06-13,2024-06-19,0.0,0.0,"Motivated by multiple applications in social networks, nervous systems, and
financial risk analysis, we consider the problem of learning the underlying
(directed) influence graph or causal graph of a high-dimensional multivariate
discrete-time Markov process with memory. At any discrete time instant, each
observed variable of the multivariate process is a binary string of random
length, which is parameterized by an unobservable or hidden [0,1]-valued
scalar. The hidden scalars corresponding to the variables evolve according to
discrete-time linear stochastic dynamics dictated by the underlying influence
graph whose nodes are the variables. We extend an existing algorithm for
learning i.i.d. graphical models to this Markovian setting with memory and
prove that it can learn the influence graph based on the binary observations
using logarithmic (in number of variables or nodes) samples when the degree of
the influence graph is bounded. The crucial analytical contribution of this
work is the derivation of the sample complexity result by upper and lower
bounding the rate of convergence of the observed Markov process with memory to
its stationary distribution in terms of the parameters of the influence graph."
Instance-level quantitative saliency in multiple sclerosis lesion segmentation,https://arxiv.org/abs/2406.09335,2024-06-13,2024-06-19,0.0,0.0,"In recent years, explainable methods for artificial intelligence (XAI) have
tried to reveal and describe models' decision mechanisms in the case of
classification tasks. However, XAI for semantic segmentation and in particular
for single instances has been little studied to date. Understanding the process
underlying automatic segmentation of single instances is crucial to reveal what
information was used to detect and segment a given object of interest. In this
study, we proposed two instance-level explanation maps for semantic
segmentation based on SmoothGrad and Grad-CAM++ methods. Then, we investigated
their relevance for the detection and segmentation of white matter lesions
(WML), a magnetic resonance imaging (MRI) biomarker in multiple sclerosis (MS).
687 patients diagnosed with MS for a total of 4043 FLAIR and MPRAGE MRI scans
were collected at the University Hospital of Basel, Switzerland. Data were
randomly split into training, validation and test sets to train a 3D U-Net for
MS lesion segmentation. We observed 3050 true positive (TP), 1818 false
positive (FP), and 789 false negative (FN) cases. We generated instance-level
explanation maps for semantic segmentation, by developing two XAI methods based
on SmoothGrad and Grad-CAM++. We investigated: 1) the distribution of gradients
in saliency maps with respect to both input MRI sequences; 2) the model's
response in the case of synthetic lesions; 3) the amount of perilesional tissue
needed by the model to segment a lesion. Saliency maps (based on SmoothGrad) in
FLAIR showed positive values inside a lesion and negative in its neighborhood.
Peak values of saliency maps generated for these four groups of volumes
presented distributions that differ significantly from one another, suggesting
a quantitative nature of the proposed saliency. Contextual information of 7mm
around the lesion border was required for their segmentation."
ProxyLM - Predicting Language Model Performance on Multilingual Tasks via Proxy Models,https://arxiv.org/abs/2406.09334,2024-06-13,2024-06-19,0.0,0.0,"Performance prediction is a method to estimate the performance of Language
Models (LMs) on various Natural Language Processing (NLP) tasks, mitigating
computational costs associated with model capacity and data for fine-tuning.
Our paper introduces ProxyLM, a scalable framework for predicting LM
performance using proxy models in multilingual tasks. These proxy models act as
surrogates, approximating the performance of the LM of interest. By leveraging
proxy models, ProxyLM significantly reduces computational overhead on task
evaluations, achieving up to a 37.08x speedup compared to traditional methods,
even with our smallest proxy models. Additionally, our methodology showcases
adaptability to previously unseen languages in pre-trained LMs, outperforming
the state-of-the-art performance by 1.89x as measured by root-mean-square error
(RMSE). This framework streamlines model selection, enabling efficient
deployment and iterative LM enhancements without extensive computational
resources."
Learning from Natural Language Explanations for Generalizable Entity Matching,https://arxiv.org/abs/2406.09330,2024-06-13,2024-06-19,0.0,0.0,"Entity matching is the task of linking records from different sources that
refer to the same real-world entity. Past work has primarily treated entity
linking as a standard supervised learning problem. However, supervised entity
matching models often do not generalize well to new data, and collecting
exhaustive labeled training data is often cost prohibitive. Further, recent
efforts have adopted LLMs for this task in few/zero-shot settings, exploiting
their general knowledge. But LLMs are prohibitively expensive for performing
inference at scale for real-world entity matching tasks.
  As an efficient alternative, we re-cast entity matching as a conditional
generation task as opposed to binary classification. This enables us to
""distill"" LLM reasoning into smaller entity matching models via natural
language explanations. This approach achieves strong performance, especially on
out-of-domain generalization tests (10.85% F-1) where standalone generative
methods struggle. We perform ablations that highlight the importance of
explanations, both for performance and model robustness."
Is Value Learning Really the Main Bottleneck in Offline RL?,https://arxiv.org/abs/2406.09329,2024-06-13,2024-06-19,0.0,0.0,"While imitation learning requires access to high-quality data, offline
reinforcement learning (RL) should, in principle, perform similarly or better
with substantially lower data quality by using a value function. However,
current results indicate that offline RL often performs worse than imitation
learning, and it is often unclear what holds back the performance of offline
RL. Motivated by this observation, we aim to understand the bottlenecks in
current offline RL algorithms. While poor performance of offline RL is
typically attributed to an imperfect value function, we ask: is the main
bottleneck of offline RL indeed in learning the value function, or something
else? To answer this question, we perform a systematic empirical study of (1)
value learning, (2) policy extraction, and (3) policy generalization in offline
RL problems, analyzing how these components affect performance. We make two
surprising observations. First, we find that the choice of a policy extraction
algorithm significantly affects the performance and scalability of offline RL,
often more so than the value learning objective. For instance, we show that
common value-weighted behavioral cloning objectives (e.g., AWR) do not fully
leverage the learned value function, and switching to behavior-constrained
policy gradient objectives (e.g., DDPG+BC) often leads to substantial
improvements in performance and scalability. Second, we find that a big barrier
to improving offline RL performance is often imperfect policy generalization on
test-time states out of the support of the training data, rather than policy
learning on in-distribution states. We then show that the use of suboptimal but
high-coverage data or test-time policy training techniques can address this
generalization issue in practice. Specifically, we propose two simple test-time
policy improvement methods and show that these methods lead to better
performance."
REVS - Unlearning Sensitive Information in Language Models via Rank Editing in the Vocabulary Space,https://arxiv.org/abs/2406.09325,2024-06-13,2024-06-19,0.0,0.0,"Large language models (LLMs) risk inadvertently memorizing and divulging
sensitive or personally identifiable information (PII) seen in training data,
causing privacy concerns. Current approaches to address this issue involve
costly dataset scrubbing, or model filtering through unlearning and model
editing, which can be bypassed through extraction attacks. We propose REVS, a
novel model editing method for unlearning sensitive information from LLMs. REVS
identifies and modifies a small subset of neurons relevant for each piece of
sensitive information. By projecting these neurons to the vocabulary space
(unembedding), we pinpoint the components driving its generation. We then
compute a model edit based on the pseudo-inverse of the unembedding matrix, and
apply it to de-promote generation of the targeted sensitive data. To adequately
evaluate our method on truly sensitive information, we curate two datasets: an
email dataset inherently memorized by GPT-J, and a synthetic social security
number dataset that we tune the model to memorize. Compared to other
state-of-the-art model editing methods, REVS demonstrates superior performance
in both eliminating sensitive information and robustness to extraction attacks,
while retaining integrity of the underlying model. The code and a demo notebook
are available at https://technion-cs-nlp.github.io/REVS."
Bag of Tricks - Benchmarking of Jailbreak Attacks on LLMs,https://arxiv.org/abs/2406.09324,2024-06-13,2024-06-19,0.0,0.0,"Although Large Language Models (LLMs) have demonstrated significant
capabilities in executing complex tasks in a zero-shot manner, they are
susceptible to jailbreak attacks and can be manipulated to produce harmful
outputs. Recently, a growing body of research has categorized jailbreak attacks
into token-level and prompt-level attacks. However, previous work primarily
overlooks the diverse key factors of jailbreak attacks, with most studies
concentrating on LLM vulnerabilities and lacking exploration of
defense-enhanced LLMs. To address these issues, we evaluate the impact of
various attack settings on LLM performance and provide a baseline benchmark for
jailbreak attacks, encouraging the adoption of a standardized evaluation
framework. Specifically, we evaluate the eight key factors of implementing
jailbreak attacks on LLMs from both target-level and attack-level perspectives.
We further conduct seven representative jailbreak attacks on six defense
methods across two widely used datasets, encompassing approximately 320
experiments with about 50,000 GPU hours on A800-80G. Our experimental results
highlight the need for standardized benchmarking to evaluate these attacks on
defense-enhanced LLMs. Our code is available at
https://github.com/usail-hkust/Bag_of_Tricks_for_LLM_Jailbreaking."
Active Inference Meeting Energy-Efficient Control of Parallel and Identical Machines,https://arxiv.org/abs/2406.09322,2024-06-13,2024-06-19,0.0,0.0,"We investigate the application of active inference in developing
energy-efficient control agents for manufacturing systems. Active inference,
rooted in neuroscience, provides a unified probabilistic framework integrating
perception, learning, and action, with inherent uncertainty quantification
elements. Our study explores deep active inference, an emerging field that
combines deep learning with the active inference decision-making framework.
Leveraging a deep active inference agent, we focus on controlling parallel and
identical machine workstations to enhance energy efficiency. We address
challenges posed by the problem's stochastic nature and delayed policy response
by introducing tailored enhancements to existing agent architectures.
Specifically, we introduce multi-step transition and hybrid horizon methods to
mitigate the need for complex planning. Our experimental results demonstrate
the effectiveness of these enhancements and highlight the potential of the
active inference-based approach."
JailbreakEval - An Integrated Toolkit for Evaluating Jailbreak Attempts Against Large Language Models,https://arxiv.org/abs/2406.09321,2024-06-13,2024-06-19,0.0,0.0,"Jailbreak attacks aim to induce Large Language Models (LLMs) to generate
harmful responses for forbidden instructions, presenting severe misuse threats
to LLMs. Up to now, research into jailbreak attacks and defenses is emerging,
however, there is (surprisingly) no consensus on how to evaluate whether a
jailbreak attempt is successful. In other words, the methods to assess the
harmfulness of an LLM's response are varied, such as manual annotation or
prompting GPT-4 in specific ways. Each approach has its own set of strengths
and weaknesses, impacting their alignment with human values, as well as the
time and financial cost. This diversity in evaluation presents challenges for
researchers in choosing suitable evaluation methods and conducting fair
comparisons across different jailbreak attacks and defenses. In this paper, we
conduct a comprehensive analysis of jailbreak evaluation methodologies, drawing
from nearly ninety jailbreak research released between May 2023 and April 2024.
Our study introduces a systematic taxonomy of jailbreak evaluators, offering
in-depth insights into their strengths and weaknesses, along with the current
status of their adaptation. Moreover, to facilitate subsequent research, we
propose JailbreakEval, a user-friendly toolkit focusing on the evaluation of
jailbreak attempts. It includes various well-known evaluators out-of-the-box,
so that users can obtain evaluation results with only a single command.
JailbreakEval also allows users to customize their own evaluation workflow in a
unified framework with the ease of development and comparison. In summary, we
regard JailbreakEval to be a catalyst that simplifies the evaluation process in
jailbreak research and fosters an inclusive standard for jailbreak evaluation
within the community."
Khmer Semantic Search Engine (KSE) - Digital Information Access and Document Retrieval,https://arxiv.org/abs/2406.09320,2024-06-13,2024-06-19,0.0,0.0,"The search engine process is crucial for document content retrieval. For
Khmer documents, an effective tool is needed to extract essential keywords and
facilitate accurate searches. Despite the daily generation of significant Khmer
content, Cambodians struggle to find necessary documents due to the lack of an
effective semantic searching tool. Even Google does not deliver high accuracy
for Khmer content. Semantic search engines improve search results by employing
advanced algorithms to understand various content types. With the rise in Khmer
digital content such as reports, articles, and social media feedback enhanced
search capabilities are essential. This research proposes the first Khmer
Semantic Search Engine (KSE), designed to enhance traditional Khmer search
methods. Utilizing semantic matching techniques and formally annotated semantic
content, our tool extracts meaningful keywords from user queries, performs
precise matching, and provides the best matching offline documents and online
URLs. We propose three semantic search frameworks: semantic search based on a
keyword dictionary, semantic search based on ontology, and semantic search
based on ranking. Additionally, we developed tools for data preparation,
including document addition and manual keyword extraction. To evaluate
performance, we created a ground truth dataset and addressed issues related to
searching and semantic search. Our findings demonstrate that understanding
search term semantics can lead to significantly more accurate results."
Characterising Interventions in Causal Games,https://arxiv.org/abs/2406.09318,2024-06-13,2024-06-19,0.0,0.0,"Causal games are probabilistic graphical models that enable causal queries to
be answered in multi-agent settings. They extend causal Bayesian networks by
specifying decision and utility variables to represent the agents' degrees of
freedom and objectives. In multi-agent settings, whether each agent decides on
their policy before or after knowing the causal intervention is important as
this affects whether they can respond to the intervention by adapting their
policy. Consequently, previous work in causal games imposed chronological
constraints on permissible interventions. We relax this by outlining a sound
and complete set of primitive causal interventions so the effect of any
arbitrarily complex interventional query can be studied in multi-agent
settings. We also demonstrate applications to the design of safe AI systems by
considering causal mechanism design and commitment."
Vertical LoRA - Dense Expectation-Maximization Interpretation of Transformers,https://arxiv.org/abs/2406.09315,2024-06-13,2024-06-19,0.0,0.0,"In this paper, we show how Transformers can be interpreted as dense
Expectation-Maximization algorithms performed on Bayesian Nets. Based on the
above interpretation, we propose a new model design paradigm, namely Vertical
LoRA (VLoRA), which reduces the parameter count dramatically while preserving
performance. In VLoRA, a model consists of layers, each of which recursively
learns an increment based on the previous layer. We then apply LoRA
decomposition to the increments. VLoRA works on the base model, which is
orthogonal to LoRA, meaning they can be used together. We do experiments on
various tasks and models. The results show that 1) with VLoRA, the Transformer
model parameter count can be reduced dramatically and 2) the performance of the
original model is preserved. The source code is available at
\url{https://github.com/neverUseThisName/vlora}"
Neural networks in non-metric spaces,https://arxiv.org/abs/2406.09310,2024-06-13,2024-06-19,0.0,0.0,"Leveraging the infinite dimensional neural network architecture we proposed
in arXiv:2109.13512v4 and which can process inputs from Fr\'echet spaces, and
using the universal approximation property shown therein, we now largely extend
the scope of this architecture by proving several universal approximation
theorems for a vast class of input and output spaces. More precisely, the input
space $\mathfrak X$ is allowed to be a general topological space satisfying
only a mild condition (""quasi-Polish""), and the output space can be either
another quasi-Polish space $\mathfrak Y$ or a topological vector space $E$.
Similarly to arXiv:2109.13512v4, we show furthermore that our neural network
architectures can be projected down to ""finite dimensional"" subspaces with any
desirable accuracy, thus obtaining approximating networks that are easy to
implement and allow for fast computation and fitting. The resulting neural
network architecture is therefore applicable for prediction tasks based on
functional data. To the best of our knowledge, this is the first result which
deals with such a wide class of input/output spaces and simultaneously
guarantees the numerical feasibility of the ensuing architectures. Finally, we
prove an obstruction result which indicates that the category of quasi-Polish
spaces is in a certain sense the correct category to work with if one aims at
constructing approximating architectures on infinite-dimensional spaces
$\mathfrak X$ which, at the same time, have sufficient expressive power to
approximate continuous functions on $\mathfrak X$, are specified by a finite
number of parameters only and are ""stable"" with respect to these parameters."
Transformers meet Neural Algorithmic Reasoners,https://arxiv.org/abs/2406.09308,2024-06-13,2024-06-19,0.0,0.0,"Transformers have revolutionized machine learning with their simple yet
effective architecture. Pre-training Transformers on massive text datasets from
the Internet has led to unmatched generalization for natural language
understanding (NLU) tasks. However, such language models remain fragile when
tasked with algorithmic forms of reasoning, where computations must be precise
and robust. To address this limitation, we propose a novel approach that
combines the Transformer's language understanding with the robustness of graph
neural network (GNN)-based neural algorithmic reasoners (NARs). Such NARs
proved effective as generic solvers for algorithmic tasks, when specified in
graph form. To make their embeddings accessible to a Transformer, we propose a
hybrid architecture with a two-phase training procedure, allowing the tokens in
the language model to cross-attend to the node embeddings from the NAR. We
evaluate our resulting TransNAR model on CLRS-Text, the text-based version of
the CLRS-30 benchmark, and demonstrate significant gains over Transformer-only
models for algorithmic reasoning, both in and out of distribution."
A tutorial on fairness in machine learning in healthcare,https://arxiv.org/abs/2406.09307,2024-06-13,2024-06-19,0.0,0.0,"$\textbf{OBJECTIVE}$: Ensuring that machine learning (ML) algorithms are safe
and effective within all patient groups, and do not disadvantage particular
patients, is essential to clinical decision making and preventing the
reinforcement of existing healthcare inequities. The objective of this tutorial
is to introduce the medical informatics community to the common notions of
fairness within ML, focusing on clinical applications and implementation in
practice.
  $\textbf{TARGET AUDIENCE}$: As gaps in fairness arise in a variety of
healthcare applications, this tutorial is designed to provide an understanding
of fairness, without assuming prior knowledge, to researchers and clinicians
who make use of modern clinical data.
  $\textbf{SCOPE}$: We describe the fundamental concepts and methods used to
define fairness in ML, including an overview of why models in healthcare may be
unfair, a summary and comparison of the metrics used to quantify fairness, and
a discussion of some ongoing research. We illustrate some of the fairness
methods introduced through a case study of mortality prediction in a publicly
available electronic health record dataset. Finally, we provide a user-friendly
R package for comprehensive group fairness evaluation, enabling researchers and
clinicians to assess fairness in their own ML work."
MLKV - Multi-Layer Key-Value Heads for Memory Efficient Transformer Decoding,https://arxiv.org/abs/2406.09297,2024-06-13,2024-06-19,0.0,0.0,"Auto-regressive inference of transformers benefit greatly from Key-Value (KV)
caching, but can lead to major memory bottlenecks as model size, batch size,
and sequence length grow at scale. We introduce Multi-Layer Key-Value (MLKV)
sharing, a novel approach extending KV sharing across transformer layers to
reduce memory usage beyond what was possible with Multi-Query Attention (MQA)
and Grouped-Query Attention (GQA). Evaluations on various NLP benchmarks and
inference metrics using uptrained Pythia-160M variants demonstrate that MLKV
significantly reduces memory usage with minimal performance loss, reducing KV
cache size down to a factor of 6x compared to MQA. These results highlight
MLKV's potential for efficient deployment of transformer models at scale. We
provide code at https://github.com/zaydzuhri/pythia-mlkv"
Parameter-Efficient Active Learning for Foundational models,https://arxiv.org/abs/2406.09296,2024-06-13,2024-06-19,0.0,0.0,"Foundational vision transformer models have shown impressive few shot
performance on many vision tasks. This research presents a novel investigation
into the application of parameter efficient fine-tuning methods within an
active learning (AL) framework, to advance the sampling selection process in
extremely budget constrained classification tasks. The focus on image datasets,
known for their out-of-distribution characteristics, adds a layer of complexity
and relevance to our study. Through a detailed evaluation, we illustrate the
improved AL performance on these challenging datasets, highlighting the
strategic advantage of merging parameter efficient fine tuning methods with
foundation models. This contributes to the broader discourse on optimizing AL
strategies, presenting a promising avenue for future exploration in leveraging
foundation models for efficient and effective data annotation in specialized
domains."
AlignMMBench - Evaluating Chinese Multimodal Alignment in Large Vision-Language Models,https://arxiv.org/abs/2406.09295,2024-06-13,2024-06-19,0.0,0.0,"Evaluating the alignment capabilities of large Vision-Language Models (VLMs)
is essential for determining their effectiveness as helpful assistants.
However, existing benchmarks primarily focus on basic abilities using nonverbal
methods, such as yes-no and multiple-choice questions. In this paper, we
address this gap by introducing AlignMMBench, a comprehensive alignment
benchmark specifically designed for emerging Chinese VLMs. This benchmark is
meticulously curated from real-world scenarios and Chinese Internet sources,
encompassing thirteen specific tasks across three categories, and includes both
single-turn and multi-turn dialogue scenarios. Incorporating a prompt rewrite
strategy, AlignMMBench encompasses 1,054 images and 4,978 question-answer
pairs. To facilitate the evaluation pipeline, we propose CritiqueVLM, a
rule-calibrated evaluator that exceeds GPT-4's evaluation ability. Finally, we
report the performance of representative VLMs on AlignMMBench, offering
insights into the capabilities and limitations of different VLM architectures.
All evaluation codes and data are available on https://alignmmbench.github.io."
Neural Assets - 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models,https://arxiv.org/abs/2406.09292,2024-06-13,2024-06-19,0.0,0.0,"We address the problem of multi-object 3D pose control in image diffusion
models. Instead of conditioning on a sequence of text tokens, we propose to use
a set of per-object representations, Neural Assets, to control the 3D pose of
individual objects in a scene. Neural Assets are obtained by pooling visual
representations of objects from a reference image, such as a frame in a video,
and are trained to reconstruct the respective objects in a different image,
e.g., a later frame in the video. Importantly, we encode object visuals from
the reference image while conditioning on object poses from the target frame.
This enables learning disentangled appearance and pose features. Combining
visual and 3D pose representations in a sequence-of-tokens format allows us to
keep the text-to-image architecture of existing models, with Neural Assets in
place of text tokens. By fine-tuning a pre-trained text-to-image diffusion
model with this information, our approach enables fine-grained 3D pose and
placement control of individual objects in a scene. We further demonstrate that
Neural Assets can be transferred and recomposed across different scenes. Our
model achieves state-of-the-art multi-object editing results on both synthetic
3D scene datasets, as well as two real-world video datasets (Objectron, Waymo
Open)."
"A Flexible, Equivariant Framework for Subgraph GNNs via Graph Products and Graph Coarsening",https://arxiv.org/abs/2406.09291,2024-06-13,2024-06-19,0.0,0.0,"Subgraph Graph Neural Networks (Subgraph GNNs) enhance the expressivity of
message-passing GNNs by representing graphs as sets of subgraphs. They have
shown impressive performance on several tasks, but their complexity limits
applications to larger graphs. Previous approaches suggested processing only
subsets of subgraphs, selected either randomly or via learnable sampling.
However, they make suboptimal subgraph selections or can only cope with very
small subset sizes, inevitably incurring performance degradation. This paper
introduces a new Subgraph GNNs framework to address these issues. We employ a
graph coarsening function to cluster nodes into super-nodes with induced
connectivity. The product between the coarsened and the original graph reveals
an implicit structure whereby subgraphs are associated with specific sets of
nodes. By running generalized message-passing on such graph product, our method
effectively implements an efficient, yet powerful Subgraph GNN. Controlling the
coarsening function enables meaningful selection of any number of subgraphs
while, contrary to previous methods, being fully compatible with standard
training techniques. Notably, we discover that the resulting node feature
tensor exhibits new, unexplored permutation symmetries. We leverage this
structure, characterize the associated linear equivariant layers and
incorporate them into the layers of our Subgraph GNN architecture. Extensive
experiments on multiple graph learning benchmarks demonstrate that our method
is significantly more flexible than previous approaches, as it can seamlessly
handle any number of subgraphs, while consistently outperforming baseline
approaches."
Exploring Spoken Language Identification Strategies for Automatic Transcription of Multilingual Broadcast and Institutional Speech,https://arxiv.org/abs/2406.09290,2024-06-13,2024-06-19,0.0,0.0,"This paper addresses spoken language identification (SLI) and speech
recognition of multilingual broadcast and institutional speech, real
application scenarios that have been rarely addressed in the SLI literature.
Observing that in these domains language changes are mostly associated with
speaker changes, we propose a cascaded system consisting of speaker diarization
and language identification and compare it with more traditional language
identification and language diarization systems. Results show that the proposed
system often achieves lower language classification and language diarization
error rates (up to 10% relative language diarization error reduction and 60%
relative language confusion reduction) and leads to lower WERs on multilingual
test sets (more than 8% relative WER reduction), while at the same time does
not negatively affect speech recognition on monolingual audio (with an absolute
WER increase between 0.1% and 0.7% w.r.t. monolingual ASR)."
Understanding Jailbreak Success - A Study of Latent Space Dynamics in Large Language Models,https://arxiv.org/abs/2406.09289,2024-06-13,2024-06-19,0.0,0.0,"Conversational Large Language Models are trained to refuse to answer harmful
questions. However, emergent jailbreaking techniques can still elicit unsafe
outputs, presenting an ongoing challenge for model alignment. To better
understand how different jailbreak types circumvent safeguards, this paper
analyses model activations on different jailbreak inputs. We find that it is
possible to extract a jailbreak vector from a single class of jailbreaks that
works to mitigate jailbreak effectiveness from other classes. This may indicate
that different kinds of effective jailbreaks operate via similar internal
mechanisms. We investigate a potential common mechanism of harmfulness feature
suppression, and provide evidence for its existence by looking at the
harmfulness vector component. These findings offer actionable insights for
developing more robust jailbreak countermeasures and lay the groundwork for a
deeper, mechanistic understanding of jailbreak dynamics in language models."
Zero-Shot Learning Over Large Output Spaces  - Utilizing Indirect Knowledge Extraction from Large Language Models,https://arxiv.org/abs/2406.09288,2024-06-13,2024-06-19,0.0,0.0,"Extreme Multi-label Learning (XMC) is a task that allocates the most relevant
labels for an instance from a predefined label set. Extreme Zero-shot XMC
(EZ-XMC) is a special setting of XMC wherein no supervision is provided; only
the instances (raw text of the document) and the predetermined label set are
given. The scenario is designed to address cold-start problems in
categorization and recommendation. Traditional state-of-the-art methods extract
pseudo labels from the document title or segments. These labels from the
document are used to train a zero-shot bi-encoder model. The main issue with
these generated labels is their misalignment with the tagging task. In this
work, we propose a framework to train a small bi-encoder model via the feedback
from the large language model (LLM), the bi-encoder model encodes the document
and labels into embeddings for retrieval. Our approach leverages the zero-shot
ability of LLM to assess the correlation between labels and the document
instead of using the low-quality labels extracted from the document itself. Our
method also guarantees fast inference without the involvement of LLM. The
performance of our approach outperforms the SOTA methods on various datasets
while retaining a similar training time for large datasets."
On the Effects of Heterogeneous Data Sources on Speech-to-Text Foundation Models,https://arxiv.org/abs/2406.09282,2024-06-13,2024-06-19,0.0,0.0,"The Open Whisper-style Speech Model (OWSM) series was introduced to achieve
full transparency in building advanced speech-to-text (S2T) foundation models.
To this end, OWSM models are trained on 25 public speech datasets, which are
heterogeneous in multiple ways. In this study, we advance the OWSM series by
introducing OWSM v3.2, which improves on prior models by investigating and
addressing the impacts of this data heterogeneity. Our study begins with a
detailed analysis of each dataset, from which we derive two key strategies:
data filtering with proxy task to enhance data quality, and the incorporation
of punctuation and true-casing using an open large language model (LLM). With
all other configurations staying the same, OWSM v3.2 improves performance over
the OWSM v3.1 baseline while using 15% less training data."
Newswire - A Large-Scale Structured Database of a Century of Historical News,https://arxiv.org/abs/2406.09490,2024-06-13,2024-06-19,0.0,0.0,"In the U.S. historically, local newspapers drew their content largely from
newswires like the Associated Press. Historians argue that newswires played a
pivotal role in creating a national identity and shared understanding of the
world, but there is no comprehensive archive of the content sent over
newswires. We reconstruct such an archive by applying a customized deep
learning pipeline to hundreds of terabytes of raw image scans from thousands of
local newspapers. The resulting dataset contains 2.7 million unique public
domain U.S. newswire articles, written between 1878 and 1977. Locations in
these articles are georeferenced, topics are tagged using customized neural
topic classification, named entities are recognized, and individuals are
disambiguated to Wikipedia using a novel entity disambiguation model. To
construct the Newswire dataset, we first recognize newspaper layouts and
transcribe around 138 millions structured article texts from raw image scans.
We then use a customized neural bi-encoder model to de-duplicate reproduced
articles, in the presence of considerable abridgement and noise, quantifying
how widely each article was reproduced. A text classifier is used to ensure
that we only include newswire articles, which historically are in the public
domain. The structured data that accompany the texts provide rich information
about the who (disambiguated individuals), what (topics), and where
(georeferencing) of the news that millions of Americans read over the course of
a century. We also include Library of Congress metadata information about the
newspapers that ran the articles on their front pages. The Newswire dataset is
useful both for large language modeling - expanding training data beyond what
is available from modern web texts - and for studying a diversity of questions
in computational linguistics, social science, and the digital humanities."
Unpacking DPO and PPO - Disentangling Best Practices for Learning from Preference Feedback,https://arxiv.org/abs/2406.09279,2024-06-13,2024-06-19,0.0,0.0,"Learning from preference feedback has emerged as an essential step for
improving the generation quality and performance of modern language models
(LMs). Despite its widespread use, the way preference-based learning is applied
varies wildly, with differing data, learning algorithms, and evaluations used,
making disentangling the impact of each aspect difficult. In this work, we
identify four core aspects of preference-based learning: preference data,
learning algorithm, reward model, and policy training prompts, systematically
investigate the impact of these components on downstream model performance, and
suggest a recipe for strong learning for preference feedback. Our findings
indicate that all aspects are important for performance, with better preference
data leading to the largest improvements, followed by the choice of learning
algorithm, the use of improved reward models, and finally the use of additional
unlabeled prompts for policy training. Notably, PPO outperforms DPO by up to
2.5% in math and 1.2% in general domains. High-quality preference data leads to
improvements of up to 8% in instruction following and truthfulness. Despite
significant gains of up to 5% in mathematical evaluation when scaling up reward
models, we surprisingly observe marginal improvements in other categories.
  We publicly release the code used for training
(https://github.com/hamishivi/EasyLM) and evaluating
(https://github.com/allenai/open-instruct) our models, along with the models
and datasets themselves
(https://huggingface.co/collections/allenai/tulu-v25-suite-66676520fd578080e126f618)."
End-to-end Streaming model for Low-Latency Speech Anonymization,https://arxiv.org/abs/2406.09277,2024-06-13,2024-06-19,0.0,0.0,"Speaker anonymization aims to conceal cues to speaker identity while
preserving linguistic content. Current machine learning based approaches
require substantial computational resources, hindering real-time streaming
applications. To address these concerns, we propose a streaming model that
achieves speaker anonymization with low latency. The system is trained in an
end-to-end autoencoder fashion using a lightweight content encoder that
extracts HuBERT-like information, a pretrained speaker encoder that extract
speaker identity, and a variance encoder that injects pitch and energy
information. These three disentangled representations are fed to a decoder that
resynthesizes the speech signal. We present evaluation results from two
implementations of our system, a full model that achieves a latency of 230ms,
and a lite version (0.1x in size) that further reduces latency to 66ms while
maintaining state-of-the-art performance in naturalness, intelligibility, and
privacy preservation."
Action2Sound - Ambient-Aware Generation of Action Sounds from Egocentric Videos,https://arxiv.org/abs/2406.09272,2024-06-13,2024-06-19,0.0,0.0,"Generating realistic audio for human actions is important for many
applications, such as creating sound effects for films or virtual reality
games. Existing approaches implicitly assume total correspondence between the
video and audio during training, yet many sounds happen off-screen and have
weak to no correspondence with the visuals -- resulting in uncontrolled ambient
sounds or hallucinations at test time. We propose a novel ambient-aware audio
generation model, AV-LDM. We devise a novel audio-conditioning mechanism to
learn to disentangle foreground action sounds from the ambient background
sounds in in-the-wild training videos. Given a novel silent video, our model
uses retrieval-augmented generation to create audio that matches the visual
content both semantically and temporally. We train and evaluate our model on
two in-the-wild egocentric video datasets, Ego4D and EPIC-KITCHENS, and we
introduce Ego4D-Sounds -- 1.2M curated clips with action-audio correspondence.
Our model outperforms an array of existing methods, allows controllable
generation of the ambient sound, and even shows promise for generalizing to
computer graphics game clips. Overall, our approach is the first to focus
video-to-audio generation faithfully on the observed visual content despite
training from uncurated clips with natural background sounds."
Sharing Matters - Analysing Neurons Across Languages and Tasks in LLMs,https://arxiv.org/abs/2406.09265,2024-06-13,2024-06-19,0.0,0.0,"Multilingual large language models (LLMs) have greatly increased the ceiling
of performance on non-English tasks. However the mechanisms behind
multilingualism in these LLMs are poorly understood. Of particular interest is
the degree to which internal representations are shared between languages.
Recent work on neuron analysis of LLMs has focused on the monolingual case, and
the limited work on the multilingual case has not considered the interaction
between tasks and linguistic representations. In our work, we investigate how
neuron activation is shared across languages by categorizing neurons into four
distinct groups according to their responses across different languages for a
particular input: all-shared, partial-shared, specific, and non-activated. This
categorization is combined with a study of neuron attribution, i.e. the
importance of a neuron w.r.t an output. Our analysis reveals the following
insights: (i) the linguistic sharing patterns are strongly affected by the type
of task, but neuron behaviour changes across different inputs even for the same
task; (ii) all-shared neurons play a key role in generating correct responses;
(iii) boosting multilingual alignment by increasing all-shared neurons can
enhance accuracy on multilingual tasks. The code is available at
https://github.com/weixuan-wang123/multilingual-neurons."
"Towards Bidirectional Human-AI Alignment - A Systematic Review for Clarifications, Framework, and Future Directions",https://arxiv.org/abs/2406.09264,2024-06-13,2024-06-19,0.0,0.0,"Recent advancements in general-purpose AI have highlighted the importance of
guiding AI systems towards the intended goals, ethical principles, and values
of individuals and groups, a concept broadly recognized as alignment. However,
the lack of clarified definitions and scopes of human-AI alignment poses a
significant obstacle, hampering collaborative efforts across research domains
to achieve this alignment. In particular, ML- and philosophy-oriented alignment
research often views AI alignment as a static, unidirectional process (i.e.,
aiming to ensure that AI systems' objectives match humans) rather than an
ongoing, mutual alignment problem. This perspective largely neglects the
long-term interaction and dynamic changes of alignment. To understand these
gaps, we introduce a systematic review of over 400 papers published between
2019 and January 2024, spanning multiple domains such as Human-Computer
Interaction (HCI), Natural Language Processing (NLP), Machine Learning (ML). We
characterize, define and scope human-AI alignment. From this, we present a
conceptual framework of ""Bidirectional Human-AI Alignment"" to organize the
literature from a human-centered perspective. This framework encompasses both
1) conventional studies of aligning AI to humans that ensures AI produces the
intended outcomes determined by humans, and 2) a proposed concept of aligning
humans to AI, which aims to help individuals and society adjust to AI
advancements both cognitively and behaviorally. Additionally, we articulate the
key findings derived from literature analysis, including literature gaps and
trends, human values, and interaction techniques. To pave the way for future
studies, we envision three key challenges and give recommendations for future
research."
Generative Inverse Design of Crystal Structures via Diffusion Models with Transformers,https://arxiv.org/abs/2406.09263,2024-06-13,2024-06-19,0.0,0.0,"Recent advances in deep learning have enabled the generation of realistic
data by training generative models on large datasets of text, images, and
audio. While these models have demonstrated exceptional performance in
generating novel and plausible data, it remains an open question whether they
can effectively accelerate scientific discovery through the data generation and
drive significant advancements across various scientific fields. In particular,
the discovery of new inorganic materials with promising properties poses a
critical challenge, both scientifically and for industrial applications.
However, unlike textual or image data, materials, or more specifically crystal
structures, consist of multiple types of variables - including lattice vectors,
atom positions, and atomic species. This complexity in data give rise to a
variety of approaches for representing and generating such data. Consequently,
the design choices of generative models for crystal structures remain an open
question. In this study, we explore a new type of diffusion model for the
generative inverse design of crystal structures, with a backbone based on a
Transformer architecture. We demonstrate our models are superior to previous
methods in their versatility for generating crystal structures with desired
properties. Furthermore, our empirical results suggest that the optimal
conditioning methods vary depending on the dataset."
Flexible Heteroscedastic Count Regression with Deep Double Poisson Networks,https://arxiv.org/abs/2406.09262,2024-06-13,2024-06-19,0.0,0.0,"Neural networks that can produce accurate, input-conditional uncertainty
representations are critical for real-world applications. Recent progress on
heteroscedastic continuous regression has shown great promise for calibrated
uncertainty quantification on complex tasks, like image regression. However,
when these methods are applied to discrete regression tasks, such as crowd
counting, ratings prediction, or inventory estimation, they tend to produce
predictive distributions with numerous pathologies. We propose to address these
issues by training a neural network to output the parameters of a Double
Poisson distribution, which we call the Deep Double Poisson Network (DDPN). In
contrast to existing methods that are trained to minimize Gaussian negative log
likelihood (NLL), DDPNs produce a proper probability mass function over
discrete output. Additionally, DDPNs naturally model under-, over-, and
equi-dispersion, unlike networks trained with the more rigid Poisson and
Negative Binomial parameterizations. We show DDPNs 1) vastly outperform
existing discrete models; 2) meet or exceed the accuracy and flexibility of
networks trained with Gaussian NLL; 3) produce proper predictive distributions
over discrete counts; and 4) exhibit superior out-of-distribution detection.
DDPNs can easily be applied to a variety of count regression datasets including
tabular, image, point cloud, and text data."
Assessing Model Generalization in Vicinity,https://arxiv.org/abs/2406.09257,2024-06-13,2024-06-19,0.0,0.0,"This paper evaluates the generalization ability of classification models on
out-of-distribution test sets without depending on ground truth labels. Common
approaches often calculate an unsupervised metric related to a specific model
property, like confidence or invariance, which correlates with
out-of-distribution accuracy. However, these metrics are typically computed for
each test sample individually, leading to potential issues caused by spurious
model responses, such as overly high or low confidence. To tackle this
challenge, we propose incorporating responses from neighboring test samples
into the correctness assessment of each individual sample. In essence, if a
model consistently demonstrates high correctness scores for nearby samples, it
increases the likelihood of correctly predicting the target sample, and vice
versa. The resulting scores are then averaged across all test samples to
provide a holistic indication of model accuracy. Developed under the vicinal
risk formulation, this approach, named vicinal risk proxy (VRP), computes
accuracy without relying on labels. We show that applying the VRP method to
existing generalization indicators, such as average confidence and effective
invariance, consistently improves over these baselines both methodologically
and experimentally. This yields a stronger correlation with model accuracy,
especially on challenging out-of-distribution test sets."
Deep Sketched Output Kernel Regression for Structured Prediction,https://arxiv.org/abs/2406.09253,2024-06-13,2024-06-19,0.0,0.0,"By leveraging the kernel trick in the output space, kernel-induced losses
provide a principled way to define structured output prediction tasks for a
wide variety of output modalities. In particular, they have been successfully
used in the context of surrogate non-parametric regression, where the kernel
trick is typically exploited in the input space as well. However, when inputs
are images or texts, more expressive models such as deep neural networks seem
more suited than non-parametric methods. In this work, we tackle the question
of how to train neural networks to solve structured output prediction tasks,
while still benefiting from the versatility and relevance of kernel-induced
losses. We design a novel family of deep neural architectures, whose last layer
predicts in a data-dependent finite-dimensional subspace of the
infinite-dimensional output feature space deriving from the kernel-induced
loss. This subspace is chosen as the span of the eigenfunctions of a
randomly-approximated version of the empirical kernel covariance operator.
Interestingly, this approach unlocks the use of gradient descent algorithms
(and consequently of any neural architecture) for structured prediction.
Experiments on synthetic tasks as well as real-world supervised graph
prediction problems show the relevance of our method."
MirrorCheck - Efficient Adversarial Defense for Vision-Language Models,https://arxiv.org/abs/2406.09250,2024-06-13,2024-06-19,0.0,0.0,"Vision-Language Models (VLMs) are becoming increasingly vulnerable to
adversarial attacks as various novel attack strategies are being proposed
against these models. While existing defenses excel in unimodal contexts, they
currently fall short in safeguarding VLMs against adversarial threats. To
mitigate this vulnerability, we propose a novel, yet elegantly simple approach
for detecting adversarial samples in VLMs. Our method leverages Text-to-Image
(T2I) models to generate images based on captions produced by target VLMs.
Subsequently, we calculate the similarities of the embeddings of both input and
generated images in the feature space to identify adversarial samples.
Empirical evaluations conducted on different datasets validate the efficacy of
our approach, outperforming baseline methods adapted from image classification
domains. Furthermore, we extend our methodology to classification tasks,
showcasing its adaptability and model-agnostic nature. Theoretical analyses and
empirical findings also show the resilience of our approach against adaptive
attacks, positioning it as an excellent defense mechanism for real-world
deployment against adversarial threats."
OpenVLA - An Open-Source Vision-Language-Action Model,https://arxiv.org/abs/2406.09246,2024-06-13,2024-06-19,0.0,0.0,"Large policies pretrained on a combination of Internet-scale vision-language
data and diverse robot demonstrations have the potential to change how we teach
robots new skills: rather than training new behaviors from scratch, we can
fine-tune such vision-language-action (VLA) models to obtain robust,
generalizable policies for visuomotor control. Yet, widespread adoption of VLAs
for robotics has been challenging as 1) existing VLAs are largely closed and
inaccessible to the public, and 2) prior work fails to explore methods for
efficiently fine-tuning VLAs for new tasks, a key component for adoption.
Addressing these challenges, we introduce OpenVLA, a 7B-parameter open-source
VLA trained on a diverse collection of 970k real-world robot demonstrations.
OpenVLA builds on a Llama 2 language model combined with a visual encoder that
fuses pretrained features from DINOv2 and SigLIP. As a product of the added
data diversity and new model components, OpenVLA demonstrates strong results
for generalist manipulation, outperforming closed models such as RT-2-X (55B)
by 16.5% in absolute task success rate across 29 tasks and multiple robot
embodiments, with 7x fewer parameters. We further show that we can effectively
fine-tune OpenVLA for new settings, with especially strong generalization
results in multi-task environments involving multiple objects and strong
language grounding abilities, and outperform expressive from-scratch imitation
learning methods such as Diffusion Policy by 20.4%. We also explore compute
efficiency; as a separate contribution, we show that OpenVLA can be fine-tuned
on consumer GPUs via modern low-rank adaptation methods and served efficiently
via quantization without a hit to downstream success rate. Finally, we release
model checkpoints, fine-tuning notebooks, and our PyTorch codebase with
built-in support for training VLAs at scale on Open X-Embodiment datasets."
Towards a Characterisation of Monte-Carlo Tree Search Performance in Different Games,https://arxiv.org/abs/2406.09242,2024-06-13,2024-06-19,0.0,0.0,"Many enhancements to Monte-Carlo Tree Search (MCTS) have been proposed over
almost two decades of general game playing and other artificial intelligence
research. However, our ability to characterise and understand which variants
work well or poorly in which games is still lacking. This paper describes work
on an initial dataset that we have built to make progress towards such an
understanding: 268,386 plays among 61 different agents across 1494 distinct
games. We describe a preliminary analysis and work on training predictive
models on this dataset, as well as lessons learned and future plans for a new
and improved version of the dataset."
What is the long-run distribution of stochastic gradient descent? A large deviations analysis,https://arxiv.org/abs/2406.09241,2024-06-13,2024-06-19,0.0,0.0,"In this paper, we examine the long-run distribution of stochastic gradient
descent (SGD) in general, non-convex problems. Specifically, we seek to
understand which regions of the problem's state space are more likely to be
visited by SGD, and by how much. Using an approach based on the theory of large
deviations and randomly perturbed dynamical systems, we show that the long-run
distribution of SGD resembles the Boltzmann-Gibbs distribution of equilibrium
thermodynamics with temperature equal to the method's step-size and energy
levels determined by the problem's objective and the statistics of the noise.
In particular, we show that, in the long run, (a) the problem's critical region
is visited exponentially more often than any non-critical region; (b) the
iterates of SGD are exponentially concentrated around the problem's minimum
energy state (which does not always coincide with the global minimum of the
objective); (c) all other connected components of critical points are visited
with frequency that is exponentially proportional to their energy level; and,
finally (d) any component of local maximizers or saddle points is ""dominated""
by a component of local minimizers which is visited exponentially more often."
SeMOPO - Learning High-quality Model and Policy from Low-quality Offline Visual Datasets,https://arxiv.org/abs/2406.09486,2024-06-13,2024-06-19,0.0,0.0,"Model-based offline reinforcement Learning (RL) is a promising approach that
leverages existing data effectively in many real-world applications, especially
those involving high-dimensional inputs like images and videos. To alleviate
the distribution shift issue in offline RL, existing model-based methods
heavily rely on the uncertainty of learned dynamics. However, the model
uncertainty estimation becomes significantly biased when observations contain
complex distractors with non-trivial dynamics. To address this challenge, we
propose a new approach - \emph{Separated Model-based Offline Policy
Optimization} (SeMOPO) - decomposing latent states into endogenous and
exogenous parts via conservative sampling and estimating model uncertainty on
the endogenous states only. We provide a theoretical guarantee of model
uncertainty and performance bound of SeMOPO. To assess the efficacy, we
construct the Low-Quality Vision Deep Data-Driven Datasets for RL (LQV-D4RL),
where the data are collected by non-expert policy and the observations include
moving distractors. Experimental results show that our method substantially
outperforms all baseline methods, and further analytical experiments validate
the critical designs in our method. The project website is
\href{https://sites.google.com/view/semopo}{https://sites.google.com/view/semopo}."
On Softmax Direct Preference Optimization for Recommendation,https://arxiv.org/abs/2406.09215,2024-06-13,2024-06-19,0.0,0.0,"Recommender systems aim to predict personalized rankings based on user
preference data. With the rise of Language Models (LMs), LM-based recommenders
have been widely explored due to their extensive world knowledge and powerful
reasoning abilities. Most of the LM-based recommenders convert historical
interactions into language prompts, pairing with a positive item as the target
response and fine-tuning LM with a language modeling loss. However, the current
objective fails to fully leverage preference data and is not optimized for
personalized ranking tasks, which hinders the performance of LM-based
recommenders. Inspired by the current advancement of Direct Preference
Optimization (DPO) in human preference alignment and the success of softmax
loss in recommendations, we propose Softmax-DPO (S-DPO) to instill ranking
information into the LM to help LM-based recommenders distinguish preferred
items from negatives, rather than solely focusing on positives. Specifically,
we incorporate multiple negatives in user preference data and devise an
alternative version of DPO loss tailored for LM-based recommenders, connected
to softmax sampling strategies. Theoretically, we bridge S-DPO with the softmax
loss over negative sampling and find that it has a side effect of mining hard
negatives, which assures its exceptional capabilities in recommendation tasks.
Empirically, extensive experiments conducted on three real-world datasets
demonstrate the superiority of S-DPO to effectively model user preference and
further boost recommendation performance while mitigating the data likelihood
decline issue of DPO. Our codes are available at
https://github.com/chenyuxin1999/S-DPO."
Applying Multi-Agent Negotiation to Solve the Production Routing Problem With Privacy Preserving,https://arxiv.org/abs/2406.09214,2024-06-13,2024-06-19,0.0,0.0,"This paper presents a novel approach to address the Production Routing
Problem with Privacy Preserving (PRPPP) in supply chain optimization. The
integrated optimization of production, inventory, distribution, and routing
decisions in real-world industry applications poses several challenges,
including increased complexity, discrepancies between planning and execution,
and constraints on information sharing. To mitigate these challenges, this
paper proposes the use of intelligent agent negotiation within a hybrid
Multi-Agent System (MAS) integrated with optimization algorithms. The MAS
facilitates communication and coordination among entities, encapsulates private
information, and enables negotiation. This, along with optimization algorithms,
makes it a compelling framework for establishing optimal solutions. The
approach is supported by real-world applications and synergies between MAS and
optimization methods, demonstrating its effectiveness in addressing complex
supply chain optimization problems."
Investigating potential causes of Sepsis with Bayesian network structure learning,https://arxiv.org/abs/2406.09207,2024-06-13,2024-06-19,0.0,0.0,"Sepsis is a life-threatening and serious global health issue. This study
combines knowledge with available hospital data to investigate the potential
causes of Sepsis that can be affected by policy decisions. We investigate the
underlying causal structure of this problem by combining clinical expertise
with score-based, constraint-based, and hybrid structure learning algorithms. A
novel approach to model averaging and knowledge-based constraints was
implemented to arrive at a consensus structure for causal inference. The
structure learning process highlighted the importance of exploring data-driven
approaches alongside clinical expertise. This includes discovering unexpected,
although reasonable, relationships from a clinical perspective. Hypothetical
interventions on Chronic Obstructive Pulmonary Disease, Alcohol dependence, and
Diabetes suggest that the presence of any of these risk factors in patients
increases the likelihood of Sepsis. This finding, alongside measuring the
effect of these risk factors on Sepsis, has potential policy implications.
Recognising the importance of prediction in improving Sepsis related health
outcomes, the model built is also assessed in its ability to predict Sepsis.
The predictions generated by the consensus model were assessed for their
accuracy, sensitivity, and specificity. These three indicators all had results
around 70%, and the AUC was 80%, which means the causal structure of the model
is reasonably accurate given that the models were trained on data available for
commissioning purposes only."
Self-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models,https://arxiv.org/abs/2406.09206,2024-06-13,2024-06-19,0.0,0.0,"Active learning is an iterative labeling process that is used to obtain a
small labeled subset, despite the absence of labeled data, thereby enabling to
train a model for supervised tasks such as text classification. While active
learning has made considerable progress in recent years due to improvements
provided by pre-trained language models, there is untapped potential in the
often neglected unlabeled portion of the data, although it is available in
considerably larger quantities than the usually small set of labeled data. Here
we investigate how self-training, a semi-supervised approach where a model is
used to obtain pseudo-labels from the unlabeled data, can be used to improve
the efficiency of active learning for text classification. Starting with an
extensive reproduction of four previous self-training approaches, some of which
are evaluated for the first time in the context of active learning or natural
language processing, we devise HAST, a new and effective self-training
strategy, which is evaluated on four text classification benchmarks, on which
it outperforms the reproduced self-training approaches and reaches
classification results comparable to previous experiments for three out of four
datasets, using only 25% of the data."
ReadCtrl - Personalizing text generation with readability-controlled instruction learning,https://arxiv.org/abs/2406.09205,2024-06-13,2024-06-19,0.0,0.0,"Content generation conditioning on users's readability is an important
application for personalization. In an era of large language models (LLMs),
readability-controlled text generation based on LLMs has become increasingly
important. This paper introduces a novel methodology called
""Readability-Controlled Instruction Learning (ReadCtrl),"" which aims to
instruction-tune LLMs to tailor users' readability levels. Unlike the
traditional methods, which primarily focused on categorical readability
adjustments typically classified as high, medium, and low or expert and
layperson levels with limited success, ReadCtrl introduces a dynamic framework
that enables LLMs to generate content at various (near continuous level)
complexity levels, thereby enhancing their versatility across different
applications. Our results show that the ReadCtrl-Mistral-7B models
significantly outperformed strong baseline models such as GPT-4 and Claude-3,
with a win rate of 52.1%:35.7% against GPT-4 in human evaluations. Furthermore,
Read-Ctrl has shown significant improvements in automatic evaluations, as
evidenced by better readability metrics (e.g., FOG, FKGL) and generation
quality metrics (e.g., BLEU, SARI, SummaC-Factuality, UniEval-Consistency and
Coherence). These results underscore Read-Ctrl's effectiveness and tenacity in
producing high-quality, contextually appropriate outputs that closely align
with targeted readability levels, marking a significant advancement in
personalized content generation using LLMs."
"Language Complexity and Speech Recognition Accuracy - Orthographic Complexity Hurts, Phonological Complexity Doesn't",https://arxiv.org/abs/2406.09202,2024-06-13,2024-06-19,0.0,0.0,"We investigate what linguistic factors affect the performance of Automatic
Speech Recognition (ASR) models. We hypothesize that orthographic and
phonological complexities both degrade accuracy. To examine this, we fine-tune
the multilingual self-supervised pretrained model Wav2Vec2-XLSR-53 on 25
languages with 15 writing systems, and we compare their ASR accuracy, number of
graphemes, unigram grapheme entropy, logographicity (how much
word/morpheme-level information is encoded in the writing system), and number
of phonemes. The results demonstrate that orthographic complexities
significantly correlate with low ASR accuracy, while phonological complexity
shows no significant correlation."
Orthogonality and isotropy of speaker and phonetic information in self-supervised speech representations,https://arxiv.org/abs/2406.09200,2024-06-13,2024-06-19,0.0,0.0,"Self-supervised speech representations can hugely benefit downstream speech
technologies, yet the properties that make them useful are still poorly
understood. Two candidate properties related to the geometry of the
representation space have been hypothesized to correlate well with downstream
tasks: (1) the degree of orthogonality between the subspaces spanned by the
speaker centroids and phone centroids, and (2) the isotropy of the space, i.e.,
the degree to which all dimensions are effectively utilized. To study them, we
introduce a new measure, Cumulative Residual Variance (CRV), which can be used
to assess both properties. Using linear classifiers for speaker and phone ID to
probe the representations of six different self-supervised models and two
untrained baselines, we ask whether either orthogonality or isotropy correlate
with linear probing accuracy. We find that both measures correlate with
phonetic probing accuracy, though our results on isotropy are more nuanced."
Precise analysis of ridge interpolators under heavy correlations -- a Random Duality Theory view,https://arxiv.org/abs/2406.09199,2024-06-13,2024-06-19,0.0,0.0,"We consider fully row/column-correlated linear regression models and study
several classical estimators (including minimum norm interpolators (GLS),
ordinary least squares (LS), and ridge regressors). We show that \emph{Random
Duality Theory} (RDT) can be utilized to obtain precise closed form
characterizations of all estimators related optimizing quantities of interest,
including the \emph{prediction risk} (testing or generalization error). On a
qualitative level out results recover the risk's well known non-monotonic
(so-called double-descent) behavior as the number of features/sample size ratio
increases. On a quantitative level, our closed form results show how the risk
explicitly depends on all key model parameters, including the problem
dimensions and covariance matrices. Moreover, a special case of our results,
obtained when intra-sample (or time-series) correlations are not present,
precisely match the corresponding ones obtained via spectral methods in
[6,16,17,24]."
Adaptive Slot Attention - Object Discovery with Dynamic Slot Number,https://arxiv.org/abs/2406.09196,2024-06-13,2024-06-19,0.0,0.0,"Object-centric learning (OCL) extracts the representation of objects with
slots, offering an exceptional blend of flexibility and interpretability for
abstracting low-level perceptual features. A widely adopted method within OCL
is slot attention, which utilizes attention mechanisms to iteratively refine
slot representations. However, a major drawback of most object-centric models,
including slot attention, is their reliance on predefining the number of slots.
This not only necessitates prior knowledge of the dataset but also overlooks
the inherent variability in the number of objects present in each instance. To
overcome this fundamental limitation, we present a novel complexity-aware
object auto-encoder framework. Within this framework, we introduce an adaptive
slot attention (AdaSlot) mechanism that dynamically determines the optimal
number of slots based on the content of the data. This is achieved by proposing
a discrete slot sampling module that is responsible for selecting an
appropriate number of slots from a candidate list. Furthermore, we introduce a
masked slot decoder that suppresses unselected slots during the decoding
process. Our framework, tested extensively on object discovery tasks with
various datasets, shows performance matching or exceeding top fixed-slot
models. Moreover, our analysis substantiates that our method exhibits the
capability to dynamically adapt the slot number according to each instance's
complexity, offering the potential for further exploration in slot attention
research. Project will be available at https://kfan21.github.io/AdaSlot/"
Benign overfitting in Fixed Dimension via Physics-Informed Learning with Smooth Inductive Bias,https://arxiv.org/abs/2406.09194,2024-06-13,2024-06-19,0.0,0.0,"Recent advances in machine learning have inspired a surge of research into
reconstructing specific quantities of interest from measurements that comply
with certain physical laws. These efforts focus on inverse problems that are
governed by partial differential equations (PDEs). In this work, we develop an
asymptotic Sobolev norm learning curve for kernel ridge(less) regression when
addressing (elliptical) linear inverse problems. Our results show that the PDE
operators in the inverse problem can stabilize the variance and even behave
benign overfitting for fixed-dimensional problems, exhibiting different
behaviors from regression problems. Besides, our investigation also
demonstrates the impact of various inductive biases introduced by minimizing
different Sobolev norms as a form of implicit regularization. For the
regularized least squares estimator, we find that all considered inductive
biases can achieve the optimal convergence rate, provided the regularization
parameter is appropriately chosen. The convergence rate is actually independent
to the choice of (smooth enough) inductive bias for both ridge and ridgeless
regression. Surprisingly, our smoothness requirement recovered the condition
found in Bayesian setting and extend the conclusion to the minimum norm
interpolation estimators."
GuardAgent - Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning,https://arxiv.org/abs/2406.09187,2024-06-13,2024-06-19,0.0,0.0,"The rapid advancement of large language models (LLMs) has catalyzed the
deployment of LLM-powered agents across numerous applications, raising new
concerns regarding their safety and trustworthiness. Existing methods for
enhancing the safety of LLMs are not directly transferable to LLM-powered
agents due to their diverse objectives and output modalities. In this paper, we
propose GuardAgent, the first LLM agent as a guardrail to other LLM agents.
Specifically, GuardAgent oversees a target LLM agent by checking whether its
inputs/outputs satisfy a set of given guard requests defined by the users.
GuardAgent comprises two steps: 1) creating a task plan by analyzing the
provided guard requests, and 2) generating guardrail code based on the task
plan and executing the code by calling APIs or using external engines. In both
steps, an LLM is utilized as the core reasoning component, supplemented by
in-context demonstrations retrieved from a memory module. Such
knowledge-enabled reasoning allows GuardAgent to understand various textual
guard requests and accurately ""translate"" them into executable code that
provides reliable guardrails. Furthermore, GuardAgent is equipped with an
extendable toolbox containing functions and APIs and requires no additional LLM
training, which underscores its generalization capabilities and low operational
overhead. Additionally, we propose two novel benchmarks: an EICU-AC benchmark
for assessing privacy-related access control for healthcare agents and a
Mind2Web-SC benchmark for safety evaluation for web agents. We show the
effectiveness of GuardAgent on these two benchmarks with 98.7% and 90.0%
accuracy in moderating invalid inputs and outputs for the two types of agents,
respectively. We also show that GuardAgent is able to define novel functions in
adaption to emergent LLM agents and guard requests, which underscores its
strong generalization capabilities."
Ridge interpolators in correlated factor regression models -- exact risk analysis,https://arxiv.org/abs/2406.09183,2024-06-13,2024-06-19,0.0,0.0,"We consider correlated \emph{factor} regression models (FRM) and analyze the
performance of classical ridge interpolators. Utilizing powerful \emph{Random
Duality Theory} (RDT) mathematical engine, we obtain \emph{precise} closed form
characterizations of the underlying optimization problems and all associated
optimizing quantities. In particular, we provide \emph{excess prediction risk}
characterizations that clearly show the dependence on all key model parameters,
covariance matrices, loadings, and dimensions. As a function of the
over-parametrization ratio, the generalized least squares (GLS) risk also
exhibits the well known \emph{double-descent} (non-monotonic) behavior.
Similarly to the classical linear regression models (LRM), we demonstrate that
such FRM phenomenon can be smoothened out by the optimally tuned ridge
regularization. The theoretical results are supplemented by numerical
simulations and an excellent agrement between the two is observed. Moreover, we
note that ``ridge smootenhing'' is often of limited effect already for
over-parametrization ratios above $5$ and of virtually no effect for those
above $10$. This solidifies the notion that one of the recently most popular
neural networks paradigms -- \emph{zero-training (interpolating) generalizes
well} -- enjoys wider applicability, including the one within the FRM
estimation/prediction context."
Federated Contrastive Learning for Personalized Semantic Communication,https://arxiv.org/abs/2406.09182,2024-06-13,2024-06-19,0.0,0.0,"In this letter, we design a federated contrastive learning (FedCL) framework
aimed at supporting personalized semantic communication. Our FedCL enables
collaborative training of local semantic encoders across multiple clients and a
global semantic decoder owned by the base station. This framework supports
heterogeneous semantic encoders since it does not require client-side model
aggregation. Furthermore, to tackle the semantic imbalance issue arising from
heterogeneous datasets across distributed clients, we employ contrastive
learning to train a semantic centroid generator (SCG). This generator obtains
representative global semantic centroids that exhibit intra-semantic
compactness and inter-semantic separability. Consequently, it provides superior
supervision for learning discriminative local semantic features. Additionally,
we conduct theoretical analysis to quantify the convergence performance of
FedCL. Simulation results verify the superiority of the proposed FedCL
framework compared to other distributed learning benchmarks in terms of task
performance and robustness under different numbers of clients and channel
conditions, especially in low signal-to-noise ratio and highly heterogeneous
data scenarios."
Detection-Rate-Emphasized Multi-objective Evolutionary Feature Selection for Network Intrusion Detection,https://arxiv.org/abs/2406.09180,2024-06-13,2024-06-19,0.0,0.0,"Network intrusion detection is one of the most important issues in the field
of cyber security, and various machine learning techniques have been applied to
build intrusion detection systems. However, since the number of features to
describe the network connections is often large, where some features are
redundant or noisy, feature selection is necessary in such scenarios, which can
both improve the efficiency and accuracy. Recently, some researchers focus on
using multi-objective evolutionary algorithms (MOEAs) to select features. But
usually, they only consider the number of features and classification accuracy
as the objectives, resulting in unsatisfactory performance on a critical
metric, detection rate. This will lead to the missing of many real attacks and
bring huge losses to the network system. In this paper, we propose DR-MOFS to
model the feature selection problem in network intrusion detection as a
three-objective optimization problem, where the number of features, accuracy
and detection rate are optimized simultaneously, and use MOEAs to solve it.
Experiments on two popular network intrusion detection datasets NSL-KDD and
UNSW-NB15 show that in most cases the proposed method can outperform previous
methods, i.e., lead to fewer features, higher accuracy and detection rate."
Unlearning with Control - Assessing Real-world Utility for Large Language Model Unlearning,https://arxiv.org/abs/2406.09179,2024-06-13,2024-06-19,0.0,0.0,"The compelling goal of eradicating undesirable data behaviors, while
preserving usual model functioning, underscores the significance of machine
unlearning within the domain of large language models (LLMs). Recent research
has begun to approach LLM unlearning via gradient ascent (GA) -- increasing the
prediction risk for those training strings targeted to be unlearned, thereby
erasing their parameterized responses. Despite their simplicity and efficiency,
we suggest that GA-based methods face the propensity towards excessive
unlearning, resulting in various undesirable model behaviors, such as
catastrophic forgetting, that diminish their practical utility. In this paper,
we suggest a set of metrics that can capture multiple facets of real-world
utility and propose several controlling methods that can regulate the extent of
excessive unlearning. Accordingly, we suggest a general framework to better
reflect the practical efficacy of various unlearning methods -- we begin by
controlling the unlearning procedures/unlearned models such that no excessive
unlearning occurs and follow by the evaluation for unlearning efficacy. Our
experimental analysis on established benchmarks revealed that GA-based methods
are far from perfect in practice, as strong unlearning is at the high cost of
hindering the model utility. We conclude that there is still a long way towards
practical and effective LLM unlearning, and more efforts are required in this
field."
Scalable and Flexible Causal Discovery with an Efficient Test for Adjacency,https://arxiv.org/abs/2406.09177,2024-06-13,2024-06-19,0.0,0.0,"To make accurate predictions, understand mechanisms, and design interventions
in systems of many variables, we wish to learn causal graphs from large scale
data. Unfortunately the space of all possible causal graphs is enormous so
scalably and accurately searching for the best fit to the data is a challenge.
In principle we could substantially decrease the search space, or learn the
graph entirely, by testing the conditional independence of variables. However,
deciding if two variables are adjacent in a causal graph may require an
exponential number of tests. Here we build a scalable and flexible method to
evaluate if two variables are adjacent in a causal graph, the Differentiable
Adjacency Test (DAT). DAT replaces an exponential number of tests with a
provably equivalent relaxed problem. It then solves this problem by training
two neural networks. We build a graph learning method based on DAT, DAT-Graph,
that can also learn from data with interventions. DAT-Graph can learn graphs of
1000 variables with state of the art accuracy. Using the graph learned by
DAT-Graph, we also build models that make much more accurate predictions of the
effects of interventions on large scale RNA sequencing data."
ReMI - A Dataset for Reasoning with Multiple Images,https://arxiv.org/abs/2406.09175,2024-06-13,2024-06-19,0.0,0.0,"With the continuous advancement of large language models (LLMs), it is
essential to create new benchmarks to effectively evaluate their expanding
capabilities and identify areas for improvement. This work focuses on
multi-image reasoning, an emerging capability in state-of-the-art LLMs. We
introduce ReMI, a dataset designed to assess LLMs' ability to Reason with
Multiple Images. This dataset encompasses a diverse range of tasks, spanning
various reasoning domains such as math, physics, logic, code, table/chart
understanding, and spatial and temporal reasoning. It also covers a broad
spectrum of characteristics found in multi-image reasoning scenarios. We have
benchmarked several cutting-edge LLMs using ReMI and found a substantial gap
between their performance and human-level proficiency. This highlights the
challenges in multi-image reasoning and the need for further research. Our
analysis also reveals the strengths and weaknesses of different models,
shedding light on the types of reasoning that are currently attainable and
areas where future models require improvement. To foster further research in
this area, we are releasing ReMI publicly:
https://huggingface.co/datasets/mehrankazemi/ReMI."
Potion - Towards Poison Unlearning,https://arxiv.org/abs/2406.09173,2024-06-13,2024-06-19,0.0,0.0,"Adversarial attacks by malicious actors on machine learning systems, such as
introducing poison triggers into training datasets, pose significant risks. The
challenge in resolving such an attack arises in practice when only a subset of
the poisoned data can be identified. This necessitates the development of
methods to remove, i.e. unlearn, poison triggers from already trained models
with only a subset of the poison data available. The requirements for this task
significantly deviate from privacy-focused unlearning where all of the data to
be forgotten by the model is known. Previous work has shown that the
undiscovered poisoned samples lead to a failure of established unlearning
methods, with only one method, Selective Synaptic Dampening (SSD), showing
limited success. Even full retraining, after the removal of the identified
poison, cannot address this challenge as the undiscovered poison samples lead
to a reintroduction of the poison trigger in the model. Our work addresses two
key challenges to advance the state of the art in poison unlearning. First, we
introduce a novel outlier-resistant method, based on SSD, that significantly
improves model protection and unlearning performance. Second, we introduce
Poison Trigger Neutralisation (PTN) search, a fast, parallelisable,
hyperparameter search that utilises the characteristic ""unlearning versus model
protection"" trade-off to find suitable hyperparameters in settings where the
forget set size is unknown and the retain set is contaminated. We benchmark our
contributions using ResNet-9 on CIFAR10 and WideResNet-28x10 on CIFAR100.
Experimental results show that our method heals 93.72% of poison compared to
SSD with 83.41% and full retraining with 40.68%. We achieve this while also
lowering the average model accuracy drop caused by unlearning from 5.68% (SSD)
to 1.41% (ours)."
Generative vs. Discriminative modeling under the lens of uncertainty quantification,https://arxiv.org/abs/2406.09172,2024-06-13,2024-06-19,0.0,0.0,"Learning a parametric model from a given dataset indeed enables to capture
intrinsic dependencies between random variables via a parametric conditional
probability distribution and in turn predict the value of a label variable
given observed variables. In this paper, we undertake a comparative analysis of
generative and discriminative approaches which differ in their construction and
the structure of the underlying inference problem. Our objective is to compare
the ability of both approaches to leverage information from various sources in
an epistemic uncertainty aware inference via the posterior predictive
distribution. We assess the role of a prior distribution, explicit in the
generative case and implicit in the discriminative case, leading to a
discussion about discriminative models suffering from imbalanced dataset. We
next examine the double role played by the observed variables in the generative
case, and discuss the compatibility of both approaches with semi-supervised
learning. We also provide with practical insights and we examine how the
modeling choice impacts the sampling from the posterior predictive
distribution. With regard to this, we propose a general sampling scheme
enabling supervised learning for both approaches, as well as semi-supervised
learning when compatible with the considered modeling approach. Throughout this
paper, we illustrate our arguments and conclusions using the example of affine
regression, and validate our comparative analysis through classification
simulations using neural network based models."
Test of Time - A Benchmark for Evaluating LLMs on Temporal Reasoning,https://arxiv.org/abs/2406.09170,2024-06-13,2024-06-19,0.0,0.0,"Large language models (LLMs) have showcased remarkable reasoning
capabilities, yet they remain susceptible to errors, particularly in temporal
reasoning tasks involving complex temporal logic. Existing research has
explored LLM performance on temporal reasoning using diverse datasets and
benchmarks. However, these studies often rely on real-world data that LLMs may
have encountered during pre-training or employ anonymization techniques that
can inadvertently introduce factual inconsistencies. In this work, we address
these limitations by introducing novel synthetic datasets specifically designed
to assess LLM temporal reasoning abilities in various scenarios. The diversity
of question types across these datasets enables systematic investigation into
the impact of the problem structure, size, question type, fact order, and other
factors on LLM performance. Our findings provide valuable insights into the
strengths and weaknesses of current LLMs in temporal reasoning tasks. To foster
further research in this area, we are open-sourcing the datasets and evaluation
framework used in our experiments: https://huggingface.co/datasets/baharef/ToT."
SR-CACO-2 - A Dataset for Confocal Fluorescence Microscopy Image Super-Resolution,https://arxiv.org/abs/2406.09168,2024-06-13,2024-06-19,0.0,0.0,"Confocal fluorescence microscopy is one of the most accessible and widely
used imaging techniques for the study of biological processes. Scanning
confocal microscopy allows the capture of high-quality images from 3D samples,
yet suffers from well-known limitations such as photobleaching and
phototoxicity of specimens caused by intense light exposure, which limits its
use in some applications, especially for living cells. Cellular damage can be
alleviated by changing imaging parameters to reduce light exposure, often at
the expense of image quality. Machine/deep learning methods for single-image
super-resolution (SISR) can be applied to restore image quality by upscaling
lower-resolution (LR) images to produce high-resolution images (HR). These SISR
methods have been successfully applied to photo-realistic images due partly to
the abundance of publicly available data. In contrast, the lack of publicly
available data partly limits their application and success in scanning confocal
microscopy. In this paper, we introduce a large scanning confocal microscopy
dataset named SR-CACO-2 that is comprised of low- and high-resolution image
pairs marked for three different fluorescent markers. It allows the evaluation
of performance of SISR methods on three different upscaling levels (X2, X4,
X8). SR-CACO-2 contains the human epithelial cell line Caco-2 (ATCC HTB-37),
and it is composed of 22 tiles that have been translated in the form of 9,937
image patches for experiments with SISR methods. Given the new SR-CACO-2
dataset, we also provide benchmarking results for 15 state-of-the-art methods
that are representative of the main SISR families. Results show that these
methods have limited success in producing high-resolution textures, indicating
that SR-CACO-2 represents a challenging problem. Our dataset, code and
pretrained weights are available: https://github.com/sbelharbi/sr-caco-2."
Fine-Grained Domain Generalization with Feature Structuralization,https://arxiv.org/abs/2406.09166,2024-06-13,2024-06-19,0.0,0.0,"Fine-grained domain generalization (FGDG) is a more challenging task than
traditional DG tasks due to its small inter-class variations and relatively
large intra-class disparities. When domain distribution changes, the
vulnerability of subtle features leads to a severe deterioration in model
performance. Nevertheless, humans inherently demonstrate the capacity for
generalizing to out-of-distribution data, leveraging structured
multi-granularity knowledge that emerges from discerning the commonality and
specificity within categories. Likewise, we propose a Feature Structuralized
Domain Generalization (FSDG) model, wherein features experience
structuralization into common, specific, and confounding segments, harmoniously
aligned with their relevant semantic concepts, to elevate performance in FGDG.
Specifically, feature structuralization (FS) is accomplished through joint
optimization of five constraints: a decorrelation function applied to
disentangled segments, three constraints ensuring common feature consistency
and specific feature distinctiveness, and a prediction calibration term. By
imposing these stipulations, FSDG is prompted to disentangle and align features
based on multi-granularity knowledge, facilitating robust subtle distinctions
among categories. Extensive experimentation on three benchmarks consistently
validates the superiority of FSDG over state-of-the-art counterparts, with an
average improvement of 6.2% in FGDG performance. Beyond that, the
explainability analysis on explicit concept matching intensity between the
shared concepts among categories and the model channels, along with experiments
on various mainstream model architectures, substantiates the validity of FS."
ALPHAGMUT - A Rationale-Guided Alpha Shape Graph Neural Network to Evaluate Mutation Effects,https://arxiv.org/abs/2406.09159,2024-06-13,2024-06-19,0.0,0.0,"In silico methods evaluating the mutation effects of missense mutations are
providing an important approach for understanding mutations in personal genomes
and identifying disease-relevant biomarkers. However, existing methods,
including deep learning methods, heavily rely on sequence-aware information,
and do not fully leverage the potential of available 3D structural information.
In addition, these methods may exhibit an inability to predict mutations in
domains difficult to formulate sequence-based embeddings. In this study, we
introduce a novel rationale-guided graph neural network AlphaGMut to evaluate
mutation effects and to distinguish pathogenic mutations from neutral
mutations. We compute the alpha shapes of protein structures to obtain
atomic-resolution edge connectivities and map them to an accurate residue-level
graph representation. We then compute structural-, topological-, biophysical-,
and sequence properties of the mutation sites, which are assigned as node
attributes in the graph. These node attributes could effectively guide the
graph neural network to learn the difference between pathogenic and neutral
mutations using k-hop message passing with a short training period. We
demonstrate that AlphaGMut outperforms state-of-the-art methods, including
DeepMind's AlphaMissense, in many performance metrics. In addition, AlphaGMut
has the advantage of performing well in alignment-free settings, which provides
broader prediction coverage and better generalization compared to current
methods requiring deep sequence-aware information."
Towards Multilingual Audio-Visual Question Answering,https://arxiv.org/abs/2406.09156,2024-06-13,2024-06-19,0.0,0.0,"In this paper, we work towards extending Audio-Visual Question Answering
(AVQA) to multilingual settings. Existing AVQA research has predominantly
revolved around English and replicating it for addressing AVQA in other
languages requires a substantial allocation of resources. As a scalable
solution, we leverage machine translation and present two multilingual AVQA
datasets for eight languages created from existing benchmark AVQA datasets.
This prevents extra human annotation efforts of collecting questions and
answers manually. To this end, we propose, MERA framework, by leveraging
state-of-the-art (SOTA) video, audio, and textual foundation models for AVQA in
multiple languages. We introduce a suite of models namely MERA-L, MERA-C,
MERA-T with varied model architectures to benchmark the proposed datasets. We
believe our work will open new research directions and act as a reference
benchmark for future works in multilingual AVQA."
DefAn - Definitive Answer Dataset for LLMs Hallucination Evaluation,https://arxiv.org/abs/2406.09155,2024-06-13,2024-06-19,0.0,0.0,"Large Language Models (LLMs) have demonstrated remarkable capabilities,
revolutionizing the integration of AI in daily life applications. However, they
are prone to hallucinations, generating claims that contradict established
facts, deviating from prompts, and producing inconsistent responses when the
same prompt is presented multiple times. Addressing these issues is challenging
due to the lack of comprehensive and easily assessable benchmark datasets. Most
existing datasets are small and rely on multiple-choice questions, which are
inadequate for evaluating the generative prowess of LLMs. To measure
hallucination in LLMs, this paper introduces a comprehensive benchmark dataset
comprising over 75,000 prompts across eight domains. These prompts are designed
to elicit definitive, concise, and informative answers. The dataset is divided
into two segments: one publicly available for testing and assessing LLM
performance and a hidden segment for benchmarking various LLMs. In our
experiments, we tested six LLMs-GPT-3.5, LLama 2, LLama 3, Gemini, Mixtral, and
Zephyr-revealing that overall factual hallucination ranges from 59% to 82% on
the public dataset and 57% to 76% in the hidden benchmark. Prompt misalignment
hallucination ranges from 6% to 95% in the public dataset and 17% to 94% in the
hidden counterpart. Average consistency ranges from 21% to 61% and 22% to 63%,
respectively. Domain-wise analysis shows that LLM performance significantly
deteriorates when asked for specific numeric information while performing
moderately with person, location, and date queries. Our dataset demonstrates
its efficacy and serves as a comprehensive benchmark for LLM performance
evaluation. Our dataset and LLMs responses are available at
\href{https://github.com/ashikiut/DefAn}{https://github.com/ashikiut/DefAn}."
Diffusion Gaussian Mixture Audio Denoise,https://arxiv.org/abs/2406.09154,2024-06-13,2024-06-19,0.0,0.0,"Recent diffusion models have achieved promising performances in
audio-denoising tasks. The unique property of the reverse process could recover
clean signals. However, the distribution of real-world noises does not comply
with a single Gaussian distribution and is even unknown. The sampling of
Gaussian noise conditions limits its application scenarios. To overcome these
challenges, we propose a DiffGMM model, a denoising model based on the
diffusion and Gaussian mixture models. We employ the reverse process to
estimate parameters for the Gaussian mixture model. Given a noisy audio signal,
we first apply a 1D-U-Net to extract features and train linear layers to
estimate parameters for the Gaussian mixture model, and we approximate the real
noise distributions. The noisy signal is continuously subtracted from the
estimated noise to output clean audio signals. Extensive experimental results
demonstrate that the proposed DiffGMM model achieves state-of-the-art
performance."
LASER - Learning by Aligning Self-supervised Representations of Speech for Improving Content-related Tasks,https://arxiv.org/abs/2406.09153,2024-06-13,2024-06-19,0.0,0.0,"Self-supervised learning (SSL)-based speech models are extensively used for
full-stack speech processing. However, it has been observed that improving
SSL-based speech representations using unlabeled speech for content-related
tasks is challenging and computationally expensive. Recent attempts have been
made to address this issue with cost-effective self-supervised fine-tuning
(SSFT) approaches. Continuing in this direction, a cost-effective SSFT method
named ""LASER: Learning by Aligning Self-supervised Representations"" is
presented. LASER is based on the soft-DTW alignment loss with temporal
regularisation term. Experiments are conducted with HuBERT and WavLM models and
evaluated on the SUPERB benchmark for two content-related tasks: automatic
speech recognition (ASR) and phoneme recognition (PR). A relative improvement
of 3.7% and 8.2% for HuBERT, and 4.1% and 11.7% for WavLM are observed, for the
ASR and PR tasks respectively, with only < 3 hours of fine-tuning on a single
GPU."
EncCluster - Scalable Functional Encryption in Federated Learning through Weight Clustering and Probabilistic Filters,https://arxiv.org/abs/2406.09152,2024-06-13,2024-06-19,0.0,0.0,"Federated Learning (FL) enables model training across decentralized devices
by communicating solely local model updates to an aggregation server. Although
such limited data sharing makes FL more secure than centralized approached, FL
remains vulnerable to inference attacks during model update transmissions.
Existing secure aggregation approaches rely on differential privacy or
cryptographic schemes like Functional Encryption (FE) to safeguard individual
client data. However, such strategies can reduce performance or introduce
unacceptable computational and communication overheads on clients running on
edge devices with limited resources. In this work, we present EncCluster, a
novel method that integrates model compression through weight clustering with
recent decentralized FE and privacy-enhancing data encoding using probabilistic
filters to deliver strong privacy guarantees in FL without affecting model
performance or adding unnecessary burdens to clients. We performed a
comprehensive evaluation, spanning various datasets and architectures, to
demonstrate EncCluster's scalability across encryption levels. Our findings
reveal that EncCluster significantly reduces communication costs - below even
conventional FedAvg - and accelerates encryption by more than four times over
all baselines; at the same time, it maintains high model accuracy and enhanced
privacy assurances."
Weakly-supervised anomaly detection for multimodal data distributions,https://arxiv.org/abs/2406.09147,2024-06-13,2024-06-19,0.0,0.0,"Weakly-supervised anomaly detection can outperform existing unsupervised
methods with the assistance of a very small number of labeled anomalies, which
attracts increasing attention from researchers. However, existing
weakly-supervised anomaly detection methods are limited as these methods do not
factor in the multimodel nature of the real-world data distribution. To
mitigate this, we propose the Weakly-supervised Variational-mixture-model-based
Anomaly Detector (WVAD). WVAD excels in multimodal datasets. It consists of two
components: a deep variational mixture model, and an anomaly score estimator.
The deep variational mixture model captures various features of the data from
different clusters, then these features are delivered to the anomaly score
estimator to assess the anomaly levels. Experimental results on three
real-world datasets demonstrate WVAD's superiority."
Optimal Control of Agent-Based Dynamics under Deep Galerkin Feedback Laws,https://arxiv.org/abs/2406.09141,2024-06-13,2024-06-19,0.0,0.0,"Ever since the concepts of dynamic programming were introduced, one of the
most difficult challenges has been to adequately address high-dimensional
control problems. With growing dimensionality, the utilisation of Deep Neural
Networks promises to circumvent the issue of an otherwise exponentially
increasing complexity. The paper specifically investigates the sampling issues
the Deep Galerkin Method is subjected to. It proposes a drift relaxation-based
sampling approach to alleviate the symptoms of high-variance policy
approximations. This is validated on mean-field control problems; namely, the
variations of the opinion dynamics presented by the Sznajd and the
Hegselmann-Krause model. The resulting policies induce a significant cost
reduction over manually optimised control functions and show improvements on
the Linear-Quadratic Regulator problem over the Deep FBSDE approach."
Investigating the translation capabilities of Large Language Models trained on parallel data only,https://arxiv.org/abs/2406.09140,2024-06-13,2024-06-19,0.0,0.0,"In recent years, Large Language Models (LLMs) have demonstrated exceptional
proficiency across a broad spectrum of Natural Language Processing (NLP) tasks,
including Machine Translation. However, previous methods predominantly relied
on iterative processes such as instruction fine-tuning or continual
pre-training, leaving unexplored the challenges of training LLMs solely on
parallel data. In this work, we introduce PLUME (Parallel Language Model), a
collection of three 2B LLMs featuring varying vocabulary sizes (32k, 128k, and
256k) trained exclusively on Catalan-centric parallel examples. These models
perform comparably to previous encoder-decoder architectures on 16 supervised
translation directions and 56 zero-shot ones. Utilizing this set of models, we
conduct a thorough investigation into the translation capabilities of LLMs,
probing their performance, the impact of the different elements of the prompt,
and their cross-lingual representation space."
Dynamic Correlation Clustering in Sublinear Update Time,https://arxiv.org/abs/2406.09137,2024-06-13,2024-06-19,0.0,0.0,"We study the classic problem of correlation clustering in dynamic node
streams. In this setting, nodes are either added or randomly deleted over time,
and each node pair is connected by a positive or negative edge. The objective
is to continuously find a partition which minimizes the sum of positive edges
crossing clusters and negative edges within clusters. We present an algorithm
that maintains an $O(1)$-approximation with $O$(polylog $n$) amortized update
time. Prior to our work, Behnezhad, Charikar, Ma, and L. Tan achieved a
$5$-approximation with $O(1)$ expected update time in edge streams which
translates in node streams to an $O(D)$-update time where $D$ is the maximum
possible degree. Finally we complement our theoretical analysis with
experiments on real world data."
Chain of Preference Optimization - Improving Chain-of-Thought Reasoning in LLMs,https://arxiv.org/abs/2406.09136,2024-06-13,2024-06-19,0.0,0.0,"The recent development of chain-of-thought (CoT) decoding has enabled large
language models (LLMs) to generate explicit logical reasoning paths for complex
problem-solving. However, research indicates that these paths are not always
deliberate and optimal. The tree-of-thought (ToT) method employs tree-searching
to extensively explore the reasoning space and find better reasoning paths that
CoT decoding might overlook. This deliberation, however, comes at the cost of
significantly increased inference complexity. In this work, we demonstrate that
fine-tuning LLMs leveraging the search tree constructed by ToT allows CoT to
achieve similar or better performance, thereby avoiding the substantial
inference burden. This is achieved through Chain of Preference Optimization
(CPO), where LLMs are fine-tuned to align each step of the CoT reasoning paths
with those of ToT using the inherent preference information in the tree-search
process. Extensive experimental results show that CPO significantly improves
LLM performance in solving a variety of complex problems, including question
answering, fact verification, and arithmetic reasoning, demonstrating its
effectiveness. Our code is available at https://github.com/sail-sg/CPO."
Jacobian-Enhanced Neural Networks,https://arxiv.org/abs/2406.09132,2024-06-13,2024-06-19,0.0,0.0,"Jacobian-Enhanced Neural Networks (JENN) are densely connected multi-layer
perceptrons, whose training process is modified to predict partial derivatives
accurately. Their main benefit is better accuracy with fewer training points
compared to standard neural networks. These attributes are particularly
desirable in the field of computer-aided design, where there is often the need
to replace computationally expensive, physics-based models with fast running
approximations, known as surrogate models or meta-models. Since a surrogate
emulates the original model accurately in near-real time, it yields a speed
benefit that can be used to carry out orders of magnitude more function calls
quickly. However, in the special case of gradient-enhanced methods, there is
the additional value proposition that partial derivatives are accurate, which
is a critical property for one important use-case: surrogate-based
optimization. This work derives the complete theory and exemplifies its
superiority over standard neural nets for surrogate-based optimization."
RH-SQL - Refined Schema and Hardness Prompt for Text-to-SQL,https://arxiv.org/abs/2406.09133,2024-06-13,2024-06-19,0.0,0.0,"Text-to-SQL is a technology that converts natural language queries into the
structured query language SQL. A novel research approach that has recently
gained attention focuses on methods based on the complexity of SQL queries,
achieving notable performance improvements. However, existing methods entail
significant storage and training costs, which hampers their practical
application. To address this issue, this paper introduces a method for
Text-to-SQL based on Refined Schema and Hardness Prompt. By filtering out
low-relevance schema information with a refined schema and identifying query
hardness through a Language Model (LM) to form prompts, this method reduces
storage and training costs while maintaining performance. It's worth mentioning
that this method is applicable to any sequence-to-sequence (seq2seq) LM. Our
experiments on the Spider dataset, specifically with large-scale LMs, achieved
an exceptional Execution accuracy (EX) of 82.6%, demonstrating the
effectiveness and greater suitability of our method for real-world
applications."
Time-Series Forecasting for Out-of-Distribution Generalization Using Invariant Learning,https://arxiv.org/abs/2406.09130,2024-06-13,2024-06-19,0.0,0.0,"Time-series forecasting (TSF) finds broad applications in real-world
scenarios. Due to the dynamic nature of time-series data, it is crucial to
equip TSF models with out-of-distribution (OOD) generalization abilities, as
historical training data and future test data can have different distributions.
In this paper, we aim to alleviate the inherent OOD problem in TSF via
invariant learning. We identify fundamental challenges of invariant learning
for TSF. First, the target variables in TSF may not be sufficiently determined
by the input due to unobserved core variables in TSF, breaking the conventional
assumption of invariant learning. Second, time-series datasets lack adequate
environment labels, while existing environmental inference methods are not
suitable for TSF.
  To address these challenges, we propose FOIL, a model-agnostic framework that
enables timeseries Forecasting for Out-of-distribution generalization via
Invariant Learning. FOIL employs a novel surrogate loss to mitigate the impact
of unobserved variables. Further, FOIL implements a joint optimization by
alternately inferring environments effectively with a multi-head network while
preserving the temporal adjacency structure, and learning invariant
representations across inferred environments for OOD generalized TSF. We
demonstrate that the proposed FOIL significantly improves the performance of
various TSF models, achieving gains of up to 85%."
CoastTerm - a Corpus for Multidisciplinary Term Extraction in Coastal Scientific Literature,https://arxiv.org/abs/2406.09128,2024-06-13,2024-06-19,0.0,0.0,"The growing impact of climate change on coastal areas, particularly active
but fragile regions, necessitates collaboration among diverse stakeholders and
disciplines to formulate effective environmental protection policies. We
introduce a novel specialized corpus comprising 2,491 sentences from 410
scientific abstracts concerning coastal areas, for the Automatic Term
Extraction (ATE) and Classification (ATC) tasks. Inspired by the ARDI
framework, focused on the identification of Actors, Resources, Dynamics and
Interactions, we automatically extract domain terms and their distinct roles in
the functioning of coastal systems by leveraging monolingual and multilingual
transformer models. The evaluation demonstrates consistent results, achieving
an F1 score of approximately 80\% for automated term extraction and F1 of 70\%
for extracting terms and their labels. These findings are promising and signify
an initial step towards the development of a specialized Knowledge Base
dedicated to coastal areas."
PC-LoRA - Low-Rank Adaptation for Progressive Model Compression with Knowledge Distillation,https://arxiv.org/abs/2406.09117,2024-06-13,2024-06-19,0.0,0.0,"Low-rank adaption (LoRA) is a prominent method that adds a small number of
learnable parameters to the frozen pre-trained weights for parameter-efficient
fine-tuning. Prompted by the question, ``Can we make its representation enough
with LoRA weights solely at the final phase of finetuning without the
pre-trained weights?'' In this work, we introduce Progressive Compression
LoRA~(PC-LoRA), which utilizes low-rank adaptation (LoRA) to simultaneously
perform model compression and fine-tuning. The PC-LoRA method gradually removes
the pre-trained weights during the training process, eventually leaving only
the low-rank adapters in the end. Thus, these low-rank adapters replace the
whole pre-trained weights, achieving the goals of compression and fine-tuning
at the same time. Empirical analysis across various models demonstrates that
PC-LoRA achieves parameter and FLOPs compression rates of 94.36%/89.1% for
vision models, e.g., ViT-B, and 93.42%/84.2% parameters and FLOPs compressions
for language models, e.g., BERT."
Injective Flows for parametric hypersurfaces,https://arxiv.org/abs/2406.09116,2024-06-13,2024-06-19,0.0,0.0,"Normalizing Flows (NFs) are powerful and efficient models for density
estimation. When modeling densities on manifolds, NFs can be generalized to
injective flows but the Jacobian determinant becomes computationally
prohibitive. Current approaches either consider bounds on the log-likelihood or
rely on some approximations of the Jacobian determinant. In contrast, we
propose injective flows for parametric hypersurfaces and show that for such
manifolds we can compute the Jacobian determinant exactly and efficiently, with
the same cost as NFs. Furthermore, we show that for the subclass of star-like
manifolds we can extend the proposed framework to always allow for a Cartesian
representation of the density. We showcase the relevance of modeling densities
on hypersurfaces in two settings. Firstly, we introduce a novel Objective
Bayesian approach to penalized likelihood models by interpreting level-sets of
the penalty as star-like manifolds. Secondly, we consider Bayesian mixture
models and introduce a general method for variational inference by defining the
posterior of mixture weights on the probability simplex."
Large-Scale Evaluation of Open-Set Image Classification Techniques,https://arxiv.org/abs/2406.09112,2024-06-13,2024-06-19,0.0,0.0,"The goal for classification is to correctly assign labels to unseen samples.
However, most methods misclassify samples with unseen labels and assign them to
one of the known classes. Open-Set Classification (OSC) algorithms aim to
maximize both closed and open-set recognition capabilities. Recent studies
showed the utility of such algorithms on small-scale data sets, but limited
experimentation makes it difficult to assess their performances in real-world
problems. Here, we provide a comprehensive comparison of various OSC
algorithms, including training-based (SoftMax, Garbage, EOS) and
post-processing methods (Maximum SoftMax Scores, Maximum Logit Scores, OpenMax,
EVM, PROSER), the latter are applied on features from the former. We perform
our evaluation on three large-scale protocols that mimic real-world challenges,
where we train on known and negative open-set samples, and test on known and
unknown instances. Our results show that EOS helps to improve performance of
almost all post-processing algorithms. Particularly, OpenMax and PROSER are
able to exploit better-trained networks, demonstrating the utility of hybrid
models. However, while most algorithms work well on negative test samples --
samples of open-set classes seen during training -- they tend to perform poorly
when tested on samples of previously unseen unknown classes, especially in
challenging conditions."
INS-MMBench - A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance,https://arxiv.org/abs/2406.09105,2024-06-13,2024-06-19,0.0,0.0,"Large Vision-Language Models (LVLMs) have demonstrated outstanding
performance in various general multimodal applications such as image
recognition and visual reasoning, and have also shown promising potential in
specialized domains. However, the application potential of LVLMs in the
insurance domain-characterized by rich application scenarios and abundant
multimodal data-has not been effectively explored. There is no systematic
review of multimodal tasks in the insurance domain, nor a benchmark
specifically designed to evaluate the capabilities of LVLMs in insurance. This
gap hinders the development of LVLMs within the insurance domain. In this
paper, we systematically review and distill multimodal tasks for four
representative types of insurance: auto insurance, property insurance, health
insurance, and agricultural insurance. We propose INS-MMBench, the first
comprehensive LVLMs benchmark tailored for the insurance domain. INS-MMBench
comprises a total of 2.2K thoroughly designed multiple-choice questions,
covering 12 meta-tasks and 22 fundamental tasks. Furthermore, we evaluate
multiple representative LVLMs, including closed-source models such as GPT-4o
and open-source models like BLIP-2. This evaluation not only validates the
effectiveness of our benchmark but also provides an in-depth performance
analysis of current LVLMs on various multimodal tasks in the insurance domain.
We hope that INS-MMBench will facilitate the further application of LVLMs in
the insurance domain and inspire interdisciplinary development. Our dataset and
evaluation code are available at https://github.com/FDU-INS/INS-MMBench."
Chain-of-Though (CoT) prompting strategies for medical error detection and correction,https://arxiv.org/abs/2406.09103,2024-06-13,2024-06-19,0.0,0.0,"This paper describes our submission to the MEDIQA-CORR 2024 shared task for
automatically detecting and correcting medical errors in clinical notes. We
report results for three methods of few-shot In-Context Learning (ICL)
augmented with Chain-of-Thought (CoT) and reason prompts using a large language
model (LLM). In the first method, we manually analyse a subset of train and
validation dataset to infer three CoT prompts by examining error types in the
clinical notes. In the second method, we utilise the training dataset to prompt
the LLM to deduce reasons about their correctness or incorrectness. The
constructed CoTs and reasons are then augmented with ICL examples to solve the
tasks of error detection, span identification, and error correction. Finally,
we combine the two methods using a rule-based ensemble method. Across the three
sub-tasks, our ensemble method achieves a ranking of 3rd for both sub-task 1
and 2, while securing 7th place in sub-task 3 among all submissions."
SciKnowEval - Evaluating Multi-level Scientific Knowledge of Large Language Models,https://arxiv.org/abs/2406.09098,2024-06-13,2024-06-19,0.0,0.0,"Large language models (LLMs) have gained increasing prominence in scientific
research, but there is a lack of comprehensive benchmarks to fully evaluate
their proficiency in understanding and mastering scientific knowledge. To
address this need, we introduce the SciKnowEval benchmark, a novel framework
that systematically evaluates LLMs across five progressive levels of scientific
knowledge: studying extensively, inquiring earnestly, thinking profoundly,
discerning clearly, and practicing assiduously. These levels aim to assess the
breadth and depth of scientific knowledge in LLMs, including memory,
comprehension, reasoning, discernment, and application. Specifically, we first
construct a large-scale evaluation dataset encompassing 70K multi-level
scientific problems and solutions in the domains of biology, chemistry,
physics, and materials science. By leveraging this dataset, we benchmark 26
advanced open-source and proprietary LLMs using zero-shot and few-shot
prompting strategies. The results reveal that despite the state-of-the-art
performance of proprietary LLMs, there is still significant room for
improvement, particularly in addressing scientific reasoning and applications.
We anticipate that SciKnowEval will establish a standard for benchmarking LLMs
in science research and promote the development of stronger scientific LLMs.
The dataset and code are publicly available at https://scimind.ai/sciknoweval ."
Modeling Comparative Logical Relation with Contrastive Learning for Text Generation,https://arxiv.org/abs/2406.09095,2024-06-13,2024-06-19,0.0,0.0,"Data-to-Text Generation (D2T), a classic natural language generation problem,
aims at producing fluent descriptions for structured input data, such as a
table. Existing D2T works mainly focus on describing the superficial
associative relations among entities, while ignoring the deep comparative
logical relations, such as A is better than B in a certain aspect with a
corresponding opinion, which is quite common in our daily life. In this paper,
we introduce a new D2T task named comparative logical relation generation
(CLRG). Additionally, we propose a Comparative Logic (CoLo) based text
generation method, which generates texts following specific comparative logical
relations with contrastive learning. Specifically, we first construct various
positive and negative samples by fine-grained perturbations in entities,
aspects and opinions. Then, we perform contrastive learning in the encoder
layer to have a better understanding of the comparative logical relations, and
integrate it in the decoder layer to guide the model to correctly generate the
relations. Noting the data scarcity problem, we construct a Chinese Comparative
Logical Relation Dataset (CLRD), which is a high-quality human-annotated
dataset and challenging for text generation with descriptions of multiple
entities and annotations on their comparative logical relations. Extensive
experiments show that our method achieves impressive performance in both
automatic and human evaluations."
DiffPoGAN - Diffusion Policies with Generative Adversarial Networks for Offline Reinforcement Learning,https://arxiv.org/abs/2406.09089,2024-06-13,2024-06-19,0.0,0.0,"Offline reinforcement learning (RL) can learn optimal policies from
pre-collected offline datasets without interacting with the environment, but
the sampled actions of the agent cannot often cover the action distribution
under a given state, resulting in the extrapolation error issue. Recent works
address this issue by employing generative adversarial networks (GANs).
However, these methods often suffer from insufficient constraints on policy
exploration and inaccurate representation of behavior policies. Moreover, the
generator in GANs fails in fooling the discriminator while maximizing the
expected returns of a policy. Inspired by the diffusion, a generative model
with powerful feature expressiveness, we propose a new offline RL method named
Diffusion Policies with Generative Adversarial Networks (DiffPoGAN). In this
approach, the diffusion serves as the policy generator to generate diverse
distributions of actions, and a regularization method based on maximum
likelihood estimation (MLE) is developed to generate data that approximate the
distribution of behavior policies. Besides, we introduce an additional
regularization term based on the discriminator output to effectively constrain
policy exploration for policy improvement. Comprehensive experiments are
conducted on the datasets for deep data-driven reinforcement learning (D4RL),
and experimental results show that DiffPoGAN outperforms state-of-the-art
methods in offline RL."
Suitability of KANs for Computer Vision - A preliminary investigation,https://arxiv.org/abs/2406.09087,2024-06-13,2024-06-19,0.0,0.0,"Kolmogorov-Arnold Networks (KANs) introduce a paradigm of neural modeling
that implements learnable functions on the edges of the networks, diverging
from the traditional node-centric activations in neural networks. This work
assesses the applicability and efficacy of KANs in visual modeling, focusing on
the image recognition task. We mainly analyze the performance and efficiency of
different network architectures built using KAN concepts along with
conventional building blocks of convolutional and linear layers, enabling a
comparative analysis with the conventional models. Our findings are aimed at
contributing to understanding the potential of KANs in computer vision,
highlighting both their strengths and areas for further research. Our
evaluation shows that whereas KAN-based architectures perform in-line with the
original claims of KAN paper for performance and model-complexity in the case
of simpler vision datasets like MNIST, the advantages seem to diminish even for
slightly more complex datasets like CIFAR-10."
Operator-informed score matching for Markov diffusion models,https://arxiv.org/abs/2406.09084,2024-06-13,2024-06-19,0.0,0.0,"Diffusion models are typically trained using score matching, yet score
matching is agnostic to the particular forward process that defines the model.
This paper argues that Markov diffusion models enjoy an advantage over other
types of diffusion model, as their associated operators can be exploited to
improve the training process. In particular, (i) there exists an explicit
formal solution to the forward process as a sequence of time-dependent kernel
mean embeddings; and (ii) the derivation of score-matching and related
estimators can be streamlined. Building upon (i), we propose Riemannian
diffusion kernel smoothing, which ameliorates the need for neural score
approximation, at least in the low-dimensional context; Building upon (ii), we
propose operator-informed score matching, a variance reduction technique that
is straightforward to implement in both low- and high-dimensional diffusion
modeling and is demonstrated to improve score matching in an empirical
proof-of-concept."
Latent Assistance Networks - Rediscovering Hyperbolic Tangents in RL,https://arxiv.org/abs/2406.09079,2024-06-13,2024-06-19,0.0,0.0,"Activation functions are one of the key components of a neural network. The
most commonly used activation functions can be classed into the category of
continuously differentiable (e.g. tanh) and linear-unit functions (e.g. ReLU),
both having their own strengths and drawbacks with respect to downstream
performance and representation capacity through learning (e.g. measured by the
number of dead neurons and the effective rank). In reinforcement learning, the
performance of continuously differentiable activations often falls short as
compared to linear-unit functions. From the perspective of the activations in
the last hidden layer, this paper provides insights regarding this
sub-optimality and explores how activation functions influence the occurrence
of dead neurons and the magnitude of the effective rank. Additionally, a novel
neural architecture is proposed that leverages the product of independent
activation values. In the Atari domain, we show faster learning, a reduction in
dead neurons and increased effective rank."
ELF-UA - Efficient Label-Free User Adaptation in Gaze Estimation,https://arxiv.org/abs/2406.09481,2024-06-13,2024-06-19,0.0,0.0,"We consider the problem of user-adaptive 3D gaze estimation. The performance
of person-independent gaze estimation is limited due to interpersonal
anatomical differences. Our goal is to provide a personalized gaze estimation
model specifically adapted to a target user. Previous work on user-adaptive
gaze estimation requires some labeled images of the target person data to
fine-tune the model at test time. However, this can be unrealistic in
real-world applications, since it is cumbersome for an end-user to provide
labeled images. In addition, previous work requires the training data to have
both gaze labels and person IDs. This data requirement makes it infeasible to
use some of the available data. To tackle these challenges, this paper proposes
a new problem called efficient label-free user adaptation in gaze estimation.
Our model only needs a few unlabeled images of a target user for the model
adaptation. During offline training, we have some labeled source data without
person IDs and some unlabeled person-specific data. Our proposed method uses a
meta-learning approach to learn how to adapt to a new user with only a few
unlabeled images. Our key technical innovation is to use a generalization bound
from domain adaptation to define the loss function in meta-learning, so that
our method can effectively make use of both the labeled source data and the
unlabeled person-specific data during training. Extensive experiments validate
the effectiveness of our method on several challenging benchmarks."
3M - Multi-modal Multi-task Multi-teacher Learning for Game Event Detection,https://arxiv.org/abs/2406.09076,2024-06-13,2024-06-19,0.0,0.0,"Esports has rapidly emerged as a global phenomenon with an ever-expanding
audience via platforms, like YouTube. Due to the inherent complexity nature of
the game, it is challenging for newcomers to comprehend what the event entails.
The chaotic nature of online chat, the fast-paced speech of the game
commentator, and the game-specific user interface further compound the
difficulty for users in comprehending the gameplay. To overcome these
challenges, it is crucial to integrate the Multi-Modal (MM) information from
the platform and understand the event. The paper introduces a new MM
multi-teacher-based game event detection framework, with the ultimate goal of
constructing a comprehensive framework that enhances the comprehension of the
ongoing game situation. While conventional MM models typically prioritise
aligning MM data through concurrent training towards a unified objective, our
framework leverages multiple teachers trained independently on different tasks
to accomplish the Game Event Detection. The experiment clearly shows the
effectiveness of the proposed MM multi-teacher framework."
Are we making progress in unlearning? Findings from the first NeurIPS unlearning competition,https://arxiv.org/abs/2406.09073,2024-06-13,2024-06-19,0.0,0.0,"We present the findings of the first NeurIPS competition on unlearning, which
sought to stimulate the development of novel algorithms and initiate
discussions on formal and robust evaluation methodologies. The competition was
highly successful: nearly 1,200 teams from across the world participated, and a
wealth of novel, imaginative solutions with different characteristics were
contributed. In this paper, we analyze top solutions and delve into discussions
on benchmarking unlearning, which itself is a research problem. The evaluation
methodology we developed for the competition measures forgetting quality
according to a formal notion of unlearning, while incorporating model utility
for a holistic evaluation. We analyze the effectiveness of different
instantiations of this evaluation framework vis-a-vis the associated compute
cost, and discuss implications for standardizing evaluation. We find that the
ranking of leading methods remains stable under several variations of this
framework, pointing to avenues for reducing the cost of evaluation. Overall,
our findings indicate progress in unlearning, with top-performing competition
entries surpassing existing algorithms under our evaluation framework. We
analyze trade-offs made by different algorithms and strengths or weaknesses in
terms of generalizability to new datasets, paving the way for advancing both
benchmarking and algorithm development in this important area."
EquiPrompt - Debiasing Diffusion Models via Iterative Bootstrapping in Chain of Thoughts,https://arxiv.org/abs/2406.09070,2024-06-13,2024-06-19,0.0,0.0,"In the domain of text-to-image generative models, biases inherent in training
datasets often propagate into generated content, posing significant ethical
challenges, particularly in socially sensitive contexts. We introduce FairCoT,
a novel framework that enhances fairness in diffusion models through
Chain-of-Thought (CoT) reasoning within multimodal generative large language
models (LLMs). FairCoT employs iterative CoT refinement and attire-based
attribute prediction to systematically mitigate biases, ensuring diverse and
equitable representation in generated images. By integrating iterative
reasoning processes, FairCoT addresses the limitations of zero-shot CoT in
sensitive scenarios, balancing creativity with ethical responsibility.
Experimental evaluations across multiple models, including DALL-E and various
Stable Diffusion variants, demonstrate that FairCoT significantly improves
fairness and diversity metrics without compromising image quality or relevance.
Our approach advances ethical AI practices in generative modeling, promoting
socially responsible content generation and setting new standards for fairness
in AI-generated imagery."
On the Robustness of Global Feature Effect Explanations,https://arxiv.org/abs/2406.09069,2024-06-13,2024-06-19,0.0,0.0,"We study the robustness of global post-hoc explanations for predictive models
trained on tabular data. Effects of predictor features in black-box supervised
learning are an essential diagnostic tool for model debugging and scientific
discovery in applied sciences. However, how vulnerable they are to data and
model perturbations remains an open research question. We introduce several
theoretical bounds for evaluating the robustness of partial dependence plots
and accumulated local effects. Our experimental results with synthetic and
real-world datasets quantify the gap between the best and worst-case scenarios
of (mis)interpreting machine learning predictions globally."
Dispelling the Mirage of Progress in Offline MARL through Standardised Baselines and Evaluation,https://arxiv.org/abs/2406.09068,2024-06-13,2024-06-19,0.0,0.0,"Offline multi-agent reinforcement learning (MARL) is an emerging field with
great promise for real-world applications. Unfortunately, the current state of
research in offline MARL is plagued by inconsistencies in baselines and
evaluation protocols, which ultimately makes it difficult to accurately assess
progress, trust newly proposed innovations, and allow researchers to easily
build upon prior work. In this paper, we firstly identify significant
shortcomings in existing methodologies for measuring the performance of novel
algorithms through a representative study of published offline MARL work.
Secondly, by directly comparing to this prior work, we demonstrate that simple,
well-implemented baselines can achieve state-of-the-art (SOTA) results across a
wide range of tasks. Specifically, we show that on 35 out of 47 datasets used
in prior work (almost 75% of cases), we match or surpass the performance of the
current purported SOTA. Strikingly, our baselines often substantially
outperform these more sophisticated algorithms. Finally, we correct for the
shortcomings highlighted from this prior work by introducing a straightforward
standardised methodology for evaluation and by providing our baseline
implementations with statistically robust results across several scenarios,
useful for comparisons in future work. Our proposal includes simple and
sensible steps that are easy to adopt, which in combination with solid
baselines and comparative results, could substantially improve the overall
rigour of empirical science in offline MARL moving forward."
How structured are the representations in transformer-based vision encoders? An analysis of multi-object representations in vision-language models,https://arxiv.org/abs/2406.09067,2024-06-13,2024-06-19,0.0,0.0,"Forming and using symbol-like structured representations for reasoning has
been considered essential for generalising over novel inputs. The primary tool
that allows generalisation outside training data distribution is the ability to
abstract away irrelevant information into a compact form relevant to the task.
An extreme form of such abstract representations is symbols. Humans make use of
symbols to bind information while abstracting away irrelevant parts to utilise
the information consistently and meaningfully. This work estimates the state of
such structured representations in vision encoders. Specifically, we evaluate
image encoders in large vision-language pre-trained models to address the
question of which desirable properties their representations lack by applying
the criteria of symbolic structured reasoning described for LLMs to the image
models. We test the representation space of image encoders like VIT, BLIP,
CLIP, and FLAVA to characterise the distribution of the object representations
in these models. In particular, we create decoding tasks using multi-object
scenes from the COCO dataset, relating the token space to its input content for
various objects in the scene. We use these tasks to characterise the network's
token and layer-wise information modelling. Our analysis highlights that the
CLS token, used for the downstream task, only focuses on a few objects
necessary for the trained downstream task. Still, other individual objects are
well-modelled separately by the tokens in the network originating from those
objects. We further observed a widespread distribution of scene information.
This demonstrates that information is far more entangled in tokens than optimal
for representing objects similar to symbols. Given these symbolic properties,
we show the network dynamics that cause failure modes of these models on basic
downstream tasks in a multi-object scene."
State-Space Modeling in Long Sequence Processing - A Survey on Recurrence in the Transformer Era,https://arxiv.org/abs/2406.09062,2024-06-13,2024-06-19,0.0,0.0,"Effectively learning from sequential data is a longstanding goal of
Artificial Intelligence, especially in the case of long sequences. From the
dawn of Machine Learning, several researchers engaged in the search of
algorithms and architectures capable of processing sequences of patterns,
retaining information about the past inputs while still leveraging the upcoming
data, without losing precious long-term dependencies and correlations. While
such an ultimate goal is inspired by the human hallmark of continuous real-time
processing of sensory information, several solutions simplified the learning
paradigm by artificially limiting the processed context or dealing with
sequences of limited length, given in advance. These solutions were further
emphasized by the large ubiquity of Transformers, that have initially shaded
the role of Recurrent Neural Nets. However, recurrent networks are facing a
strong recent revival due to the growing popularity of (deep) State-Space
models and novel instances of large-context Transformers, which are both based
on recurrent computations to go beyond several limits of currently ubiquitous
technologies. In fact, the fast development of Large Language Models enhanced
the interest in efficient solutions to process data over time. This survey
provides an in-depth summary of the latest approaches that are based on
recurrent models for sequential data processing. A complete taxonomy over the
latest trends in architectural and algorithmic solutions is reported and
discussed, guiding researchers in this appealing research field. The emerging
picture suggests that there is room for thinking of novel routes, constituted
by learning algorithms which depart from the standard Backpropagation Through
Time, towards a more realistic scenario where patterns are effectively
processed online, leveraging local-forward computations, opening to further
research on this topic."
CUDRT - Benchmarking the Detection of Human vs. Large Language Models Generated Texts,https://arxiv.org/abs/2406.09056,2024-06-13,2024-06-19,0.0,0.0,"The proliferation of large language models (LLMs) has significantly enhanced
text generation capabilities across various industries. However, these models'
ability to generate human-like text poses substantial challenges in discerning
between human and AI authorship. Despite the effectiveness of existing
AI-generated text detectors, their development is hindered by the lack of
comprehensive, publicly available benchmarks. Current benchmarks are limited to
specific scenarios, such as question answering and text polishing, and
predominantly focus on English texts, failing to capture the diverse
applications and linguistic nuances of LLMs. To address these limitations, this
paper constructs a comprehensive bilingual benchmark in both Chinese and
English to evaluate mainstream AI-generated text detectors. We categorize LLM
text generation into five distinct operations: Create, Update, Delete, Rewrite,
and Translate (CUDRT), encompassing all current LLMs activities. We also
establish a robust benchmark evaluation framework to support scalable and
reproducible experiments. For each CUDRT category, we have developed extensive
datasets to thoroughly assess detector performance. By employing the latest
mainstream LLMs specific to each language, our datasets provide a thorough
evaluation environment. Extensive experimental results offer critical insights
for optimizing AI-generated text detectors and suggest future research
directions to improve detection accuracy and generalizability across various
scenarios."
MiLoRA - Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning,https://arxiv.org/abs/2406.09044,2024-06-13,2024-06-19,0.0,0.0,"Efficient finetuning of large language models (LLMs) aims to adapt the LLMs
with reduced computational and memory cost. Previous LoRA-based approaches
initialize the low-rank matrices with Gaussian distribution and zero values
while keeping the original weight matrices frozen. However, the trainable model
parameters optimized in an unguided subspace might interfere with the
well-learned subspace of the pretrained weight matrices. In this paper, we
propose MiLoRA, a simple yet effective LLM finetuning approach that only
updates the minor singular components of the weight matrix while keeping the
principal singular components frozen. It is observed that the minor matrix
corresponds to the noisy or long-tail information, while the principal matrix
contains important knowledge. The MiLoRA initializes the low-rank matrices
within a subspace that is orthogonal to the principal matrix, thus the
pretrained knowledge is expected to be well preserved. During finetuning,
MiLoRA makes the most use of the less-optimized subspace for learning the
labeled dataset. Extensive experiments on commonsense reasoning, math
reasoning, instruction following and visual instruction following benchmarks
present the superior performance of our method."
Language Models are Crossword Solvers,https://arxiv.org/abs/2406.09043,2024-06-13,2024-06-19,0.0,0.0,"Crosswords are a form of word puzzle that require a solver to demonstrate a
high degree of proficiency in natural language understanding, wordplay,
reasoning, and world knowledge, along with adherence to character and length
constraints. In this paper we tackle the challenge of solving crosswords with
Large Language Models (LLMs). We demonstrate that the current generation of
state-of-the art (SoTA) language models show significant competence at
deciphering cryptic crossword clues, and outperform previously reported SoTA
results by a factor of 2-3 in relevant benchmarks. We also develop a search
algorithm that builds off this performance to tackle the problem of solving
full crossword grids with LLMs for the very first time, achieving an accuracy
of 93\% on New York Times crossword puzzles. Contrary to previous work in this
area which concluded that LLMs lag human expert performance significantly, our
research suggests this gap is a lot narrower."
ME-Switch - A Memory-Efficient Expert Switching Framework for Large Language Models,https://arxiv.org/abs/2406.09041,2024-06-13,2024-06-19,0.0,0.0,"The typical process for developing LLMs involves pre-training a general
foundation model on massive data, followed by fine-tuning on task-specific data
to create specialized experts. Serving these experts poses challenges, as
loading all experts onto devices is impractical, and frequent switching between
experts in response to user requests incurs substantial I/O costs, increasing
latency and expenses. Previous approaches decompose expert weights into
pre-trained model weights and residual delta weights, then quantize the delta
weights to reduce model size. However, these methods often lead to significant
quantization errors at extremely low bitwidths and assume the appropriate model
for a user request is known in advance, which is not practical. To address
these issues, we introduce ME-Switch, a memory-efficient expert switching
framework for LLM serving. ME-Switch uses mixed-precision quantization,
selectively quantizing non-salient input channels of delta weights to extremely
low bits while keeping salient ones intact, significantly reducing storage
demands while maintaining performance. Additionally, we develop a routing
method that efficiently directs user queries to the most suitable expert by
transforming the model selection problem into a domain classification problem.
Extensive experiments show ME-Switch's promising memory efficiency and routing
performance. For example, when serving three models from the Mistral-7B family,
ME-Switch reduces model size by 1.74x while maintaining nearly lossless
performance on instruction, mathematical reasoning, and code generation tasks.
Furthermore, ME-Switch can efficiently serve 16 models from the Mistral-7B
family on a single NVIDIA A100 GPU."
CGP++  - A Modern C++ Implementation of Cartesian Genetic Programming,https://arxiv.org/abs/2406.09038,2024-06-13,2024-06-19,0.0,0.0,"The reference implementation of Cartesian Genetic Programming (CGP) was
written in the C programming language. C inherently follows a procedural
programming paradigm, which entails challenges in providing a reusable and
scalable implementation model for complex structures and methods. Moreover, due
to the limiting factors of C, the reference implementation of CGP does not
provide a generic framework and is therefore restricted to a set of predefined
evaluation types. Besides the reference implementation, we also observe that
other existing implementations are limited with respect to the features
provided. In this work, we therefore propose the first version of a modern C++
implementation of CGP that pursues object-oriented design and generic
programming paradigm to provide an efficient implementation model that can
facilitate the discovery of new problem domains and the implementation of
complex advanced methods that have been proposed for CGP over time. With the
proposal of our new implementation, we aim to generally promote
interpretability, accessibility and reproducibility in the field of CGP."
"A Comprehensive Graph Pooling Benchmark - Effectiveness, Robustness and Generalizability",https://arxiv.org/abs/2406.09031,2024-06-13,2024-06-19,0.0,0.0,"Graph pooling has gained attention for its ability to obtain effective node
and graph representations for various downstream tasks. Despite the recent
surge in graph pooling approaches, there is a lack of standardized experimental
settings and fair benchmarks to evaluate their performance. To address this
issue, we have constructed a comprehensive benchmark that includes 17 graph
pooling methods and 28 different graph datasets. This benchmark systematically
assesses the performance of graph pooling methods in three dimensions, i.e.,
effectiveness, robustness, and generalizability. We first evaluate the
performance of these graph pooling approaches across different tasks including
graph classification, graph regression and node classification. Then, we
investigate their performance under potential noise attacks and
out-of-distribution shifts in real-world scenarios. We also involve detailed
efficiency analysis, backbone analysis, parameter analysis and visualization to
provide more evidence. Extensive experiments validate the strong capability and
applicability of graph pooling approaches in various scenarios, which can
provide valuable insights and guidance for deep geometric learning research.
The source code of our benchmark is available at
https://github.com/goose315/Graph_Pooling_Benchmark."
CUER - Corrected Uniform Experience Replay for Off-Policy Continuous Deep Reinforcement Learning Algorithms,https://arxiv.org/abs/2406.09030,2024-06-13,2024-06-19,0.0,0.0,"The utilization of the experience replay mechanism enables agents to
effectively leverage their experiences on several occasions. In previous
studies, the sampling probability of the transitions was modified based on
their relative significance. The process of reassigning sample probabilities
for every transition in the replay buffer after each iteration is considered
extremely inefficient. Hence, in order to enhance computing efficiency,
experience replay prioritization algorithms reassess the importance of a
transition as it is sampled. However, the relative importance of the
transitions undergoes dynamic adjustments when the agent's policy and value
function are iteratively updated. Furthermore, experience replay is a mechanism
that retains the transitions generated by the agent's past policies, which
could potentially diverge significantly from the agent's most recent policy. An
increased deviation from the agent's most recent policy results in a greater
frequency of off-policy updates, which has a negative impact on the agent's
performance. In this paper, we develop a novel algorithm, Corrected Uniform
Experience Replay (CUER), which stochastically samples the stored experience
while considering the fairness among all other experiences without ignoring the
dynamic nature of the transition importance by making sampled state
distribution more on-policy. CUER provides promising improvements for
off-policy continuous control algorithms in terms of sample efficiency, final
performance, and stability of the policy during the training."
From Biased to Unbiased Dynamics - An Infinitesimal Generator Approach,https://arxiv.org/abs/2406.09028,2024-06-13,2024-06-19,0.0,0.0,"We investigate learning the eigenfunctions of evolution operators for
time-reversal invariant stochastic processes, a prime example being the
Langevin equation used in molecular dynamics. Many physical or chemical
processes described by this equation involve transitions between metastable
states separated by high potential barriers that can hardly be crossed during a
simulation. To overcome this bottleneck, data are collected via biased
simulations that explore the state space more rapidly. We propose a framework
for learning from biased simulations rooted in the infinitesimal generator of
the process and the associated resolvent operator. We contrast our approach to
more common ones based on the transfer operator, showing that it can provably
learn the spectral properties of the unbiased system from biased data. In
experiments, we highlight the advantages of our method over transfer operator
approaches and recent developments based on generator learning, demonstrating
its effectiveness in estimating eigenfunctions and eigenvalues. Importantly, we
show that even with datasets containing only a few relevant transitions due to
sub-optimal biasing, our approach recovers relevant information about the
transition mechanism."
Schur's Positive-Definite Network - Deep Learning in the SPD cone with structure,https://arxiv.org/abs/2406.09023,2024-06-13,2024-06-19,0.0,0.0,"Estimating matrices in the symmetric positive-definite (SPD) cone is of
interest for many applications ranging from computer vision to graph learning.
While there exist various convex optimization-based estimators, they remain
limited in expressivity due to their model-based approach. The success of deep
learning has thus led many to use neural networks to learn to estimate SPD
matrices in a data-driven fashion. For learning structured outputs, one
promising strategy involves architectures designed by unrolling iterative
algorithms, which potentially benefit from inductive bias properties. However,
designing correct unrolled architectures for SPD learning is difficult: they
either do not guarantee that their output has all the desired properties, rely
on heavy computations, or are overly restrained to specific matrices which
hinders their expressivity. In this paper, we propose a novel and generic
learning module with guaranteed SPD outputs called SpodNet, that also enables
learning a larger class of functions than existing approaches. Notably, it
solves the challenging task of learning jointly SPD and sparse matrices. Our
experiments demonstrate the versatility of SpodNet layers."
Deep learning empowered sensor fusion to improve infant movement classification,https://arxiv.org/abs/2406.09014,2024-06-13,2024-06-19,0.0,0.0,"There is a recent boom in the development of AI solutions to facilitate and
enhance diagnostic procedures for established clinical tools. To assess the
integrity of the developing nervous system, the Prechtl general movement
assessment (GMA) is recognized for its clinical value in diagnosing
neurological impairments in early infancy. GMA has been increasingly augmented
through machine learning approaches intending to scale-up its application,
circumvent costs in the training of human assessors and further standardize
classification of spontaneous motor patterns. Available deep learning tools,
all of which are based on single sensor modalities, are however still
considerably inferior to that of well-trained human assessors. These approaches
are hardly comparable as all models are designed, trained and evaluated on
proprietary/silo-data sets. With this study we propose a sensor fusion approach
for assessing fidgety movements (FMs) comparing three different sensor
modalities (pressure, inertial, and visual sensors). Various combinations and
two sensor fusion approaches (late and early fusion) for infant movement
classification were tested to evaluate whether a multi-sensor system
outperforms single modality assessments. The performance of the three-sensor
fusion (classification accuracy of 94.5\%) was significantly higher than that
of any single modality evaluated, suggesting the sensor fusion approach is a
promising avenue for automated classification of infant motor patterns. The
development of a robust sensor fusion system may significantly enhance AI-based
early recognition of neurofunctions, ultimately facilitating automated early
detection of neurodevelopmental conditions."
Bayesian Statistical Modeling with Predictors from LLMs,https://arxiv.org/abs/2406.09012,2024-06-13,2024-06-19,0.0,0.0,"State of the art large language models (LLMs) have shown impressive
performance on a variety of benchmark tasks and are increasingly used as
components in larger applications, where LLM-based predictions serve as proxies
for human judgements or decision. This raises questions about the
human-likeness of LLM-derived information, alignment with human intuition, and
whether LLMs could possibly be considered (parts of) explanatory models of
(aspects of) human cognition or language use. To shed more light on these
issues, we here investigate the human-likeness of LLMs' predictions for
multiple-choice decision tasks from the perspective of Bayesian statistical
modeling. Using human data from a forced-choice experiment on pragmatic
language use, we find that LLMs do not capture the variance in the human data
at the item-level. We suggest different ways of deriving full distributional
predictions from LLMs for aggregate, condition-level data, and find that some,
but not all ways of obtaining condition-level predictions yield adequate fits
to human data. These results suggests that assessment of LLM performance
depends strongly on seemingly subtle choices in methodology, and that LLMs are
at best predictors of human behavior at the aggregate, condition-level, for
which they are, however, not designed to, or usually used to, make predictions
in the first place."
Fredformer - Frequency Debiased Transformer for Time Series Forecasting,https://arxiv.org/abs/2406.09009,2024-06-13,2024-06-19,0.0,0.0,"The Transformer model has shown leading performance in time series
forecasting. Nevertheless, in some complex scenarios, it tends to learn
low-frequency features in the data and overlook high-frequency features,
showing a frequency bias. This bias prevents the model from accurately
capturing important high-frequency data features. In this paper, we undertook
empirical analyses to understand this bias and discovered that frequency bias
results from the model disproportionately focusing on frequency features with
higher energy. Based on our analysis, we formulate this bias and propose
Fredformer, a Transformer-based framework designed to mitigate frequency bias
by learning features equally across different frequency bands. This approach
prevents the model from overlooking lower amplitude features important for
accurate forecasting. Extensive experiments show the effectiveness of our
proposed approach, which can outperform other baselines in different real-world
time-series datasets. Furthermore, we introduce a lightweight variant of the
Fredformer with an attention matrix approximation, which achieves comparable
performance but with much fewer parameters and lower computation costs. The
code is available at: https://github.com/chenzRG/Fredformer"
LLM Reading Tea Leaves - Automatically Evaluating Topic Models with Large Language Models,https://arxiv.org/abs/2406.09008,2024-06-13,2024-06-19,0.0,0.0,"Topic modeling has been a widely used tool for unsupervised text analysis.
However, comprehensive evaluations of a topic model remain challenging.
Existing evaluation methods are either less comparable across different models
(e.g., perplexity) or focus on only one specific aspect of a model (e.g., topic
quality or document representation quality) at a time, which is insufficient to
reflect the overall model performance. In this paper, we propose WALM (Words
Agreement with Language Model), a new evaluation method for topic modeling that
comprehensively considers the semantic quality of document representations and
topics in a joint manner, leveraging the power of large language models (LLMs).
With extensive experiments involving different types of topic models, WALM is
shown to align with human judgment and can serve as a complementary evaluation
method to the existing ones, bringing a new perspective to topic modeling. Our
software package will be available at
https://github.com/Xiaohao-Yang/Topic_Model_Evaluation, which can be integrated
with many widely used topic models."
Classic GNNs are Strong Baselines - Reassessing GNNs for Node Classification,https://arxiv.org/abs/2406.08993,2024-06-13,2024-06-19,0.0,0.0,"Graph Transformers (GTs) have recently emerged as popular alternatives to
traditional message-passing Graph Neural Networks (GNNs), due to their
theoretically superior expressiveness and impressive performance reported on
standard node classification benchmarks, often significantly outperforming
GNNs. In this paper, we conduct a thorough empirical analysis to reevaluate the
performance of three classic GNN models (GCN, GAT, and GraphSAGE) against GTs.
Our findings suggest that the previously reported superiority of GTs may have
been overstated due to suboptimal hyperparameter configurations in GNNs.
Remarkably, with slight hyperparameter tuning, these classic GNN models achieve
state-of-the-art performance, matching or even exceeding that of recent GTs
across 17 out of the 18 diverse datasets examined. Additionally, we conduct
detailed ablation studies to investigate the influence of various GNN
configurations, such as normalization, dropout, residual connections, network
depth, and jumping knowledge mode, on node classification performance. Our
study aims to promote a higher standard of empirical rigor in the field of
graph machine learning, encouraging more accurate comparisons and evaluations
of model capabilities."
BTS - Building Timeseries Dataset - Empowering Large-Scale Building Analytics,https://arxiv.org/abs/2406.08990,2024-06-13,2024-06-19,0.0,0.0,"Buildings play a crucial role in human well-being, influencing occupant
comfort, health, and safety. Additionally, they contribute significantly to
global energy consumption, accounting for one-third of total energy usage, and
carbon emissions. Optimizing building performance presents a vital opportunity
to combat climate change and promote human flourishing. However, research in
building analytics has been hampered by the lack of accessible, available, and
comprehensive real-world datasets on multiple building operations. In this
paper, we introduce the Building TimeSeries (BTS) dataset. Our dataset covers
three buildings over a three-year period, comprising more than ten thousand
timeseries data points with hundreds of unique ontologies. Moreover, the
metadata is standardized using the Brick schema. To demonstrate the utility of
this dataset, we performed benchmarks on two tasks: timeseries ontology
classification and zero-shot forecasting. These tasks represent an essential
initial step in addressing challenges related to interoperability in building
analytics. Access to the dataset and the code used for benchmarking are
available here: https://github.com/cruiseresearchgroup/DIEF_BTS ."
From Theory to Therapy - Reframing SBDD Model Evaluation via Practical Metrics,https://arxiv.org/abs/2406.08980,2024-06-13,2024-06-19,0.0,0.0,"Recent advancements in structure-based drug design (SBDD) have significantly
enhanced the efficiency and precision of drug discovery by generating molecules
tailored to bind specific protein pockets. Despite these technological strides,
their practical application in real-world drug development remains challenging
due to the complexities of synthesizing and testing these molecules. The
reliability of the Vina docking score, the current standard for assessing
binding abilities, is increasingly questioned due to its susceptibility to
overfitting. To address these limitations, we propose a comprehensive
evaluation framework that includes assessing the similarity of generated
molecules to known active compounds, introducing a virtual screening-based
metric for practical deployment capabilities, and re-evaluating binding
affinity more rigorously. Our experiments reveal that while current SBDD models
achieve high Vina scores, they fall short in practical usability metrics,
highlighting a significant gap between theoretical predictions and real-world
applicability. Our proposed metrics and dataset aim to bridge this gap,
enhancing the practical applicability of future SBDD models and aligning them
more closely with the needs of pharmaceutical research and development."
Multi-Agent Software Development through Cross-Team Collaboration,https://arxiv.org/abs/2406.08979,2024-06-13,2024-06-19,0.0,0.0,"The latest breakthroughs in Large Language Models (LLMs), eg., ChatDev, have
catalyzed profound transformations, particularly through multi-agent
collaboration for software development. LLM agents can collaborate in teams
like humans, and follow the waterfall model to sequentially work on
requirements analysis, development, review, testing, and other phases to
perform autonomous software generation. However, for an agent team, each phase
in a single development process yields only one possible outcome. This results
in the completion of only one development chain, thereby losing the opportunity
to explore multiple potential decision paths within the solution space.
Consequently, this may lead to obtaining suboptimal results. To address this
challenge, we introduce Cross-Team Collaboration (CTC), a scalable multi-team
framework that enables orchestrated teams to jointly propose various decisions
and communicate with their insights in a cross-team collaboration environment
for superior content generation. Experimental results in software development
reveal a notable increase in quality compared to state-of-the-art baselines,
underscoring the efficacy of our framework. The significant improvements in
story generation demonstrate the promising generalization ability of our
framework across various domains. We anticipate that our work will guide LLM
agents towards a cross-team paradigm and contribute to their significant growth
in but not limited to software development. The code and data will be available
at https://github.com/OpenBMB/ChatDev."
XLand-100B - A Large-Scale Multi-Task Dataset for In-Context Reinforcement Learning,https://arxiv.org/abs/2406.08973,2024-06-13,2024-06-19,0.0,0.0,"Following the success of the in-context learning paradigm in large-scale
language and computer vision models, the recently emerging field of in-context
reinforcement learning is experiencing a rapid growth. However, its development
has been held back by the lack of challenging benchmarks, as all the
experiments have been carried out in simple environments and on small-scale
datasets. We present \textbf{XLand-100B}, a large-scale dataset for in-context
reinforcement learning based on the XLand-MiniGrid environment, as a first step
to alleviate this problem. It contains complete learning histories for nearly
$30,000$ different tasks, covering $100$B transitions and $2.5$B episodes. It
took $50,000$ GPU hours to collect the dataset, which is beyond the reach of
most academic labs. Along with the dataset, we provide the utilities to
reproduce or expand it even further. With this substantial effort, we aim to
democratize research in the rapidly growing field of in-context reinforcement
learning and provide a solid foundation for further scaling. The code is
open-source and available under Apache 2.0 licence at
https://github.com/dunno-lab/xland-minigrid-datasets."
Distributed genetic algorithm for application placement in the compute continuum leveraging infrastructure nodes for optimization,https://arxiv.org/abs/2406.09478,2024-06-13,2024-06-19,0.0,0.0,"The increasing complexity of fog computing environments calls for efficient
resource optimization techniques. In this paper, we propose and evaluate three
distributed designs of a genetic algorithm (GA) for resource optimization in
fog computing, within an increasing degree of distribution. The designs
leverage the execution of the GA in the fog devices themselves by dealing with
the specific features of this domain: constrained resources and widely
geographical distribution of the devices. For their evaluation, we implemented
a benchmark case using the NSGA-II for the specific problem of optimizing the
fog service placement, according to the guidelines of our three distributed
designs. These three experimental scenarios were compared with a control case,
a traditional centralized version of this GA algorithm, considering solution
quality and network overhead. The results show that the design with the lowest
distribution degree, which keeps centralized storage of the objective space,
achieves comparable solution quality to the traditional approach but incurs a
higher network load. The second design, which completely distributes the
population between the workers, reduces network overhead but exhibits lower
solution diversity while keeping enough good results in terms of optimization
objective minimization. Finally, the proposal with a distributed population and
that only interchanges solution between the workers' neighbors achieves the
lowest network load but with compromised solution quality."
Q-S5 - Towards Quantized State Space Models,https://arxiv.org/abs/2406.09477,2024-06-13,2024-06-19,0.0,0.0,"In the quest for next-generation sequence modeling architectures, State Space
Models (SSMs) have emerged as a potent alternative to transformers,
particularly for their computational efficiency and suitability for dynamical
systems. This paper investigates the effect of quantization on the S5 model to
understand its impact on model performance and to facilitate its deployment to
edge and resource-constrained platforms. Using quantization-aware training
(QAT) and post-training quantization (PTQ), we systematically evaluate the
quantization sensitivity of SSMs across different tasks like dynamical systems
modeling, Sequential MNIST (sMNIST) and most of the Long Range Arena (LRA). We
present fully quantized S5 models whose test accuracy drops less than 1% on
sMNIST and most of the LRA. We find that performance on most tasks degrades
significantly for recurrent weights below 8-bit precision, but that other
components can be compressed further without significant loss of performance.
Our results further show that PTQ only performs well on language-based LRA
tasks whereas all others require QAT. Our investigation provides necessary
insights for the continued development of efficient and hardware-optimized
SSMs."
Separation Power of Equivariant Neural Networks,https://arxiv.org/abs/2406.08966,2024-06-13,2024-06-19,0.0,0.0,"The separation power of a machine learning model refers to its capacity to
distinguish distinct inputs, and it is often employed as a proxy for its
expressivity. In this paper, we propose a theoretical framework to investigate
the separation power of equivariant neural networks with point-wise
activations. Using the proposed framework, we can derive an explicit
description of inputs indistinguishable by a family of neural networks with
given architecture, demonstrating that it remains unaffected by the choice of
non-polynomial activation function employed. We are able to understand the role
played by activation functions in separability. Indeed, we show that all
non-polynomial activations, such as ReLU and sigmoid, are equivalent in terms
of expressivity, and that they reach maximum discrimination capacity. We
demonstrate how assessing the separation power of an equivariant neural network
can be simplified to evaluating the separation power of minimal
representations. We conclude by illustrating how these minimal components form
a hierarchy in separation power."
SIU - A Million-Scale Structural Small Molecule-Protein Interaction Dataset for Unbiased Bioactivity Prediction,https://arxiv.org/abs/2406.08961,2024-06-13,2024-06-19,0.0,0.0,"Small molecules play a pivotal role in modern medicine, and scrutinizing
their interactions with protein targets is essential for the discovery and
development of novel, life-saving therapeutics. The term ""bioactivity""
encompasses various biological effects resulting from these interactions,
including both binding and functional responses. The magnitude of bioactivity
dictates the therapeutic or toxic pharmacological outcomes of small molecules,
rendering accurate bioactivity prediction crucial for the development of safe
and effective drugs. However, existing structural datasets of small
molecule-protein interactions are often limited in scale and lack
systematically organized bioactivity labels, thereby impeding our understanding
of these interactions and precise bioactivity prediction. In this study, we
introduce a comprehensive dataset of small molecule-protein interactions,
consisting of over a million binding structures, each annotated with real
biological activity labels. This dataset is designed to facilitate unbiased
bioactivity prediction. We evaluated several classical models on this dataset,
and the results demonstrate that the task of unbiased bioactivity prediction is
challenging yet essential."
Beyond Recommendations - From Backward to Forward AI Support of Pilots' Decision-Making Process,https://arxiv.org/abs/2406.08959,2024-06-13,2024-06-19,0.0,0.0,"AI is anticipated to enhance human decision-making in high-stakes domains
like aviation, but adoption is often hindered by challenges such as
inappropriate reliance and poor alignment with users' decision-making. Recent
research suggests that a core underlying issue is the recommendation-centric
design of many AI systems, i.e., they give end-to-end recommendations and
ignore the rest of the decision-making process. Alternative support paradigms
are rare, and it remains unclear how the few that do exist compare to
recommendation-centric support. In this work, we aimed to empirically compare
recommendation-centric support to an alternative paradigm, continuous support,
in the context of diversions in aviation. We conducted a mixed-methods study
with 32 professional pilots in a realistic setting. To ensure the quality of
our study scenarios, we conducted a focus group with four additional pilots
prior to the study. We found that continuous support can support pilots'
decision-making in a forward direction, allowing them to think more beyond the
limits of the system and make faster decisions when combined with
recommendations, though the forward support can be disrupted. Participants'
statements further suggest a shift in design goal away from providing
recommendations, to supporting quick information gathering. Our results show
ways to design more helpful and effective AI decision support that goes beyond
end-to-end recommendations."
Financial Assets Dependency Prediction Utilizing Spatiotemporal Patterns,https://arxiv.org/abs/2406.11886,2024-06-13,2024-06-19,0.0,0.0,"Financial assets exhibit complex dependency structures, which are crucial for
investors to create diversified portfolios to mitigate risk in volatile
financial markets. To explore the financial asset dependencies dynamics, we
propose a novel approach that models the dependencies of assets as an Asset
Dependency Matrix (ADM) and treats the ADM sequences as image sequences. This
allows us to leverage deep learning-based video prediction methods to capture
the spatiotemporal dependencies among assets. However, unlike images where
neighboring pixels exhibit explicit spatiotemporal dependencies due to the
natural continuity of object movements, assets in ADM do not have a natural
order. This poses challenges to organizing the relational assets to reveal
better the spatiotemporal dependencies among neighboring assets for ADM
forecasting. To tackle the challenges, we propose the Asset Dependency Neural
Network (ADNN), which employs the Convolutional Long Short-Term Memory
(ConvLSTM) network, a highly successful method for video prediction. ADNN can
employ static and dynamic transformation functions to optimize the
representations of the ADM. Through extensive experiments, we demonstrate that
our proposed framework consistently outperforms the baselines in the ADM
prediction and downstream application tasks. This research contributes to
understanding and predicting asset dependencies, offering valuable insights for
financial market participants."
An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records,https://arxiv.org/abs/2406.08958,2024-06-13,2024-06-19,0.0,0.0,"Electronic healthcare records are vital for patient safety as they document
conditions, plans, and procedures in both free text and medical codes. Language
models have significantly enhanced the processing of such records, streamlining
workflows and reducing manual data entry, thereby saving healthcare providers
significant resources. However, the black-box nature of these models often
leaves healthcare professionals hesitant to trust them. State-of-the-art
explainability methods increase model transparency but rely on human-annotated
evidence spans, which are costly. In this study, we propose an approach to
produce plausible and faithful explanations without needing such annotations.
We demonstrate on the automated medical coding task that adversarial robustness
training improves explanation plausibility and introduce AttInGrad, a new
explanation method superior to previous ones. By combining both contributions
in a fully unsupervised setup, we produce explanations of comparable quality,
or better, to that of a supervised approach. We release our code and model
weights."
Tool Wear Prediction in CNC Turning Operations using Ultrasonic Microphone Arrays and CNNs,https://arxiv.org/abs/2406.08957,2024-06-13,2024-06-19,0.0,0.0,"This paper introduces a novel method for predicting tool wear in CNC turning
operations, combining ultrasonic microphone arrays and convolutional neural
networks (CNNs). High-frequency acoustic emissions between 0 kHz and 60 kHz are
enhanced using beamforming techniques to improve the signal- to-noise ratio.
The processed acoustic data is then analyzed by a CNN, which predicts the
Remaining Useful Life (RUL) of cutting tools. Trained on data from 350
workpieces machined with a single carbide insert, the model can accurately
predict the RUL of the carbide insert. Our results demonstrate the potential
gained by integrating advanced ultrasonic sensors with deep learning for
accurate predictive maintenance tasks in CNC machining."
Preserving Identity with Variational Score for General-purpose 3D Editing,https://arxiv.org/abs/2406.08953,2024-06-13,2024-06-19,0.0,0.0,"We present Piva (Preserving Identity with Variational Score Distillation), a
novel optimization-based method for editing images and 3D models based on
diffusion models. Specifically, our approach is inspired by the recently
proposed method for 2D image editing - Delta Denoising Score (DDS). We pinpoint
the limitations in DDS for 2D and 3D editing, which causes detail loss and
over-saturation. To address this, we propose an additional score distillation
term that enforces identity preservation. This results in a more stable editing
process, gradually optimizing NeRF models to match target prompts while
retaining crucial input characteristics. We demonstrate the effectiveness of
our approach in zero-shot image and neural field editing. Our method
successfully alters visual attributes, adds both subtle and substantial
structural elements, translates shapes, and achieves competitive results on
standard 2D and 3D editing benchmarks. Additionally, our method imposes no
constraints like masking or pre-training, making it compatible with a wide
range of pre-trained diffusion models. This allows for versatile editing
without needing neural field-to-mesh conversion, offering a more user-friendly
experience."
CLST - Cold-Start Mitigation in Knowledge Tracing by Aligning a Generative Language Model as a Students' Knowledge Tracer,https://arxiv.org/abs/2406.10296,2024-06-13,2024-06-19,0.0,0.0,"Knowledge tracing (KT), wherein students' problem-solving histories are used
to estimate their current levels of knowledge, has attracted significant
interest from researchers. However, most existing KT models were developed with
an ID-based paradigm, which exhibits limitations in cold-start performance.
These limitations can be mitigated by leveraging the vast quantities of
external knowledge possessed by generative large language models (LLMs). In
this study, we propose cold-start mitigation in knowledge tracing by aligning a
generative language model as a students' knowledge tracer (CLST) as a framework
that utilizes a generative LLM as a knowledge tracer. Upon collecting data from
math, social studies, and science subjects, we framed the KT task as a natural
language processing task, wherein problem-solving data are expressed in natural
language, and fine-tuned the generative LLM using the formatted KT dataset.
Subsequently, we evaluated the performance of the CLST in situations of data
scarcity using various baseline models for comparison. The results indicate
that the CLST significantly enhanced performance with a dataset of fewer than
100 students in terms of prediction, reliability, and cross-domain
generalization."
Neural NeRF Compression,https://arxiv.org/abs/2406.08943,2024-06-13,2024-06-19,0.0,0.0,"Neural Radiance Fields (NeRFs) have emerged as powerful tools for capturing
detailed 3D scenes through continuous volumetric representations. Recent NeRFs
utilize feature grids to improve rendering quality and speed; however, these
representations introduce significant storage overhead. This paper presents a
novel method for efficiently compressing a grid-based NeRF model, addressing
the storage overhead concern. Our approach is based on the non-linear transform
coding paradigm, employing neural compression for compressing the model's
feature grids. Due to the lack of training data involving many i.i.d scenes, we
design an encoder-free, end-to-end optimized approach for individual scenes,
using lightweight decoders. To leverage the spatial inhomogeneity of the latent
feature grids, we introduce an importance-weighted rate-distortion objective
and a sparse entropy model employing a masking mechanism. Our experimental
results validate that our proposed method surpasses existing works in terms of
grid-based NeRF compression efficacy and reconstruction quality."
Word Order in English-Japanese Simultaneous Interpretation - Analyses and Evaluation using Chunk-wise Monotonic Translation,https://arxiv.org/abs/2406.08940,2024-06-13,2024-06-19,0.0,0.0,"This paper analyzes the features of monotonic translations, which follow the
word order of the source language, in simultaneous interpreting (SI). Word
order differences are one of the biggest challenges in SI, especially for
language pairs with significant structural differences like English and
Japanese. We analyzed the characteristics of chunk-wise monotonic translation
(CMT) sentences using the NAIST English-to-Japanese Chunk-wise Monotonic
Translation Evaluation Dataset and identified some grammatical structures that
make monotonic translation difficult in English-Japanese SI. We further
investigated the features of CMT sentences by evaluating the output from the
existing speech translation (ST) and simultaneous speech translation (simulST)
models on the NAIST English-to-Japanese Chunk-wise Monotonic Translation
Evaluation Dataset as well as on existing test sets. The results indicate the
possibility that the existing SI-based test set underestimates the model
performance. The results also suggest that using CMT sentences as references
gives higher scores to simulST models than ST models, and that using an
offline-based test set to evaluate the simulST models underestimates the model
performance."
Mirror and Preconditioned Gradient Descent in Wasserstein Space,https://arxiv.org/abs/2406.08938,2024-06-13,2024-06-19,0.0,0.0,"As the problem of minimizing functionals on the Wasserstein space encompasses
many applications in machine learning, different optimization algorithms on
$\mathbb{R}^d$ have received their counterpart analog on the Wasserstein space.
We focus here on lifting two explicit algorithms: mirror descent and
preconditioned gradient descent. These algorithms have been introduced to
better capture the geometry of the function to minimize and are provably
convergent under appropriate (namely relative) smoothness and convexity
conditions. Adapting these notions to the Wasserstein space, we prove
guarantees of convergence of some Wasserstein-gradient-based discrete-time
schemes for new pairings of objective functionals and regularizers. The
difficulty here is to carefully select along which curves the functionals
should be smooth and convex. We illustrate the advantages of adapting the
geometry induced by the regularizer on ill-conditioned optimization tasks, and
showcase the improvement of choosing different discrepancies and geometries in
a computational biology task of aligning single-cells."
LaCoOT - Layer Collapse through Optimal Transport,https://arxiv.org/abs/2406.08933,2024-06-13,2024-06-19,0.0,0.0,"Although deep neural networks are well-known for their remarkable performance
in tackling complex tasks, their hunger for computational resources remains a
significant hurdle, posing energy-consumption issues and restricting their
deployment on resource-constrained devices, which stalls their widespread
adoption. In this paper, we present an optimal transport method to reduce the
depth of over-parametrized deep neural networks, alleviating their
computational burden. More specifically, we propose a new regularization
strategy based on the Max-Sliced Wasserstein distance to minimize the distance
between the intermediate feature distributions in the neural network. We show
that minimizing this distance enables the complete removal of intermediate
layers in the network, with almost no performance loss and without requiring
any finetuning. We assess the effectiveness of our method on traditional image
classification setups. We commit to releasing the source code upon acceptance
of the article."
Exploring Multilingual Unseen Speaker Emotion Recognition - Leveraging Co-Attention Cues in Multitask Learning,https://arxiv.org/abs/2406.08931,2024-06-13,2024-06-19,0.0,0.0,"Advent of modern deep learning techniques has given rise to advancements in
the field of Speech Emotion Recognition (SER). However, most systems prevalent
in the field fail to generalize to speakers not seen during training. This
study focuses on handling challenges of multilingual SER, specifically on
unseen speakers. We introduce CAMuLeNet, a novel architecture leveraging
co-attention based fusion and multitask learning to address this problem.
Additionally, we benchmark pretrained encoders of Whisper, HuBERT, Wav2Vec2.0,
and WavLM using 10-fold leave-speaker-out cross-validation on five existing
multilingual benchmark datasets: IEMOCAP, RAVDESS, CREMA-D, EmoDB and CaFE and,
release a novel dataset for SER on the Hindi language (BhavVani). CAMuLeNet
shows an average improvement of approximately 8% over all benchmarks on unseen
speakers determined by our cross-validation strategy."
Efficient Multi-View Fusion and Flexible Adaptation to View Missing in Cardiovascular System Signals,https://arxiv.org/abs/2406.08930,2024-06-13,2024-06-19,0.0,0.0,"The progression of deep learning and the widespread adoption of sensors have
facilitated automatic multi-view fusion (MVF) about the cardiovascular system
(CVS) signals. However, prevalent MVF model architecture often amalgamates CVS
signals from the same temporal step but different views into a unified
representation, disregarding the asynchronous nature of cardiovascular events
and the inherent heterogeneity across views, leading to catastrophic view
confusion. Efficient training strategies specifically tailored for MVF models
to attain comprehensive representations need simultaneous consideration.
Crucially, real-world data frequently arrives with incomplete views, an aspect
rarely noticed by researchers. Thus, the View-Centric Transformer (VCT) and
Multitask Masked Autoencoder (M2AE) are specifically designed to emphasize the
centrality of each view and harness unlabeled data to achieve superior fused
representations. Additionally, we systematically define the missing-view
problem for the first time and introduce prompt techniques to aid pretrained
MVF models in flexibly adapting to various missing-view scenarios. Rigorous
experiments involving atrial fibrillation detection, blood pressure estimation,
and sleep staging-typical health monitoring tasks-demonstrate the remarkable
advantage of our method in MVF compared to prevailing methodologies. Notably,
the prompt technique requires finetuning less than 3% of the entire model's
data, substantially fortifying the model's resilience to view missing while
circumventing the need for complete retraining. The results demonstrate the
effectiveness of our approaches, highlighting their potential for practical
applications in cardiovascular health monitoring. Codes and models are released
at URL."
Step-by-Step Diffusion - An Elementary Tutorial,https://arxiv.org/abs/2406.08929,2024-06-13,2024-06-19,0.0,0.0,"We present an accessible first course on diffusion models and flow matching
for machine learning, aimed at a technical audience with no diffusion
experience. We try to simplify the mathematical details as much as possible
(sometimes heuristically), while retaining enough precision to derive correct
algorithms."
Robustness of Structured Data Extraction from In-plane Rotated Documents using Multi-Modal Large Language Models (LLM),https://arxiv.org/abs/2406.10295,2024-06-13,2024-06-19,0.0,0.0,"Multi-modal large language models (LLMs) have shown remarkable performance in
various natural language processing tasks, including data extraction from
documents. However, the accuracy of these models can be significantly affected
by document in-plane rotation, also known as skew, a common issue in real-world
scenarios for scanned documents. This study investigates the impact of document
skew on the data extraction accuracy of three state-of-the-art multi-modal
LLMs: Anthropic Claude V3 Sonnet, GPT-4-Turbo, and Llava:v1.6. We focus on
extracting specific entities from synthetically generated sample documents with
varying degrees of skewness. The results demonstrate that document skew
adversely affects the data extraction accuracy of all the tested LLMs, with the
severity of the impact varying across models. We identify the safe in-plane
rotation angles (SIPRA) for each model and investigate the effects of skew on
model hallucinations. Furthermore, we explore existing skew detection and
correction mechanisms and discuss their potential limitations. We propose
alternative approaches, including developing new multi-modal architectures that
are inherently more robust to document skew and incorporating skewing
techniques during the pre-training phase of the models. Additionally, we
highlight the need for more comprehensive testing on a wider range of document
quality and conditions to fully understand the challenges and opportunities
associated with using multi-modal LLMs for information extraction in real-world
scenarios."
Learning Images Across Scales Using Adversarial Training,https://arxiv.org/abs/2406.08924,2024-06-13,2024-06-19,0.0,0.0,"The real world exhibits rich structure and detail across many scales of
observation. It is difficult, however, to capture and represent a broad
spectrum of scales using ordinary images. We devise a novel paradigm for
learning a representation that captures an orders-of-magnitude variety of
scales from an unstructured collection of ordinary images. We treat this
collection as a distribution of scale-space slices to be learned using
adversarial training, and additionally enforce coherency across slices. Our
approach relies on a multiscale generator with carefully injected procedural
frequency content, which allows to interactively explore the emerging
continuous scale space. Training across vastly different scales poses
challenges regarding stability, which we tackle using a supervision scheme that
involves careful sampling of scales. We show that our generator can be used as
a multiscale generative model, and for reconstructions of scale spaces from
unstructured patches. Significantly outperforming the state of the art, we
demonstrate zoom-in factors of up to 256x at high quality and scale
consistency."
Navigating the Shadows - Unveiling Effective Disturbances for Modern AI Content Detectors,https://arxiv.org/abs/2406.08922,2024-06-13,2024-06-19,0.0,0.0,"With the launch of ChatGPT, large language models (LLMs) have attracted
global attention. In the realm of article writing, LLMs have witnessed
extensive utilization, giving rise to concerns related to intellectual property
protection, personal privacy, and academic integrity. In response, AI-text
detection has emerged to distinguish between human and machine-generated
content. However, recent research indicates that these detection systems often
lack robustness and struggle to effectively differentiate perturbed texts.
Currently, there is a lack of systematic evaluations regarding detection
performance in real-world applications, and a comprehensive examination of
perturbation techniques and detector robustness is also absent. To bridge this
gap, our work simulates real-world scenarios in both informal and professional
writing, exploring the out-of-the-box performance of current detectors.
Additionally, we have constructed 12 black-box text perturbation methods to
assess the robustness of current detection models across various perturbation
granularities. Furthermore, through adversarial learning experiments, we
investigate the impact of perturbation data augmentation on the robustness of
AI-text detectors. We have released our code and data at
https://github.com/zhouying20/ai-text-detector-evaluation."
AV-GS - Learning Material and Geometry Aware Priors for Novel View Acoustic Synthesis,https://arxiv.org/abs/2406.08920,2024-06-13,2024-06-19,0.0,0.0,"Novel view acoustic synthesis (NVAS) aims to render binaural audio at any
target viewpoint, given a mono audio emitted by a sound source at a 3D scene.
Existing methods have proposed NeRF-based implicit models to exploit visual
cues as a condition for synthesizing binaural audio. However, in addition to
low efficiency originating from heavy NeRF rendering, these methods all have a
limited ability of characterizing the entire scene environment such as room
geometry, material properties, and the spatial relation between the listener
and sound source. To address these issues, we propose a novel Audio-Visual
Gaussian Splatting (AV-GS) model. To obtain a material-aware and geometry-aware
condition for audio synthesis, we learn an explicit point-based scene
representation with an audio-guidance parameter on locally initialized Gaussian
points, taking into account the space relation from the listener and sound
source. To make the visual scene model audio adaptive, we propose a point
densification and pruning strategy to optimally distribute the Gaussian points,
with the per-point contribution in sound propagation (e.g., more points needed
for texture-less wall surfaces as they affect sound path diversion). Extensive
experiments validate the superiority of our AV-GS over existing alternatives on
the real-world RWAS and simulation-based SoundSpaces datasets."
Beyond the Calibration Point - Mechanism Comparison in Differential Privacy,https://arxiv.org/abs/2406.08918,2024-06-13,2024-06-19,0.0,0.0,"In differentially private (DP) machine learning, the privacy guarantees of DP
mechanisms are often reported and compared on the basis of a single
$(\varepsilon, \delta)$-pair. This practice overlooks that DP guarantees can
vary substantially even between mechanisms sharing a given $(\varepsilon,
\delta)$, and potentially introduces privacy vulnerabilities which can remain
undetected. This motivates the need for robust, rigorous methods for comparing
DP guarantees in such cases. Here, we introduce the $\Delta$-divergence between
mechanisms which quantifies the worst-case excess privacy vulnerability of
choosing one mechanism over another in terms of $(\varepsilon, \delta)$, $f$-DP
and in terms of a newly presented Bayesian interpretation. Moreover, as a
generalisation of the Blackwell theorem, it is endowed with strong
decision-theoretic foundations. Through application examples, we show that our
techniques can facilitate informed decision-making and reveal gaps in the
current understanding of privacy risks, as current practices in DP-SGD often
result in choosing mechanisms with high excess privacy vulnerabilities."
Predicting Fault-Ride-Through Probability of Inverter-Dominated Power Grids using Machine Learning,https://arxiv.org/abs/2406.08917,2024-06-13,2024-06-19,0.0,0.0,"Due to the increasing share of renewables, the analysis of the dynamical
behavior of power grids gains importance. Effective risk assessments
necessitate the analysis of large number of fault scenarios. The computational
costs inherent in dynamic simulations impose constraints on the number of
configurations that can be analyzed. Machine Learning (ML) has proven to
efficiently predict complex power grid properties. Hence, we analyze the
potential of ML for predicting dynamic stability of future power grids with
large shares of inverters. For this purpose, we generate a new dataset
consisting of synthetic power grid models and perform dynamical simulations. As
targets for the ML training, we calculate the fault-ride-through probability,
which we define as the probability of staying within a ride-through curve after
a fault at a bus has been cleared. Importantly, we demonstrate that ML models
accurately predict the fault-ride-through probability of synthetic power grids.
Finally, we also show that the ML models generalize to an IEEE-96 Test System,
which emphasizes the potential of deploying ML methods to study probabilistic
stability of power grids."
Transcription-Free Fine-Tuning of Speech Separation Models for Noisy and Reverberant Multi-Speaker Automatic Speech Recognition,https://arxiv.org/abs/2406.08914,2024-06-13,2024-06-19,0.0,0.0,"One solution to automatic speech recognition (ASR) of overlapping speakers is
to separate speech and then perform ASR on the separated signals. Commonly, the
separator produces artefacts which often degrade ASR performance. Addressing
this issue typically requires reference transcriptions to jointly train the
separation and ASR networks. This is often not viable for training on
real-world in-domain audio where reference transcript information is not always
available. This paper proposes a transcription-free method for joint training
using only audio signals. The proposed method uses embedding differences of
pre-trained ASR encoders as a loss with a proposed modification to permutation
invariant training (PIT) called guided PIT (GPIT). The method achieves a 6.4%
improvement in word error rate (WER) measures over a signal-level loss and also
shows enhancement improvements in perceptual measures such as short-time
objective intelligibility (STOI)."
An Initial Investigation of Language Adaptation for TTS Systems under Low-resource Scenarios,https://arxiv.org/abs/2406.08911,2024-06-13,2024-06-19,0.0,0.0,"Self-supervised learning (SSL) representations from massively multilingual
models offer a promising solution for low-resource language speech tasks.
Despite advancements, language adaptation in TTS systems remains an open
problem. This paper explores the language adaptation capability of ZMM-TTS, a
recent SSL-based multilingual TTS system proposed in our previous work. We
conducted experiments on 12 languages using limited data with various
fine-tuning configurations. We demonstrate that the similarity in phonetics
between the pre-training and target languages, as well as the language
category, affects the target language's adaptation performance. Additionally,
we find that the fine-tuning dataset size and number of speakers influence
adaptability. Surprisingly, we also observed that using paired data for
fine-tuning is not always optimal compared to audio-only data. Beyond speech
intelligibility, our analysis covers speaker similarity, language
identification, and predicted MOS."
AdaPTwin - Low-Cost Adaptive Compression of Product Twins in Transformers,https://arxiv.org/abs/2406.08904,2024-06-13,2024-06-19,0.0,0.0,"While large transformer-based models have exhibited remarkable performance in
speaker-independent speech recognition, their large size and computational
requirements make them expensive or impractical to use in resource-constrained
settings. In this work, we propose a low-rank adaptive compression technique
called AdaPTwin that jointly compresses product-dependent pairs of weight
matrices in the transformer attention layer. Our approach can prioritize the
compressed model's performance on a specific speaker while maintaining
generalizability to new speakers and acoustic conditions. Notably, our
technique requires only 8 hours of speech data for fine-tuning, which can be
accomplished in under 20 minutes, making it highly cost-effective compared to
other compression methods. We demonstrate the efficacy of our approach by
compressing the Whisper and Distil-Whisper models by up to 45% while incurring
less than a 2% increase in word error rate."
Delta-CoMe - Training-Free Delta-Compression with Mixed-Precision for Large Language Models,https://arxiv.org/abs/2406.08903,2024-06-13,2024-06-19,0.0,0.0,"Fine-tuning is a crucial process for adapting large language models (LLMs) to
diverse applications. In certain scenarios, such as multi-tenant serving,
deploying multiple LLMs becomes necessary to meet complex demands. Recent
studies suggest decomposing a fine-tuned LLM into a base model and
corresponding delta weights, which are then compressed using low-rank or
low-bit approaches to reduce costs. In this work, we observe that existing
low-rank and low-bit compression methods can significantly harm the model
performance for task-specific fine-tuned LLMs (e.g., WizardMath for math
problems). Motivated by the long-tail distribution of singular values in the
delta weights, we propose a delta quantization approach using mixed-precision.
This method employs higher-bit representation for singular vectors
corresponding to larger singular values. We evaluate our approach on various
fine-tuned LLMs, including math LLMs, code LLMs, chat LLMs, and even VLMs.
Experimental results demonstrate that our approach performs comparably to full
fine-tuned LLMs, surpassing both low-rank and low-bit baselines by a
considerable margin. Additionally, we show that our method is compatible with
various backbone LLMs, such as Llama-2, Llama-3, and Mistral, highlighting its
generalizability."
Computer Vision Approaches for Automated Bee Counting Application,https://arxiv.org/abs/2406.08898,2024-06-13,2024-06-19,0.0,0.0,"Many application from the bee colony health state monitoring could be
efficiently solved using a computer vision techniques. One of such challenges
is an efficient way for counting the number of incoming and outcoming bees,
which could be used to further analyse many trends, such as the bee colony
health state, blooming periods, or for investigating the effects of
agricultural spraying. In this paper, we compare three methods for the
automated bee counting over two own datasets. The best performing method is
based on the ResNet-50 convolutional neural network classifier, which achieved
accuracy of 87% over the BUT1 dataset and the accuracy of 93% over the BUT2
dataset."
Motif-driven Subgraph Structure Learning for Graph Classification,https://arxiv.org/abs/2406.08897,2024-06-13,2024-06-19,0.0,0.0,"To mitigate the suboptimal nature of graph structure, Graph Structure
Learning (GSL) has emerged as a promising approach to improve graph structure
and boost performance in downstream tasks. Despite the proposal of numerous GSL
methods, the progresses in this field mostly concentrated on node-level tasks,
while graph-level tasks (e.g., graph classification) remain largely unexplored.
Notably, applying node-level GSL to graph classification is non-trivial due to
the lack of find-grained guidance for intricate structure learning. Inspired by
the vital role of subgraph in graph classification, in this paper we explore
the potential of subgraph structure learning for graph classification by
tackling the challenges of key subgraph selection and structure optimization.
We propose a novel Motif-driven Subgraph Structure Learning method for Graph
Classification (MOSGSL). Specifically, MOSGSL incorporates a subgraph structure
learning module which can adaptively select important subgraphs. A motif-driven
structure guidance module is further introduced to capture key subgraph-level
structural patterns (motifs) and facilitate personalized structure learning.
Extensive experiments demonstrate a significant and consistent improvement over
baselines, as well as its flexibility and generalizability for various
backbones and learning procedures."
The Penalized Inverse Probability Measure for Conformal Classification,https://arxiv.org/abs/2406.08884,2024-06-13,2024-06-19,0.0,0.0,"The deployment of safe and trustworthy machine learning systems, and
particularly complex black box neural networks, in real-world applications
requires reliable and certified guarantees on their performance. The conformal
prediction framework offers such formal guarantees by transforming any point
into a set predictor with valid, finite-set, guarantees on the coverage of the
true at a chosen level of confidence. Central to this methodology is the notion
of the nonconformity score function that assigns to each example a measure of
''strangeness'' in comparison with the previously seen observations. While the
coverage guarantees are maintained regardless of the nonconformity measure, the
point predictor and the dataset, previous research has shown that the
performance of a conformal model, as measured by its efficiency (the average
size of the predicted sets) and its informativeness (the proportion of
prediction sets that are singletons), is influenced by the choice of the
nonconformity score function. The current work introduces the Penalized Inverse
Probability (PIP) nonconformity score, and its regularized version RePIP, that
allow the joint optimization of both efficiency and informativeness. Through
toy examples and empirical results on the task of crop and weed image
classification in agricultural robotics, the current work shows how PIP-based
conformal classifiers exhibit precisely the desired behavior in comparison with
other nonconformity measures and strike a good balance between informativeness
and efficiency."
"No perspective, no perception!! Perspective-aware Healthcare Answer Summarization",https://arxiv.org/abs/2406.08881,2024-06-13,2024-06-19,0.0,0.0,"Healthcare Community Question Answering (CQA) forums offer an accessible
platform for individuals seeking information on various healthcare-related
topics. People find such platforms suitable for self-disclosure, seeking
medical opinions, finding simplified explanations for their medical conditions,
and answering others' questions. However, answers on these forums are typically
diverse and prone to off-topic discussions. It can be challenging for readers
to sift through numerous answers and extract meaningful insights, making answer
summarization a crucial task for CQA forums. While several efforts have been
made to summarize the community answers, most of them are limited to the open
domain and overlook the different perspectives offered by these answers. To
address this problem, this paper proposes a novel task of perspective-specific
answer summarization. We identify various perspectives, within
healthcare-related responses and frame a perspective-driven abstractive summary
covering all responses. To achieve this, we annotate 3167 CQA threads with 6193
perspective-aware summaries in our PUMA dataset. Further, we propose PLASMA, a
prompt-driven controllable summarization model. To encapsulate the
perspective-specific conditions, we design an energy-controlled loss function
for the optimization. We also leverage the prefix tuner to learn the
intricacies of the health-care perspective summarization. Our evaluation
against five baselines suggests the superior performance of PLASMA by a margin
of 1.5-21% improvement. We supplement our experiments with ablation and
qualitative analysis."
Hierarchical Compression of Text-Rich Graphs via Large Language Models,https://arxiv.org/abs/2406.11884,2024-06-13,2024-06-19,0.0,0.0,"Text-rich graphs, prevalent in data mining contexts like e-commerce and
academic graphs, consist of nodes with textual features linked by various
relations. Traditional graph machine learning models, such as Graph Neural
Networks (GNNs), excel in encoding the graph structural information, but have
limited capability in handling rich text on graph nodes. Large Language Models
(LLMs), noted for their superior text understanding abilities, offer a solution
for processing the text in graphs but face integration challenges due to their
limitation for encoding graph structures and their computational complexities
when dealing with extensive text in large neighborhoods of interconnected
nodes. This paper introduces ``Hierarchical Compression'' (HiCom), a novel
method to align the capabilities of LLMs with the structure of text-rich
graphs. HiCom processes text in a node's neighborhood in a structured manner by
organizing the extensive textual information into a more manageable hierarchy
and compressing node text step by step. Therefore, HiCom not only preserves the
contextual richness of the text but also addresses the computational challenges
of LLMs, which presents an advancement in integrating the text processing power
of LLMs with the structural complexities of text-rich graphs. Empirical results
show that HiCom can outperform both GNNs and LLM backbones for node
classification on e-commerce and citation graphs. HiCom is especially effective
for nodes from a dense region in a graph, where it achieves a 3.48% average
performance improvement on five datasets while being more efficient than LLM
backbones."
Zoom and Shift are All You Need,https://arxiv.org/abs/2406.08866,2024-06-13,2024-06-19,0.0,0.0,"Feature alignment serves as the primary mechanism for fusing multimodal data.
We put forth a feature alignment approach that achieves full integration of
multimodal information. This is accomplished via an alternating process of
shifting and expanding feature representations across modalities to obtain a
consistent unified representation in a joint feature space. The proposed
technique can reliably capture high-level interplay between features
originating from distinct modalities. Consequently, substantial gains in
multimodal learning performance are attained. Additionally, we demonstrate the
superiority of our approach over other prevalent multimodal fusion schemes on a
range of tasks. Extensive experimental evaluation conducted on multimodal
datasets comprising time series, image, and text demonstrates that our method
achieves state-of-the-art results."
Research on Early Warning Model of Cardiovascular Disease Based on Computer Deep Learning,https://arxiv.org/abs/2406.08864,2024-06-13,2024-06-19,0.0,0.0,"This project intends to study a cardiovascular disease risk early warning
model based on one-dimensional convolutional neural networks. First, the
missing values of 13 physiological and symptom indicators such as patient age,
blood glucose, cholesterol, and chest pain were filled and Z-score was
standardized. The convolutional neural network is converted into a 2D matrix,
the convolution function of 1,3, and 5 is used for the first-order convolution
operation, and the Max Pooling algorithm is adopted for dimension reduction.
Set the learning rate and output rate. It is optimized by the Adam algorithm.
The result of classification is output by a soft classifier. This study was
conducted based on Statlog in the UCI database and heart disease database
respectively. The empirical data indicate that the forecasting precision of
this technique has been enhanced by 11.2%, relative to conventional approaches,
while there is a significant improvement in the logarithmic curve fitting. The
efficacy and applicability of the novel approach are corroborated through the
examination employing a one-dimensional convolutional neural network."
Self-supervised Graph Neural Network for Mechanical CAD Retrieval,https://arxiv.org/abs/2406.08863,2024-06-13,2024-06-19,0.0,0.0,"CAD (Computer-Aided Design) plays a crucial role in mechanical industry,
where large numbers of similar-shaped CAD parts are often created. Efficiently
reusing these parts is key to reducing design and production costs for
enterprises. Retrieval systems are vital for achieving CAD reuse, but the
complex shapes of CAD models are difficult to accurately describe using text or
keywords, making traditional retrieval methods ineffective. While existing
representation learning approaches have been developed for CAD, manually
labeling similar samples in these methods is expensive. Additionally, CAD
models' unique parameterized data structure presents challenges for applying
existing 3D shape representation learning techniques directly. In this work, we
propose GC-CAD, a self-supervised contrastive graph neural network-based method
for mechanical CAD retrieval that directly models parameterized CAD raw files.
GC-CAD consists of two key modules: structure-aware representation learning and
contrastive graph learning framework. The method leverages graph neural
networks to extract both geometric and topological information from CAD models,
generating feature representations. We then introduce a simple yet effective
contrastive graph learning framework approach, enabling the model to train
without manual labels and generate retrieval-ready representations.
Experimental results on four datasets including human evaluation demonstrate
that the proposed method achieves significant accuracy improvements and up to
100 times efficiency improvement over the baseline methods."
Cognitively Inspired Energy-Based World Models,https://arxiv.org/abs/2406.08862,2024-06-13,2024-06-19,0.0,0.0,"One of the predominant methods for training world models is autoregressive
prediction in the output space of the next element of a sequence. In Natural
Language Processing (NLP), this takes the form of Large Language Models (LLMs)
predicting the next token; in Computer Vision (CV), this takes the form of
autoregressive models predicting the next frame/token/pixel. However, this
approach differs from human cognition in several respects. First, human
predictions about the future actively influence internal cognitive processes.
Second, humans naturally evaluate the plausibility of predictions regarding
future states. Based on this capability, and third, by assessing when
predictions are sufficient, humans allocate a dynamic amount of time to make a
prediction. This adaptive process is analogous to System 2 thinking in
psychology. All these capabilities are fundamental to the success of humans at
high-level reasoning and planning. Therefore, to address the limitations of
traditional autoregressive models lacking these human-like capabilities, we
introduce Energy-Based World Models (EBWM). EBWM involves training an
Energy-Based Model (EBM) to predict the compatibility of a given context and a
predicted future state. In doing so, EBWM enables models to achieve all three
facets of human cognition described. Moreover, we developed a variant of the
traditional autoregressive transformer tailored for Energy-Based models, termed
the Energy-Based Transformer (EBT). Our results demonstrate that EBWM scales
better with data and GPU Hours than traditional autoregressive transformers in
CV, and that EBWM offers promising early scaling in NLP. Consequently, this
approach offers an exciting path toward training future models capable of
System 2 thinking and intelligently searching across state spaces."
"Plan, Generate and Complicate - Improving Low-resource Dialogue State Tracking via Easy-to-Difficult Zero-shot Data Augmentation",https://arxiv.org/abs/2406.08860,2024-06-13,2024-06-19,0.0,0.0,"Data augmentation methods have been a promising direction to improve the
performance of small models for low-resource dialogue state tracking. However,
traditional methods rely on pre-defined user goals and neglect the importance
of data complexity in this task. In this paper, we propose EDZ-DA, an
Easy-to-Difficult Zero-shot Data Augmentation framework for low-resource
dialogue state tracking that utilizes large language models to automatically
catch the relationships of different domains and then generate the dialogue
data. We also complicate the dialogues based on the domain relation to enhance
the model's capability for co-reference slot tracking. Furthermore, we permute
slot values to mitigate the influence of output orders and the problem of
incomplete value generation. Experimental results illustrate the superiority of
our proposed method compared to previous strong data augmentation baselines on
MultiWOZ."
RelevAI-Reviewer - A Benchmark on AI Reviewers for Survey Paper Relevance,https://arxiv.org/abs/2406.10294,2024-06-13,2024-06-19,0.0,0.0,"Recent advancements in Artificial Intelligence (AI), particularly the
widespread adoption of Large Language Models (LLMs), have significantly
enhanced text analysis capabilities. This technological evolution offers
considerable promise for automating the review of scientific papers, a task
traditionally managed through peer review by fellow researchers. Despite its
critical role in maintaining research quality, the conventional peer-review
process is often slow and subject to biases, potentially impeding the swift
propagation of scientific knowledge. In this paper, we propose
RelevAI-Reviewer, an automatic system that conceptualizes the task of survey
paper review as a classification problem, aimed at assessing the relevance of a
paper in relation to a specified prompt, analogous to a ""call for papers"". To
address this, we introduce a novel dataset comprised of 25,164 instances. Each
instance contains one prompt and four candidate papers, each varying in
relevance to the prompt. The objective is to develop a machine learning (ML)
model capable of determining the relevance of each paper and identifying the
most pertinent one. We explore various baseline approaches, including
traditional ML classifiers like Support Vector Machine (SVM) and advanced
language models such as BERT. Preliminary findings indicate that the BERT-based
end-to-end classifier surpasses other conventional ML methods in performance.
We present this problem as a public challenge to foster engagement and interest
in this area of research."
Current applications and potential future directions of reinforcement learning-based Digital Twins in agriculture,https://arxiv.org/abs/2406.08854,2024-06-13,2024-06-19,0.0,0.0,"Digital Twins have gained attention in various industries for simulation,
monitoring, and decision-making, relying on ever-improving machine learning
models. However, agricultural Digital Twin implementations are limited compared
to other industries. Meanwhile, machine learning, particularly reinforcement
learning, has shown potential in agricultural applications like optimizing
decision-making, task automation, and resource management. A key aspect of
Digital Twins is representing physical assets or systems in a virtual
environment, which aligns well with reinforcement learning's need for
environment representations to learn the best policy for a task. Reinforcement
learning in agriculture can thus enable various Digital Twin applications in
agricultural domains. This review aims to categorize existing research
employing reinforcement learning in agricultural settings by application
domains like robotics, greenhouse management, irrigation systems, and crop
management, identifying potential future areas for reinforcement learning-based
Digital Twins. It also categorizes the reinforcement learning techniques used,
including tabular methods, Deep Q-Networks (DQN), Policy Gradient methods, and
Actor-Critic algorithms, to overview currently employed models. The review
seeks to provide insights into the state-of-the-art in integrating Digital
Twins and reinforcement learning in agriculture, identifying gaps and
opportunities for future research, and exploring synergies to tackle
agricultural challenges and optimize farming, paving the way for more efficient
and sustainable farming methodologies."
Assessment of Uncertainty Quantification in Universal Differential Equations,https://arxiv.org/abs/2406.08853,2024-06-13,2024-06-19,0.0,0.0,"Scientific Machine Learning is a new class of approaches that integrate
physical knowledge and mechanistic models with data-driven techniques for
uncovering governing equations of complex processes. Among the available
approaches, Universal Differential Equations (UDEs) are used to combine prior
knowledge in the form of mechanistic formulations with universal function
approximators, like neural networks. Integral to the efficacy of UDEs is the
joint estimation of parameters within mechanistic formulations and the
universal function approximators using empirical data. The robustness and
applicability of resultant models, however, hinge upon the rigorous
quantification of uncertainties associated with these parameters, as well as
the predictive capabilities of the overall model or its constituent components.
With this work, we provide a formalisation of uncertainty quantification (UQ)
for UDEs and investigate important frequentist and Bayesian methods. By
analysing three synthetic examples of varying complexity, we evaluate the
validity and efficiency of ensembles, variational inference and Markov chain
Monte Carlo sampling as epistemic UQ methods for UDEs."
Inverse Probability of Treatment Weighting with Deep Sequence Models Enables Accurate treatment effect Estimation from Electronic Health Records,https://arxiv.org/abs/2406.08851,2024-06-13,2024-06-19,0.0,0.0,"Observational data have been actively used to estimate treatment effect,
driven by the growing availability of electronic health records (EHRs).
However, EHRs typically consist of longitudinal records, often introducing
time-dependent confoundings that hinder the unbiased estimation of treatment
effect. Inverse probability of treatment weighting (IPTW) is a widely used
propensity score method since it provides unbiased treatment effect estimation
and its derivation is straightforward. In this study, we aim to utilize IPTW to
estimate treatment effect in the presence of time-dependent confounding using
claims records. Previous studies have utilized propensity score methods with
features derived from claims records through feature processing, which
generally requires domain knowledge and additional resources to extract
information to accurately estimate propensity scores. Deep sequence models,
particularly recurrent neural networks and self-attention-based architectures,
have demonstrated good performance in modeling EHRs for various downstream
tasks. We propose that these deep sequence models can provide accurate IPTW
estimation of treatment effect by directly estimating the propensity scores
from claims records without the need for feature processing. We empirically
demonstrate this by conducting comprehensive evaluations using synthetic and
semi-synthetic datasets."
An Approach to Build Zero-Shot Slot-Filling System for Industry-Grade Conversational Assistants,https://arxiv.org/abs/2406.08848,2024-06-13,2024-06-19,0.0,0.0,"We present an approach to build Large Language Model (LLM) based slot-filling
system to perform Dialogue State Tracking in conversational assistants serving
across a wide variety of industry-grade applications. Key requirements of this
system include: 1) usage of smaller-sized models to meet low latency
requirements and to enable convenient and cost-effective cloud and customer
premise deployments, and 2) zero-shot capabilities to serve across a wide
variety of domains, slot types and conversational scenarios. We adopt a
fine-tuning approach where a pre-trained LLM is fine-tuned into a slot-filling
model using task specific data. The fine-tuning data is prepared carefully to
cover a wide variety of slot-filling task scenarios that the model is expected
to face across various domains. We give details of the data preparation and
model building process. We also give a detailed analysis of the results of our
experimental evaluations. Results show that our prescribed approach for
slot-filling model building has resulted in 6.9% relative improvement of F1
metric over the best baseline on a realistic benchmark, while at the same time
reducing the latency by 57%. More over, the data we prepared has helped improve
F1 on an average by 4.2% relative across various slot-types."
Roping in Uncertainty - Robustness and Regularization in Markov Games,https://arxiv.org/abs/2406.08847,2024-06-13,2024-06-19,0.0,0.0,"We study robust Markov games (RMG) with $s$-rectangular uncertainty. We show
a general equivalence between computing a robust Nash equilibrium (RNE) of a
$s$-rectangular RMG and computing a Nash equilibrium (NE) of an appropriately
constructed regularized MG. The equivalence result yields a planning algorithm
for solving $s$-rectangular RMGs, as well as provable robustness guarantees for
policies computed using regularized methods. However, we show that even for
just reward-uncertain two-player zero-sum matrix games, computing an RNE is
PPAD-hard. Consequently, we derive a special uncertainty structure called
efficient player-decomposability and show that RNE for two-player zero-sum RMG
in this class can be provably solved in polynomial time. This class includes
commonly used uncertainty sets such as $L_1$ and $L_\infty$ ball uncertainty
sets."
ContraSolver - Self-Alignment of Language Models by Resolving Internal Preference Contradictions,https://arxiv.org/abs/2406.08842,2024-06-13,2024-06-19,0.0,0.0,"While substantial advancements have been made in developing large language
models (LLMs), achieving control over their behavior can be difficult. Direct
preference optimization (DPO) assumes the existence of a latent reward function
to evaluate the responses of LLMs. This assumption indicates a strict
preference ordering of different responses to the same input. However, there
always exist contradictions of preference in LLMs according to our experimental
observations. In this paper, we construct a graph structure of the preference
relationship among different responses with self-annotation to find
contradictions in the preference order. We propose ContraSolver, an algorithm
that traverses all edges on the preference graph to identify those that might
cause contradictions. ContraSolver initializes the graph with a maximum
spanning tree and identifies contradictory edges, prioritizing the resolution
of low-confidence preferences while preserving high-confidence ones.
Experimental results on four different generation tasks show that the
performance of different LLMs can be largely improved through our completely
unsupervised self-alignment. Furthermore, by analyzing the preference graphs of
LLMs with and without self-alignment by ContraSolver, we quantify the reduction
in contradictions, suggesting that resolving preference contradictions is
crucial for achieving better alignment performance."
Conceptual Learning via Embedding Approximations for Reinforcing Interpretability and Transparency,https://arxiv.org/abs/2406.08840,2024-06-13,2024-06-19,0.0,0.0,"Concept bottleneck models (CBMs) have emerged as critical tools in domains
where interpretability is paramount. These models rely on predefined textual
descriptions, referred to as concepts, to inform their decision-making process
and offer more accurate reasoning. As a result, the selection of concepts used
in the model is of utmost significance. This study proposes
\underline{\textbf{C}}onceptual \underline{\textbf{L}}earning via
\underline{\textbf{E}}mbedding \underline{\textbf{A}}pproximations for
\underline{\textbf{R}}einforcing Interpretability and Transparency, abbreviated
as CLEAR, a framework for constructing a CBM for image classification. Using
score matching and Langevin sampling, we approximate the embedding of concepts
within the latent space of a vision-language model (VLM) by learning the scores
associated with the joint distribution of images and concepts. A concept
selection process is then employed to optimize the similarity between the
learned embeddings and the predefined ones. The derived bottleneck offers
insights into the CBM's decision-making process, enabling more comprehensive
interpretations. Our approach was evaluated through extensive experiments and
achieved state-of-the-art performance on various benchmarks. The code for our
experiments is available at https://github.com/clearProject/CLEAR/tree/main"
Research on Optimization of Natural Language Processing Model Based on Multimodal Deep Learning,https://arxiv.org/abs/2406.08838,2024-06-13,2024-06-19,0.0,0.0,"This project intends to study the image representation based on attention
mechanism and multimodal data. By adding multiple pattern layers to the
attribute model, the semantic and hidden layers of image content are
integrated. The word vector is quantified by the Word2Vec method and then
evaluated by a word embedding convolutional neural network. The published
experimental results of the two groups were tested. The experimental results
show that this method can convert discrete features into continuous characters,
thus reducing the complexity of feature preprocessing. Word2Vec and natural
language processing technology are integrated to achieve the goal of direct
evaluation of missing image features. The robustness of the image feature
evaluation model is improved by using the excellent feature analysis
characteristics of a convolutional neural network. This project intends to
improve the existing image feature identification methods and eliminate the
subjective influence in the evaluation process. The findings from the
simulation indicate that the novel approach has developed is viable,
effectively augmenting the features within the produced representations."
Research on Deep Learning Model of Feature Extraction Based on Convolutional Neural Network,https://arxiv.org/abs/2406.08837,2024-06-13,2024-06-19,0.0,0.0,"Neural networks with relatively shallow layers and simple structures may have
limited ability in accurately identifying pneumonia. In addition, deep neural
networks also have a large demand for computing resources, which may cause
convolutional neural networks to be unable to be implemented on terminals.
Therefore, this paper will carry out the optimal classification of
convolutional neural networks. Firstly, according to the characteristics of
pneumonia images, AlexNet and InceptionV3 were selected to obtain better image
recognition results. Combining the features of medical images, the forward
neural network with deeper and more complex structure is learned. Finally,
knowledge extraction technology is used to extract the obtained data into the
AlexNet model to achieve the purpose of improving computing efficiency and
reducing computing costs. The results showed that the prediction accuracy,
specificity, and sensitivity of the trained AlexNet model increased by 4.25
percentage points, 7.85 percentage points, and 2.32 percentage points,
respectively. The graphics processing usage has decreased by 51% compared to
the InceptionV3 mode."
Center-Sensitive Kernel Optimization for Efficient On-Device Incremental Learning,https://arxiv.org/abs/2406.08830,2024-06-13,2024-06-19,0.0,0.0,"To facilitate the evolution of edge intelligence in ever-changing
environments, we study on-device incremental learning constrained in limited
computation resource in this paper. Current on-device training methods just
focus on efficient training without considering the catastrophic forgetting,
preventing the model getting stronger when continually exploring the world. To
solve this problem, a direct solution is to involve the existing incremental
learning mechanisms into the on-device training framework. Unfortunately, such
a manner cannot work well as those mechanisms usually introduce large
additional computational cost to the network optimization process, which would
inevitably exceed the memory capacity of the edge devices. To address this
issue, this paper makes an early effort to propose a simple but effective
edge-friendly incremental learning framework. Based on an empirical study on
the knowledge intensity of the kernel elements of the neural network, we find
that the center kernel is the key for maximizing the knowledge intensity for
learning new data, while freezing the other kernel elements would get a good
balance on the model's capacity for overcoming catastrophic forgetting. Upon
this finding, we further design a center-sensitive kernel optimization
framework to largely alleviate the cost of the gradient computation and
back-propagation. Besides, a dynamic channel element selection strategy is also
proposed to facilitate a sparse orthogonal gradient projection for further
reducing the optimization complexity, upon the knowledge explored from the new
task data. Extensive experiments validate our method is efficient and
effective, e.g., our method achieves average accuracy boost of 38.08% with even
less memory and approximate computation compared to existing on-device training
methods, indicating its significant potential for on-device incremental
learning."
Estimating Difficulty Levels of Programming Problems with Pre-trained Model,https://arxiv.org/abs/2406.08828,2024-06-13,2024-06-19,0.0,0.0,"As the demand for programming skills grows across industries and academia,
students often turn to Programming Online Judge (POJ) platforms for coding
practice and competition. The difficulty level of each programming problem
serves as an essential reference for guiding students' adaptive learning.
However, current methods of determining difficulty levels either require
extensive expert annotations or take a long time to accumulate enough student
solutions for each problem. To address this issue, we formulate the problem of
automatic difficulty level estimation of each programming problem, given its
textual description and a solution example of code. For tackling this problem,
we propose to couple two pre-trained models, one for text modality and the
other for code modality, into a unified model. We built two POJ datasets for
the task and the results demonstrate the effectiveness of the proposed approach
and the contributions of both modalities."
Computer vision-based model for detecting turning lane features on Florida's public roadways,https://arxiv.org/abs/2406.08822,2024-06-13,2024-06-19,0.0,0.0,"Efficient and current roadway geometry data collection is critical to
transportation agencies in road planning, maintenance, design, and
rehabilitation. Data collection methods are divided into land-based and
aerial-based. Land-based methods for extensive highway networks are tedious,
costly, pose safety risks. Therefore, there is the need for efficient, safe,
and economical data acquisition methodologies. The rise of computer vision and
object detection technologies have made automated extraction of roadway
geometry features feasible. This study detects roadway features on Florida's
public roads from high-resolution aerial images using AI. The developed model
achieved an average accuracy of 80.4 percent when compared with ground truth
data. The extracted roadway geometry data can be integrated with crash and
traffic data to provide valuable insights to policymakers and roadway users."
DisfluencySpeech -- Single-Speaker Conversational Speech Dataset with Paralanguage,https://arxiv.org/abs/2406.08820,2024-06-13,2024-06-19,0.0,0.0,"Laughing, sighing, stuttering, and other forms of paralanguage do not
contribute any direct lexical meaning to speech, but they provide crucial
propositional context that aids semantic and pragmatic processes such as irony.
It is thus important for artificial social agents to both understand and be
able to generate speech with semantically-important paralanguage. Most speech
datasets do not include transcribed non-lexical speech sounds and disfluencies,
while those that do are typically multi-speaker datasets where each speaker
provides relatively little audio. This makes it challenging to train
conversational Text-to-Speech (TTS) synthesis models that include such
paralinguistic components.
  We thus present DisfluencySpeech, a studio-quality labeled English speech
dataset with paralanguage. A single speaker recreates nearly 10 hours of
expressive utterances from the Switchboard-1 Telephone Speech Corpus
(Switchboard), simulating realistic informal conversations. To aid the
development of a TTS model that is able to predictively synthesise paralanguage
from text without such components, we provide three different transcripts at
different levels of information removal (removal of non-speech events, removal
of non-sentence elements, and removal of false starts), as well as benchmark
TTS models trained on each of these levels."
"AIM - Attributing, Interpreting, Mitigating Data Unfairness",https://arxiv.org/abs/2406.08819,2024-06-13,2024-06-19,0.0,0.0,"Data collected in the real world often encapsulates historical discrimination
against disadvantaged groups and individuals. Existing fair machine learning
(FairML) research has predominantly focused on mitigating discriminative bias
in the model prediction, with far less effort dedicated towards exploring how
to trace biases present in the data, despite its importance for the
transparency and interpretability of FairML. To fill this gap, we investigate a
novel research problem: discovering samples that reflect biases/prejudices from
the training data. Grounding on the existing fairness notions, we lay out a
sample bias criterion and propose practical algorithms for measuring and
countering sample bias. The derived bias score provides intuitive sample-level
attribution and explanation of historical bias in data. On this basis, we
further design two FairML strategies via sample-bias-informed minimal data
editing. They can mitigate both group and individual unfairness at the cost of
minimal or zero predictive utility loss. Extensive experiments and analyses on
multiple real-world datasets demonstrate the effectiveness of our methods in
explaining and mitigating unfairness. Code is available at
https://github.com/ZhiningLiu1998/AIM."
Linguistic Bias in ChatGPT - Language Models Reinforce Dialect Discrimination,https://arxiv.org/abs/2406.08818,2024-06-13,2024-06-19,0.0,0.0,"We present a large-scale study of linguistic bias exhibited by ChatGPT
covering ten dialects of English (Standard American English, Standard British
English, and eight widely spoken non-""standard"" varieties from around the
world). We prompted GPT-3.5 Turbo and GPT-4 with text by native speakers of
each variety and analyzed the responses via detailed linguistic feature
annotation and native speaker evaluation. We find that the models default to
""standard"" varieties of English; based on evaluation by native speakers, we
also find that model responses to non-""standard"" varieties consistently exhibit
a range of issues: stereotyping (19% worse than for ""standard"" varieties),
demeaning content (25% worse), lack of comprehension (9% worse), and
condescending responses (15% worse). We also find that if these models are
asked to imitate the writing style of prompts in non-""standard"" varieties, they
produce text that exhibits lower comprehension of the input and is especially
prone to stereotyping. GPT-4 improves on GPT-3.5 in terms of comprehension,
warmth, and friendliness, but also exhibits a marked increase in stereotyping
(+18%). The results indicate that GPT-3.5 Turbo and GPT-4 can perpetuate
linguistic discrimination toward speakers of non-""standard"" varieties."
Automated Essay Scoring Using Grammatical Variety and Errors with Multi-Task Learning and Item Response Theory,https://arxiv.org/abs/2406.08817,2024-06-13,2024-06-19,0.0,0.0,"This study examines the effect of grammatical features in automatic essay
scoring (AES). We use two kinds of grammatical features as input to an AES
model: (1) grammatical items that writers used correctly in essays, and (2) the
number of grammatical errors. Experimental results show that grammatical
features improve the performance of AES models that predict the holistic scores
of essays. Multi-task learning with the holistic and grammar scores, alongside
using grammatical features, resulted in a larger improvement in model
performance. We also show that a model using grammar abilities estimated using
Item Response Theory (IRT) as the labels for the auxiliary task achieved
comparable performance to when we used grammar scores assigned by human raters.
In addition, we weight the grammatical features using IRT to consider the
difficulty of grammatical items and writers' grammar abilities. We found that
weighting grammatical features with the difficulty led to further improvement
in performance."
Mixture-of-Skills - Learning to Optimize Data Usage for Fine-Tuning Large Language Models,https://arxiv.org/abs/2406.08811,2024-06-13,2024-06-19,0.0,0.0,"Large language models (LLMs) are typically fine-tuned on diverse and
extensive datasets sourced from various origins to develop a comprehensive
range of skills, such as writing, reasoning, chatting, coding, and more. Each
skill has unique characteristics, and these datasets are often heterogeneous
and imbalanced, making the fine-tuning process highly challenging. Balancing
the development of each skill while ensuring the model maintains its overall
performance requires sophisticated techniques and careful dataset curation. In
this work, we propose a general, model-agnostic, reinforcement learning
framework, Mixture-of-Skills (MoS), that learns to optimize data usage
automatically during the fine-tuning process. This framework ensures the
optimal comprehensive skill development of LLMs by dynamically adjusting the
focus on different datasets based on their current learning state. To validate
the effectiveness of MoS, we conduct extensive experiments using three diverse
LLM backbones on two widely used benchmarks and demonstrate that MoS
substantially enhances model performance. Building on the success of MoS, we
propose MoSpec, an adaptation for task-specific fine-tuning, which harnesses
the utilities of various datasets for a specific purpose. Our work underlines
the significance of dataset rebalancing and present MoS as a powerful, general
solution for optimizing data usage in the fine-tuning of LLMs for various
purposes."
"Are we there yet? A brief survey of Music Emotion Prediction Datasets, Models and Outstanding Challenges",https://arxiv.org/abs/2406.08809,2024-06-13,2024-06-19,0.0,0.0,"Deep learning models for music have advanced drastically in the last few
years. But how good are machine learning models at capturing emotion these days
and what challenges are researchers facing? In this paper, we provide a
comprehensive overview of the available music-emotion datasets and discuss
evaluation standards as well as competitions in the field. We also provide a
brief overview of various types of music emotion prediction models that have
been built over the years, offering insights into the diverse approaches within
the field. Through this examination, we highlight the challenges that persist
in accurately capturing emotion in music. Recognizing the dynamic nature of
this field, we have complemented our findings with an accompanying GitHub
repository. This repository contains a comprehensive list of music emotion
datasets and recent predictive models."
Optimal Kernel Orchestration for Tensor Programs with Korch,https://arxiv.org/abs/2406.09465,2024-06-13,2024-06-19,0.0,0.0,"Kernel orchestration is the task of mapping the computation defined in
different operators of a deep neural network (DNN) to the execution of GPU
kernels on modern hardware platforms. Prior approaches optimize kernel
orchestration by greedily applying operator fusion, which fuses the computation
of multiple operators into a single kernel, and miss a variety of optimization
opportunities in kernel orchestration.
  This paper presents Korch, a tensor program optimizer that discovers optimal
kernel orchestration strategies for tensor programs. Instead of directly fusing
operators, Korch first applies operator fission to decompose tensor operators
into a small set of basic tensor algebra primitives. This decomposition enables
a diversity of fine-grained, inter-operator optimizations. Next, Korch
optimizes kernel orchestration by formalizing it as a constrained optimization
problem, leveraging an off-the-shelf binary linear programming solver to
discover an optimal orchestration strategy, and generating an executable that
can be directly deployed on modern GPU platforms. Evaluation on a variety of
DNNs shows that Korch outperforms existing tensor program optimizers by up to
1.7x on V100 GPUs and up to 1.6x on A100 GPUs. Korch is publicly available at
https://github.com/humuyan/Korch."
A Dual Approach to Imitation Learning from Observations with Offline Datasets,https://arxiv.org/abs/2406.08805,2024-06-13,2024-06-19,0.0,0.0,"Demonstrations are an effective alternative to task specification for
learning agents in settings where designing a reward function is difficult.
However, demonstrating expert behavior in the action space of the agent becomes
unwieldy when robots have complex, unintuitive morphologies. We consider the
practical setting where an agent has a dataset of prior interactions with the
environment and is provided with observation-only expert demonstrations.
Typical learning from observations approaches have required either learning an
inverse dynamics model or a discriminator as intermediate steps of training.
Errors in these intermediate one-step models compound during downstream policy
learning or deployment. We overcome these limitations by directly learning a
multi-step utility function that quantifies how each action impacts the agent's
divergence from the expert's visitation distribution. Using the principle of
duality, we derive DILO (Dual Imitation Learning from Observations), an
algorithm that can leverage arbitrary suboptimal data to learn imitating
policies without requiring expert actions. DILO reduces the learning from
observations problem to that of simply learning an actor and a critic, bearing
similar complexity to vanilla offline RL. This allows DILO to gracefully scale
to high dimensional observations, and demonstrate improved performance across
the board. Project page (code and videos):
$\href{https://hari-sikchi.github.io/dilo/}{\text{hari-sikchi.github.io/dilo/}}$"
DIET - Customized Slimming for Incompatible Networks in Sequential Recommendation,https://arxiv.org/abs/2406.08804,2024-06-13,2024-06-19,0.0,0.0,"Due to the continuously improving capabilities of mobile edges, recommender
systems start to deploy models on edges to alleviate network congestion caused
by frequent mobile requests. Several studies have leveraged the proximity of
edge-side to real-time data, fine-tuning them to create edge-specific models.
Despite their significant progress, these methods require substantial on-edge
computational resources and frequent network transfers to keep the model up to
date. The former may disrupt other processes on the edge to acquire
computational resources, while the latter consumes network bandwidth, leading
to a decrease in user satisfaction. In response to these challenges, we propose
a customizeD slImming framework for incompatiblE neTworks(DIET). DIET deploys
the same generic backbone (potentially incompatible for a specific edge) to all
devices. To minimize frequent bandwidth usage and storage consumption in
personalization, DIET tailors specific subnets for each edge based on its past
interactions, learning to generate slimming subnets(diets) within incompatible
networks for efficient transfer. It also takes the inter-layer relationships
into account, empirically reducing inference time while obtaining more suitable
diets. We further explore the repeated modules within networks and propose a
more storage-efficient framework, DIETING, which utilizes a single layer of
parameters to represent the entire network, achieving comparably excellent
performance. The experiments across four state-of-the-art datasets and two
widely used models demonstrate the superior accuracy in recommendation and
efficiency in transmission and storage of our framework."
Can Synthetic Audio From Generative Foundation Models Assist Audio Recognition and Speech Modeling?,https://arxiv.org/abs/2406.08800,2024-06-13,2024-06-19,0.0,0.0,"Recent advances in foundation models have enabled audio-generative models
that produce high-fidelity sounds associated with music, events, and human
actions. Despite the success achieved in modern audio-generative models, the
conventional approach to assessing the quality of the audio generation relies
heavily on distance metrics like Frechet Audio Distance. In contrast, we aim to
evaluate the quality of audio generation by examining the effectiveness of
using them as training data. Specifically, we conduct studies to explore the
use of synthetic audio for audio recognition. Moreover, we investigate whether
synthetic audio can serve as a resource for data augmentation in speech-related
modeling. Our comprehensive experiments demonstrate the potential of using
synthetic audio for audio recognition and speech-related modeling. Our code is
available at https://github.com/usc-sail/SynthAudio."
Pareto Front-Diverse Batch Multi-Objective Bayesian Optimization,https://arxiv.org/abs/2406.08799,2024-06-13,2024-06-19,0.0,0.0,"We consider the problem of multi-objective optimization (MOO) of expensive
black-box functions with the goal of discovering high-quality and diverse
Pareto fronts where we are allowed to evaluate a batch of inputs. This problem
arises in many real-world applications including penicillin production where
diversity of solutions is critical. We solve this problem in the framework of
Bayesian optimization (BO) and propose a novel approach referred to as Pareto
front-Diverse Batch Multi-Objective BO (PDBO). PDBO tackles two important
challenges: 1) How to automatically select the best acquisition function in
each BO iteration, and 2) How to select a diverse batch of inputs by
considering multiple objectives. We propose principled solutions to address
these two challenges. First, PDBO employs a multi-armed bandit approach to
select one acquisition function from a given library. We solve a cheap MOO
problem by assigning the selected acquisition function for each expensive
objective function to obtain a candidate set of inputs for evaluation. Second,
it utilizes Determinantal Point Processes (DPPs) to choose a
Pareto-front-diverse batch of inputs for evaluation from the candidate set
obtained from the first step. The key parameters for the methods behind these
two steps are updated after each round of function evaluations. Experiments on
multiple MOO benchmarks demonstrate that PDBO outperforms prior methods in
terms of both the quality and diversity of Pareto solutions."
Automatically Labeling $200B Life-Saving Datasets - A Large Clinical Trial Outcome Benchmark,https://arxiv.org/abs/2406.10292,2024-06-13,2024-06-19,0.0,0.0,"The global cost of drug discovery and development exceeds $200 billion
annually. The main results of drug discovery and development are the outcomes
of clinical trials, which directly influence the regulatory approval of new
drug candidates and ultimately affect patient outcomes. Despite their
significance, large-scale, high-quality clinical trial outcome data are not
readily available to the public. Suppose a large clinical trial outcome dataset
is provided; machine learning researchers can potentially develop accurate
prediction models using past trials and outcome labels, which could help
prioritize and optimize therapeutic programs, ultimately benefiting patients.
This paper introduces Clinical Trial Outcome (CTO) dataset, the largest trial
outcome dataset with around 479K clinical trials, aggregating outcomes from
multiple sources of weakly supervised labels, minimizing the noise from
individual sources, and eliminating the need for human annotation. These
sources include large language model (LLM) decisions on trial-related
documents, news headline sentiments, stock prices of trial sponsors, trial
linkages across phases, and other signals such as patient dropout rates and
adverse events. CTO's labels show unprecedented agreement with supervised
clinical trial outcome labels from test split of the supervised TOP dataset,
with a 91 F1."
"GPT-ology, Computational Models, Silicon Sampling - How should we think about LLMs in Cognitive Science?",https://arxiv.org/abs/2406.09464,2024-06-13,2024-06-19,0.0,0.0,"Large Language Models have taken the cognitive science world by storm. It is
perhaps timely now to take stock of the various research paradigms that have
been used to make scientific inferences about ``cognition"" in these models or
about human cognition. We review several emerging research paradigms --
GPT-ology, LLMs-as-computational-models, and ``silicon sampling"" -- and review
recent papers that have used LLMs under these paradigms. In doing so, we
discuss their claims as well as challenges to scientific inference under these
various paradigms. We highlight several outstanding issues about LLMs that have
to be addressed to push our science forward: closed-source vs open-sourced
models; (the lack of visibility of) training data; and reproducibility in LLM
research, including forming conventions on new task ``hyperparameters"" like
instructions and prompts."
An effective software risk prediction management analysis of data using machine learning and data mining method,https://arxiv.org/abs/2406.09463,2024-06-13,2024-06-19,0.0,0.0,"For one to guarantee higher-quality software development processes, risk
management is essential. Furthermore, risks are those that could negatively
impact an organization's operations or a project's progress. The appropriate
prioritisation of software project risks is a crucial factor in ascertaining
the software project's performance features and eventual success. They can be
used harmoniously with the same training samples and have good complement and
compatibility. We carried out in-depth tests on four benchmark datasets to
confirm the efficacy of our CIA approach in closed-world and open-world
scenarios, with and without defence. We also present a sequential augmentation
parameter optimisation technique that captures the interdependencies of the
latest deep learning state-of-the-art WF attack models. To achieve precise
software risk assessment, the enhanced crow search algorithm (ECSA) is used to
modify the ANFIS settings. Solutions that very slightly alter the local optimum
and stay inside it are extracted using the ECSA. ANFIS variable when utilising
the ANFIS technique. An experimental validation with NASA 93 dataset and 93
software project values was performed. This method's output presents a clear
image of the software risk elements that are essential to achieving project
performance. The results of our experiments show that, when compared to other
current methods, our integrative fuzzy techniques may perform more accurately
and effectively in the evaluation of software project risks."
Deep Exploration of Cross-Lingual Zero-Shot Generalization in Instruction Tuning,https://arxiv.org/abs/2406.08796,2024-06-13,2024-06-19,0.0,0.0,"Instruction tuning has emerged as a powerful technique, significantly
boosting zero-shot performance on unseen tasks. While recent work has explored
cross-lingual generalization by applying instruction tuning to multilingual
models, previous studies have primarily focused on English, with a limited
exploration of non-English tasks. For an in-depth exploration of cross-lingual
generalization in instruction tuning, we perform instruction tuning
individually for two distinct language meta-datasets. Subsequently, we assess
the performance on unseen tasks in a language different from the one used for
training. To facilitate this investigation, we introduce a novel non-English
meta-dataset named ""KORANI"" (Korean Natural Instruction), comprising 51 Korean
benchmarks. Moreover, we design cross-lingual templates to mitigate
discrepancies in language and instruction-format of the template between
training and inference within the cross-lingual setting. Our experiments reveal
consistent improvements through cross-lingual generalization in both English
and Korean, outperforming baseline by average scores of 20.7\% and 13.6\%,
respectively. Remarkably, these enhancements are comparable to those achieved
by monolingual instruction tuning and even surpass them in some tasks. The
result underscores the significance of relevant data acquisition across
languages over linguistic congruence with unseen tasks during instruction
tuning."
SViTT-Ego - A Sparse Video-Text Transformer for Egocentric Video,https://arxiv.org/abs/2406.09462,2024-06-13,2024-06-19,0.0,0.0,"Pretraining egocentric vision-language models has become essential to
improving downstream egocentric video-text tasks. These egocentric foundation
models commonly use the transformer architecture. The memory footprint of these
models during pretraining can be substantial. Therefore, we pretrain SViTT-Ego,
the first sparse egocentric video-text transformer model integrating edge and
node sparsification. We pretrain on the EgoClip dataset and incorporate the
egocentric-friendly objective EgoNCE, instead of the frequently used InfoNCE.
Most notably, SViTT-Ego obtains a +2.8% gain on EgoMCQ (intra-video) accuracy
compared to LAVILA large, with no additional data augmentation techniques other
than standard image augmentations, yet pretrainable on memory-limited devices."
Understanding the Generalizability of Link Predictors Under Distribution Shifts on Graphs,https://arxiv.org/abs/2406.08788,2024-06-13,2024-06-19,0.0,0.0,"Recently, multiple models proposed for link prediction (LP) demonstrate
impressive results on benchmark datasets. However, many popular benchmark
datasets often assume that dataset samples are drawn from the same distribution
(i.e., IID samples). In real-world situations, this assumption is often
incorrect; since uncontrolled factors may lead train and test samples to come
from separate distributions. To tackle the distribution shift problem, recent
work focuses on creating datasets that feature distribution shifts and
designing generalization methods that perform well on the new data. However,
those studies only consider distribution shifts that affect {\it node-} and
{\it graph-level} tasks, thus ignoring link-level tasks. Furthermore,
relatively few LP generalization methods exist. To bridge this gap, we
introduce a set of LP-specific data splits which utilizes structural properties
to induce a controlled distribution shift. We verify the shift's effect
empirically through evaluation of different SOTA LP methods and subsequently
couple these methods with generalization techniques. Interestingly, LP-specific
methods frequently generalize poorly relative to heuristics or basic GNN
methods. Finally, this work provides analysis to uncover insights for enhancing
LP generalization. Our code is available at:
\href{https://github.com/revolins/LPStructGen}{https://github.com/revolins/LPStructGen}"
A Survey on Compositional Learning of AI Models - Theoretical and Experimetnal Practices,https://arxiv.org/abs/2406.08787,2024-06-13,2024-06-19,0.0,0.0,"Compositional learning, mastering the ability to combine basic concepts and
construct more intricate ones, is crucial for human cognition, especially in
human language comprehension and visual perception. This notion is tightly
connected to generalization over unobserved situations. Despite its integral
role in intelligence, there is a lack of systematic theoretical and
experimental research methodologies, making it difficult to analyze the
compositional learning abilities of computational models. In this paper, we
survey the literature on compositional learning of AI models and the
connections made to cognitive studies. We identify abstract concepts of
compositionality in cognitive and linguistic studies and connect these to the
computational challenges faced by language and vision models in compositional
reasoning. We overview the formal definitions, tasks, evaluation benchmarks,
variety of computational models, and theoretical findings. We cover modern
studies on large language models to provide a deeper understanding of the
cutting-edge compositional capabilities exhibited by state-of-the-art AI models
and pinpoint important directions for future research."
ResearchArena - Benchmarking LLMs' Ability to Collect and Organize Information as Research Agents,https://arxiv.org/abs/2406.10291,2024-06-13,2024-06-19,0.0,0.0,"Large language models (LLMs) have exhibited remarkable performance across
various tasks in natural language processing. Nevertheless, challenges still
arise when these tasks demand domain-specific expertise and advanced analytical
skills, such as conducting research surveys on a designated topic. In this
research, we develop ResearchArena, a benchmark that measures LLM agents'
ability to conduct academic surveys, an initial step of academic research
process. Specifically, we deconstructs the surveying process into three stages
1) information discovery: locating relevant papers, 2) information selection:
assessing papers' importance to the topic, and 3) information organization:
organizing papers into meaningful structures. In particular, we establish an
offline environment comprising 12.0M full-text academic papers and 7.9K survey
papers, which evaluates agents' ability to locate supporting materials for
composing the survey on a topic, rank the located papers based on their impact,
and organize these into a hierarchical knowledge mind-map. With this benchmark,
we conduct preliminary evaluations of existing techniques and find that all
LLM-based methods under-performing when compared to basic keyword-based
retrieval techniques, highlighting substantial opportunities for future
research."
Learning Joint and Individual Structure in Network Data with Covariates,https://arxiv.org/abs/2406.08776,2024-06-13,2024-06-19,0.0,0.0,"Datasets consisting of a network and covariates associated with its vertices
have become ubiquitous. One problem pertaining to this type of data is to
identify information unique to the network, information unique to the vertex
covariates and information that is shared between the network and the vertex
covariates. Existing techniques for network data and vertex covariates focus on
capturing structure that is shared but are usually not able to differentiate
structure that is unique to each dataset. This work formulates a low-rank model
that simultaneously captures joint and individual information in network data
with vertex covariates. A two-step estimation procedure is proposed, composed
of an efficient spectral method followed by a refinement optimization step.
Theoretically, we show that the spectral method is able to consistently recover
the joint and individual components under a general signal-plus-noise model.
  Simulations and real data examples demonstrate the ability of the methods to
recover accurate and interpretable components. In particular, the application
of the methodology to a food trade network between countries with economic,
developmental and geographical country-level indicators as covariates yields
joint and individual factors that explain the trading patterns."
MMFakeBench - A Mixed-Source Multimodal Misinformation Detection Benchmark for LVLMs,https://arxiv.org/abs/2406.08772,2024-06-13,2024-06-19,0.0,0.0,"Current multimodal misinformation detection (MMD) methods often assume a
single source and type of forgery for each sample, which is insufficient for
real-world scenarios where multiple forgery sources coexist. The lack of a
benchmark for mixed-source misinformation has hindered progress in this field.
To address this, we introduce MMFakeBench, the first comprehensive benchmark
for mixed-source MMD. MMFakeBench includes 3 critical sources: textual veracity
distortion, visual veracity distortion, and cross-modal consistency distortion,
along with 12 sub-categories of misinformation forgery types. We further
conduct an extensive evaluation of 6 prevalent detection methods and 15 large
vision-language models (LVLMs) on MMFakeBench under a zero-shot setting. The
results indicate that current methods struggle under this challenging and
realistic mixed-source MMD setting. Additionally, we propose an innovative
unified framework, which integrates rationales, actions, and tool-use
capabilities of LVLM agents, significantly enhancing accuracy and
generalization. We believe this study will catalyze future research into more
realistic mixed-source multimodal misinformation and provide a fair evaluation
of misinformation detection methods."
MFF-EINV2 - Multi-scale Feature Fusion across Spectral-Spatial-Temporal Domains for Sound Event Localization and Detection,https://arxiv.org/abs/2406.08771,2024-06-13,2024-06-19,0.0,0.0,"Sound Event Localization and Detection (SELD) involves detecting and
localizing sound events using multichannel sound recordings. Previously
proposed Event-Independent Network V2 (EINV2) has achieved outstanding
performance on SELD. However, it still faces challenges in effectively
extracting features across spectral, spatial, and temporal domains. This paper
proposes a three-stage network structure named Multi-scale Feature Fusion (MFF)
module to fully extract multi-scale features across spectral, spatial, and
temporal domains. The MFF module utilizes parallel subnetworks architecture to
generate multi-scale spectral and spatial features. The TF-Convolution Module
is employed to provide multi-scale temporal features. We incorporated MFF into
EINV2 and term the proposed method as MFF-EINV2. Experimental results in 2022
and 2023 DCASE challenge task3 datasets show the effectiveness of our
MFF-EINV2, which achieves state-of-the-art (SOTA) performance compared to
published methods."
SRFUND - A Multi-Granularity Hierarchical Structure Reconstruction Benchmark in Form Understanding,https://arxiv.org/abs/2406.08757,2024-06-13,2024-06-19,0.0,0.0,"Accurately identifying and organizing textual content is crucial for the
automation of document processing in the field of form understanding. Existing
datasets, such as FUNSD and XFUND, support entity classification and
relationship prediction tasks but are typically limited to local and
entity-level annotations. This limitation overlooks the hierarchically
structured representation of documents, constraining comprehensive
understanding of complex forms. To address this issue, we present the SRFUND, a
hierarchically structured multi-task form understanding benchmark. SRFUND
provides refined annotations on top of the original FUNSD and XFUND datasets,
encompassing five tasks: (1) word to text-line merging, (2) text-line to entity
merging, (3) entity category classification, (4) item table localization, and
(5) entity-based full-document hierarchical structure recovery. We meticulously
supplemented the original dataset with missing annotations at various levels of
granularity and added detailed annotations for multi-item table regions within
the forms. Additionally, we introduce global hierarchical structure
dependencies for entity relation prediction tasks, surpassing traditional local
key-value associations. The SRFUND dataset includes eight languages including
English, Chinese, Japanese, German, French, Spanish, Italian, and Portuguese,
making it a powerful tool for cross-lingual form understanding. Extensive
experimental results demonstrate that the SRFUND dataset presents new
challenges and significant opportunities in handling diverse layouts and global
hierarchical structures of forms, thus providing deep insights into the field
of form understanding. The original dataset and implementations of baseline
methods are available at https://sprateam-ustc.github.io/SRFUND"
Optimizing Large Model Training through Overlapped Activation Recomputation,https://arxiv.org/abs/2406.08756,2024-06-13,2024-06-19,0.0,0.0,"Large model training has been using recomputation to alleviate the memory
pressure and pipelining to exploit the parallelism of data, tensor, and
devices. The existing recomputation approaches may incur up to 40% overhead
when training real-world models, e.g., the GPT model with 22B parameters. This
is because they are executed on demand in the critical training path. In this
paper, we design a new recomputation framework, Lynx, to reduce the overhead by
overlapping the recomputation with communication occurring in training
pipelines. It consists of an optimal scheduling algorithm (OPT) and a
heuristic-based scheduling algorithm (HEU). OPT achieves a global optimum but
suffers from a long search time. HEU was designed based on our observation that
there are identical structures in large DNN models so that we can apply the
same scheduling policy to all identical structures. HEU achieves a local
optimum but reduces the search time by 99% compared to OPT. Our comprehensive
evaluation using GPT models with 1.3B-20B parameters shows that both OPT and
HEU outperform the state-of-the-art recomputation approaches (e.g., Megatron-LM
and Checkmake) by 1.02-1.53x. HEU achieves a similar performance as OPT with a
search time of 0.16s on average."
StructuralSleight - Automated Jailbreak Attacks on Large Language Models Utilizing Uncommon Text-Encoded Structure,https://arxiv.org/abs/2406.08754,2024-06-13,2024-06-19,0.0,0.0,"Large Language Models (LLMs) are widely used in natural language processing
but face the risk of jailbreak attacks that maliciously induce them to generate
harmful content. Existing jailbreak attacks, including character-level and
context-level attacks, mainly focus on the prompt of the plain text without
specifically exploring the significant influence of its structure. In this
paper, we focus on studying how prompt structure contributes to the jailbreak
attack. We introduce a novel structure-level attack method based on tail
structures that are rarely used during LLM training, which we refer to as
Uncommon Text-Encoded Structure (UTES). We extensively study 12 UTESs templates
and 6 obfuscation methods to build an effective automated jailbreak tool named
StructuralSleight that contains three escalating attack strategies: Structural
Attack, Structural and Character/Context Obfuscation Attack, and Fully
Obfuscated Structural Attack. Extensive experiments on existing LLMs show that
StructuralSleight significantly outperforms baseline methods. In particular,
the attack success rate reaches 94.62\% on GPT-4o, which has not been addressed
by state-of-the-art techniques."
3D Building Generation in Minecraft via Large Language Models,https://arxiv.org/abs/2406.08751,2024-06-13,2024-06-19,0.0,0.0,"Recently, procedural content generation has exhibited considerable
advancements in the domain of 2D game level generation such as Super Mario
Bros. and Sokoban through large language models (LLMs). To further validate the
capabilities of LLMs, this paper explores how LLMs contribute to the generation
of 3D buildings in a sandbox game, Minecraft. We propose a Text to Building in
Minecraft (T2BM) model, which involves refining prompts, decoding interlayer
representation and repairing. Facade, indoor scene and functional blocks like
doors are supported in the generation. Experiments are conducted to evaluate
the completeness and satisfaction of buildings generated via LLMs. It shows
that LLMs hold significant potential for 3D building generation. Given
appropriate prompts, LLMs can generate correct buildings in Minecraft with
complete structures and incorporate specific building blocks such as windows
and beds, meeting the specified requirements of human users."
Mathematical models for off-ball scoring prediction in basketball,https://arxiv.org/abs/2406.08749,2024-06-13,2024-06-19,0.0,0.0,"In professional basketball, the accurate prediction of scoring opportunities
based on strategic decision-making is crucial for spatial and player
evaluations. However, traditional models often face challenges in accounting
for the complexities of off-ball movements, which are essential for
comprehensive performance evaluations. In this study, we propose two
mathematical models to predict off-ball scoring opportunities in basketball,
considering pass-to-score and dribble-to-score sequences: the Ball Movement for
Off-ball Scoring (BMOS) and the Ball Intercept and Movement for Off-ball
Scoring (BIMOS) models. The BMOS model adapts principles from the Off-Ball
Scoring Opportunities (OBSO) model, originally designed for soccer, to
basketball, whereas the BIMOS model also incorporates the likelihood of
interception during ball movements. We evaluated these models using player
tracking data from 630 NBA games in the 2015-2016 regular season, demonstrating
that the BIMOS model outperforms the BMOS model in terms of team scoring
prediction accuracy, while also highlighting its potential for further
development. Overall, the BIMOS model provides valuable insights for tactical
analysis and player evaluation in basketball."
Learning in Feature Spaces via Coupled Covariances - Asymmetric Kernel SVD and Nystrm method,https://arxiv.org/abs/2406.08748,2024-06-13,2024-06-19,0.0,0.0,"In contrast with Mercer kernel-based approaches as used e.g., in Kernel
Principal Component Analysis (KPCA), it was previously shown that Singular
Value Decomposition (SVD) inherently relates to asymmetric kernels and
Asymmetric Kernel Singular Value Decomposition (KSVD) has been proposed.
However, the existing formulation to KSVD cannot work with infinite-dimensional
feature mappings, the variational objective can be unbounded, and needs further
numerical evaluation and exploration towards machine learning. In this work, i)
we introduce a new asymmetric learning paradigm based on coupled covariance
eigenproblem (CCE) through covariance operators, allowing infinite-dimensional
feature maps. The solution to CCE is ultimately obtained from the SVD of the
induced asymmetric kernel matrix, providing links to KSVD. ii) Starting from
the integral equations corresponding to a pair of coupled adjoint
eigenfunctions, we formalize the asymmetric Nystr\""om method through a finite
sample approximation to speed up training. iii) We provide the first empirical
evaluations verifying the practical utility and benefits of KSVD and compare
with methods resorting to symmetrization or linear SVD across multiple tasks."
StreamBench - Towards Benchmarking Continuous Improvement of Language Agents,https://arxiv.org/abs/2406.08747,2024-06-13,2024-06-19,0.0,0.0,"Recent works have shown that large language model (LLM) agents are able to
improve themselves from experience, which is an important ability for
continuous enhancement post-deployment. However, existing benchmarks primarily
evaluate their innate capabilities and do not assess their ability to improve
over time. To address this gap, we introduce StreamBench, a pioneering
benchmark designed to evaluate the continuous improvement of LLM agents over an
input-feedback sequence. StreamBench simulates an online learning environment
where LLMs receive a continuous flow of feedback stream and iteratively enhance
their performance. In addition, we propose several simple yet effective
baselines for improving LLMs on StreamBench, and provide a comprehensive
analysis to identify critical components that contribute to successful
streaming strategies. Our work serves as a stepping stone towards developing
effective online learning strategies for LLMs, paving the way for more adaptive
AI systems in streaming scenarios."
Generalizable Implicit Neural Representation As a Universal Spatiotemporal Traffic Data Learner,https://arxiv.org/abs/2406.08743,2024-06-13,2024-06-19,0.0,0.0,"$\textbf{This is the conference version of our paper: Spatiotemporal Implicit
Neural Representation as a Generalized Traffic Data Learner}$. Spatiotemporal
Traffic Data (STTD) measures the complex dynamical behaviors of the multiscale
transportation system. Existing methods aim to reconstruct STTD using
low-dimensional models. However, they are limited to data-specific dimensions
or source-dependent patterns, restricting them from unifying representations.
Here, we present a novel paradigm to address the STTD learning problem by
parameterizing STTD as an implicit neural representation. To discern the
underlying dynamics in low-dimensional regimes, coordinate-based neural
networks that can encode high-frequency structures are employed to directly map
coordinates to traffic variables. To unravel the entangled spatial-temporal
interactions, the variability is decomposed into separate processes. We further
enable modeling in irregular spaces such as sensor graphs using spectral
embedding. Through continuous representations, our approach enables the
modeling of a variety of STTD with a unified input, thereby serving as a
generalized learner of the underlying traffic dynamics. It is also shown that
it can learn implicit low-rank priors and smoothness regularization from the
data, making it versatile for learning different dominating data patterns. We
validate its effectiveness through extensive experiments in real-world
scenarios, showcasing applications from corridor to network scales. Empirical
results not only indicate that our model has significant superiority over
conventional low-rank models, but also highlight that the versatility of the
approach. We anticipate that this pioneering modeling perspective could lay the
foundation for universal representation of STTD in various real-world tasks.
$\textbf{The full version can be found at:}$
https://doi.org/10.48550/arXiv.2405.03185."
An AI Architecture with the Capability to Explain Recognition Results,https://arxiv.org/abs/2406.08740,2024-06-13,2024-06-19,0.0,0.0,"Explainability is needed to establish confidence in machine learning results.
Some explainable methods take a post hoc approach to explain the weights of
machine learning models, others highlight areas of the input contributing to
decisions. These methods do not adequately explain decisions, in plain terms.
Explainable property-based systems have been shown to provide explanations in
plain terms, however, they have not performed as well as leading unexplainable
machine learning methods. This research focuses on the importance of metrics to
explainability and contributes two methods yielding performance gains. The
first method introduces a combination of explainable and unexplainable flows,
proposing a metric to characterize explainability of a decision. The second
method compares classic metrics for estimating the effectiveness of neural
networks in the system, posing a new metric as the leading performer. Results
from the new methods and examples from handwritten datasets are presented."
Standard Language Ideology in AI-Generated Language,https://arxiv.org/abs/2406.08726,2024-06-13,2024-06-19,0.0,0.0,"In this position paper, we explore standard language ideology in language
generated by large language models (LLMs). First, we outline how standard
language ideology is reflected and reinforced in LLMs. We then present a
taxonomy of open problems regarding standard language ideology in AI-generated
language with implications for minoritized language communities. We introduce
the concept of standard AI-generated language ideology, the process by which
AI-generated language regards Standard American English (SAE) as a linguistic
default and reinforces a linguistic bias that SAE is the most ""appropriate""
language. Finally, we discuss tensions that remain, including reflecting on
what desirable system behavior looks like, as well as advantages and drawbacks
of generative AI tools imitating--or often not--different English language
varieties. Throughout, we discuss standard language ideology as a manifestation
of existing global power structures in and through AI-generated language before
ending with questions to move towards alternative, more emancipatory digital
futures."
ECBD - Evidence-Centered Benchmark Design for NLP,https://arxiv.org/abs/2406.08723,2024-06-13,2024-06-19,0.0,0.0,"Benchmarking is seen as critical to assessing progress in NLP. However,
creating a benchmark involves many design decisions (e.g., which datasets to
include, which metrics to use) that often rely on tacit, untested assumptions
about what the benchmark is intended to measure or is actually measuring. There
is currently no principled way of analyzing these decisions and how they impact
the validity of the benchmark's measurements. To address this gap, we draw on
evidence-centered design in educational assessments and propose
Evidence-Centered Benchmark Design (ECBD), a framework which formalizes the
benchmark design process into five modules. ECBD specifies the role each module
plays in helping practitioners collect evidence about capabilities of interest.
Specifically, each module requires benchmark designers to describe, justify,
and support benchmark design choices -- e.g., clearly specifying the
capabilities the benchmark aims to measure or how evidence about those
capabilities is collected from model responses. To demonstrate the use of ECBD,
we conduct case studies with three benchmarks: BoolQ, SuperGLUE, and HELM. Our
analysis reveals common trends in benchmark design and documentation that could
threaten the validity of benchmarks' measurements."
Enhancing Psychotherapy Counseling - A Data Augmentation Pipeline Leveraging Large Language Models for Counseling Conversations,https://arxiv.org/abs/2406.08718,2024-06-13,2024-06-19,0.0,0.0,"We introduce a pipeline that leverages Large Language Models (LLMs) to
transform single-turn psychotherapy counseling sessions into multi-turn
interactions. While AI-supported online counseling services for individuals
with mental disorders exist, they are often constrained by the limited
availability of multi-turn training datasets and frequently fail to fully
utilize therapists' expertise. Our proposed pipeline effectively addresses
these limitations. The pipeline comprises two main steps: 1) Information
Extraction and 2) Multi-turn Counseling Generation. Each step is meticulously
designed to extract and generate comprehensive multi-turn counseling
conversations from the available datasets. Experimental results from both
zero-shot and few-shot generation scenarios demonstrate that our approach
significantly enhances the ability of LLMs to produce higher quality multi-turn
dialogues in the context of mental health counseling. Our pipeline and dataset
are publicly available
https://github.com/jwkim-chat/A-Data-Augmentation-Pipeline-Leveraging-Large-Language-Models-for-Counseling-Conversations."
Batch-Instructed Gradient for Prompt Evolution -Systematic Prompt Optimization for Enhanced Text-to-Image Synthesis,https://arxiv.org/abs/2406.08713,2024-06-13,2024-06-19,0.0,0.0,"Text-to-image models have shown remarkable progress in generating
high-quality images from user-provided prompts. Despite this, the quality of
these images varies due to the models' sensitivity to human language nuances.
With advancements in large language models, there are new opportunities to
enhance prompt design for image generation tasks. Existing research primarily
focuses on optimizing prompts for direct interaction, while less attention is
given to scenarios involving intermediary agents, like the Stable Diffusion
model. This study proposes a Multi-Agent framework to optimize input prompts
for text-to-image generation models. Central to this framework is a prompt
generation mechanism that refines initial queries using dynamic instructions,
which evolve through iterative performance feedback. High-quality prompts are
then fed into a state-of-the-art text-to-image model. A professional prompts
database serves as a benchmark to guide the instruction modifier towards
generating high-caliber prompts. A scoring system evaluates the generated
images, and an LLM generates new instructions based on calculated gradients.
This iterative process is managed by the Upper Confidence Bound (UCB) algorithm
and assessed using the Human Preference Score version 2 (HPS v2). Preliminary
ablation studies highlight the effectiveness of various system components and
suggest areas for future improvements."
Introducing Diminutive Causal Structure into Graph Representation Learning,https://arxiv.org/abs/2406.08709,2024-06-13,2024-06-19,0.0,0.0,"When engaging in end-to-end graph representation learning with Graph Neural
Networks (GNNs), the intricate causal relationships and rules inherent in graph
data pose a formidable challenge for the model in accurately capturing
authentic data relationships. A proposed mitigating strategy involves the
direct integration of rules or relationships corresponding to the graph data
into the model. However, within the domain of graph representation learning,
the inherent complexity of graph data obstructs the derivation of a
comprehensive causal structure that encapsulates universal rules or
relationships governing the entire dataset. Instead, only specialized
diminutive causal structures, delineating specific causal relationships within
constrained subsets of graph data, emerge as discernible. Motivated by
empirical insights, it is observed that GNN models exhibit a tendency to
converge towards such specialized causal structures during the training
process. Consequently, we posit that the introduction of these specific causal
structures is advantageous for the training of GNN models. Building upon this
proposition, we introduce a novel method that enables GNN models to glean
insights from these specialized diminutive causal structures, thereby enhancing
overall performance. Our method specifically extracts causal knowledge from the
model representation of these diminutive causal structures and incorporates
interchange intervention to optimize the learning process. Theoretical analysis
serves to corroborate the efficacy of our proposed method. Furthermore,
empirical experiments consistently demonstrate significant performance
improvements across diverse datasets."
mOSCAR - A Large-scale Multilingual and Multimodal Document-level Corpus,https://arxiv.org/abs/2406.08707,2024-06-13,2024-06-19,0.0,0.0,"Multimodal Large Language Models (mLLMs) are trained on a large amount of
text-image data. While most mLLMs are trained on caption-like data only,
Alayrac et al. [2022] showed that additionally training them on interleaved
sequences of text and images can lead to the emergence of in-context learning
capabilities. However, the dataset they used, M3W, is not public and is only in
English. There have been attempts to reproduce their results but the released
datasets are English-only. In contrast, current multilingual and multimodal
datasets are either composed of caption-like only or medium-scale or fully
private data. This limits mLLM research for the 7,000 other languages spoken in
the world. We therefore introduce mOSCAR, to the best of our knowledge the
first large-scale multilingual and multimodal document corpus crawled from the
web. It covers 163 languages, 315M documents, 214B tokens and 1.2B images. We
carefully conduct a set of filtering and evaluation steps to make sure mOSCAR
is sufficiently safe, diverse and of good quality. We additionally train two
types of multilingual model to prove the benefits of mOSCAR: (1) a model
trained on a subset of mOSCAR and captioning data and (2) a model train on
captioning data only. The model additionally trained on mOSCAR shows a strong
boost in few-shot learning performance across various multilingual image-text
tasks and benchmarks, confirming previous findings for English-only mLLMs."
VLind-Bench - Measuring Language Priors in Large Vision-Language Models,https://arxiv.org/abs/2406.08702,2024-06-13,2024-06-19,0.0,0.0,"Large Vision-Language Models (LVLMs) have demonstrated outstanding
performance across various multimodal tasks. However, they suffer from a
problem known as language prior, where responses are generated based solely on
textual patterns while disregarding image information. Addressing the issue of
language prior is crucial, as it can lead to undesirable biases or
hallucinations when dealing with images that are out of training distribution.
Despite its importance, current methods for accurately measuring language
priors in LVLMs are poorly studied. Although existing benchmarks based on
counterfactual or out-of-distribution images can partially be used to measure
language priors, they fail to disentangle language priors from other
confounding factors. To this end, we propose a new benchmark called
VLind-Bench, which is the first benchmark specifically designed to measure the
language priors, or blindness, of LVLMs. It not only includes tests on
counterfactual images to assess language priors but also involves a series of
tests to evaluate more basic capabilities such as commonsense knowledge, visual
perception, and commonsense biases. For each instance in our benchmark, we
ensure that all these basic tests are passed before evaluating the language
priors, thereby minimizing the influence of other factors on the assessment.
The evaluation and analysis of recent LVLMs in our benchmark reveal that almost
all models exhibit a significant reliance on language priors, presenting a
strong challenge in the field."
Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B,https://arxiv.org/abs/2406.07394,2024-06-11,2024-06-19,1.0,1.0,"This paper introduces the MCT Self-Refine (MCTSr) algorithm, an innovative
integration of Large Language Models (LLMs) with Monte Carlo Tree Search
(MCTS), designed to enhance performance in complex mathematical reasoning
tasks. Addressing the challenges of accuracy and reliability in LLMs,
particularly in strategic and mathematical reasoning, MCTSr leverages
systematic exploration and heuristic self-refine mechanisms to improve
decision-making frameworks within LLMs. The algorithm constructs a Monte Carlo
search tree through iterative processes of Selection, self-refine,
self-evaluation, and Backpropagation, utilizing an improved Upper Confidence
Bound (UCB) formula to optimize the exploration-exploitation balance. Extensive
experiments demonstrate MCTSr's efficacy in solving Olympiad-level mathematical
problems, significantly improving success rates across multiple datasets,
including GSM8K, GSM Hard, MATH, and Olympiad-level benchmarks, including Math
Odyssey, AIME, and OlympiadBench. The study advances the application of LLMs in
complex reasoning tasks and sets a foundation for future AI integration,
enhancing decision-making accuracy and reliability in LLM-driven applications."
Beyond Scaling Laws - Understanding Transformer Performance with Associative Memory,https://arxiv.org/abs/2405.08707,2024-05-14,2024-06-20,1.0,0.0,"Increasing the size of a Transformer model does not always lead to enhanced
performance. This phenomenon cannot be explained by the empirical scaling laws.
Furthermore, improved generalization ability occurs as the model memorizes the
training samples. We present a theoretical framework that sheds light on the
memorization process and performance dynamics of transformer-based language
models. We model the behavior of Transformers with associative memories using
Hopfield networks, such that each transformer block effectively conducts an
approximate nearest-neighbor search. Based on this, we design an energy
function analogous to that in the modern continuous Hopfield network which
provides an insightful explanation for the attention mechanism. Using the
majorization-minimization technique, we construct a global energy function that
captures the layered architecture of the Transformer. Under specific
conditions, we show that the minimum achievable cross-entropy loss is bounded
from below by a constant approximately equal to 1. We substantiate our
theoretical results by conducting experiments with GPT-2 on various data sizes,
as well as training vanilla Transformers on a dataset of 2M tokens."
Mixture-of-Agents Enhances Large Language Model Capabilities,https://arxiv.org/abs/2406.04692,2024-06-07,2024-06-20,1.0,1.0,"Recent advances in large language models (LLMs) demonstrate substantial
capabilities in natural language understanding and generation tasks. With the
growing number of LLMs, how to harness the collective expertise of multiple
LLMs is an exciting open direction. Toward this goal, we propose a new approach
that leverages the collective strengths of multiple LLMs through a
Mixture-of-Agents (MoA) methodology. In our approach, we construct a layered
MoA architecture wherein each layer comprises multiple LLM agents. Each agent
takes all the outputs from agents in the previous layer as auxiliary
information in generating its response. MoA models achieves state-of-art
performance on AlpacaEval 2.0, MT-Bench and FLASK, surpassing GPT-4 Omni. For
example, our MoA using only open-source LLMs is the leader of AlpacaEval 2.0 by
a substantial gap, achieving a score of 65.1% compared to 57.5% by GPT-4 Omni."
Model Merging and Safety Alignment - One Bad Model Spoils the Bunch,https://arxiv.org/abs/2406.14563,2024-06-20,2024-06-21,0.0,0.0,"Merging Large Language Models (LLMs) is a cost-effective technique for
combining multiple expert LLMs into a single versatile model, retaining the
expertise of the original ones. However, current approaches often overlook the
importance of safety alignment during merging, leading to highly misaligned
models. This work investigates the effects of model merging on alignment. We
evaluate several popular model merging techniques, demonstrating that existing
methods do not only transfer domain expertise but also propagate misalignment.
We propose a simple two-step approach to address this problem: (i) generating
synthetic safety and domain-specific data, and (ii) incorporating these
generated data into the optimization process of existing data-aware model
merging techniques. This allows us to treat alignment as a skill that can be
maximized in the resulting merged LLM. Our experiments illustrate the
effectiveness of integrating alignment-related data during merging, resulting
in models that excel in both domain expertise and alignment."
Whiteboard-of-Thought - Thinking Step-by-Step Across Modalities,https://arxiv.org/abs/2406.14562,2024-06-20,2024-06-21,1.0,0.0,"When presented with questions involving visual thinking, humans naturally
switch reasoning modalities, often forming mental images or drawing visual
aids. Large language models have shown promising results in arithmetic and
symbolic reasoning by expressing intermediate reasoning in text as a chain of
thought, yet struggle to extend this capability to answer text queries that are
easily solved by visual reasoning, even with extensive multimodal pretraining.
We introduce a simple method, whiteboard-of-thought prompting, to unlock the
visual reasoning capabilities of multimodal large language models across
modalities. Whiteboard-of-thought prompting provides multimodal large language
models with a metaphorical `whiteboard' to draw out reasoning steps as images,
then returns these images back to the model for further processing. We find
this can be accomplished with no demonstrations or specialized modules, instead
leveraging models' existing ability to write code with libraries such as
Matplotlib and Turtle. This simple approach shows state-of-the-art results on
four difficult natural language tasks that involve visual and spatial
reasoning. We identify multiple settings where GPT-4o using chain-of-thought
fails dramatically, including more than one where it achieves $0\%$ accuracy,
while whiteboard-of-thought enables up to $92\%$ accuracy in these same
settings. We present a detailed exploration of where the technique succeeds as
well as its sources of error."
How to Compute the Probability of a Word,https://arxiv.org/abs/2406.14561,2024-06-20,2024-06-21,0.0,0.0,"Language models (LMs) estimate the probability distribution over sequences of
natural language; these distributions are crucial for computing perplexity and
surprisal in linguistics research. While we are usually concerned with
measuring these values for words, most LMs operate over subwords. Despite
seemingly straightforward, accurately computing probabilities over one unit
given probabilities over the other requires care. Indeed, we show here that
many recent linguistic studies have been incorrectly computing these values.
This paper derives the correct methods for computing word probabilities,
highlighting issues when relying on language models that use beginning-of-word
(bow)-marking tokenisers, e.g., the GPT family. Empirically, we show that
correcting the widespread bug in probability computations affects measured
outcomes in sentence comprehension and lexical optimisation analyses."
CooHOI - Learning Cooperative Human-Object Interaction with Manipulated Object Dynamics,https://arxiv.org/abs/2406.14558,2024-06-20,2024-06-21,0.0,0.0,"Recent years have seen significant advancements in humanoid control, largely
due to the availability of large-scale motion capture data and the application
of reinforcement learning methodologies. However, many real-world tasks, such
as moving large and heavy furniture, require multi-character collaboration.
Given the scarcity of data on multi-character collaboration and the efficiency
challenges associated with multi-agent learning, these tasks cannot be
straightforwardly addressed using training paradigms designed for single-agent
scenarios. In this paper, we introduce Cooperative Human-Object Interaction
(CooHOI), a novel framework that addresses multi-character objects transporting
through a two-phase learning paradigm: individual skill acquisition and
subsequent transfer. Initially, a single agent learns to perform tasks using
the Adversarial Motion Priors (AMP) framework. Following this, the agent learns
to collaborate with others by considering the shared dynamics of the
manipulated object during parallel training using Multi Agent Proximal Policy
Optimization (MAPPO). When one agent interacts with the object, resulting in
specific object dynamics changes, the other agents learn to respond
appropriately, thereby achieving implicit communication and coordination
between teammates. Unlike previous approaches that relied on tracking-based
methods for multi-character HOI, CooHOI is inherently efficient, does not
depend on motion capture data of multi-character interactions, and can be
seamlessly extended to include more participants and a wide range of object
types"
xCOMET-lite - Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics,https://arxiv.org/abs/2406.14553,2024-06-20,2024-06-21,0.0,0.0,"State-of-the-art trainable machine translation evaluation metrics like xCOMET
achieve high correlation with human judgment but rely on large encoders (up to
10.7B parameters), making them computationally expensive and inaccessible to
researchers with limited resources. To address this issue, we investigate
whether the knowledge stored in these large encoders can be compressed while
maintaining quality. We employ distillation, quantization, and pruning
techniques to create efficient xCOMET alternatives and introduce a novel data
collection pipeline for efficient black-box distillation. Our experiments show
that, using quantization, xCOMET can be compressed up to three times with no
quality degradation. Additionally, through distillation, we create an
xCOMET-lite metric, which has only 2.6% of xCOMET-XXL parameters, but retains
92.1% of its quality. Besides, it surpasses strong small-scale metrics like
COMET-22 and BLEURT-20 on the WMT22 metrics challenge dataset by 6.4%, despite
using 50% fewer parameters. All code, dataset, and models are available online."
GraphReader - Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models,https://arxiv.org/abs/2406.14550,2024-06-20,2024-06-21,0.0,0.0,"Long-context capabilities are essential for large language models (LLMs) to
tackle complex and long-input tasks. Despite numerous efforts made to optimize
LLMs for long contexts, challenges persist in robustly processing long inputs.
In this paper, we introduce GraphReader, a graph-based agent system designed to
handle long texts by structuring them into a graph and employing an agent to
explore this graph autonomously. Upon receiving a question, the agent first
undertakes a step-by-step analysis and devises a rational plan. It then invokes
a set of predefined functions to read node content and neighbors, facilitating
a coarse-to-fine exploration of the graph. Throughout the exploration, the
agent continuously records new insights and reflects on current circumstances
to optimize the process until it has gathered sufficient information to
generate an answer. Experimental results on the LV-Eval dataset reveal that
GraphReader, using a 4k context window, consistently outperforms GPT-4-128k
across context lengths from 16k to 256k by a large margin. Additionally, our
approach demonstrates superior performance on four challenging single-hop and
multi-hop benchmarks."
Uncovering Latent Memories - Assessing Data Leakage and Memorization Patterns in Large Language Models,https://arxiv.org/abs/2406.14549,2024-06-20,2024-06-21,0.0,0.0,"Frontier AI systems are making transformative impacts across society, but
such benefits are not without costs: models trained on web-scale datasets
containing personal and private data raise profound concerns about data privacy
and security. Language models are trained on extensive corpora including
potentially sensitive or proprietary information, and the risk of data leakage
- where the model response reveals pieces of such information - remains
inadequately understood. Prior work has investigated what factors drive
memorization and have identified that sequence complexity and the number of
repetitions drive memorization. Here, we focus on the evolution of memorization
over training. We begin by reproducing findings that the probability of
memorizing a sequence scales logarithmically with the number of times it is
present in the data. We next show that sequences which are apparently not
memorized after the first encounter can be ""uncovered"" throughout the course of
training even without subsequent encounters, a phenomenon we term ""latent
memorization"". The presence of latent memorization presents a challenge for
data privacy as memorized sequences may be hidden at the final checkpoint of
the model but remain easily recoverable. To this end, we develop a diagnostic
test relying on the cross entropy loss to uncover latent memorized sequences
with high accuracy."
Consistency Models Made Easy,https://arxiv.org/abs/2406.14548,2024-06-20,2024-06-21,0.0,0.0,"Consistency models (CMs) are an emerging class of generative models that
offer faster sampling than traditional diffusion models. CMs enforce that all
points along a sampling trajectory are mapped to the same initial point. But
this target leads to resource-intensive training: for example, as of 2024,
training a SoTA CM on CIFAR-10 takes one week on 8 GPUs. In this work, we
propose an alternative scheme for training CMs, vastly improving the efficiency
of building such models. Specifically, by expressing CM trajectories via a
particular differential equation, we argue that diffusion models can be viewed
as a special case of CMs with a specific discretization. We can thus fine-tune
a consistency model starting from a pre-trained diffusion model and
progressively approximate the full consistency condition to stronger degrees
over the training process. Our resulting method, which we term Easy Consistency
Tuning (ECT), achieves vastly improved training times while indeed improving
upon the quality of previous methods: for example, ECT achieves a 2-step FID of
2.73 on CIFAR10 within 1 hour on a single A100 GPU, matching Consistency
Distillation trained of hundreds of GPU hours. Owing to this computational
efficiency, we investigate the scaling law of CMs under ECT, showing that they
seem to obey classic power law scaling, hinting at their ability to improve
efficiency and performance at larger scales. Code
(https://github.com/locuslab/ect) is available."
Connecting the Dots - LLMs can Infer and Verbalize Latent Structure from Disparate Training Data,https://arxiv.org/abs/2406.14546,2024-06-20,2024-06-21,0.0,0.0,"One way to address safety risks from large language models (LLMs) is to
censor dangerous knowledge from their training data. While this removes the
explicit information, implicit information can remain scattered across various
training documents. Could an LLM infer the censored knowledge by piecing
together these implicit hints? As a step towards answering this question, we
study inductive out-of-context reasoning (OOCR), a type of generalization in
which LLMs infer latent information from evidence distributed across training
documents and apply it to downstream tasks without in-context learning. Using a
suite of five tasks, we demonstrate that frontier LLMs can perform inductive
OOCR. In one experiment we finetune an LLM on a corpus consisting only of
distances between an unknown city and other known cities. Remarkably, without
in-context examples or Chain of Thought, the LLM can verbalize that the unknown
city is Paris and use this fact to answer downstream questions. Further
experiments show that LLMs trained only on individual coin flip outcomes can
verbalize whether the coin is biased, and those trained only on pairs
$(x,f(x))$ can articulate a definition of $f$ and compute inverses. While OOCR
succeeds in a range of cases, we also show that it is unreliable, particularly
for smaller LLMs learning complex structures. Overall, the ability of LLMs to
""connect the dots"" without explicit in-context learning poses a potential
obstacle to monitoring and controlling the knowledge acquired by LLMs."
Unmasking Database Vulnerabilities - Zero-Knowledge Schema Inference Attacks in Text-to-SQL Systems,https://arxiv.org/abs/2406.14545,2024-06-20,2024-06-21,0.0,0.0,"Relational databases are integral to modern information systems, serving as
the foundation for storing, querying, and managing data efficiently and
effectively. Advancements in large language modeling have led to the emergence
of text-to-SQL technologies, significantly enhancing the querying and
extracting of information from these databases and raising concerns about
privacy and security. Our research extracts the database schema elements
underlying a text-to-SQL model. Knowledge of the schema can make attacks such
as SQL injection easier. By asking specially crafted questions, we have
developed a zero-knowledge framework designed to probe various database schema
elements without knowledge of the database itself. The text-to-SQL models then
process these questions to produce an output that we use to uncover the
structure of the database schema. We apply it to specialized text-to-SQL models
fine-tuned on text-SQL pairs and generative language models used for SQL
generation. Overall, we can reconstruct the table names with an F1 of nearly
.75 for fine-tuned models and .96 for generative."
Prism - A Framework for Decoupling and Assessing the Capabilities of VLMs,https://arxiv.org/abs/2406.14544,2024-06-20,2024-06-21,0.0,0.0,"Vision Language Models (VLMs) demonstrate remarkable proficiency in
addressing a wide array of visual questions, which requires strong perception
and reasoning faculties. Assessing these two competencies independently is
crucial for model refinement, despite the inherent difficulty due to the
intertwined nature of seeing and reasoning in existing VLMs. To tackle this
issue, we present Prism, an innovative framework designed to disentangle the
perception and reasoning processes involved in visual question solving. Prism
comprises two distinct stages: a perception stage that utilizes a VLM to
extract and articulate visual information in textual form, and a reasoning
stage that formulates responses based on the extracted visual information using
a Large Language Model (LLM). This modular design enables the systematic
comparison and assessment of both proprietary and open-source VLM for their
perception and reasoning strengths. Our analytical framework provides several
valuable insights, underscoring Prism's potential as a cost-effective solution
for vision-language tasks. By combining a streamlined VLM focused on perception
with a powerful LLM tailored for reasoning, Prism achieves superior results in
general vision-language tasks while substantially cutting down on training and
operational expenses. Quantitative evaluations show that Prism, when configured
with a vanilla 2B LLaVA and freely accessible GPT-3.5, delivers performance on
par with VLMs $10 \times$ larger on the rigorous multimodal benchmark MMStar.
The project is released at: https://github.com/SparksJoe/Prism."
Are LLMs Naturally Good at Synthetic Tabular Data Generation?,https://arxiv.org/abs/2406.14541,2024-06-20,2024-06-21,0.0,0.0,"Large language models (LLMs) have demonstrated their prowess in generating
synthetic text and images; however, their potential for generating tabular data
-- arguably the most common data type in business and scientific applications
-- is largely underexplored. This paper demonstrates that LLMs, used as-is, or
after traditional fine-tuning, are severely inadequate as synthetic table
generators. Due to the autoregressive nature of LLMs, fine-tuning with random
order permutation runs counter to the importance of modeling functional
dependencies, and renders LLMs unable to model conditional mixtures of
distributions (key to capturing real world constraints). We showcase how LLMs
can be made to overcome some of these deficiencies by making them
permutation-aware."
IRASim - Learning Interactive Real-Robot Action Simulators,https://arxiv.org/abs/2406.14540,2024-06-20,2024-06-21,0.0,0.0,"Scalable robot learning in the real world is limited by the cost and safety
issues of real robots. In addition, rolling out robot trajectories in the real
world can be time-consuming and labor-intensive. In this paper, we propose to
learn an interactive real-robot action simulator as an alternative. We
introduce a novel method, IRASim, which leverages the power of generative
models to generate extremely realistic videos of a robot arm that executes a
given action trajectory, starting from an initial given frame. To validate the
effectiveness of our method, we create a new benchmark, IRASim Benchmark, based
on three real-robot datasets and perform extensive experiments on the
benchmark. Results show that IRASim outperforms all the baseline methods and is
more preferable in human evaluations. We hope that IRASim can serve as an
effective and scalable approach to enhance robot learning in the real world. To
promote research for generative real-robot action simulators, we open-source
code, benchmark, and checkpoints at https: //gen-irasim.github.io."
MacroHFT - Memory Augmented Context-aware Reinforcement Learning On High Frequency Trading,https://arxiv.org/abs/2406.14537,2024-06-20,2024-06-21,0.0,0.0,"High-frequency trading (HFT) that executes algorithmic trading in short time
scales, has recently occupied the majority of cryptocurrency market. Besides
traditional quantitative trading methods, reinforcement learning (RL) has
become another appealing approach for HFT due to its terrific ability of
handling high-dimensional financial data and solving sophisticated sequential
decision-making problems, \emph{e.g.,} hierarchical reinforcement learning
(HRL) has shown its promising performance on second-level HFT by training a
router to select only one sub-agent from the agent pool to execute the current
transaction. However, existing RL methods for HFT still have some defects: 1)
standard RL-based trading agents suffer from the overfitting issue, preventing
them from making effective policy adjustments based on financial context; 2)
due to the rapid changes in market conditions, investment decisions made by an
individual agent are usually one-sided and highly biased, which might lead to
significant loss in extreme markets. To tackle these problems, we propose a
novel Memory Augmented Context-aware Reinforcement learning method On HFT,
\emph{a.k.a.} MacroHFT, which consists of two training phases: 1) we first
train multiple types of sub-agents with the market data decomposed according to
various financial indicators, specifically market trend and volatility, where
each agent owns a conditional adapter to adjust its trading policy according to
market conditions; 2) then we train a hyper-agent to mix the decisions from
these sub-agents and output a consistently profitable meta-policy to handle
rapid market fluctuations, equipped with a memory mechanism to enhance the
capability of decision-making. Extensive experiments on various cryptocurrency
markets demonstrate that MacroHFT can achieve state-of-the-art performance on
minute-level trading tasks."
RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold,https://arxiv.org/abs/2406.14532,2024-06-20,2024-06-21,0.0,0.0,"Training on model-generated synthetic data is a promising approach for
finetuning LLMs, but it remains unclear when it helps or hurts. In this paper,
we investigate this question for math reasoning via an empirical study,
followed by building a conceptual understanding of our observations. First, we
find that while the typical approach of finetuning a model on synthetic correct
or positive problem-solution pairs generated by capable models offers modest
performance gains, sampling more correct solutions from the finetuned learner
itself followed by subsequent fine-tuning on this self-generated data
$\textbf{doubles}$ the efficiency of the same synthetic problems. At the same
time, training on model-generated positives can amplify various spurious
correlations, resulting in flat or even inverse scaling trends as the amount of
data increases. Surprisingly, we find that several of these issues can be
addressed if we also utilize negative responses, i.e., model-generated
responses that are deemed incorrect by a final answer verifier. Crucially,
these negatives must be constructed such that the training can appropriately
recover the utility or advantage of each intermediate step in the negative
response. With this per-step scheme, we are able to attain consistent gains
over only positive data, attaining performance similar to amplifying the amount
of synthetic data by $\mathbf{8 \times}$. We show that training on per-step
negatives can help to unlearn spurious correlations in the positive data, and
is equivalent to advantage-weighted reinforcement learning (RL), implying that
it inherits robustness benefits of RL over imitating positive data alone."
A Benchmarking Study of Kolmogorov-Arnold Networks on Tabular Data,https://arxiv.org/abs/2406.14529,2024-06-20,2024-06-21,0.0,0.0,"Kolmogorov-Arnold Networks (KANs) have very recently been introduced into the
world of machine learning, quickly capturing the attention of the entire
community. However, KANs have mostly been tested for approximating complex
functions or processing synthetic data, while a test on real-world tabular
datasets is currently lacking. In this paper, we present a benchmarking study
comparing KANs and Multi-Layer Perceptrons (MLPs) on tabular datasets. The
study evaluates task performance and training times. From the results obtained
on the various datasets, KANs demonstrate superior or comparable accuracy and
F1 scores, excelling particularly in datasets with numerous instances,
suggesting robust handling of complex data. We also highlight that this
performance improvement of KANs comes with a higher computational cost when
compared to MLPs of comparable sizes."
DeciMamba - Exploring the Length Extrapolation Potential of Mamba,https://arxiv.org/abs/2406.14528,2024-06-20,2024-06-21,0.0,0.0,"Long-range sequence processing poses a significant challenge for Transformers
due to their quadratic complexity in input length. A promising alternative is
Mamba, which demonstrates high performance and achieves Transformer-level
capabilities while requiring substantially fewer computational resources. In
this paper we explore the length-generalization capabilities of Mamba, which we
find to be relatively limited. Through a series of visualizations and analyses
we identify that the limitations arise from a restricted effective receptive
field, dictated by the sequence length used during training. To address this
constraint, we introduce DeciMamba, a context-extension method specifically
designed for Mamba. This mechanism, built on top of a hidden filtering
mechanism embedded within the S6 layer, enables the trained model to
extrapolate well even without additional training. Empirical experiments over
real-world long-range NLP tasks show that DeciMamba can extrapolate to context
lengths that are 25x times longer than the ones seen during training, and does
so without utilizing additional computational resources. We will release our
code and models."
Towards evolution of Deep Neural Networks through contrastive Self-Supervised learning,https://arxiv.org/abs/2406.14525,2024-06-20,2024-06-21,0.0,0.0,"Deep Neural Networks (DNNs) have been successfully applied to a wide range of
problems. However, two main limitations are commonly pointed out. The first one
is that they require long time to design. The other is that they heavily rely
on labelled data, which can sometimes be costly and hard to obtain. In order to
address the first problem, neuroevolution has been proved to be a plausible
option to automate the design of DNNs. As for the second problem,
self-supervised learning has been used to leverage unlabelled data to learn
representations. Our goal is to study how neuroevolution can help
self-supervised learning to bridge the gap to supervised learning in terms of
performance. In this work, we propose a framework that is able to evolve deep
neural networks using self-supervised learning. Our results on the CIFAR-10
dataset show that it is possible to evolve adequate neural networks while
reducing the reliance on labelled data. Moreover, an analysis to the structure
of the evolved networks suggests that the amount of labelled data fed to them
has less effect on the structure of networks that learned via self-supervised
learning, when compared to individuals that relied on supervised learning."
Fantastic Copyrighted Beasts and How (Not) to Generate Them,https://arxiv.org/abs/2406.14526,2024-06-20,2024-06-21,0.0,0.0,"Recent studies show that image and video generation models can be prompted to
reproduce copyrighted content from their training data, raising serious legal
concerns around copyright infringement. Copyrighted characters, in particular,
pose a difficult challenge for image generation services, with at least one
lawsuit already awarding damages based on the generation of these characters.
Yet, little research has empirically examined this issue. We conduct a
systematic evaluation to fill this gap. First, we build CopyCat, an evaluation
suite consisting of diverse copyrighted characters and a novel evaluation
pipeline. Our evaluation considers both the detection of similarity to
copyrighted characters and generated image's consistency with user input. Our
evaluation systematically shows that both image and video generation models can
still generate characters even if characters' names are not explicitly
mentioned in the prompt, sometimes with only two generic keywords (e.g.,
prompting with ""videogame, plumber"" consistently generates Nintendo's Mario
character). We then introduce techniques to semi-automatically identify such
keywords or descriptions that trigger character generation. Using our
evaluation suite, we study runtime mitigation strategies, including both
existing methods and new strategies we propose. Our findings reveal that
commonly employed strategies, such as prompt rewriting in the DALL-E system,
are not sufficient as standalone guardrails. These strategies must be coupled
with other approaches, like negative prompting, to effectively reduce the
unintended generation of copyrighted characters. Our work provides empirical
grounding to the discussion of copyright mitigation strategies and offers
actionable insights for model deployers actively implementing them."
PostMark - A Robust Blackbox Watermark for Large Language Models,https://arxiv.org/abs/2406.14517,2024-06-20,2024-06-21,0.0,0.0,"The most effective techniques to detect LLM-generated text rely on inserting
a detectable signature -- or watermark -- during the model's decoding process.
Most existing watermarking methods require access to the underlying LLM's
logits, which LLM API providers are loath to share due to fears of model
distillation. As such, these watermarks must be implemented independently by
each LLM provider. In this paper, we develop PostMark, a modular post-hoc
watermarking procedure in which an input-dependent set of words (determined via
a semantic embedding) is inserted into the text after the decoding process has
completed. Critically, PostMark does not require logit access, which means it
can be implemented by a third party. We also show that PostMark is more robust
to paraphrasing attacks than existing watermarking methods: our experiments
cover eight baseline algorithms, five base LLMs, and three datasets. Finally,
we evaluate the impact of PostMark on text quality using both automated and
human assessments, highlighting the trade-off between quality and robustness to
paraphrasing. We release our code, outputs, and annotations at
https://github.com/lilakk/PostMark."
Solving a Stackelberg Game on Transportation Networks in a Dynamic Crime Scenario - A Mixed Approach on Multi-Layer Networks,https://arxiv.org/abs/2406.14514,2024-06-20,2024-06-21,0.0,0.0,"Interdicting a criminal with limited police resources is a challenging task
as the criminal changes location over time. The size of the large
transportation network further adds to the difficulty of this scenario. To
tackle this issue, we consider the concept of a layered graph. At each time
stamp, we create a copy of the entire transportation network to track the
possible movements of both players, the attacker and the defenders. We consider
a Stackelberg game in a dynamic crime scenario where the attacker changes
location over time while the defenders attempt to interdict the attacker on his
escape route. Given a set of defender strategies, the optimal attacker strategy
is determined by applying Dijkstra's algorithm on the layered networks. Here,
the attacker aims to minimize while the defenders aim to maximize the
probability of interdiction. We develop an approximation algorithm on the
layered networks to find near-optimal strategy for defenders. The efficacy of
the developed approach is compared with the adopted MILP approach. We compare
the results in terms of computational time and solution quality. The quality of
the results demonstrates the need for the developed approach, as it effectively
solves the complex problem within a short amount of time."
Investigating Mysteries of CoT-Augmented Distillation,https://arxiv.org/abs/2406.14511,2024-06-20,2024-06-21,0.0,0.0,"Eliciting ""chain of thought"" (CoT) rationales -- sequences of token that
convey a ""reasoning"" process -- has been shown to consistently improve LLM
performance on tasks like question answering. More recent efforts have shown
that such rationales can also be used for model distillation: Including CoT
sequences (elicited from a large ""teacher"" model) in addition to target labels
when fine-tuning a small student model yields (often substantial) improvements.
In this work we ask: Why and how does this additional training signal help in
model distillation? We perform ablations to interrogate this, and report some
potentially surprising results. Specifically: (1) Placing CoT sequences after
labels (rather than before) realizes consistently better downstream performance
-- this means that no student ""reasoning"" is necessary at test time to realize
gains. (2) When rationales are appended in this way, they need not be coherent
reasoning sequences to yield improvements; performance increases are robust to
permutations of CoT tokens, for example. In fact, (3) a small number of key
tokens are sufficient to achieve improvements equivalent to those observed when
full rationales are used in model distillation."
V-LASIK - Consistent Glasses-Removal from Videos Using Synthetic Data,https://arxiv.org/abs/2406.14510,2024-06-20,2024-06-21,0.0,0.0,"Diffusion-based generative models have recently shown remarkable image and
video editing capabilities. However, local video editing, particularly removal
of small attributes like glasses, remains a challenge. Existing methods either
alter the videos excessively, generate unrealistic artifacts, or fail to
perform the requested edit consistently throughout the video. In this work, we
focus on consistent and identity-preserving removal of glasses in videos, using
it as a case study for consistent local attribute removal in videos. Due to the
lack of paired data, we adopt a weakly supervised approach and generate
synthetic imperfect data, using an adjusted pretrained diffusion model. We show
that despite data imperfection, by learning from our generated data and
leveraging the prior of pretrained diffusion models, our model is able to
perform the desired edit consistently while preserving the original video
content. Furthermore, we exemplify the generalization ability of our method to
other local video editing tasks by applying it successfully to facial
sticker-removal. Our approach demonstrates significant improvement over
existing methods, showcasing the potential of leveraging synthetic data and
strong video priors for local video editing tasks."
Evidence of a log scaling law for political persuasion with large language models,https://arxiv.org/abs/2406.14508,2024-06-20,2024-06-21,0.0,0.0,"Large language models can now generate political messages as persuasive as
those written by humans, raising concerns about how far this persuasiveness may
continue to increase with model size. Here, we generate 720 persuasive messages
on 10 U.S. political issues from 24 language models spanning several orders of
magnitude in size. We then deploy these messages in a large-scale randomized
survey experiment (N = 25,982) to estimate the persuasive capability of each
model. Our findings are twofold. First, we find evidence of a log scaling law:
model persuasiveness is characterized by sharply diminishing returns, such that
current frontier models are barely more persuasive than models smaller in size
by an order of magnitude or more. Second, mere task completion (coherence,
staying on topic) appears to account for larger models' persuasive advantage.
These findings suggest that further scaling model size will not much increase
the persuasiveness of static LLM-generated messages."
On Newton's Method to Unlearn Neural Networks,https://arxiv.org/abs/2406.14507,2024-06-20,2024-06-21,0.0,0.0,"With the widespread applications of neural networks (NNs) trained on personal
data, machine unlearning has become increasingly important for enabling
individuals to exercise their personal data ownership, particularly the ""right
to be forgotten"" from trained NNs. Since retraining is computationally
expensive, we seek approximate unlearning algorithms for NNs that return
identical models to the retrained oracle. While Newton's method has been
successfully used to approximately unlearn linear models, we observe that
adapting it for NN is challenging due to degenerate Hessians that make
computing Newton's update impossible. Additionally, we show that when coupled
with popular techniques to resolve the degeneracy, Newton's method often incurs
offensively large norm updates and empirically degrades model performance
post-unlearning. To address these challenges, we propose CureNewton's method, a
principle approach that leverages cubic regularization to handle the Hessian
degeneracy effectively. The added regularizer eliminates the need for manual
finetuning and affords a natural interpretation within the unlearning context.
Experiments across different models and datasets show that our method can
achieve competitive unlearning performance to the state-of-the-art algorithm in
practical unlearning settings, while being theoretically justified and
efficient in running time."
Overview of the CAIL 2023 Argument Mining Track,https://arxiv.org/abs/2406.14503,2024-06-20,2024-06-21,0.0,0.0,"We give a detailed overview of the CAIL 2023 Argument Mining Track, one of
the Chinese AI and Law Challenge (CAIL) 2023 tracks. The main goal of the track
is to identify and extract interacting argument pairs in trial dialogs. It
mainly uses summarized judgment documents but can also refer to trial
recordings. The track consists of two stages, and we introduce the tasks
designed for each stage; we also extend the data from previous events into a
new dataset -- CAIL2023-ArgMine -- with annotated new cases from various causes
of action. We outline several submissions that achieve the best results,
including their methods for different stages. While all submissions rely on
language models, they have incorporated strategies that may benefit future work
in this field."
Improving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary,https://arxiv.org/abs/2406.14500,2024-06-20,2024-06-21,0.0,0.0,"Radiology report summarization (RRS) is crucial for patient care, requiring
concise ""Impressions"" from detailed ""Findings."" This paper introduces a novel
prompting strategy to enhance RRS by first generating a layperson summary. This
approach normalizes key observations and simplifies complex information using
non-expert communication techniques inspired by doctor-patient interactions.
Combined with few-shot in-context learning, this method improves the model's
ability to link general terms to specific findings. We evaluate this approach
on the MIMIC-CXR, CheXpert, and MIMIC-III datasets, benchmarking it against
7B/8B parameter state-of-the-art open-source large language models (LLMs) like
Meta-Llama-3-8B-Instruct. Our results demonstrate improvements in summarization
accuracy and accessibility, particularly in out-of-domain tests, with
improvements as high as 5% for some metrics."
LLaSA - Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors,https://arxiv.org/abs/2406.14498,2024-06-20,2024-06-21,0.0,0.0,"Integrating inertial measurement units (IMUs) with large language models
(LLMs) advances multimodal AI by enhancing human activity understanding. We
introduce SensorCaps, a dataset of 26,288 IMU-derived activity narrations, and
OpenSQA, an instruction-following dataset with 257,562 question-answer pairs.
Combining LIMU-BERT and Llama, we develop LLaSA, a Large Multimodal Agent
capable of interpreting and responding to activity and motion analysis queries.
Our evaluation demonstrates LLaSA's effectiveness in activity classification
and question answering, highlighting its potential in healthcare, sports
science, and human-computer interaction. These contributions advance
sensor-aware language models and open new research avenues. Our code repository
and datasets can be found on https://github.com/BASHLab/LLaSA."
CodeRAG-Bench - Can Retrieval Augment Code Generation?,https://arxiv.org/abs/2406.14497,2024-06-20,2024-06-21,0.0,0.0,"While language models (LMs) have proven remarkably adept at generating code,
many programs are challenging for LMs to generate using their parametric
knowledge alone. Providing external contexts such as library documentation can
facilitate generating accurate and functional code. Despite the success of
retrieval-augmented generation (RAG) in various text-oriented tasks, its
potential for improving code generation remains under-explored. In this work,
we conduct a systematic, large-scale analysis by asking: in what scenarios can
retrieval benefit code generation models? and what challenges remain? We first
curate a comprehensive evaluation benchmark, CodeRAG-Bench, encompassing three
categories of code generation tasks, including basic programming, open-domain,
and repository-level problems. We aggregate documents from five sources for
models to retrieve contexts: competition solutions, online tutorials, library
documentation, StackOverflow posts, and GitHub repositories. We examine
top-performing models on CodeRAG-Bench by providing contexts retrieved from one
or multiple sources. While notable gains are made in final code generation by
retrieving high-quality contexts across various settings, our analysis reveals
room for improvement -- current retrievers still struggle to fetch useful
contexts especially with limited lexical overlap, and generators fail to
improve with limited context lengths or abilities to integrate additional
contexts. We hope CodeRAG-Bench serves as an effective testbed to encourage
further development of advanced code-oriented RAG methods."
African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification,https://arxiv.org/abs/2406.14496,2024-06-20,2024-06-21,0.0,0.0,"Recent Large Vision-Language Models (LVLMs) demonstrate impressive abilities
on numerous image understanding and reasoning tasks. The task of fine-grained
object classification (e.g., distinction between \textit{animal species}),
however, has been probed insufficiently, despite its downstream importance. We
fill this evaluation gap by creating \texttt{FOCI} (\textbf{F}ine-grained
\textbf{O}bject \textbf{C}lass\textbf{I}fication), a difficult multiple-choice
benchmark for fine-grained object classification, from existing object
classification datasets: (1) multiple-choice avoids ambiguous answers
associated with casting classification as open-ended QA task; (2) we retain
classification difficulty by mining negative labels with a CLIP model.
\texttt{FOCI}\xspace complements five popular classification datasets with four
domain-specific subsets from ImageNet-21k. We benchmark 12 public LVLMs on
\texttt{FOCI} and show that it tests for a \textit{complementary skill} to
established image understanding and reasoning benchmarks. Crucially, CLIP
models exhibit dramatically better performance than LVLMs. Since the image
encoders of LVLMs come from these CLIP models, this points to inadequate
alignment for fine-grained object distinction between the encoder and the LLM
and warrants (pre)training data with more fine-grained annotation. We release
our code at \url{https://github.com/gregor-ge/FOCI-Benchmark}."
rKAN - Rational Kolmogorov-Arnold Networks,https://arxiv.org/abs/2406.14495,2024-06-20,2024-06-21,0.0,0.0,"The development of Kolmogorov-Arnold networks (KANs) marks a significant
shift from traditional multi-layer perceptrons in deep learning. Initially,
KANs employed B-spline curves as their primary basis function, but their
inherent complexity posed implementation challenges. Consequently, researchers
have explored alternative basis functions such as Wavelets, Polynomials, and
Fractional functions. In this research, we explore the use of rational
functions as a novel basis function for KANs. We propose two different
approaches based on Pade approximation and rational Jacobi functions as
trainable basis functions, establishing the rational KAN (rKAN). We then
evaluate rKAN's performance in various deep learning and physics-informed tasks
to demonstrate its practicality and effectiveness in function approximation."
Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?,https://arxiv.org/abs/2406.14492,2024-06-20,2024-06-21,0.0,0.0,"Large vision-language models (LVLMs) have recently dramatically pushed the
state of the art in image captioning and many image understanding tasks (e.g.,
visual question answering). LVLMs, however, often \textit{hallucinate} and
produce captions that mention concepts that cannot be found in the image. These
hallucinations erode the trustworthiness of LVLMs and are arguably among the
main obstacles to their ubiquitous adoption. Recent work suggests that addition
of grounding objectives -- those that explicitly align image regions or objects
to text spans -- reduces the amount of LVLM hallucination. Although intuitive,
this claim is not empirically justified as the reduction effects have been
established, we argue, with flawed evaluation protocols that (i) rely on data
(i.e., MSCOCO) that has been extensively used in LVLM training and (ii) measure
hallucination via question answering rather than open-ended caption generation.
In this work, in contrast, we offer the first systematic analysis of the effect
of fine-grained object grounding on LVLM hallucination under an evaluation
protocol that more realistically captures LVLM hallucination in open
generation. Our extensive experiments over three backbone LLMs reveal that
grounding objectives have little to no effect on object hallucination in open
caption generation."
Instruction Pre-Training - Language Models are Supervised Multitask Learners,https://arxiv.org/abs/2406.14491,2024-06-20,2024-06-21,0.0,0.0,"Unsupervised multitask pre-training has been the critical method behind the
recent success of language models (LMs). However, supervised multitask learning
still holds significant promise, as scaling it in the post-training stage
trends towards better generalization. In this paper, we explore supervised
multitask pre-training by proposing Instruction Pre-Training, a framework that
scalably augments massive raw corpora with instruction-response pairs to
pre-train LMs. The instruction-response pairs are generated by an efficient
instruction synthesizer built on open-source models. In our experiments, we
synthesize 200M instruction-response pairs covering 40+ task categories to
verify the effectiveness of Instruction Pre-Training. In pre-training from
scratch, Instruction Pre-Training not only consistently enhances pre-trained
base models but also benefits more from further instruction tuning. In
continual pre-training, Instruction Pre-Training enables Llama3-8B to be
comparable to or even outperform Llama3-70B. Our model, code, and data are
available at https://github.com/microsoft/LMOps."
Proceedings of The second international workshop on eXplainable AI for the Arts (XAIxArts),https://arxiv.org/abs/2406.14485,2024-06-20,2024-06-21,0.0,0.0,"This second international workshop on explainable AI for the Arts (XAIxArts)
brought together a community of researchers in HCI, Interaction Design, AI,
explainable AI (XAI), and digital arts to explore the role of XAI for the Arts.
Workshop held at the 16th ACM Conference on Creativity and Cognition (C&C
2024), Chicago, USA."
Valid Error Bars for Neural Weather Models using Conformal Prediction,https://arxiv.org/abs/2406.14483,2024-06-20,2024-06-21,0.0,0.0,"Neural weather models have shown immense potential as inexpensive and
accurate alternatives to physics-based models. However, most models trained to
perform weather forecasting do not quantify the uncertainty associated with
their forecasts. This limits the trust in the model and the usefulness of the
forecasts. In this work we construct and formalise a conformal prediction
framework as a post-processing method for estimating this uncertainty. The
method is model-agnostic and gives calibrated error bounds for all variables,
lead times and spatial locations. No modifications are required to the model
and the computational cost is negligible compared to model training. We
demonstrate the usefulness of the conformal prediction framework on a limited
area neural weather model for the Nordic region. We further explore the
advantages of the framework for deterministic and probabilistic models."
Revealing Vision-Language Integration in the Brain with Multimodal Networks,https://arxiv.org/abs/2406.14481,2024-06-20,2024-06-21,0.0,0.0,"We use (multi)modal deep neural networks (DNNs) to probe for sites of
multimodal integration in the human brain by predicting stereoencephalography
(SEEG) recordings taken while human subjects watched movies. We operationalize
sites of multimodal integration as regions where a multimodal vision-language
model predicts recordings better than unimodal language, unimodal vision, or
linearly-integrated language-vision models. Our target DNN models span
different architectures (e.g., convolutional networks and transformers) and
multimodal training techniques (e.g., cross-attention and contrastive
learning). As a key enabling step, we first demonstrate that trained vision and
language models systematically outperform their randomly initialized
counterparts in their ability to predict SEEG signals. We then compare unimodal
and multimodal models against one another. Because our target DNN models often
have different architectures, number of parameters, and training sets (possibly
obscuring those differences attributable to integration), we carry out a
controlled comparison of two models (SLIP and SimCLR), which keep all of these
attributes the same aside from input modality. Using this approach, we identify
a sizable number of neural sites (on average 141 out of 1090 total sites or
12.94%) and brain regions where multimodal integration seems to occur.
Additionally, we find that among the variants of multimodal training techniques
we assess, CLIP-style training is the best suited for downstream prediction of
the neural activity in these sites."
On Layer-wise Representation Similarity - Application for Multi-Exit Models with a Single Classifier,https://arxiv.org/abs/2406.14479,2024-06-20,2024-06-21,0.0,0.0,"Analyzing the similarity of internal representations within and across
different models has been an important technique for understanding the behavior
of deep neural networks. Most existing methods for analyzing the similarity
between representations of high dimensions, such as those based on Canonical
Correlation Analysis (CCA) and widely used Centered Kernel Alignment (CKA),
rely on statistical properties of the representations for a set of data points.
In this paper, we focus on transformer models and study the similarity of
representations between the hidden layers of individual transformers. In this
context, we show that a simple sample-wise cosine similarity metric is capable
of capturing the similarity and aligns with the complicated CKA. Our
experimental results on common transformers reveal that representations across
layers are positively correlated, albeit the similarity decreases when layers
are far apart. We then propose an aligned training approach to enhance the
similarity between internal representations, with trained models that enjoy the
following properties: (1) the last-layer classifier can be directly applied
right after any hidden layers, yielding intermediate layer accuracies much
higher than those under standard training, (2) the layer-wise accuracies
monotonically increase and reveal the minimal depth needed for the given task,
(3) when served as multi-exit models, they achieve on-par performance with
standard multi-exit architectures which consist of additional classifiers
designed for early exiting in shallow layers. To our knowledge, our work is the
first to show that one common classifier is sufficient for multi-exit models.
We conduct experiments on both vision and NLP tasks to demonstrate the
performance of the proposed aligned training."
Toward data-driven research - preliminary study to predict surface roughness in material extrusion using previously published data with Machine Learning,https://arxiv.org/abs/2406.14478,2024-06-20,2024-06-21,0.0,0.0,"Material extrusion is one of the most commonly used approaches within the
additive manufacturing processes available. Despite its popularity and related
technical advancements, process reliability and quality assurance remain only
partially solved. In particular, the surface roughness caused by this process
is a key concern. To solve this constraint, experimental plans have been
exploited to optimize surface roughness in recent years. However, the latter
empirical trial and error process is extremely time- and resource-consuming.
Thus, this study aims to avoid using large experimental programs to optimize
surface roughness in material extrusion.
  Methodology. This research provides an in-depth analysis of the effect of
several printing parameters: layer height, printing temperature, printing speed
and wall thickness. The proposed data-driven predictive modeling approach takes
advantage of Machine Learning models to automatically predict surface roughness
based on the data gathered from the literature and the experimental data
generated for testing.
  Findings. Using 10-fold cross-validation of data gathered from the
literature, the proposed Machine Learning solution attains a 0.93 correlation
with a mean absolute percentage error of 13 %. When testing with our own data,
the correlation diminishes to 0.79 and the mean absolute percentage error
reduces to 8 %. Thus, the solution for predicting surface roughness in
extrusion-based printing offers competitive results regarding the variability
of the analyzed factors.
  Originality. As available manufacturing data continue to increase on a daily
basis, the ability to learn from these large volumes of data is critical in
future manufacturing and science. Specifically, the power of Machine Learning
helps model surface roughness with limited experimental tests."
SafeSora - Towards Safety Alignment of Text2Video Generation via a Human Preference Dataset,https://arxiv.org/abs/2406.14477,2024-06-20,2024-06-21,0.0,0.0,"To mitigate the risk of harmful outputs from large vision models (LVMs), we
introduce the SafeSora dataset to promote research on aligning text-to-video
generation with human values. This dataset encompasses human preferences in
text-to-video generation tasks along two primary dimensions: helpfulness and
harmlessness. To capture in-depth human preferences and facilitate structured
reasoning by crowdworkers, we subdivide helpfulness into 4 sub-dimensions and
harmlessness into 12 sub-categories, serving as the basis for pilot
annotations. The SafeSora dataset includes 14,711 unique prompts, 57,333 unique
videos generated by 4 distinct LVMs, and 51,691 pairs of preference annotations
labeled by humans. We further demonstrate the utility of the SafeSora dataset
through several applications, including training the text-video moderation
model and aligning LVMs with human preference by fine-tuning a prompt
augmentation module or the diffusion model. These applications highlight its
potential as the foundation for text-to-video alignment research, such as human
preference modeling and the development and validation of alignment algorithms."
Learning telic-controllable state representations,https://arxiv.org/abs/2406.14476,2024-06-20,2024-06-21,0.0,0.0,"Computational descriptions of purposeful behavior comprise both descriptive
and normative} aspects. The former are used to ascertain current (or future)
states of the world and the latter to evaluate the desirability, or lack
thereof, of these states under some goal. In Reinforcement Learning, the
normative aspect (reward and value functions) is assumed to depend on a
predefined and fixed descriptive one (state representation). Alternatively,
these two aspects may emerge interdependently: goals can be, and indeed often
are, approximated by state-dependent reward functions, but they may also shape
the acquired state representations themselves. Here, we present a novel
computational framework for state representation learning in bounded agents,
where descriptive and normative aspects are coupled through the notion of
goal-directed, or telic, states. We introduce the concept of telic
controllability to characterize the tradeoff between the granularity of a telic
state representation and the policy complexity required to reach all telic
states. We propose an algorithm for learning controllable state
representations, illustrating it using a simple navigation task with shifting
goals. Our framework highlights the crucial role of deliberate ignorance --
knowing which features of experience to ignore -- for learning state
representations that balance goal flexibility and policy complexity. More
broadly, our work advances a unified theoretical perspective on goal-directed
state representation learning in natural and artificial agents."
Data-Centric AI in the Age of Large Language Models,https://arxiv.org/abs/2406.14473,2024-06-20,2024-06-21,0.0,0.0,"This position paper proposes a data-centric viewpoint of AI research,
focusing on large language models (LLMs). We start by making the key
observation that data is instrumental in the developmental (e.g., pretraining
and fine-tuning) and inferential stages (e.g., in-context learning) of LLMs,
and yet it receives disproportionally low attention from the research
community. We identify four specific scenarios centered around data, covering
data-centric benchmarks and data curation, data attribution, knowledge
transfer, and inference contextualization. In each scenario, we underscore the
importance of data, highlight promising research directions, and articulate the
potential impacts on the research community and, where applicable, the society
as a whole. For instance, we advocate for a suite of data-centric benchmarks
tailored to the scale and complexity of data for LLMs. These benchmarks can be
used to develop new data curation methods and document research efforts and
results, which can help promote openness and transparency in AI and LLM
research."
Fusion of Movement and Naive Predictions for Point Forecasting in Univariate Random Walks,https://arxiv.org/abs/2406.14469,2024-06-20,2024-06-21,0.0,0.0,"Point forecasting in univariate random walks is an important but challenging
research topic that has attracted numerous researchers. Unfortunately,
traditional regression methods for this task often fail to surpass naive
benchmarks due to data unpredictability. From a decision fusion perspective,
this study proposes a novel forecasting method, which is derived from a variant
definition of random walks, where the random error term for the future value is
expressed as a positive random error multiplied by a direction sign. This
method, based on the fusion of movement and naive predictions, does not require
a loss function for optimization and can be optimized by estimating movement
prediction accuracy on the validation set. This characteristic prevents the
fusion method from reverting to traditional regression methods and allows it to
integrate various machine learning and deep learning models for movement
prediction. The method's efficacy is demonstrated through simulations and
real-world data experiments. It reliably outperforms naive forecasts with
moderate movement prediction accuracies, such as 0.55, and is superior to
baseline models such as the ARIMA, linear regression, MLP, and LSTM networks in
forecasting the S&P 500 index and Bitcoin prices. This method is particularly
advantageous when accurate point predictions are challenging but accurate
movement predictions are attainable, translating movement predictions into
point forecasts in random walk contexts."
A Review of Common Online Speaker Diarization Methods,https://arxiv.org/abs/2406.14464,2024-06-20,2024-06-21,0.0,0.0,"Speaker diarization provides the answer to the question ""who spoke when?"" for
an audio file. This information can be used to complete audio transcripts for
further processing steps. Most speaker diarization systems assume that the
audio file is available as a whole. However, there are scenarios in which the
speaker labels are needed immediately after the arrival of an audio segment.
Speaker diarization with a correspondingly low latency is referred to as online
speaker diarization. This paper provides an overview. First the history of
online speaker diarization is briefly presented. Next a taxonomy and datasets
for training and evaluation are given. In the sections that follow, online
diarization methods and systems are discussed in detail. This paper concludes
with the presentation of challenges that still need to be solved by future
research in the field of online speaker diarization."
Explicit and Implicit Large Language Model Personas Generate Opinions but Fail to Replicate Deeper Perceptions and Biases,https://arxiv.org/abs/2406.14462,2024-06-20,2024-06-21,1.0,0.0,"Large language models (LLMs) are increasingly being used in human-centered
social scientific tasks, such as data annotation, synthetic data creation, and
engaging in dialog. However, these tasks are highly subjective and dependent on
human factors, such as one's environment, attitudes, beliefs, and lived
experiences. Thus, employing LLMs (which do not have such human factors) in
these tasks may result in a lack of variation in data, failing to reflect the
diversity of human experiences. In this paper, we examine the role of prompting
LLMs with human-like personas and asking the models to answer as if they were a
specific human. This is done explicitly, with exact demographics, political
beliefs, and lived experiences, or implicitly via names prevalent in specific
populations. The LLM personas are then evaluated via (1) subjective annotation
task (e.g., detecting toxicity) and (2) a belief generation task, where both
tasks are known to vary across human factors. We examine the impact of explicit
vs. implicit personas and investigate which human factors LLMs recognize and
respond to. Results show that LLM personas show mixed results when reproducing
known human biases, but generate generally fail to demonstrate implicit biases.
We conclude that LLMs lack the intrinsic cognitive mechanisms of human thought,
while capturing the statistical patterns of how people speak, which may
restrict their effectiveness in complex social science applications."
Healing Powers of BERT - How Task-Specific Fine-Tuning Recovers Corrupted Language Models,https://arxiv.org/abs/2406.14459,2024-06-20,2024-06-21,0.0,0.0,"Language models like BERT excel at sentence classification tasks due to
extensive pre-training on general data, but their robustness to parameter
corruption is unexplored. To understand this better, we look at what happens if
a language model is ""broken"", in the sense that some of its parameters are
corrupted and then recovered by fine-tuning. Strategically corrupting BERT
variants at different levels, we find corrupted models struggle to fully
recover their original performance, with higher corruption causing more severe
degradation. Notably, bottom-layer corruption affecting fundamental linguistic
features is more detrimental than top-layer corruption. Our insights contribute
to understanding language model robustness and adaptability under adverse
conditions, informing strategies for developing resilient NLP systems against
parameter perturbations."
Centimeter Positioning Accuracy using AI/ML for 6G Applications,https://arxiv.org/abs/2406.14458,2024-06-20,2024-06-21,0.0,0.0,"This research looks at using AI/ML to achieve centimeter-level user
positioning in 6G applications such as the Industrial Internet of Things
(IIoT). Initial results show that our AI/ML-based method can estimate user
positions with an accuracy of 17 cm in an indoor factory environment. In this
proposal, we highlight our approaches and future directions."
Rewarding What Matters - Step-by-Step Reinforcement Learning for Task-Oriented Dialogue,https://arxiv.org/abs/2406.14457,2024-06-20,2024-06-21,0.0,0.0,"Reinforcement learning (RL) is a powerful approach to enhance task-oriented
dialogue (TOD) systems. However, existing RL methods tend to mainly focus on
generation tasks, such as dialogue policy learning (DPL) or response generation
(RG), while neglecting dialogue state tracking (DST) for understanding. This
narrow focus limits the systems to achieve globally optimal performance by
overlooking the interdependence between understanding and generation.
Additionally, RL methods face challenges with sparse and delayed rewards, which
complicates training and optimization. To address these issues, we extend RL
into both understanding and generation tasks by introducing step-by-step
rewards throughout the token generation. The understanding reward increases as
more slots are correctly filled in DST, while the generation reward grows with
the accurate inclusion of user requests. Our approach provides a balanced
optimization aligned with task completion. Experimental results demonstrate
that our approach effectively enhances the performance of TOD systems and
achieves new state-of-the-art results on three widely used datasets, including
MultiWOZ2.0, MultiWOZ2.1, and In-Car. Our approach also shows superior few-shot
ability in low-resource settings compared to current models."
Capturing Temporal Components for Time Series Classification,https://arxiv.org/abs/2406.14456,2024-06-20,2024-06-21,0.0,0.0,"Analyzing sequential data is crucial in many domains, particularly due to the
abundance of data collected from the Internet of Things paradigm. Time series
classification, the task of categorizing sequential data, has gained
prominence, with machine learning approaches demonstrating remarkable
performance on public benchmark datasets. However, progress has primarily been
in designing architectures for learning representations from raw data at fixed
(or ideal) time scales, which can fail to generalize to longer sequences. This
work introduces a \textit{compositional representation learning} approach
trained on statistically coherent components extracted from sequential data.
Based on a multi-scale change space, an unsupervised approach is proposed to
segment the sequential data into chunks with similar statistical properties. A
sequence-based encoder model is trained in a multi-task setting to learn
compositional representations from these temporal components for time series
classification. We demonstrate its effectiveness through extensive experiments
on publicly available time series classification benchmarks. Evaluating the
coherence of segmented components shows its competitive performance on the
unsupervised segmentation task."
APEER - Automatic Prompt Engineering Enhances Large Language Model Reranking,https://arxiv.org/abs/2406.14449,2024-06-20,2024-06-21,0.0,0.0,"Large Language Models (LLMs) have significantly enhanced Information
Retrieval (IR) across various modules, such as reranking. Despite impressive
performance, current zero-shot relevance ranking with LLMs heavily relies on
human prompt engineering. Existing automatic prompt engineering algorithms
primarily focus on language modeling and classification tasks, leaving the
domain of IR, particularly reranking, underexplored. Directly applying current
prompt engineering algorithms to relevance ranking is challenging due to the
integration of query and long passage pairs in the input, where the ranking
complexity surpasses classification tasks. To reduce human effort and unlock
the potential of prompt optimization in reranking, we introduce a novel
automatic prompt engineering algorithm named APEER. APEER iteratively generates
refined prompts through feedback and preference optimization. Extensive
experiments with four LLMs and ten datasets demonstrate the substantial
performance improvement of APEER over existing state-of-the-art (SoTA) manual
prompts. Furthermore, we find that the prompts generated by APEER exhibit
better transferability across diverse tasks and LLMs. Code is available at
https://github.com/jincan333/APEER."
Maintenance Required - Updating and Extending Bootstrapped Human Activity Recognition Systems for Smart Homes,https://arxiv.org/abs/2406.14446,2024-06-20,2024-06-21,0.0,0.0,"Developing human activity recognition (HAR) systems for smart homes is not
straightforward due to varied layouts of the homes and their personalized
settings, as well as idiosyncratic behaviors of residents. As such,
off-the-shelf HAR systems are effective in limited capacity for an individual
home, and HAR systems often need to be derived ""from scratch"", which comes with
substantial efforts and often is burdensome to the resident. Previous work has
successfully targeted the initial phase. At the end of this initial phase, we
identify seed points. We build on bootstrapped HAR systems and introduce an
effective updating and extension procedure for continuous improvement of HAR
systems with the aim of keeping up with ever changing life circumstances. Our
method makes use of the seed points identified at the end of the initial
bootstrapping phase. A contrastive learning framework is trained using these
seed points and labels obtained for the same. This model is then used to
improve the segmentation accuracy of the identified prominent activities.
Improvements in the activity recognition system through this procedure help
model the majority of the routine activities in the smart home. We demonstrate
the effectiveness of our procedure through experiments on the CASAS datasets
that show the practical value of our approach."
Vahana.jl -- A framework (not only) for large-scale agent-based models,https://arxiv.org/abs/2406.14441,2024-06-20,2024-06-21,0.0,0.0,"Agent-based models (ABMs) offer a powerful framework for understanding
complex systems. However, their computational demands often become a
significant barrier as the number of agents and complexity of the simulation
increase. Traditional ABM platforms often struggle to fully exploit modern
computing resources, hindering the development of large-scale simulations. This
paper presents Vahana.jl, a high performance computing open source framework
that aims to address these limitations. Building on the formalism of
synchronous graph dynamical systems, Vahana.jl is especially well suited for
models with a focus on (social) networks. The framework seamlessly supports
distribution across multiple compute nodes, enabling simulations that would
otherwise be beyond the capabilities of a single machine. Implemented in Julia,
Vahana.jl leverages the interactive Read-Eval-Print Loop (REPL) environment,
facilitating rapid model development and experimentation."
Towards Truthful Multilingual Large Language Models - Benchmarking and Alignment Strategies,https://arxiv.org/abs/2406.14434,2024-06-20,2024-06-21,0.0,0.0,"In the era of large language models (LLMs), building multilingual large
language models (MLLMs) that can serve users worldwide holds great
significance. However, existing research seldom focuses on the truthfulness of
MLLMs. Meanwhile, contemporary multilingual aligning technologies struggle to
balance massive languages and often exhibit serious truthfulness gaps across
different languages, especially those that differ greatly from English. In our
work, we construct a benchmark for truthfulness evaluation in multilingual
scenarios and explore the ways to align facts across languages to enhance the
truthfulness of MLLMs. Furthermore, we propose Fact-aware Multilingual
Selective Synergy (FaMSS) to optimize the data allocation across a large number
of languages and different data types. Experimental results demonstrate that
our approach can effectively reduce the multilingual representation disparity
and enhance the multilingual capabilities of LLMs."
CollaFuse - Collaborative Diffusion Models,https://arxiv.org/abs/2406.14429,2024-06-20,2024-06-21,0.0,0.0,"In the landscape of generative artificial intelligence, diffusion-based
models have emerged as a promising method for generating synthetic images.
However, the application of diffusion models poses numerous challenges,
particularly concerning data availability, computational requirements, and
privacy. Traditional approaches to address these shortcomings, like federated
learning, often impose significant computational burdens on individual clients,
especially those with constrained resources. In response to these challenges,
we introduce a novel approach for distributed collaborative diffusion models
inspired by split learning. Our approach facilitates collaborative training of
diffusion models while alleviating client computational burdens during image
synthesis. This reduced computational burden is achieved by retaining data and
computationally inexpensive processes locally at each client while outsourcing
the computationally expensive processes to shared, more efficient server
resources. Through experiments on the common CelebA dataset, our approach
demonstrates enhanced privacy by reducing the necessity for sharing raw data.
These capabilities hold significant potential across various application areas,
including the design of edge computing solutions. Thus, our work advances
distributed machine learning by contributing to the evolution of collaborative
diffusion models."
Control when confidence is costly,https://arxiv.org/abs/2406.14427,2024-06-20,2024-06-21,0.0,0.0,"We develop a version of stochastic control that accounts for computational
costs of inference. Past studies identified efficient coding without control,
or efficient control that neglects the cost of synthesizing information. Here
we combine these concepts into a framework where agents rationally approximate
inference for efficient control. Specifically, we study Linear Quadratic
Gaussian (LQG) control with an added internal cost on the relative precision of
the posterior probability over the world state. This creates a trade-off: an
agent can obtain more utility overall by sacrificing some task performance, if
doing so saves enough bits during inference. We discover that the rational
strategy that solves the joint inference and control problem goes through phase
transitions depending on the task demands, switching from a costly but optimal
inference to a family of suboptimal inferences related by rotation
transformations, each misestimate the stability of the world. In all cases, the
agent moves more to think less. This work provides a foundation for a new type
of rational computations that could be used by both brains and machines for
efficient but computationally constrained control."
Transferable Boltzmann Generators,https://arxiv.org/abs/2406.14426,2024-06-20,2024-06-21,0.0,0.0,"The generation of equilibrium samples of molecular systems has been a
long-standing problem in statistical physics. Boltzmann Generators are a
generative machine learning method that addresses this issue by learning a
transformation via a normalizing flow from a simple prior distribution to the
target Boltzmann distribution of interest. Recently, flow matching has been
employed to train Boltzmann Generators for small molecular systems in Cartesian
coordinates. We extend this work and propose a first framework for Boltzmann
Generators that are transferable across chemical space, such that they predict
zero-shot Boltzmann distributions for test molecules without being retrained
for these systems. These transferable Boltzmann Generators allow approximate
sampling from the target distribution of unseen systems, as well as efficient
reweighting to the target Boltzmann distribution. The transferability of the
proposed framework is evaluated on dipeptides, where we show that it
generalizes efficiently to unseen systems. Furthermore, we demonstrate that our
proposed architecture enhances the efficiency of Boltzmann Generators trained
on single molecular systems."
SynDARin - Synthesising Datasets for Automated Reasoning in Low-Resource Languages,https://arxiv.org/abs/2406.14425,2024-06-20,2024-06-21,0.0,0.0,"Question Answering (QA) datasets have been instrumental in developing and
evaluating Large Language Model (LLM) capabilities. However, such datasets are
scarce for languages other than English due to the cost and difficulties of
collection and manual annotation. This means that producing novel models and
measuring the performance of multilingual LLMs in low-resource languages is
challenging. To mitigate this, we propose $\textbf{S}$yn$\textbf{DAR}$in, a
method for generating and validating QA datasets for low-resource languages. We
utilize parallel content mining to obtain $\textit{human-curated}$ paragraphs
between English and the target language. We use the English data as context to
$\textit{generate}$ synthetic multiple-choice (MC) question-answer pairs, which
are automatically translated and further validated for quality. Combining these
with their designated non-English $\textit{human-curated}$ paragraphs form the
final QA dataset. The method allows to maintain the content quality, reduces
the likelihood of factual errors, and circumvents the need for costly
annotation. To test the method, we created a QA dataset with $1.2$K samples for
the Armenian language. The human evaluation shows that $98\%$ of the generated
English data maintains quality and diversity in the question types and topics,
while the translation validation pipeline can filter out $\sim70\%$ of data
with poor quality. We use the dataset to benchmark state-of-the-art LLMs,
showing their inability to achieve human accuracy with some model performances
closer to random chance. This shows that the generated dataset is non-trivial
and can be used to evaluate reasoning capabilities in low-resource language."
CascadeServe - Unlocking Model Cascades for Inference Serving,https://arxiv.org/abs/2406.14424,2024-06-20,2024-06-21,0.0,0.0,"Machine learning (ML) models are increasingly deployed to production, calling
for efficient inference serving systems. Efficient inference serving is
complicated by two challenges: (i) ML models incur high computational costs,
and (ii) the request arrival rates of practical applications have frequent,
high, and sudden variations which make it hard to correctly provision hardware.
Model cascades are positioned to tackle both of these challenges, as they (i)
save work while maintaining accuracy, and (ii) expose a high-resolution
trade-off between work and accuracy, allowing for fine-grained adjustments to
request arrival rates. Despite their potential, model cascades haven't been
used inside an online serving system. This comes with its own set of
challenges, including workload adaption, model replication onto hardware,
inference scheduling, request batching, and more. In this work, we propose
CascadeServe, which automates and optimizes end-to-end inference serving with
cascades. CascadeServe operates in an offline and online phase. In the offline
phase, the system pre-computes a gear plan that specifies how to serve
inferences online. In the online phase, the gear plan allows the system to
serve inferences while making near-optimal adaptations to the query load at
negligible decision overheads. We find that CascadeServe saves 2-3x in cost
across a wide spectrum of the latency-accuracy space when compared to
state-of-the-art baselines on different workloads."
Communication-efficient Vertical Federated Learning via Compressed Error Feedback,https://arxiv.org/abs/2406.14420,2024-06-20,2024-06-21,0.0,0.0,"Communication overhead is a known bottleneck in federated learning (FL). To
address this, lossy compression is commonly used on the information
communicated between the server and clients during training. In horizontal FL,
where each client holds a subset of the samples, such communication-compressed
training methods have recently seen significant progress. However, in their
vertical FL counterparts, where each client holds a subset of the features, our
understanding remains limited. To address this, we propose an error feedback
compressed vertical federated learning (EFVFL) method to train split neural
networks. In contrast with previous communication-compressed methods for
vertical FL, EFVFL does not require a vanishing compression error for the
gradient norm to converge to zero for smooth nonconvex problems. By leveraging
error feedback, our method can achieve a $\mathcal{O}(1/T)$ convergence rate in
the full-batch case, improving over the state-of-the-art
$\mathcal{O}(1/\sqrt{T})$ rate under $\mathcal{O}(1/\sqrt{T})$ compression
error, and matching the rate of uncompressed methods. Further, when the
objective function satisfies the Polyak-{\L}ojasiewicz inequality, our method
converges linearly. In addition to improving convergence rates, our method also
supports the use of private labels. Numerical experiments show that EFVFL
significantly improves over the prior art, confirming our theoretical results."
Fair Streaming Feature Selection,https://arxiv.org/abs/2406.14401,2024-06-20,2024-06-21,0.0,0.0,"Streaming feature selection techniques have become essential in processing
real-time data streams, as they facilitate the identification of the most
relevant attributes from continuously updating information. Despite their
performance, current algorithms to streaming feature selection frequently fall
short in managing biases and avoiding discrimination that could be perpetuated
by sensitive attributes, potentially leading to unfair outcomes in the
resulting models. To address this issue, we propose FairSFS, a novel algorithm
for Fair Streaming Feature Selection, to uphold fairness in the feature
selection process without compromising the ability to handle data in an online
manner. FairSFS adapts to incoming feature vectors by dynamically adjusting the
feature set and discerns the correlations between classification attributes and
sensitive attributes from this revised set, thereby forestalling the
propagation of sensitive data. Empirical evaluations show that FairSFS not only
maintains accuracy that is on par with leading streaming feature selection
methods and existing fair feature techniques but also significantly improves
fairness metrics."
WEATHER-5K - A Large-scale Global Station Weather Dataset Towards Comprehensive Time-series Forecasting Benchmark,https://arxiv.org/abs/2406.14399,2024-06-20,2024-06-21,0.0,0.0,"Global Station Weather Forecasting (GSWF) is crucial for various sectors,
including aviation, agriculture, energy, and disaster preparedness. Recent
advancements in deep learning have significantly improved the accuracy of
weather predictions by optimizing models based on public meteorological data.
However, existing public datasets for GSWF optimization and benchmarking still
suffer from significant limitations, such as small sizes, limited temporal
coverage, and a lack of comprehensive variables. These shortcomings prevent
them from effectively reflecting the benchmarks of current forecasting methods
and fail to support the real needs of operational weather forecasting. To
address these challenges, we present the WEATHER-5K dataset. This dataset
comprises a comprehensive collection of data from 5,672 weather stations
worldwide, spanning a 10-year period with one-hour intervals. It includes
multiple crucial weather elements, providing a more reliable and interpretable
resource for forecasting. Furthermore, our WEATHER-5K dataset can serve as a
benchmark for comprehensively evaluating existing well-known forecasting
models, extending beyond GSWF methods to support future time-series research
challenges and opportunities. The dataset and benchmark implementation are
publicly available at: https://github.com/taohan10200/WEATHER-5K."
SEC-QA - A Systematic Evaluation Corpus for Financial QA,https://arxiv.org/abs/2406.14394,2024-06-20,2024-06-21,0.0,0.0,"The financial domain frequently deals with large numbers of long documents
that are essential for daily operations. Significant effort is put towards
automating financial data analysis. However, a persistent challenge, not
limited to the finance domain, is the scarcity of datasets that accurately
reflect real-world tasks for model evaluation. Existing datasets are often
constrained by size, context, or relevance to practical applications. Moreover,
LLMs are currently trained on trillions of tokens of text, limiting access to
novel data or documents that models have not encountered during training for
unbiased evaluation. We propose SEC-QA, a continuous dataset generation
framework with two key features: 1) the semi-automatic generation of
Question-Answer (QA) pairs spanning multiple long context financial documents,
which better represent real-world financial scenarios; 2) the ability to
continually refresh the dataset using the most recent public document
collections, not yet ingested by LLMs. Our experiments show that current
retrieval augmented generation methods systematically fail to answer these
challenging multi-document questions. In response, we introduce a QA system
based on program-of-thought that improves the ability to perform complex
information retrieval and quantitative reasoning pipelines, thereby increasing
QA accuracy."
Jailbreaking as a Reward Misspecification Problem,https://arxiv.org/abs/2406.14393,2024-06-20,2024-06-21,0.0,0.0,"The widespread adoption of large language models (LLMs) has raised concerns
about their safety and reliability, particularly regarding their vulnerability
to adversarial attacks. In this paper, we propose a novel perspective that
attributes this vulnerability to reward misspecification during the alignment
process. We introduce a metric ReGap to quantify the extent of reward
misspecification and demonstrate its effectiveness and robustness in detecting
harmful backdoor prompts. Building upon these insights, we present ReMiss, a
system for automated red teaming that generates adversarial prompts against
various target aligned LLMs. ReMiss achieves state-of-the-art attack success
rates on the AdvBench benchmark while preserving the human readability of the
generated prompts. Detailed analysis highlights the unique advantages brought
by the proposed reward misspecification objective compared to previous methods."
Active Diffusion Subsampling,https://arxiv.org/abs/2406.14388,2024-06-20,2024-06-21,0.0,0.0,"Subsampling is commonly used to mitigate costs associated with data
acquisition, such as time or energy requirements, motivating the development of
algorithms for estimating the fully-sampled signal of interest $x$ from
partially observed measurements $y$. In maximum-entropy sampling, one selects
measurement locations that are expected to have the highest entropy, so as to
minimize uncertainty about $x$. This approach relies on an accurate model of
the posterior distribution over future measurements, given the measurements
observed so far. Recently, diffusion models have been shown to produce
high-quality posterior samples of high-dimensional signals using guided
diffusion. In this work, we propose Active Diffusion Subsampling (ADS), a
method for performing active subsampling using guided diffusion in which the
model tracks a distribution of beliefs over the true state of $x$ throughout
the reverse diffusion process, progressively decreasing its uncertainty by
choosing to acquire measurements with maximum expected entropy, and ultimately
generating the posterior distribution $p(x | y)$. ADS can be applied using
pre-trained diffusion models for any subsampling rate, and does not require
task-specific retraining - just the specification of a measurement model.
Furthermore, the maximum entropy sampling policy employed by ADS is
interpretable, enhancing transparency relative to existing methods using
black-box policies. Experimentally, we show that ADS outperforms fixed sampling
strategies, and study an application of ADS in Magnetic Resonance Imaging
acceleration using the fastMRI dataset, finding that ADS performs competitively
with supervised methods. Code available at
https://active-diffusion-subsampling.github.io/."
Estimating Treatment Effects under Recommender Interference - A Structured Neural Networks Approach,https://arxiv.org/abs/2406.14380,2024-06-20,2024-06-21,0.0,0.0,"Recommender systems are essential for content-sharing platforms by curating
personalized content. To evaluate updates to recommender systems targeting
content creators, platforms frequently rely on creator-side randomized
experiments. The treatment effect measures the change in outcomes when a new
algorithm is implemented compared to the status quo. We show that the standard
difference-in-means estimator can lead to biased estimates due to recommender
interference that arises when treated and control creators compete for
exposure. We propose a ""recommender choice model"" that describes which item
gets exposed from a pool containing both treated and control items. By
combining a structural choice model with neural networks, this framework
directly models the interference pathway while accounting for rich
viewer-content heterogeneity. We construct a debiased estimator of the
treatment effect and prove it is $\sqrt n$-consistent and asymptotically normal
with potentially correlated samples. We validate our estimator's empirical
performance with a field experiment on Weixin short-video platform. In addition
to the standard creator-side experiment, we conduct a costly double-sided
randomization design to obtain a benchmark estimate free from interference
bias. We show that the proposed estimator yields results comparable to the
benchmark, whereas the standard difference-in-means estimator can exhibit
significant bias and even produce reversed signs."
Computation-Efficient Semi-Supervised Learning for ECG-based Cardiovascular Diseases Detection,https://arxiv.org/abs/2406.14377,2024-06-20,2024-06-21,0.0,0.0,"Label scarcity problem is the main challenge that hinders the wide
application of deep learning systems in automatic cardiovascular diseases
(CVDs) detection using electrocardiography (ECG). Tuning pre-trained models
alleviates this problem by transferring knowledge learned from large datasets
to downstream small datasets. However, bottlenecks in computational efficiency
and CVDs detection performance limit its clinical applications. It is difficult
to improve the detection performance without significantly sacrificing model
computational efficiency. Here, we propose a computation-efficient
semi-supervised learning paradigm (FastECG) for robust and
computation-efficient CVDs detection using ECG. It enables a robust adaptation
of pre-trained models on downstream datasets with limited supervision and high
computational efficiency. First, a random-deactivation technique is developed
to achieve robust and fast low-rank adaptation of pre-trained weights.
Subsequently, we propose a one-shot rank allocation module to determine the
optimal ranks for the update matrices of the pre-trained weights. Finally, a
lightweight semi-supervised learning pipeline is introduced to enhance model
performance by leveraging labeled and unlabeled data with high computational
efficiency. Extensive experiments on four downstream ECG datasets demonstrate
that FastECG not only outperforms the state-of-the-art methods in multi-label
CVDs detection but also consumes fewer GPU footprints, training time, and
parameter storage space. As such, this paradigm provides an effective solution
for achieving high computational efficiency and robust detection performance in
the clinical applications of pre-trained models under limited supervision."
Artificial Leviathan - Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory,https://arxiv.org/abs/2406.14373,2024-06-20,2024-06-21,0.0,0.0,"The emergence of Large Language Models (LLMs) and advancements in Artificial
Intelligence (AI) offer an opportunity for computational social science
research at scale. Building upon prior explorations of LLM agent design, our
work introduces a simulated agent society where complex social relationships
dynamically form and evolve over time. Agents are imbued with psychological
drives and placed in a sandbox survival environment. We conduct an evaluation
of the agent society through the lens of Thomas Hobbes's seminal Social
Contract Theory (SCT). We analyze whether, as the theory postulates, agents
seek to escape a brutish ""state of nature"" by surrendering rights to an
absolute sovereign in exchange for order and security. Our experiments unveil
an alignment: Initially, agents engage in unrestrained conflict, mirroring
Hobbes's depiction of the state of nature. However, as the simulation
progresses, social contracts emerge, leading to the authorization of an
absolute sovereign and the establishment of a peaceful commonwealth founded on
mutual cooperation. This congruence between our LLM agent society's
evolutionary trajectory and Hobbes's theoretical account indicates LLMs'
capability to model intricate social dynamics and potentially replicate forces
that shape human societies. By enabling such insights into group behavior and
emergent societal phenomena, LLM-driven multi-agent simulations, while unable
to simulate all the nuances of human behavior, may hold potential for advancing
our understanding of social structures, group dynamics, and complex human
systems."
PoseBench - Benchmarking the Robustness of Pose Estimation Models under Corruptions,https://arxiv.org/abs/2406.14367,2024-06-20,2024-06-21,0.0,0.0,"Pose estimation aims to accurately identify anatomical keypoints in humans
and animals using monocular images, which is crucial for various applications
such as human-machine interaction, embodied AI, and autonomous driving. While
current models show promising results, they are typically trained and tested on
clean data, potentially overlooking the corruption during real-world deployment
and thus posing safety risks in practical scenarios. To address this issue, we
introduce PoseBench, a comprehensive benchmark designed to evaluate the
robustness of pose estimation models against real-world corruption. We
evaluated 60 representative models, including top-down, bottom-up,
heatmap-based, regression-based, and classification-based methods, across three
datasets for human and animal pose estimation. Our evaluation involves 10 types
of corruption in four categories: 1) blur and noise, 2) compression and color
loss, 3) severe lighting, and 4) masks. Our findings reveal that
state-of-the-art models are vulnerable to common real-world corruptions and
exhibit distinct behaviors when tackling human and animal pose estimation
tasks. To improve model robustness, we delve into various design
considerations, including input resolution, pre-training datasets, backbone
capacity, post-processing, and data augmentations. We hope that our benchmark
will serve as a foundation for advancing research in robust pose estimation.
The benchmark and source code will be released at
https://xymsh.github.io/PoseBench"
Communication-Efficient Byzantine-Resilient Federated Zero-Order Optimization,https://arxiv.org/abs/2406.14362,2024-06-20,2024-06-21,0.0,0.0,"We introduce CYBER-0, the first zero-order optimization algorithm for
memory-and-communication efficient Federated Learning, resilient to Byzantine
faults. We show through extensive numerical experiments on the MNIST dataset
and finetuning RoBERTa-Large that CYBER-0 outperforms state-of-the-art
algorithms in terms of communication and memory efficiency while reaching
similar accuracy. We provide theoretical guarantees on its convergence for
convex loss functions."
Robustness Analysis of AI Models in Critical Energy Systems,https://arxiv.org/abs/2406.14361,2024-06-20,2024-06-21,0.0,0.0,"This paper analyzes the robustness of state-of-the-art AI-based models for
power grid operations under the $N-1$ security criterion. While these models
perform well in regular grid settings, our results highlight a significant loss
in accuracy following the disconnection of a line.%under this security
criterion. Using graph theory-based analysis, we demonstrate the impact of node
connectivity on this loss. Our findings emphasize the need for practical
scenario considerations in developing AI methodologies for critical
infrastructure."
The neural correlates of logical-mathematical symbol systems processing resemble that of spatial cognition more than natural language processing,https://arxiv.org/abs/2406.14358,2024-06-20,2024-06-21,0.0,0.0,"The ability to manipulate logical-mathematical symbols (LMS), encompassing
tasks such as calculation, reasoning, and programming, is a cognitive skill
arguably unique to humans. Considering the relatively recent emergence of this
ability in human evolutionary history, it has been suggested that LMS
processing may build upon more fundamental cognitive systems, possibly through
neuronal recycling. Previous studies have pinpointed two primary candidates,
natural language processing and spatial cognition. Existing comparisons between
these domains largely relied on task-level comparison, which may be confounded
by task idiosyncrasy. The present study instead compared the neural correlates
at the domain level with both automated meta-analysis and synthesized maps
based on three representative LMS tasks, reasoning, calculation, and mental
programming. Our results revealed a more substantial cortical overlap between
LMS processing and spatial cognition, in contrast to language processing.
Furthermore, in regions activated by both spatial and language processing, the
multivariate activation pattern for LMS processing exhibited greater
multivariate similarity to spatial cognition than to language processing. A
hierarchical clustering analysis further indicated that typical LMS tasks were
indistinguishable from spatial cognition tasks at the neural level, suggesting
an inherent connection between these two cognitive processes. Taken together,
our findings support the hypothesis that spatial cognition is likely the basis
of LMS processing, which may shed light on the limitations of large language
models in logical reasoning, particularly those trained exclusively on textual
data without explicit emphasis on spatial content."
Can you trust your explanations? A robustness test for feature attribution methods,https://arxiv.org/abs/2406.14349,2024-06-20,2024-06-21,0.0,0.0,"The increase of legislative concerns towards the usage of Artificial
Intelligence (AI) has recently led to a series of regulations striving for a
more transparent, trustworthy and accountable AI. Along with these proposals,
the field of Explainable AI (XAI) has seen a rapid growth but the usage of its
techniques has at times led to unexpected results. The robustness of the
approaches is, in fact, a key property often overlooked: it is necessary to
evaluate the stability of an explanation (to random and adversarial
perturbations) to ensure that the results are trustable. To this end, we
propose a test to evaluate the robustness to non-adversarial perturbations and
an ensemble approach to analyse more in depth the robustness of XAI methods
applied to neural networks and tabular datasets. We will show how leveraging
manifold hypothesis and ensemble approaches can be beneficial to an in-depth
analysis of the robustness."
$\nabla^2$DFT - A Universal Quantum Chemistry Dataset of Drug-Like Molecules and a Benchmark for Neural Network Potentials,https://arxiv.org/abs/2406.14347,2024-06-20,2024-06-21,0.0,0.0,"Methods of computational quantum chemistry provide accurate approximations of
molecular properties crucial for computer-aided drug discovery and other areas
of chemical science. However, high computational complexity limits the
scalability of their applications. Neural network potentials (NNPs) are a
promising alternative to quantum chemistry methods, but they require large and
diverse datasets for training. This work presents a new dataset and benchmark
called $\nabla^2$DFT that is based on the nablaDFT. It contains twice as much
molecular structures, three times more conformations, new data types and tasks,
and state-of-the-art models. The dataset includes energies, forces, 17
molecular properties, Hamiltonian and overlap matrices, and a wavefunction
object. All calculations were performed at the DFT level
($\omega$B97X-D/def2-SVP) for each conformation. Moreover, $\nabla^2$DFT is the
first dataset that contains relaxation trajectories for a substantial number of
drug-like molecules. We also introduce a novel benchmark for evaluating NNPs in
molecular property prediction, Hamiltonian prediction, and conformational
optimization tasks. Finally, we propose an extendable framework for training
NNPs and implement 10 models within it."
iWISDM - Assessing instruction following in multimodal models at scale,https://arxiv.org/abs/2406.14343,2024-06-20,2024-06-21,0.0,0.0,"The ability to perform complex tasks from detailed instructions is a key to
many remarkable achievements of our species. As humans, we are not only capable
of performing a wide variety of tasks but also very complex ones that may
entail hundreds or thousands of steps to complete. Large language models and
their more recent multimodal counterparts that integrate textual and visual
inputs have achieved unprecedented success in performing complex tasks. Yet,
most existing benchmarks are largely confined to single-modality inputs (either
text or vision), narrowing the scope of multimodal assessments, particularly
for instruction-following in multimodal contexts. To bridge this gap, we
introduce the instructed-Virtual VISual Decision Making (iWISDM) environment
engineered to generate a limitless array of vision-language tasks of varying
complexity. Using iWISDM, we compiled three distinct benchmarks of instruction
following visual tasks across varying complexity levels and evaluated several
newly developed multimodal models on these benchmarks. Our findings establish
iWISDM as a robust benchmark for assessing the instructional adherence of both
existing and emergent multimodal models and highlight a large gap between these
models' ability to precisely follow instructions with that of humans.The code
of iWISDM is available on GitHub at https://github.com/BashivanLab/iWISDM."
HoTPP Benchmark - Are We Good at the Long Horizon Events Forecasting?,https://arxiv.org/abs/2406.14341,2024-06-20,2024-06-21,0.0,0.0,"Accurately forecasting multiple future events within a given time horizon is
crucial for finance, retail, social networks, and healthcare applications.
Event timing and labels are typically modeled using Marked Temporal Point
Processes (MTPP), with evaluations often focused on next-event prediction
quality. While some studies have extended evaluations to a fixed number of
future events, we demonstrate that this approach leads to inaccuracies in
handling false positives and false negatives. To address these issues, we
propose a novel evaluation method inspired by object detection techniques from
computer vision. Specifically, we introduce Temporal mean Average Precision
(T-mAP), a temporal variant of mAP, which overcomes the limitations of existing
long-horizon evaluation metrics. Our extensive experiments demonstrate that
models with strong next-event prediction accuracy can yield poor long-horizon
forecasts and vice versa, indicating that specialized methods are needed for
each task. To support further research, we release HoTPP, the first benchmark
designed explicitly for evaluating long-horizon MTPP predictions. HoTPP
includes large-scale datasets with up to 43 million events and provides
optimized procedures for both autoregressive and parallel inference, paving the
way for future advancements in the field."
Learning rate adaptive stochastic gradient descent optimization methods - numerical simulations for deep learning methods for partial differential equations and convergence analyses,https://arxiv.org/abs/2406.14340,2024-06-20,2024-06-21,0.0,0.0,"It is known that the standard stochastic gradient descent (SGD) optimization
method, as well as accelerated and adaptive SGD optimization methods such as
the Adam optimizer fail to converge if the learning rates do not converge to
zero (as, for example, in the situation of constant learning rates). Numerical
simulations often use human-tuned deterministic learning rate schedules or
small constant learning rates. The default learning rate schedules for SGD
optimization methods in machine learning implementation frameworks such as
TensorFlow and Pytorch are constant learning rates. In this work we propose and
study a learning-rate-adaptive approach for SGD optimization methods in which
the learning rate is adjusted based on empirical estimates for the values of
the objective function of the considered optimization problem (the function
that one intends to minimize). In particular, we propose a
learning-rate-adaptive variant of the Adam optimizer and implement it in case
of several neural network learning problems, particularly, in the context of
deep learning approximation methods for partial differential equations such as
deep Kolmogorov methods, physics-informed neural networks, and deep Ritz
methods. In each of the presented learning problems the proposed
learning-rate-adaptive variant of the Adam optimizer faster reduces the value
of the objective function than the Adam optimizer with the default learning
rate. For a simple class of quadratic minimization problems we also rigorously
prove that a learning-rate-adaptive variant of the SGD optimization method
converges to the minimizer of the considered minimization problem. Our
convergence proof is based on an analysis of the laws of invariant measures of
the SGD method as well as on a more general convergence analysis for SGD with
random but predictable learning rates which we develop in this work."
Exploring Spatial Representations in the Historical Lake District Texts with LLM-based Relation Extraction,https://arxiv.org/abs/2406.14336,2024-06-20,2024-06-21,0.0,0.0,"Navigating historical narratives poses a challenge in unveiling the spatial
intricacies of past landscapes. The proposed work addresses this challenge
within the context of the English Lake District, employing the Corpus of the
Lake District Writing. The method utilizes a generative pre-trained transformer
model to extract spatial relations from the textual descriptions in the corpus.
The study applies this large language model to understand the spatial
dimensions inherent in historical narratives comprehensively. The outcomes are
presented as semantic triples, capturing the nuanced connections between
entities and locations, and visualized as a network, offering a graphical
representation of the spatial narrative. The study contributes to a deeper
comprehension of the English Lake District's spatial tapestry and provides an
approach to uncovering spatial relations within diverse historical contexts."
Self-supervised Interpretable Concept-based Models for Text Classification,https://arxiv.org/abs/2406.14335,2024-06-20,2024-06-21,0.0,0.0,"Despite their success, Large-Language Models (LLMs) still face criticism as
their lack of interpretability limits their controllability and reliability.
Traditional post-hoc interpretation methods, based on attention and
gradient-based analysis, offer limited insight into the model's decision-making
processes. In the image field, Concept-based models have emerged as
explainable-by-design architectures, employing human-interpretable features as
intermediate representations. However, these methods have not been yet adapted
to textual data, mainly because they require expensive concept annotations,
which are impractical for real-world text data. This paper addresses this
challenge by proposing a self-supervised Interpretable Concept Embedding Models
(ICEMs). We leverage the generalization abilities of LLMs to predict the
concepts labels in a self-supervised way, while we deliver the final
predictions with an interpretable function. The results of our experiments show
that ICEMs can be trained in a self-supervised way achieving similar
performance to fully supervised concept-based models and end-to-end black-box
ones. Additionally, we show that our models are (i) interpretable, offering
meaningful logical explanations for their predictions; (ii) interactable,
allowing humans to modify intermediate predictions through concept
interventions; and (iii) controllable, guiding the LLMs' decoding process to
follow a required decision-making path."
Adaptive Adversarial Cross-Entropy Loss for Sharpness-Aware Minimization,https://arxiv.org/abs/2406.14329,2024-06-20,2024-06-21,0.0,0.0,"Recent advancements in learning algorithms have demonstrated that the
sharpness of the loss surface is an effective measure for improving the
generalization gap. Building upon this concept, Sharpness-Aware Minimization
(SAM) was proposed to enhance model generalization and achieved
state-of-the-art performance. SAM consists of two main steps, the weight
perturbation step and the weight updating step. However, the perturbation in
SAM is determined by only the gradient of the training loss, or cross-entropy
loss. As the model approaches a stationary point, this gradient becomes small
and oscillates, leading to inconsistent perturbation directions and also has a
chance of diminishing the gradient. Our research introduces an innovative
approach to further enhancing model generalization. We propose the Adaptive
Adversarial Cross-Entropy (AACE) loss function to replace standard
cross-entropy loss for SAM's perturbation. AACE loss and its gradient uniquely
increase as the model nears convergence, ensuring consistent perturbation
direction and addressing the gradient diminishing issue. Additionally, a novel
perturbation-generating function utilizing AACE loss without normalization is
proposed, enhancing the model's exploratory capabilities in near-optimum
stages. Empirical testing confirms the effectiveness of AACE, with experiments
demonstrating improved performance in image classification tasks using Wide
ResNet and PyramidNet across various datasets. The reproduction code is
available online"
Computing Within Limits - An Empirical Study of Energy Consumption in ML Training and Inference,https://arxiv.org/abs/2406.14328,2024-06-20,2024-06-21,0.0,0.0,"Machine learning (ML) has seen tremendous advancements, but its environmental
footprint remains a concern. Acknowledging the growing environmental impact of
ML this paper investigates Green ML, examining various model architectures and
hyperparameters in both training and inference phases to identify
energy-efficient practices. Our study leverages software-based power
measurements for ease of replication across diverse configurations, models and
datasets. In this paper, we examine multiple models and hardware configurations
to identify correlations across the various measurements and metrics and key
contributors to energy reduction. Our analysis offers practical guidelines for
constructing sustainable ML operations, emphasising energy consumption and
carbon footprint reductions while maintaining performance. As identified,
short-lived profiling can quantify the long-term expected energy consumption.
Moreover, model parameters can also be used to accurately estimate the expected
total energy without the need for extensive experimentation."
"Reproducibility in Machine Learning-based Research - Overview, Barriers and Drivers",https://arxiv.org/abs/2406.14325,2024-06-20,2024-06-21,0.0,0.0,"Research in various fields is currently experiencing challenges regarding the
reproducibility of results. This problem is also prevalent in machine learning
(ML) research. The issue arises, for example, due to unpublished data and/or
source code and the sensitivity of ML training conditions. Although different
solutions have been proposed to address this issue, such as using ML platforms,
the level of reproducibility in ML-driven research remains unsatisfactory.
Therefore, in this article, we discuss the reproducibility of ML-driven
research with three main aims: (i) identifying the barriers to reproducibility
when applying ML in research as well as categorize the barriers to different
types of reproducibility (description, code, data, and experiment
reproducibility), (ii) discussing potential drivers such as tools, practices,
and interventions that support ML reproducibility, as well as distinguish
between technology-driven drivers, procedural drivers, and drivers related to
awareness and education, and (iii) mapping the drivers to the barriers. With
this work, we hope to provide insights and to contribute to the decision-making
process regarding the adoption of different solutions to support ML
reproducibility."
Revealing the learning process in reinforcement learning agents through attention-oriented metrics,https://arxiv.org/abs/2406.14324,2024-06-20,2024-06-21,0.0,0.0,"The learning process of a reinforcement learning (RL) agent remains poorly
understood beyond the mathematical formulation of its learning algorithm. To
address this gap, we introduce attention-oriented metrics (ATOMs) to
investigate the development of an RL agent's attention during training. We
tested ATOMs on three variations of a Pong game, each designed to teach the
agent distinct behaviours, complemented by a behavioural assessment. Our
findings reveal that ATOMs successfully delineate the attention patterns of an
agent trained on each game variation, and that these differences in attention
patterns translate into differences in the agent's behaviour. Through
continuous monitoring of ATOMs during training, we observed that the agent's
attention developed in phases, and that these phases were consistent across
games. Finally, we noted that the agent's attention to its paddle emerged
relatively late in the training and coincided with a marked increase in its
performance score. Overall, we believe that ATOMs could significantly enhance
our understanding of RL agents' learning processes, which is essential for
improving their reliability and efficiency."
Mind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning,https://arxiv.org/abs/2406.14322,2024-06-20,2024-06-21,0.0,0.0,"Large language models (LLMs) have emerged as powerful tools for tackling
complex tasks across diverse domains, but they also raise privacy concerns when
fine-tuned on sensitive data due to potential memorization. While differential
privacy (DP) offers a promising solution by ensuring models are 'almost
indistinguishable' with or without any particular privacy unit, current
evaluations on LLMs mostly treat each example (text record) as the privacy
unit. This leads to uneven user privacy guarantees when contributions per user
vary. We therefore study user-level DP motivated by applications where it
necessary to ensure uniform privacy protection across users. We present a
systematic evaluation of user-level DP for LLM fine-tuning on natural language
generation tasks. Focusing on two mechanisms for achieving user-level DP
guarantees, Group Privacy and User-wise DP-SGD, we investigate design choices
like data selection strategies and parameter tuning for the best
privacy-utility tradeoff."
LiveMind - Low-latency Large Language Models with Simultaneous Inference,https://arxiv.org/abs/2406.14319,2024-06-20,2024-06-21,0.0,0.0,"In this paper, we introduce a novel low-latency inference framework for large
language models (LLMs) inference which enables LLMs to perform inferences with
incomplete prompts. By reallocating computational processes to prompt input
phase, we achieve a substantial reduction in latency, thereby significantly
enhancing the interactive experience for users of LLMs. The framework adeptly
manages the visibility of the streaming prompt to the model, allowing it to
infer from incomplete prompts or await additional prompts. Compared with
traditional inference methods that utilize complete prompts, our approach
demonstrates an average reduction of 59% in response latency on the MMLU-Pro
dataset, while maintaining comparable accuracy. Additionally, our framework
facilitates collaborative inference and output across different models. By
employing an LLM for inference and a small language model (SLM) for output, we
achieve an average 68% reduction in response latency, alongside a 5.5%
improvement in accuracy on the MMLU-Pro dataset compared with the SLM baseline.
For long prompts exceeding 20 sentences, the response latency can be reduced by
up to 93%."
The Fire Thief Is Also the Keeper - Balancing Usability and Privacy in Prompts,https://arxiv.org/abs/2406.14318,2024-06-20,2024-06-21,0.0,0.0,"The rapid adoption of online chatbots represents a significant advancement in
artificial intelligence. However, this convenience brings considerable privacy
concerns, as prompts can inadvertently contain sensitive information exposed to
large language models (LLMs). Limited by high computational costs, reduced task
usability, and excessive system modifications, previous works based on local
deployment, embedding perturbation, and homomorphic encryption are inapplicable
to online prompt-based LLM applications.
  To address these issues, this paper introduces Prompt Privacy Sanitizer
(i.e., ProSan), an end-to-end prompt privacy protection framework that can
produce anonymized prompts with contextual privacy removed while maintaining
task usability and human readability. It can also be seamlessly integrated into
the online LLM service pipeline. To achieve high usability and dynamic
anonymity, ProSan flexibly adjusts its protection targets and strength based on
the importance of the words and the privacy leakage risk of the prompts.
Additionally, ProSan is capable of adapting to diverse computational resource
conditions, ensuring privacy protection even for mobile devices with limited
computing power. Our experiments demonstrate that ProSan effectively removes
private information across various tasks, including question answering, text
summarization, and code generation, with minimal reduction in task performance."
Identifying User Goals from UI Trajectories,https://arxiv.org/abs/2406.14314,2024-06-20,2024-06-21,0.0,0.0,"Autonomous agents that interact with graphical user interfaces (GUIs) hold
significant potential for enhancing user experiences. To further improve these
experiences, agents need to be personalized and proactive. By effectively
comprehending user intentions through their actions and interactions with GUIs,
agents will be better positioned to achieve these goals. This paper introduces
the task of goal identification from observed UI trajectories, aiming to infer
the user's intended task based on their GUI interactions. We propose a novel
evaluation metric to assess whether two task descriptions are paraphrases
within a specific UI environment. By Leveraging the inverse relation with the
UI automation task, we utilized the Android-In-The-Wild and Mind2Web datasets
for our experiments. Using our metric and these datasets, we conducted several
experiments comparing the performance of humans and state-of-the-art models,
specifically GPT-4 and Gemini-1.5 Pro. Our results show that Gemini performs
better than GPT but still underperforms compared to humans, indicating
significant room for improvement."
Robust Few-shot Transfer Learning for Knowledge Base Question Answering with Unanswerable Questions,https://arxiv.org/abs/2406.14313,2024-06-20,2024-06-21,0.0,0.0,"Real-world KBQA applications require models that are (1) robust -- e.g., can
differentiate between answerable and unanswerable questions, and (2)
low-resource -- do not require large training data. Towards this goal, we
propose the novel task of few-shot transfer for KBQA with unanswerable
questions. We present FUn-FuSIC that extends the state-of-the-art (SoTA)
few-shot transfer model for answerable-only KBQA to handle unanswerability. It
iteratively prompts an LLM to generate logical forms for the question by
providing feedback using a diverse suite of syntactic, semantic and execution
guided checks, and adapts self-consistency to assess confidence of the LLM to
decide answerability. Experiments over newly constructed datasets show that
FUn-FuSIC outperforms suitable adaptations of the SoTA model for KBQA with
unanswerability, and the SoTA model for answerable-only few-shot-transfer KBQA."
Cross-level Requirement Traceability - A Novel Approach Integrating Bag-of-Words and Word Embedding for Enhanced Similarity Functionality,https://arxiv.org/abs/2406.14310,2024-06-20,2024-06-21,0.0,0.0,"Requirement traceability is the process of identifying the inter-dependencies
between requirements. It poses a significant challenge when conducted manually,
especially when dealing with requirements at various levels of abstraction. In
this work, we propose a novel approach to automate the task of linking
high-level business requirements with more technical system requirements. The
proposed approach begins by representing each requirement using a Bag of-Words
(BOW) model combined with the Term Frequency-Inverse Document Frequency
(TF-IDF) scoring function. Then, we suggested an enhanced cosine similarity
that uses recent advances in word embedding representation to correct
traditional cosine similarity function limitations. To evaluate the
effectiveness of our approach, we conducted experiments on three well-known
datasets: COEST, WARC(NFR), and WARC(FRS). The results demonstrate that our
approach significantly improves efficiency compared to existing methods. We
achieved better results with an increase of approximately 18.4% in one of the
datasets, as measured by the F2 score."
QuST-LLM - Integrating Large Language Models for Comprehensive Spatial Transcriptomics Analysis,https://arxiv.org/abs/2406.14307,2024-06-20,2024-06-21,0.0,0.0,"In this paper, we introduce QuST-LLM, an innovative extension of QuPath that
utilizes the capabilities of large language models (LLMs) to analyze and
interpret spatial transcriptomics (ST) data. In addition to simplifying the
intricate and high-dimensional nature of ST data by offering a comprehensive
workflow that includes data loading, region selection, gene expression
analysis, and functional annotation, QuST-LLM employs LLMs to transform complex
ST data into understandable and detailed biological narratives based on gene
ontology annotations, thereby significantly improving the interpretability of
ST data. Consequently, users can interact with their own ST data using natural
language. Hence, QuST-LLM provides researchers with a potent functionality to
unravel the spatial and functional complexities of tissues, fostering novel
insights and advancements in biomedical research. QuST-LLM is a part of QuST
project. The source code is hosted on GitHub and documentation is available at
(https://github.com/huangch/qust)."
Identifiable Exchangeable Mechanisms for Causal Structure and Representation Learning,https://arxiv.org/abs/2406.14302,2024-06-20,2024-06-21,0.0,0.0,"Identifying latent representations or causal structures is important for good
generalization and downstream task performance. However, both fields have been
developed rather independently. We observe that several methods in both
representation and causal structure learning rely on the same data-generating
process (DGP), namely, exchangeable but not i.i.d. (independent and identically
distributed) data. We provide a unified framework, termed Identifiable
Exchangeable Mechanisms (IEM), for representation and structure learning under
the lens of exchangeability. IEM provides new insights that let us relax the
necessary conditions for causal structure identification in exchangeable
non--i.i.d. data. We also demonstrate the existence of a duality condition in
identifiable representation learning, leading to new identifiability results.
We hope this work will pave the way for further research in causal
representation learning."
Resource Optimization for Tail-Based Control in Wireless Networked Control Systems,https://arxiv.org/abs/2406.14301,2024-06-20,2024-06-21,0.0,0.0,"Achieving control stability is one of the key design challenges of scalable
Wireless Networked Control Systems (WNCS) under limited communication and
computing resources. This paper explores the use of an alternative control
concept defined as tail-based control, which extends the classical Linear
Quadratic Regulator (LQR) cost function for multiple dynamic control systems
over a shared wireless network. We cast the control of multiple control systems
as a network-wide optimization problem and decouple it in terms of sensor
scheduling, plant state prediction, and control policies. Toward this, we
propose a solution consisting of a scheduling algorithm based on Lyapunov
optimization for sensing, a mechanism based on Gaussian Process Regression
(GPR) for state prediction and uncertainty estimation, and a control policy
based on Reinforcement Learning (RL) to ensure tail-based control stability. A
set of discrete time-invariant mountain car control systems is used to evaluate
the proposed solution and is compared against four variants that use
state-of-the-art scheduling, prediction, and control methods. The experimental
results indicate that the proposed method yields 22% reduction in overall cost
in terms of communication and control resource utilization compared to
state-of-the-art methods."
AI in Space for Scientific Missions - Strategies for Minimizing Neural-Network Model Upload,https://arxiv.org/abs/2406.14297,2024-06-20,2024-06-21,0.0,0.0,"Artificial Intelligence (AI) has the potential to revolutionize space
exploration by delegating several spacecraft decisions to an onboard AI instead
of relying on ground control and predefined procedures. It is likely that there
will be an AI/ML Processing Unit onboard the spacecraft running an inference
engine. The neural-network will have pre-installed parameters that can be
updated onboard by uploading, by telecommands, parameters obtained by training
on the ground. However, satellite uplinks have limited bandwidth and
transmissions can be costly. Furthermore, a mission operating with a suboptimal
neural network will miss out on valuable scientific data. Smaller networks can
thereby decrease the uplink cost, while increasing the value of the scientific
data that is downloaded. In this work, we evaluate and discuss the use of
reduced-precision and bare-minimum neural networks to reduce the time for
upload. As an example of an AI use case, we focus on the NASA's Magnetosperic
MultiScale (MMS) mission. We show how an AI onboard could be used in the
Earth's magnetosphere to classify data to selectively downlink higher value
data or to recognize a region-of-interest to trigger a burst-mode, collecting
data at a high-rate. Using a simple filtering scheme and algorithm, we show how
the start and end of a region-of-interest can be detected in on a stream of
classifications. To provide the classifications, we use an established
Convolutional Neural Network (CNN) trained to an accuracy >94%. We also show
how the network can be reduced to a single linear layer and trained to the same
accuracy as the established CNN. Thereby, reducing the overall size of the
model by up to 98.9%. We further show how each network can be reduced by up to
75% of its original size, by using lower-precision formats to represent the
network parameters, with a change in accuracy of less than 0.6 percentage
points."
DASB -- Discrete Audio and Speech Benchmark,https://arxiv.org/abs/2406.14294,2024-06-20,2024-06-21,0.0,0.0,"Discrete audio tokens have recently gained considerable attention for their
potential to connect audio and language processing, enabling the creation of
modern multimodal large language models. Ideal audio tokens must effectively
preserve phonetic and semantic content along with paralinguistic information,
speaker identity, and other details. While several types of audio tokens have
been recently proposed, identifying the optimal tokenizer for various tasks is
challenging due to the inconsistent evaluation settings in existing studies. To
address this gap, we release the Discrete Audio and Speech Benchmark (DASB), a
comprehensive leaderboard for benchmarking discrete audio tokens across a wide
range of discriminative tasks, including speech recognition, speaker
identification and verification, emotion recognition, keyword spotting, and
intent classification, as well as generative tasks such as speech enhancement,
separation, and text-to-speech. Our results show that, on average, semantic
tokens outperform compression tokens across most discriminative and generative
tasks. However, the performance gap between semantic tokens and standard
continuous representations remains substantial, highlighting the need for
further research in this field."
Proximal Interacting Particle Langevin Algorithms,https://arxiv.org/abs/2406.14292,2024-06-20,2024-06-21,0.0,0.0,"We introduce a class of algorithms, termed Proximal Interacting Particle
Langevin Algorithms (PIPLA), for inference and learning in latent variable
models whose joint probability density is non-differentiable. Leveraging
proximal Markov chain Monte Carlo (MCMC) techniques and the recently introduced
interacting particle Langevin algorithm (IPLA), we propose several variants
within the novel proximal IPLA family, tailored to the problem of estimating
parameters in a non-differentiable statistical model. We prove nonasymptotic
bounds for the parameter estimates produced by multiple algorithms in the
strongly log-concave setting and provide comprehensive numerical experiments on
various models to demonstrate the effectiveness of the proposed methods. In
particular, we demonstrate the utility of the proposed family of algorithms on
a toy hierarchical example where our assumptions can be checked, as well as on
the problems of sparse Bayesian logistic regression, sparse Bayesian neural
network, and sparse matrix completion. Our theory and experiments together show
that PIPLA family can be the de facto choice for parameter estimation problems
in latent variable models for non-differentiable models."
Revisiting Modularity Maximization for Graph Clustering - A Contrastive Learning Perspective,https://arxiv.org/abs/2406.14288,2024-06-20,2024-06-21,0.0,0.0,"Graph clustering, a fundamental and challenging task in graph mining, aims to
classify nodes in a graph into several disjoint clusters. In recent years,
graph contrastive learning (GCL) has emerged as a dominant line of research in
graph clustering and advances the new state-of-the-art. However, GCL-based
methods heavily rely on graph augmentations and contrastive schemes, which may
potentially introduce challenges such as semantic drift and scalability issues.
Another promising line of research involves the adoption of modularity
maximization, a popular and effective measure for community detection, as the
guiding principle for clustering tasks. Despite the recent progress, the
underlying mechanism of modularity maximization is still not well understood.
In this work, we dig into the hidden success of modularity maximization for
graph clustering. Our analysis reveals the strong connections between
modularity maximization and graph contrastive learning, where positive and
negative examples are naturally defined by modularity. In light of our results,
we propose a community-aware graph clustering framework, coined MAGI, which
leverages modularity maximization as a contrastive pretext task to effectively
uncover the underlying information of communities in graphs, while avoiding the
problem of semantic drift. Extensive experiments on multiple graph datasets
verify the effectiveness of MAGI in terms of scalability and clustering
performance compared to state-of-the-art graph clustering methods. Notably,
MAGI easily scales a sufficiently large graph with 100M nodes while
outperforming strong baselines."
VAIYAKARANA  - A Benchmark for Automatic Grammar Correction in Bangla,https://arxiv.org/abs/2406.14284,2024-06-20,2024-06-21,0.0,0.0,"Bangla (Bengali) is the fifth most spoken language globally and, yet, the
problem of automatic grammar correction in Bangla is still in its nascent
stage. This is mostly due to the need for a large corpus of grammatically
incorrect sentences, with their corresponding correct counterparts. The present
state-of-the-art techniques to curate a corpus for grammatically wrong
sentences involve random swapping, insertion and deletion of words.
However,these steps may not always generate grammatically wrong sentences in
Bangla. In this work, we propose a pragmatic approach to generate grammatically
wrong sentences in Bangla. We first categorize the different kinds of errors in
Bangla into 5 broad classes and 12 finer classes. We then use these to generate
grammatically wrong sentences systematically from a correct sentence. This
approach can generate a large number of wrong sentences and can, thus, mitigate
the challenge of lacking a large corpus for neural networks. We provide a
dataset, Vaiyakarana, consisting of 92,830 grammatically incorrect sentences as
well as 18,426 correct sentences. We also collected 619 human-generated
sentences from essays written by Bangla native speakers. This helped us to
understand errors that are more frequent. We evaluated our corpus against
neural models and LLMs and also benchmark it against human evaluators who are
native speakers of Bangla. Our analysis shows that native speakers are far more
accurate than state-of-the-art models to detect whether the sentence is
grammatically correct. Our methodology of generating erroneous sentences can be
applied for most other Indian languages as well."
Q* - Improving Multi-step Reasoning for LLMs with Deliberative Planning,https://arxiv.org/abs/2406.14283,2024-06-20,2024-06-21,0.0,0.0,"Large Language Models (LLMs) have demonstrated impressive capability in many
natural language tasks. However, the auto-regressive generation process makes
LLMs prone to produce errors, hallucinations and inconsistent statements when
performing multi-step reasoning. In this paper, by casting multi-step reasoning
of LLMs as a heuristic search problem, we aim to alleviate the pathology by
introducing Q*, a general, versatile and agile framework for guiding LLMs
decoding process with deliberative planning. By learning a plug-and-play
Q-value model as heuristic function for estimating expected future rewards, our
Q* can effectively guide LLMs to select the most promising next reasoning step
without fine-tuning LLMs for the current task, which avoids the significant
computational overhead and potential risk of performance degeneration on other
tasks. Extensive experiments on GSM8K, MATH and MBPP demonstrate the
superiority of our method, contributing to improving the reasoning performance
of existing open-source LLMs."
Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs,https://arxiv.org/abs/2406.14282,2024-06-20,2024-06-21,0.0,0.0,"Improving the performance of large language models (LLMs) in complex
question-answering (QA) scenarios has always been a research focal point.
Recent studies have attempted to enhance LLMs' performance by combining
step-wise planning with external retrieval. While effective for advanced models
like GPT-3.5, smaller LLMs face challenges in decomposing complex questions,
necessitating supervised fine-tuning. Previous work has relied on manual
annotation and knowledge distillation from teacher LLMs, which are
time-consuming and not accurate enough. In this paper, we introduce a novel
framework for enhancing LLMs' planning capabilities by using planning data
derived from knowledge graphs (KGs). LLMs fine-tuned with this data have
improved planning capabilities, better equipping them to handle complex QA
tasks that involve retrieval. Evaluations on multiple datasets, including our
newly proposed benchmark, highlight the effectiveness of our framework and the
benefits of KG-derived planning data."
"FairX - A comprehensive benchmarking tool for model analysis using fairness, utility, and explainability",https://arxiv.org/abs/2406.14281,2024-06-20,2024-06-21,0.0,0.0,"We present FairX, an open-source Python-based benchmarking tool designed for
the comprehensive analysis of models under the umbrella of fairness, utility,
and eXplainability (XAI). FairX enables users to train benchmarking
bias-mitigation models and evaluate their fairness using a wide array of
fairness metrics, data utility metrics, and generate explanations for model
predictions, all within a unified framework. Existing benchmarking tools do not
have the way to evaluate synthetic data generated from fair generative models,
also they do not have the support for training fair generative models either.
In FairX, we add fair generative models in the collection of our fair-model
library (pre-processing, in-processing, post-processing) and evaluation metrics
for evaluating the quality of synthetic fair data. This version of FairX
supports both tabular and image datasets. It also allows users to provide their
own custom datasets. The open-source FairX benchmarking package is publicly
available at \url{https://github.com/fahim-sikder/FairX}."
Augmenting Query and Passage for Retrieval-Augmented Generation using LLMs for Open-Domain Question Answering,https://arxiv.org/abs/2406.14277,2024-06-20,2024-06-21,0.0,0.0,"Retrieval-augmented generation (RAG) has received much attention for
Open-domain question-answering (ODQA) tasks as a means to compensate for the
parametric knowledge of large language models (LLMs). While previous approaches
focused on processing retrieved passages to remove irrelevant context, they
still rely heavily on the quality of retrieved passages which can degrade if
the question is ambiguous or complex. In this paper, we propose a simple yet
efficient method called question and passage augmentation (QPaug) via LLMs for
open-domain QA. QPaug first decomposes the original questions into
multiple-step sub-questions. By augmenting the original question with detailed
sub-questions and planning, we are able to make the query more specific on what
needs to be retrieved, improving the retrieval performance. In addition, to
compensate for the case where the retrieved passages contain distracting
information or divided opinions, we augment the retrieved passages with
self-generated passages by LLMs to guide the answer extraction. Experimental
results show that QPaug outperforms the previous state-of-the-art and achieves
significant performance gain over existing RAG methods. The source code is
available at \url{https://github.com/kmswin1/QPaug}."
Step-Back Profiling - Distilling User History for Personalized Scientific Writing,https://arxiv.org/abs/2406.14275,2024-06-20,2024-06-21,0.0,0.0,"Large language models (LLM) excel at a variety of natural language processing
tasks, yet they struggle to generate personalized content for individuals,
particularly in real-world scenarios like scientific writing. Addressing this
challenge, we introduce STEP-BACK PROFILING to personalize LLMs by distilling
user history into concise profiles, including essential traits and preferences
of users. To conduct the experiments, we construct a Personalized Scientific
Writing (PSW) dataset to study multi-user personalization. PSW requires the
models to write scientific papers given specialized author groups with diverse
academic backgrounds. As for the results, we demonstrate the effectiveness of
capturing user characteristics via STEP-BACK PROFILING for collaborative
writing. Moreover, our approach outperforms the baselines by up to 3.6 points
on the general personalization benchmark (LaMP), including 7 personalization
LLM tasks. Our ablation studies validate the contributions of different
components in our method and provide insights into our task definition. Our
dataset and code are available at
\url{https://github.com/gersteinlab/step-back-profiling}."
Learning to Discover Knowledge - A Weakly-Supervised Partial Domain Adaptation Approach,https://arxiv.org/abs/2406.14274,2024-06-20,2024-06-21,0.0,0.0,"Domain adaptation has shown appealing performance by leveraging knowledge
from a source domain with rich annotations. However, for a specific target
task, it is cumbersome to collect related and high-quality source domains. In
real-world scenarios, large-scale datasets corrupted with noisy labels are easy
to collect, stimulating a great demand for automatic recognition in a
generalized setting, i.e., weakly-supervised partial domain adaptation
(WS-PDA), which transfers a classifier from a large source domain with noises
in labels to a small unlabeled target domain. As such, the key issues of WS-PDA
are: 1) how to sufficiently discover the knowledge from the noisy labeled
source domain and the unlabeled target domain, and 2) how to successfully adapt
the knowledge across domains. In this paper, we propose a simple yet effective
domain adaptation approach, termed as self-paced transfer classifier learning
(SP-TCL), to address the above issues, which could be regarded as a
well-performing baseline for several generalized domain adaptation tasks. The
proposed model is established upon the self-paced learning scheme, seeking a
preferable classifier for the target domain. Specifically, SP-TCL learns to
discover faithful knowledge via a carefully designed prudent loss function and
simultaneously adapts the learned knowledge to the target domain by iteratively
excluding source examples from training under the self-paced fashion. Extensive
evaluations on several benchmark datasets demonstrate that SP-TCL significantly
outperforms state-of-the-art approaches on several generalized domain
adaptation tasks."
The Impact of AI on Perceived Job Decency and Meaningfulness - A Case Study,https://arxiv.org/abs/2406.14273,2024-06-20,2024-06-21,1.0,0.0,"The proliferation of Artificial Intelligence (AI) in workplaces stands to
change the way humans work, with job satisfaction intrinsically linked to work
life. Existing research on human-AI collaboration tends to prioritize
performance over the experiential aspects of work. In contrast, this paper
explores the impact of AI on job decency and meaningfulness in workplaces.
Through interviews in the Information Technology (IT) domain, we not only
examined the current work environment, but also explored the perceived
evolution of the workplace ecosystem with the introduction of an AI. Findings
from the preliminary exploratory study reveal that respondents tend to
visualize a workplace where humans continue to play a dominant role, even with
the introduction of advanced AIs. In this prospective scenario, AI is seen as
serving as a complement rather than replacing the human workforce. Furthermore,
respondents believe that the introduction of AI will maintain or potentially
increase overall job satisfaction."
Concentration of a sparse Bayesian model with Horseshoe prior in estimating high-dimensional precision matrix,https://arxiv.org/abs/2406.14269,2024-06-20,2024-06-21,0.0,0.0,"Precision matrices are crucial in many fields such as social networks,
neuroscience, and economics, representing the edge structure of Gaussian
graphical models (GGMs), where a zero in an off-diagonal position of the
precision matrix indicates conditional independence between nodes. In
high-dimensional settings where the dimension of the precision matrix \( p \)
exceeds the sample size \( n \) and the matrix is sparse, methods like
graphical Lasso, graphical SCAD, and CLIME are popular for estimating GGMs.
While frequentist methods are well-studied, Bayesian approaches for
(unstructured) sparse precision matrices are less explored. The graphical
horseshoe estimate by \cite{li2019graphical}, applying the global-local
horseshoe prior, shows superior empirical performance, but theoretical work for
sparse precision matrix estimations using shrinkage priors is limited. This
paper addresses these gaps by providing concentration results for the tempered
posterior with the fully specified horseshoe prior in high-dimensional
settings. Moreover, we also provide novel theoretical results for model
misspecification, offering a general oracle inequality for the posterior. A
concise set of simulations is performed to validate our theoretical findings."
Intelligent Interface - Enhancing Lecture Engagement with Didactic Activity Summaries,https://arxiv.org/abs/2406.14266,2024-06-20,2024-06-21,0.0,0.0,"Recently, multiple applications of machine learning have been introduced.
They include various possibilities arising when image analysis methods are
applied to, broadly understood, video streams. In this context, a novel tool,
developed for academic educators to enhance the teaching process by automating,
summarizing, and offering prompt feedback on conducting lectures, has been
developed. The implemented prototype utilizes machine learning-based techniques
to recognise selected didactic and behavioural teachers' features within
lecture video recordings.
  Specifically, users (teachers) can upload their lecture videos, which are
preprocessed and analysed using machine learning models. Next, users can view
summaries of recognized didactic features through interactive charts and
tables. Additionally, stored ML-based prediction results support comparisons
between lectures based on their didactic content. In the developed application
text-based models trained on lecture transcriptions, with enhancements to the
transcription quality, by adopting an automatic speech recognition solution are
applied. Furthermore, the system offers flexibility for (future) integration of
new/additional machine-learning models and software modules for image and video
analysis."
VeriFlow - Modeling Distributions for Neural Network Verification,https://arxiv.org/abs/2406.14265,2024-06-20,2024-06-21,0.0,0.0,"Formal verification has emerged as a promising method to ensure the safety
and reliability of neural networks. Naively verifying a safety property amounts
to ensuring the safety of a neural network for the whole input space
irrespective of any training or test set. However, this also implies that the
safety of the neural network is checked even for inputs that do not occur in
the real-world and have no meaning at all, often resulting in spurious errors.
To tackle this shortcoming, we propose the VeriFlow architecture as a flow
based density model tailored to allow any verification approach to restrict its
search to the some data distribution of interest. We argue that our
architecture is particularly well suited for this purpose because of two major
properties. First, we show that the transformation and log-density function
that are defined by our model are piece-wise affine. Therefore, the model
allows the usage of verifiers based on SMT with linear arithmetic. Second,
upper density level sets (UDL) of the data distribution take the shape of an
$L^p$-ball in the latent space. As a consequence, representations of UDLs
specified by a given probability are effectively computable in latent space.
This allows for SMT and abstract interpretation approaches with fine-grained,
probabilistically interpretable, control regarding on how (a)typical the inputs
subject to verification are."
MEAT - Median-Ensemble Adversarial Training for Improving Robustness and Generalization,https://arxiv.org/abs/2406.14259,2024-06-20,2024-06-21,0.0,0.0,"Self-ensemble adversarial training methods improve model robustness by
ensembling models at different training epochs, such as model weight averaging
(WA). However, previous research has shown that self-ensemble defense methods
in adversarial training (AT) still suffer from robust overfitting, which
severely affects the generalization performance. Empirically, in the late
phases of training, the AT becomes more overfitting to the extent that the
individuals for weight averaging also suffer from overfitting and produce
anomalous weight values, which causes the self-ensemble model to continue to
undergo robust overfitting due to the failure in removing the weight anomalies.
To solve this problem, we aim to tackle the influence of outliers in the weight
space in this work and propose an easy-to-operate and effective Median-Ensemble
Adversarial Training (MEAT) method to solve the robust overfitting phenomenon
existing in self-ensemble defense from the source by searching for the median
of the historical model weights. Experimental results show that MEAT achieves
the best robustness against the powerful AutoAttack and can effectively
allievate the robust overfitting. We further demonstrate that most defense
methods can improve robust generalization and robustness by combining with
MEAT."
Non-Negative Universal Differential Equations With Applications in Systems Biology,https://arxiv.org/abs/2406.14246,2024-06-20,2024-06-21,0.0,0.0,"Universal differential equations (UDEs) leverage the respective advantages of
mechanistic models and artificial neural networks and combine them into one
dynamic model. However, these hybrid models can suffer from unrealistic
solutions, such as negative values for biochemical quantities. We present
non-negative UDE (nUDEs), a constrained UDE variant that guarantees
non-negative values. Furthermore, we explore regularisation techniques to
improve generalisation and interpretability of UDEs."
CityNav - Language-Goal Aerial Navigation Dataset with Geographic Information,https://arxiv.org/abs/2406.14240,2024-06-20,2024-06-21,0.0,0.0,"Vision-and-language navigation (VLN) aims to guide autonomous agents through
real-world environments by integrating visual and linguistic cues. While
substantial progress has been made in understanding these interactive
modalities in ground-level navigation, aerial navigation remains largely
underexplored. This is primarily due to the scarcity of resources suitable for
real-world, city-scale aerial navigation studies. To bridge this gap, we
introduce CityNav, a new dataset for language-goal aerial navigation using a 3D
point cloud representation from real-world cities. CityNav includes 32,637
natural language descriptions paired with human demonstration trajectories,
collected from participants via a new web-based 3D simulator developed for this
research. Each description specifies a navigation goal, leveraging the names
and locations of landmarks within real-world cities. We also provide baseline
models of navigation agents that incorporate an internal 2D spatial map
representing landmarks referenced in the descriptions. We benchmark the latest
aerial navigation baselines and our proposed model on the CityNav dataset. The
results using this dataset reveal the following key findings: (i) Our aerial
agent models trained on human demonstration trajectories outperform those
trained on shortest path trajectories, highlighting the importance of
human-driven navigation strategies; (ii) The integration of a 2D spatial map
significantly enhances navigation efficiency at city scale. Our dataset and
code are available at https://water-cookie.github.io/city-nav-proj/"
Enhancing robustness of data-driven SHM models - adversarial training with circle loss,https://arxiv.org/abs/2406.14232,2024-06-20,2024-06-21,0.0,0.0,"Structural health monitoring (SHM) is critical to safeguarding the safety and
reliability of aerospace, civil, and mechanical infrastructure. Machine
learning-based data-driven approaches have gained popularity in SHM due to
advancements in sensors and computational power. However, machine learning
models used in SHM are vulnerable to adversarial examples -- even small changes
in input can lead to different model outputs. This paper aims to address this
problem by discussing adversarial defenses in SHM. In this paper, we propose an
adversarial training method for defense, which uses circle loss to optimize the
distance between features in training to keep examples away from the decision
boundary. Through this simple yet effective constraint, our method demonstrates
substantial improvements in model robustness, surpassing existing defense
mechanisms."
aeon - a Python toolkit for learning from time series,https://arxiv.org/abs/2406.14231,2024-06-20,2024-06-21,0.0,0.0,"aeon is a unified Python 3 library for all machine learning tasks involving
time series. The package contains modules for time series forecasting,
classification, extrinsic regression and clustering, as well as a variety of
utilities, transformations and distance measures designed for time series data.
aeon also has a number of experimental modules for tasks such as anomaly
detection, similarity search and segmentation. aeon follows the scikit-learn
API as much as possible to help new users and enable easy integration of aeon
estimators with useful tools such as model selection and pipelines. It provides
a broad library of time series algorithms, including efficient implementations
of the very latest advances in research. Using a system of optional
dependencies, aeon integrates a wide variety of packages into a single
interface while keeping the core framework with minimal dependencies. The
package is distributed under the 3-Clause BSD license and is available at
https://github.com/ aeon-toolkit/aeon. This version was submitted to the JMLR
journal on 02 Nov 2023 for v0.5.0 of aeon. At the time of this preprint aeon
has released v0.9.0, and has had substantial changes."
Raising the Bar - Investigating the Values of Large Language Models via Generative Evolving Testing,https://arxiv.org/abs/2406.14230,2024-06-20,2024-06-21,0.0,0.0,"Warning: this paper contains model outputs exhibiting unethical information.
Large Language Models (LLMs) have achieved significant breakthroughs, but their
generated unethical content poses potential risks. Measuring value alignment of
LLMs becomes crucial for their regulation and responsible deployment. Numerous
datasets have been constructed to assess social bias, toxicity, and ethics in
LLMs, but they suffer from evaluation chronoeffect, that is, as models rapidly
evolve, existing data becomes leaked or undemanding, overestimating
ever-developing LLMs. To tackle this problem, we propose GETA, a novel
generative evolving testing approach that dynamically probes the underlying
moral baselines of LLMs. Distinct from previous adaptive testing methods that
rely on static datasets with limited difficulty, GETA incorporates an
iteratively-updated item generator which infers each LLM's moral boundaries and
generates difficulty-tailored testing items, accurately reflecting the true
alignment extent. This process theoretically learns a joint distribution of
item and model response, with item difficulty and value conformity as latent
variables, where the generator co-evolves with the LLM, addressing
chronoeffect. We evaluate various popular LLMs with diverse capabilities and
demonstrate that GETA can create difficulty-matching testing items and more
accurately assess LLMs' values, better consistent with their performance on
unseen OOD and i.i.d. items, laying the groundwork for future evaluation
paradigms."
EvoAgent - Towards Automatic Multi-Agent Generation via Evolutionary Algorithms,https://arxiv.org/abs/2406.14228,2024-06-20,2024-06-21,0.0,0.0,"The rise of powerful large language models (LLMs) has spurred a new trend in
building LLM-based autonomous agents for solving complex tasks, especially
multi-agent systems. Despite the remarkable progress, we notice that existing
works are heavily dependent on human-designed frameworks, which greatly limits
the functional scope and scalability of agent systems. How to automatically
extend the specialized agent to multi-agent systems to improve task-solving
capability still remains a significant challenge. In this paper, we introduce
EvoAgent, a generic method to automatically extend expert agents to multi-agent
systems via the evolutionary algorithm, thereby improving the effectiveness of
LLM-based agents in solving tasks. Specifically, we consider the existing agent
frameworks as the initial individual and then apply a series of evolutionary
operators (e.g., mutation, crossover, selection, etc.) to generate multiple
agents with diverse agent settings. EvoAgent can be generalized to any
LLM-based agent framework, and can automatically extend the existing agent
framework to multi-agent systems without any extra human designs. Experimental
results across various tasks have shown that EvoAgent can automatically
generate multiple expert agents and significantly enhance the task-solving
capabilities of LLM-based agents."
"Evaluation of Deep Learning Semantic Segmentation for Land Cover Mapping on Multispectral, Hyperspectral and High Spatial Aerial Imagery",https://arxiv.org/abs/2406.14220,2024-06-20,2024-06-21,0.0,0.0,"In the rise of climate change, land cover mapping has become such an urgent
need in environmental monitoring. The accuracy of land cover classification has
gotten increasingly based on the improvement of remote sensing data. Land cover
classification using satellite imageries has been explored and become more
prevalent in recent years, but the methodologies remain some drawbacks of
subjective and time-consuming. Some deep learning techniques have been utilized
to overcome these limitations. However, most studies implemented just one image
type to evaluate algorithms for land cover mapping. Therefore, our study
conducted deep learning semantic segmentation in multispectral, hyperspectral,
and high spatial aerial image datasets for landcover mapping. This research
implemented a semantic segmentation method such as Unet, Linknet, FPN, and
PSPnet for categorizing vegetation, water, and others (i.e., soil and
impervious surface). The LinkNet model obtained high accuracy in IoU
(Intersection Over Union) at 0.92 in all datasets, which is comparable with
other mentioned techniques. In evaluation with different image types, the
multispectral images showed higher performance with the IoU, and F1-score are
0.993 and 0.997, respectively. Our outcome highlighted the efficiency and broad
applicability of LinkNet and multispectral image on land cover classification.
This research contributes to establishing an approach on landcover segmentation
via open source for long-term future application."
Proving Olympiad Algebraic Inequalities without Human Demonstrations,https://arxiv.org/abs/2406.14219,2024-06-20,2024-06-21,0.0,0.0,"Solving Olympiad-level mathematical problems represents a significant
advancement in machine intelligence and automated reasoning. Current machine
learning methods, however, struggle to solve Olympiad-level problems beyond
Euclidean plane geometry due to a lack of large-scale, high-quality datasets.
The challenge is even greater in algebraic systems, which involve infinite
reasoning spaces within finite conditions. To address these issues, we propose
AIPS, an Algebraic Inequality Proving System capable of autonomously generating
complex inequality theorems and effectively solving Olympiad-level inequality
problems without requiring human demonstrations. During proof search in a mixed
reasoning manner, a value curriculum learning strategy on generated datasets is
implemented to improve proving performance, demonstrating strong mathematical
intuitions. On a test set of 20 International Mathematical Olympiad-level
inequality problems, AIPS successfully solved 10, outperforming
state-of-the-art methods. Furthermore, AIPS automatically generated a vast
array of non-trivial theorems without human intervention, some of which have
been evaluated by professional contestants and deemed to reach the level of the
International Mathematical Olympiad. Notably, one theorem was selected as a
competition problem in a major city 2024 Mathematical Olympiad."
Defending Against Sophisticated Poisoning Attacks with RL-based Aggregation in Federated Learning,https://arxiv.org/abs/2406.14217,2024-06-20,2024-06-21,0.0,0.0,"Federated learning is highly susceptible to model poisoning attacks,
especially those meticulously crafted for servers. Traditional defense methods
mainly focus on updating assessments or robust aggregation against manually
crafted myopic attacks. When facing advanced attacks, their defense stability
is notably insufficient. Therefore, it is imperative to develop adaptive
defenses against such advanced poisoning attacks. We find that benign clients
exhibit significantly higher data distribution stability than malicious clients
in federated learning in both CV and NLP tasks. Therefore, the malicious
clients can be recognized by observing the stability of their data
distribution. In this paper, we propose AdaAggRL, an RL-based Adaptive
Aggregation method, to defend against sophisticated poisoning attacks.
Specifically, we first utilize distribution learning to simulate the clients'
data distributions. Then, we use the maximum mean discrepancy (MMD) to
calculate the pairwise similarity of the current local model data distribution,
its historical data distribution, and global model data distribution. Finally,
we use policy learning to adaptively determine the aggregation weights based on
the above similarities. Experiments on four real-world datasets demonstrate
that the proposed defense model significantly outperforms widely adopted
defense models for sophisticated attacks."
REVEAL-IT - REinforcement learning with Visibility of Evolving Agent poLicy for InTerpretability,https://arxiv.org/abs/2406.14214,2024-06-20,2024-06-21,0.0,0.0,"Understanding the agent's learning process, particularly the factors that
contribute to its success or failure post-training, is crucial for
comprehending the rationale behind the agent's decision-making process. Prior
methods clarify the learning process by creating a structural causal model
(SCM) or visually representing the distribution of value functions.
Nevertheless, these approaches have constraints as they exclusively function in
2D-environments or with uncomplicated transition dynamics. Understanding the
agent's learning process in complicated environments or tasks is more
challenging. In this paper, we propose REVEAL-IT, a novel framework for
explaining the learning process of an agent in complex environments. Initially,
we visualize the policy structure and the agent's learning process for various
training tasks. By visualizing these findings, we can understand how much a
particular training task or stage affects the agent's performance in test.
Then, a GNN-based explainer learns to highlight the most important section of
the policy, providing a more clear and robust explanation of the agent's
learning process. The experiments demonstrate that explanations derived from
this framework can effectively help in the optimization of the training tasks,
resulting in improved learning efficiency and final performance."
Complexity of Symbolic Representation in Working Memory of Transformer Correlates with the Complexity of a Task,https://arxiv.org/abs/2406.14213,2024-06-20,2024-06-21,0.0,0.0,"Even though Transformers are extensively used for Natural Language Processing
tasks, especially for machine translation, they lack an explicit memory to
store key concepts of processed texts. This paper explores the properties of
the content of symbolic working memory added to the Transformer model decoder.
Such working memory enhances the quality of model predictions in machine
translation task and works as a neural-symbolic representation of information
that is important for the model to make correct translations. The study of
memory content revealed that translated text keywords are stored in the working
memory, pointing to the relevance of memory content to the processed text.
Also, the diversity of tokens and parts of speech stored in memory correlates
with the complexity of the corpora for machine translation task."
Self-Supervised Pretext Tasks for Alzheimer's Disease Classification using 3D Convolutional Neural Networks on Large-Scale Synthetic Neuroimaging Dataset,https://arxiv.org/abs/2406.14210,2024-06-20,2024-06-21,0.0,0.0,"Structural magnetic resonance imaging (MRI) studies have shown that
Alzheimer's Disease (AD) induces both localised and widespread neural
degenerative changes throughout the brain. However, the absence of segmentation
that highlights brain degenerative changes presents unique challenges for
training CNN-based classifiers in a supervised fashion. In this work, we
evaluated several unsupervised methods to train a feature extractor for
downstream AD vs. CN classification. Using the 3D T1-weighted MRI data of
cognitive normal (CN) subjects from the synthetic neuroimaging LDM100K dataset,
lightweight 3D CNN-based models are trained for brain age prediction, brain
image rotation classification, brain image reconstruction and a multi-head task
combining all three tasks into one. Feature extractors trained on the LDM100K
synthetic dataset achieved similar performance compared to the same model using
real-world data. This supports the feasibility of utilising large-scale
synthetic data for pretext task training. All the training and testing splits
are performed on the subject-level to prevent data leakage issues. Alongside
the simple preprocessing steps, the random cropping data augmentation technique
shows consistent improvement across all experiments."
SeCoKD - Aligning Large Language Models for In-Context Learning with Fewer Shots,https://arxiv.org/abs/2406.14208,2024-06-20,2024-06-21,0.0,0.0,"Previous studies have shown that demonstrations can significantly help Large
Language Models (LLMs ) perform better on the given tasks. However, this
so-called In-Context Learning ( ICL ) ability is very sensitive to the
presenting context, and often dozens of demonstrations are needed. In this
work, we investigate if we can reduce the shot number while still maintaining a
competitive performance. We present SeCoKD, a self-Knowledge Distillation ( KD
) training framework that aligns the student model with a heavily prompted
variation, thereby increasing the utilization of a single demonstration. We
experiment with the SeCoKD across three LLMs and six benchmarks focusing mainly
on reasoning tasks. Results show that our method outperforms the base model and
Supervised Fine-tuning ( SFT ), especially in zero-shot and one-shot settings
by 30% and 10%, respectively. Moreover, SeCoKD brings little negative artifacts
when evaluated on new tasks, which is more robust than Supervised Fine-tuning."
LayerMatch - Do Pseudo-labels Benefit All Layers?,https://arxiv.org/abs/2406.14207,2024-06-20,2024-06-21,0.0,0.0,"Deep neural networks have achieved remarkable performance across various
tasks when supplied with large-scale labeled data. However, the collection of
labeled data can be time-consuming and labor-intensive. Semi-supervised
learning (SSL), particularly through pseudo-labeling algorithms that
iteratively assign pseudo-labels for self-training, offers a promising solution
to mitigate the dependency of labeled data. Previous research generally applies
a uniform pseudo-labeling strategy across all model layers, assuming that
pseudo-labels exert uniform influence throughout. Contrasting this, our
theoretical analysis and empirical experiment demonstrate feature extraction
layer and linear classification layer have distinct learning behaviors in
response to pseudo-labels. Based on these insights, we develop two
layer-specific pseudo-label strategies, termed Grad-ReLU and Avg-Clustering.
Grad-ReLU mitigates the impact of noisy pseudo-labels by removing the gradient
detrimental effects of pseudo-labels in the linear classification layer.
Avg-Clustering accelerates the convergence of feature extraction layer towards
stable clustering centers by integrating consistent outputs. Our approach,
LayerMatch, which integrates these two strategies, can avoid the severe
interference of noisy pseudo-labels in the linear classification layer while
accelerating the clustering capability of the feature extraction layer. Through
extensive experimentation, our approach consistently demonstrates exceptional
performance on standard semi-supervised learning benchmarks, achieving a
significant improvement of 10.38% over baseline method and a 2.44% increase
compared to state-of-the-art methods."
On the Representational Capacity of Neural Language Models with Chain-of-Thought Reasoning,https://arxiv.org/abs/2406.14197,2024-06-20,2024-06-21,0.0,0.0,"The performance of modern language models (LMs) has been improved by
chain-of-thought (CoT) reasoning, i.e., the process of generating intermediate
results that guide the model towards a final answer. A possible explanation for
this improvement is that CoT reasoning extends an LM's computational power, as
RNNs and transformers with additional scratch space are known to be Turing
complete. Comparing LMs to Turing machines, however, introduces a category
error - Turing machines decide language membership, whereas LMs define
distributions over strings. To bridge this gap, we formalize CoT reasoning in a
probabilistic setting. We present several results on the representational
capacity of recurrent and transformer LMs with CoT reasoning, showing that they
can represent the same family of distributions over strings as probabilistic
Turing machines."
Timo - Towards Better Temporal Reasoning for Language Models,https://arxiv.org/abs/2406.14192,2024-06-20,2024-06-21,0.0,0.0,"Reasoning about time is essential for Large Language Models (LLMs) to
understand the world. Previous works focus on solving specific tasks, primarily
on time-sensitive question answering. While these methods have proven
effective, they cannot generalize to a wider spectrum of temporal reasoning
tasks. Therefore, we propose a crucial question: Can we build a universal
framework to handle a variety of temporal reasoning tasks? To that end, we
systematically study 38 temporal reasoning tasks. Based on the observation that
19 tasks are directly related to mathematics, we first leverage the available
mathematical dataset to set a solid foundation for temporal reasoning. However,
the in-depth study indicates that focusing solely on mathematical enhancement
falls short of addressing pure temporal reasoning tasks. To mitigate this
limitation, we propose a simple but effective self-critic temporal optimization
method to enhance the model's temporal reasoning capabilities without
sacrificing general task abilities. Finally, we develop Timo, a model designed
to excel in temporal reasoning at the 7B and 13B scales. Notably, Timo
outperforms the counterpart LLMs by 10.0 and 7.6 in average accuracy scores and
achieves the new state-of-the-art (SOTA) performance of comparable size.
Extensive experiments further validate our framework's effectiveness and its
generalization across diverse temporal tasks. The code is available at
https://github.com/zhaochen0110/Timo."
Temporal Knowledge Graph Question Answering - A Survey,https://arxiv.org/abs/2406.14191,2024-06-20,2024-06-21,0.0,0.0,"Knowledge Base Question Answering (KBQA) has been a long-standing field to
answer questions based on knowledge bases. Recently, the evolving dynamics of
knowledge have attracted a growing interest in Temporal Knowledge Graph
Question Answering (TKGQA), an emerging task to answer temporal questions.
However, this field grapples with ambiguities in defining temporal questions
and lacks a systematic categorization of existing methods for TKGQA. In
response, this paper provides a thorough survey from two perspectives: the
taxonomy of temporal questions and the methodological categorization for TKGQA.
Specifically, we first establish a detailed taxonomy of temporal questions
engaged in prior studies. Subsequently, we provide a comprehensive review of
TKGQA techniques of two categories: semantic parsing-based and TKG
embedding-based. Building on this review, the paper outlines potential research
directions aimed at advancing the field of TKGQA. This work aims to serve as a
comprehensive reference for TKGQA and to stimulate further research."
In Tree Structure Should Sentence Be Generated,https://arxiv.org/abs/2406.14189,2024-06-20,2024-06-21,1.0,1.0,"Generative models reliant on sequential autoregression have been at the
forefront of language generation for an extensive period, particularly
following the introduction of widely acclaimed transformers. Despite its
excellent performance, there are always some issues that we face today. For
example, problems such as hallucinations and getting trapped in a logic loop
may occur. To enhance the performance of existing systems, this paper
introduces a new method for generating sequences in natural language, which
involves generating the targeted sentence in a tree-traversing order. The paper
includes an illustration of the theoretical basis and validity of the approach,
as well as a comparison of its fundamentals with the diffusion model in graphic
generation. Finally, a module called SenTree is introduced for generating an
approximating binary tree. It is already available at
https://github.com/arklyg/sentree. Additionally, a joint training framework
based on this approach is proposed, incorporating the intrinsics of generative
adversarial networks."
Latent. Functional Map,https://arxiv.org/abs/2406.14183,2024-06-20,2024-06-21,0.0,0.0,"Neural models learn data representations that lie on low-dimensional
manifolds, yet modeling the relation between these representational spaces is
an ongoing challenge. By integrating spectral geometry principles into neural
modeling, we show that this problem can be better addressed in the functional
domain, mitigating complexity, while enhancing interpretability and
performances on downstream tasks. To this end, we introduce a multi-purpose
framework to the representation learning community, which allows to: (i)
compare different spaces in an interpretable way and measure their intrinsic
similarity; (ii) find correspondences between them, both in unsupervised and
weakly supervised settings, and (iii) to effectively transfer representations
between distinct spaces. We validate our framework on various applications,
ranging from stitching to retrieval tasks, demonstrating that latent functional
maps can serve as a swiss-army knife for representation alignment."
SimulSeamless - FBK at IWSLT 2024 Simultaneous Speech Translation,https://arxiv.org/abs/2406.14177,2024-06-20,2024-06-21,0.0,0.0,"This paper describes the FBK's participation in the Simultaneous Translation
Evaluation Campaign at IWSLT 2024. For this year's submission in the
speech-to-text translation (ST) sub-track, we propose SimulSeamless, which is
realized by combining AlignAtt and SeamlessM4T in its medium configuration. The
SeamlessM4T model is used ""off-the-shelf"" and its simultaneous inference is
enabled through the adoption of AlignAtt, a SimulST policy based on
cross-attention that can be applied without any retraining or adaptation of the
underlying model for the simultaneous task. We participated in all the Shared
Task languages (English->{German, Japanese, Chinese}, and Czech->English),
achieving acceptable or even better results compared to last year's
submissions. SimulSeamless, covering more than 143 source languages and 200
target languages, is released at: https://github.com/hlt-mt/FBK-fairseq/."
A Multi-Stream Fusion Approach with One-Class Learning for Audio-Visual Deepfake Detection,https://arxiv.org/abs/2406.14176,2024-06-20,2024-06-21,0.0,0.0,"This paper addresses the challenge of developing a robust audio-visual
deepfake detection model. In practical use cases, new generation algorithms are
continually emerging, and these algorithms are not encountered during the
development of detection methods. This calls for the generalization ability of
the method. Additionally, to ensure the credibility of detection methods, it is
beneficial for the model to interpret which cues from the video indicate it is
fake. Motivated by these considerations, we then propose a multi-stream fusion
approach with one-class learning as a representation-level regularization
technique. We study the generalization problem of audio-visual deepfake
detection by creating a new benchmark by extending and re-splitting the
existing FakeAVCeleb dataset. The benchmark contains four categories of fake
videos (Real Audio-Fake Visual, Fake Audio-Fake Visual, Fake Audio-Real Visual,
and Unsynchronized videos). The experimental results demonstrate that our
approach surpasses the previous models by a large margin. Furthermore, our
proposed framework offers interpretability, indicating which modality the model
identifies as more likely to be fake. The source code is released at
https://github.com/bok-bok/MSOC."
Ranking LLMs by compression,https://arxiv.org/abs/2406.14171,2024-06-20,2024-06-21,1.0,0.0,"We conceptualize the process of understanding as information compression, and
propose a method for ranking large language models (LLMs) based on lossless
data compression. We demonstrate the equivalence of compression length under
arithmetic coding with cumulative negative log probabilities when using a large
language model as a prior, that is, the pre-training phase of the model is
essentially the process of learning the optimal coding length. At the same
time, the evaluation metric compression ratio can be obtained without actual
compression, which greatly saves overhead. In this paper, we use five large
language models as priors for compression, then compare their performance on
challenging natural language processing tasks, including sentence completion,
question answering, and coreference resolution. Experimental results show that
compression ratio and model performance are positively correlated, so it can be
used as a general metric to evaluate large language models."
Optimizing Novelty of Top-k Recommendations using Large Language Models and Reinforcement Learning,https://arxiv.org/abs/2406.14169,2024-06-20,2024-06-21,0.0,0.0,"Given an input query, a recommendation model is trained using user feedback
data (e.g., click data) to output a ranked list of items. In real-world
systems, besides accuracy, an important consideration for a new model is
novelty of its top-k recommendations w.r.t. an existing deployed model.
However, novelty of top-k items is a difficult goal to optimize a model for,
since it involves a non-differentiable sorting operation on the model's
predictions. Moreover, novel items, by definition, do not have any user
feedback data. Given the semantic capabilities of large language models, we
address these problems using a reinforcement learning (RL) formulation where
large language models provide feedback for the novel items. However, given
millions of candidate items, the sample complexity of a standard RL algorithm
can be prohibitively high. To reduce sample complexity, we reduce the top-k
list reward to a set of item-wise rewards and reformulate the state space to
consist of <query, item> tuples such that the action space is reduced to a
binary decision; and show that this reformulation results in a significantly
lower complexity when the number of items is large. We evaluate the proposed
algorithm on improving novelty for a query-ad recommendation task on a
large-scale search engine. Compared to supervised finetuning on recent <query,
ad> pairs, the proposed RL-based algorithm leads to significant novelty gains
with minimal loss in recall. We obtain similar results on the ORCAS
query-webpage matching dataset and a product recommendation dataset based on
Amazon reviews."
Definition generation for lexical semantic change detection,https://arxiv.org/abs/2406.14167,2024-06-20,2024-06-21,0.0,0.0,"We use contextualized word definitions generated by large language models as
semantic representations in the task of diachronic lexical semantic change
detection (LSCD). In short, generated definitions are used as `senses', and the
change score of a target word is retrieved by comparing their distributions in
two time periods under comparison. On the material of five datasets and three
languages, we show that generated definitions are indeed specific and general
enough to convey a signal sufficient to rank sets of words by the degree of
their semantic change over time. Our approach is on par with or outperforms
prior non-supervised sense-based LSCD methods. At the same time, it preserves
interpretability and allows to inspect the reasons behind a specific shift in
terms of discrete definitions-as-senses. This is another step in the direction
of explainable semantic change modeling."
DIRAS - Efficient LLM-Assisted Annotation of Document Relevance in Retrieval Augmented Generation,https://arxiv.org/abs/2406.14162,2024-06-20,2024-06-21,0.0,0.0,"Retrieval Augmented Generation (RAG) is widely employed to ground responses
to queries on domain-specific documents. But do RAG implementations leave out
important information or excessively include irrelevant information? To allay
these concerns, it is necessary to annotate domain-specific benchmarks to
evaluate information retrieval (IR) performance, as relevance definitions vary
across queries and domains. Furthermore, such benchmarks should be
cost-efficiently annotated to avoid annotation selection bias. In this paper,
we propose DIRAS (Domain-specific Information Retrieval Annotation with
Scalability), a manual-annotation-free schema that fine-tunes open-sourced LLMs
to annotate relevance labels with calibrated relevance probabilities. Extensive
evaluation shows that DIRAS fine-tuned models achieve GPT-4-level performance
on annotating and ranking unseen (query, document) pairs, and is helpful for
real-world RAG development."
Enhancing multivariate post-processed visibility predictions utilizing CAMS forecasts,https://arxiv.org/abs/2406.14159,2024-06-20,2024-06-21,0.0,0.0,"In our contemporary era, meteorological weather forecasts increasingly
incorporate ensemble predictions of visibility - a parameter of great
importance in aviation, maritime navigation, and air quality assessment, with
direct implications for public health. However, this weather variable falls
short of the predictive accuracy achieved for other quantities issued by
meteorological centers. Therefore, statistical post-processing is recommended
to enhance the reliability and accuracy of predictions. By estimating the
predictive distributions of the variables with the aid of historical
observations and forecasts, one can achieve statistical consistency between
true observations and ensemble predictions. Visibility observations, following
the recommendation of the World Meteorological Organization, are typically
reported in discrete values; hence, the predictive distribution of the weather
quantity takes the form of a discrete parametric law. Recent studies
demonstrated that the application of classification algorithms can successfully
improve the skill of such discrete forecasts; however, a frequently emerging
issue is that certain spatial and/or temporal dependencies could be lost
between marginals. Based on visibility ensemble forecasts of the European
Centre for Medium-Range Weather Forecasts for 30 locations in Central Europe,
we investigate whether the inclusion of Copernicus Atmosphere Monitoring
Service (CAMS) predictions of the same weather quantity as an additional
covariate could enhance the skill of the post-processing methods and whether it
contributes to the successful integration of spatial dependence between
marginals. Our study confirms that post-processed forecasts are substantially
superior to raw and climatological predictions, and the utilization of CAMS
forecasts provides a further significant enhancement both in the univariate and
multivariate setup."
Tractable Equilibrium Computation in Markov Games through Risk Aversion,https://arxiv.org/abs/2406.14156,2024-06-20,2024-06-21,0.0,0.0,"A significant roadblock to the development of principled multi-agent
reinforcement learning is the fact that desired solution concepts like Nash
equilibria may be intractable to compute. To overcome this obstacle, we take
inspiration from behavioral economics and show that -- by imbuing agents with
important features of human decision-making like risk aversion and bounded
rationality -- a class of risk-averse quantal response equilibria (RQE) become
tractable to compute in all $n$-player matrix and finite-horizon Markov games.
In particular, we show that they emerge as the endpoint of no-regret learning
in suitably adjusted versions of the games. Crucially, the class of
computationally tractable RQE is independent of the underlying game structure
and only depends on agents' degree of risk-aversion and bounded rationality. To
validate the richness of this class of solution concepts we show that it
captures peoples' patterns of play in a number of 2-player matrix games
previously studied in experimental economics. Furthermore, we give a first
analysis of the sample complexity of computing these equilibria in
finite-horizon Markov games when one has access to a generative model and
validate our findings on a simple multi-agent reinforcement learning benchmark."
Aligning Large Language Models with Diverse Political Viewpoints,https://arxiv.org/abs/2406.14155,2024-06-20,2024-06-21,0.0,0.0,"Large language models such as ChatGPT often exhibit striking political
biases. If users query them about political information, they might take a
normative stance and reinforce such biases. To overcome this, we align LLMs
with diverse political viewpoints from 100,000 comments written by candidates
running for national parliament in Switzerland. Such aligned models are able to
generate more accurate political viewpoints from Swiss parties compared to
commercial models such as ChatGPT. We also propose a procedure to generate
balanced overviews from multiple viewpoints using such models."
Watching the Watchers - A Comparative Fairness Audit of Cloud-based Content Moderation Services,https://arxiv.org/abs/2406.14154,2024-06-20,2024-06-21,0.0,0.0,"Online platforms face the challenge of moderating an ever-increasing volume
of content, including harmful hate speech. In the absence of clear legal
definitions and a lack of transparency regarding the role of algorithms in
shaping decisions on content moderation, there is a critical need for external
accountability. Our study contributes to filling this gap by systematically
evaluating four leading cloud-based content moderation services through a
third-party audit, highlighting issues such as biases against minorities and
vulnerable groups that may arise through over-reliance on these services. Using
a black-box audit approach and four benchmark data sets, we measure performance
in explicit and implicit hate speech detection as well as counterfactual
fairness through perturbation sensitivity analysis and present disparities in
performance for certain target identity groups and data sets. Our analysis
reveals that all services had difficulties detecting implicit hate speech,
which relies on more subtle and codified messages. Moreover, our results point
to the need to remove group-specific bias. It seems that biases towards some
groups, such as Women, have been mostly rectified, while biases towards other
groups, such as LGBTQ+ and PoC remain."
Multi-modal Transfer Learning between Biological Foundation Models,https://arxiv.org/abs/2406.14150,2024-06-20,2024-06-21,0.0,0.0,"Biological sequences encode fundamental instructions for the building blocks
of life, in the form of DNA, RNA, and proteins. Modeling these sequences is key
to understand disease mechanisms and is an active research area in
computational biology. Recently, Large Language Models have shown great promise
in solving certain biological tasks but current approaches are limited to a
single sequence modality (DNA, RNA, or protein). Key problems in genomics
intrinsically involve multiple modalities, but it remains unclear how to adapt
general-purpose sequence models to those cases. In this work we propose a
multi-modal model that connects DNA, RNA, and proteins by leveraging
information from different pre-trained modality-specific encoders. We
demonstrate its capabilities by applying it to the largely unsolved problem of
predicting how multiple RNA transcript isoforms originate from the same gene
(i.e. same DNA sequence) and map to different transcription expression levels
across various human tissues. We show that our model, dubbed IsoFormer, is able
to accurately predict differential transcript expression, outperforming
existing methods and leveraging the use of multiple modalities. Our framework
also achieves efficient transfer knowledge from the encoders pre-training as
well as in between modalities. We open-source our model, paving the way for new
multi-modal gene expression approaches."
CheMFi - A Multifidelity Dataset of Quantum Chemical Properties of Diverse Molecules,https://arxiv.org/abs/2406.14149,2024-06-20,2024-06-21,0.0,0.0,"Progress in both Machine Learning (ML) and Quantum Chemistry (QC) methods
have resulted in high accuracy ML models for QC properties. Datasets such as
MD17 and WS22 have been used to benchmark these models at some level of QC
method, or fidelity, which refers to the accuracy of the chosen QC method.
Multifidelity ML (MFML) methods, where models are trained on data from more
than one fidelity, have shown to be effective over single fidelity methods.
Much research is progressing in this direction for diverse applications ranging
from energy band gaps to excitation energies. One hurdle for effective research
here is the lack of a diverse multifidelity dataset for benchmarking. We
provide the quantum Chemistry MultiFidelity (CheMFi) dataset consisting of five
fidelities calculated with the TD-DFT formalism. The fidelities differ in their
basis set choice: STO-3G, 3-21G, 6-31G, def2-SVP, and def2-TZVP. CheMFi offers
to the community a variety of QC properties such as vertical excitation
properties and molecular dipole moments, further including QC computation times
allowing for a time benefit benchmark of multifidelity models for ML-QC."
Finding Safety Neurons in Large Language Models,https://arxiv.org/abs/2406.14144,2024-06-20,2024-06-21,0.0,0.0,"Large language models (LLMs) excel in various capabilities but also pose
safety risks such as generating harmful content and misinformation, even after
safety alignment. In this paper, we explore the inner mechanisms of safety
alignment from the perspective of mechanistic interpretability, focusing on
identifying and analyzing safety neurons within LLMs that are responsible for
safety behaviors. We propose generation-time activation contrasting to locate
these neurons and dynamic activation patching to evaluate their causal effects.
Experiments on multiple recent LLMs show that: (1) Safety neurons are sparse
and effective. We can restore $90$% safety performance with intervention only
on about $5$% of all the neurons. (2) Safety neurons encode transferrable
mechanisms. They exhibit consistent effectiveness on different red-teaming
datasets. The finding of safety neurons also interprets ""alignment tax"". We
observe that the identified key neurons for safety and helpfulness
significantly overlap, but they require different activation patterns of the
shared neurons. Furthermore, we demonstrate an application of safety neurons in
detecting unsafe outputs before generation. Our findings may promote further
research on understanding LLM alignment. The source codes will be publicly
released to facilitate future research."
Geometric Self-Supervised Pretraining on 3D Protein Structures using Subgraphs,https://arxiv.org/abs/2406.14142,2024-06-20,2024-06-21,0.0,0.0,"Protein representation learning aims to learn informative protein embeddings
capable of addressing crucial biological questions, such as protein function
prediction. Although sequence-based transformer models have shown promising
results by leveraging the vast amount of protein sequence data in a
self-supervised way, there is still a gap in exploiting the available 3D
protein structures. In this work, we propose a pre-training scheme going beyond
trivial masking methods leveraging 3D and hierarchical structures of proteins.
We propose a novel self-supervised method to pretrain 3D graph neural networks
on 3D protein structures, by predicting the distances between local geometric
centroids of protein subgraphs and the global geometric centroid of the
protein. By considering subgraphs and their relationships to the global protein
structure, our model can better learn the geometric properties of the protein
structure. We experimentally show that our proposed pertaining strategy leads
to significant improvements up to 6\%, in the performance of 3D GNNs in various
protein classification tasks. Our work opens new possibilities in unsupervised
learning for protein graph models while eliminating the need for multiple
views, augmentations, or masking strategies which are currently used so far."
Online Learning of Weakly Coupled MDP Policies for Load Balancing and Auto Scaling,https://arxiv.org/abs/2406.14141,2024-06-20,2024-06-21,0.0,0.0,"Load balancing and auto scaling are at the core of scalable, contemporary
systems, addressing dynamic resource allocation and service rate adjustments in
response to workload changes. This paper introduces a novel model and
algorithms for tuning load balancers coupled with auto scalers, considering
bursty traffic arriving at finite queues. We begin by presenting the problem as
a weakly coupled Markov Decision Processes (MDP), solvable via a linear program
(LP). However, as the number of control variables of such LP grows
combinatorially, we introduce a more tractable relaxed LP formulation, and
extend it to tackle the problem of online parameter learning and policy
optimization using a two-timescale algorithm based on the LP Lagrangian."
MACAROON - Training Vision-Language Models To Be Your Engaged Partners,https://arxiv.org/abs/2406.14137,2024-06-20,2024-06-21,0.0,0.0,"Large vision-language models (LVLMs), while proficient in following
instructions and responding to diverse questions, invariably generate detailed
responses even when questions are ambiguous or unanswerable, leading to
hallucinations and bias issues. Thus, it is essential for LVLMs to proactively
engage with humans to ask for clarifications or additional information for
better responses. In this study, we aim to shift LVLMs from passive answer
providers to proactive engaged partners. We begin by establishing a
three-tiered hierarchy for questions of invalid, ambiguous, and personalizable
nature to measure the proactive engagement capabilities of LVLMs. Utilizing
this hierarchy, we create PIE, (ProactIve Engagement Evaluation) through GPT-4o
and human annotators, consisting of 853 questions across six distinct,
fine-grained question types that are verified by human annotators and
accompanied with well-defined metrics. Our evaluations on \benchmark indicate
poor performance of existing LVLMs, with the best-performing open-weights model
only achieving an Aggregate Align Rate (AAR) of 0.28. In response, we introduce
MACAROON, self-iMaginAtion for ContrAstive pReference OptimizatiON, which
instructs LVLMs to autonomously generate contrastive response pairs for
unlabeled questions given the task description and human-crafted criteria.
Then, the self-imagined data is formatted for conditional reinforcement
learning. Experimental results show MACAROON effectively improves LVLMs'
capabilities to be proactively engaged (0.84 AAR) while maintaining comparable
performance on general tasks."
Autonomous Robotic Drilling System for Mice Cranial Window Creation,https://arxiv.org/abs/2406.14135,2024-06-20,2024-06-21,0.0,0.0,"Robotic assistance for experimental manipulation in the life sciences is
expected to enable favorable outcomes, regardless of the skill of the
scientist. Experimental specimens in the life sciences are subject to
individual variability hence require intricate algorithms for successful
autonomous robotic control. As a use case, we are studying the creation of
cranial windows in mice. This operation requires the removal of an
8-mm-circular patch of the skull, which is approximately 300 um thick, but the
shape and thickness of the mouse skull significantly varies depending on the
strain of mouse, sex, and age. In this work, we propose an autonomous robotic
drilling method with no offline planning, consisting of a trajectory planning
block with execution-time feedback with completion level recognition based on
image and force information. The force information allows for completion-level
resolution to increase 10 fold. We evaluate the proposed method in two ways.
First, in an eggshell drilling task and achieved a success rate of 95% and
average drilling time of 7.1 min out of 20 trials. Second, in postmortem mice
and with a success rate of 70% and average drilling time of 9.3 min out of 20
trials."
Enhancing Monotonic Modeling with Spatio-Temporal Adaptive Awareness in Diverse Marketing,https://arxiv.org/abs/2406.14132,2024-06-20,2024-06-21,0.0,0.0,"In the mobile internet era, the Online Food Ordering Service (OFOS) emerges
as an integral component of inclusive finance owing to the convenience it
brings to people. OFOS platforms offer dynamic allocation incentives to users
and merchants through diverse marketing campaigns to encourage payments while
maintaining the platforms' budget efficiency. Despite significant progress, the
marketing domain continues to face two primary challenges: (i) how to allocate
a limited budget with greater efficiency, demanding precision in predicting
users' monotonic response (i.e. sensitivity) to incentives, and (ii) ensuring
spatio-temporal adaptability and robustness in diverse marketing campaigns
across different times and locations. To address these issues, we propose a
Constrained Monotonic Adaptive Network (CoMAN) method for spatio-temporal
perception within marketing pricing. Specifically, we capture spatio-temporal
preferences within attribute features through two foundational spatio-temporal
perception modules. To further enhance catching the user sensitivity
differentials to incentives across varied times and locations, we design
modules for learning spatio-temporal convexity and concavity as well as for
expressing sensitivity functions. CoMAN can achieve a more efficient allocation
of incentive investments during pricing, thus increasing the conversion rate
and orders while maintaining budget efficiency. Extensive offline and online
experimental results within our diverse marketing campaigns demonstrate the
effectiveness of the proposed approach while outperforming the monotonic
state-of-the-art method."
Towards Event-oriented Long Video Understanding,https://arxiv.org/abs/2406.14129,2024-06-20,2024-06-21,0.0,0.0,"With the rapid development of video Multimodal Large Language Models (MLLMs),
numerous benchmarks have been proposed to assess their video understanding
capability. However, due to the lack of rich events in the videos, these
datasets may suffer from the short-cut bias that the answers can be deduced
from a few frames, without the need to watch the entire video. To address this
issue, we introduce Event-Bench, an event-oriented long video understanding
benchmark built on existing datasets and human annotations. Event-Bench
includes six event-related tasks and 2,190 test instances to comprehensively
evaluate video event understanding ability. Additionally, we propose Video
Instruction Merging~(VIM), a cost-effective method that enhances video MLLMs
using merged, event-intensive video instructions, addressing the scarcity of
human-annotated, event-intensive data. Extensive experiments show that the
best-performing model, GPT-4o, achieves an overall accuracy of 53.33,
significantly outperforming the best open-source model by 41.42%. Leveraging an
effective instruction synthesis method and an adaptive model architecture, VIM
surpasses both state-of-the-art open-source models and GPT-4V on the
Event-Bench. All code, data, and models are publicly available at
https://github.com/RUCAIBox/Event-Bench."
Measuring Sample Importance in Data Pruning for Training LLMs from a Data Compression Perspective,https://arxiv.org/abs/2406.14124,2024-06-20,2024-06-21,0.0,0.0,"Compute-efficient training of large language models (LLMs) has become an
important research problem. In this work, we consider data pruning as a method
of data-efficient training of LLMs, where we take a data compression view on
data pruning. We argue that the amount of information of a sample, or the
achievable compression on its description length, represents its sample
importance. The key idea is that, less informative samples are likely to
contain redundant information, and thus should be pruned first. We leverage
log-likelihood function of trained models as a surrogate to measure information
content of samples. Experiments reveal a surprising insight that
information-based pruning can enhance the generalization capability of the
model, improves upon language modeling and downstream tasks as compared to the
model trained on the entire dataset."
EduQate - Generating Adaptive Curricula through RMABs in Education Settings,https://arxiv.org/abs/2406.14122,2024-06-20,2024-06-21,0.0,0.0,"There has been significant interest in the development of personalized and
adaptive educational tools that cater to a student's individual learning
progress. A crucial aspect in developing such tools is in exploring how mastery
can be achieved across a diverse yet related range of content in an efficient
manner. While Reinforcement Learning and Multi-armed Bandits have shown promise
in educational settings, existing works often assume the independence of
learning content, neglecting the prevalent interdependencies between such
content. In response, we introduce Education Network Restless Multi-armed
Bandits (EdNetRMABs), utilizing a network to represent the relationships
between interdependent arms. Subsequently, we propose EduQate, a method
employing interdependency-aware Q-learning to make informed decisions on arm
selection at each time step. We establish the optimality guarantee of EduQate
and demonstrate its efficacy compared to baseline policies, using students
modeled from both synthetic and real-world data."
An Investigation of Prompt Variations for Zero-shot LLM-based Rankers,https://arxiv.org/abs/2406.14117,2024-06-20,2024-06-21,0.0,0.0,"We provide a systematic understanding of the impact of specific components
and wordings used in prompts on the effectiveness of rankers based on zero-shot
Large Language Models (LLMs). Several zero-shot ranking methods based on LLMs
have recently been proposed. Among many aspects, methods differ across (1) the
ranking algorithm they implement, e.g., pointwise vs. listwise, (2) the
backbone LLMs used, e.g., GPT3.5 vs. FLAN-T5, (3) the components and wording
used in prompts, e.g., the use or not of role-definition (role-playing) and the
actual words used to express this. It is currently unclear whether performance
differences are due to the underlying ranking algorithm, or because of spurious
factors such as better choice of words used in prompts. This confusion risks to
undermine future research. Through our large-scale experimentation and
analysis, we find that ranking algorithms do contribute to differences between
methods for zero-shot LLM ranking. However, so do the LLM backbones -- but even
more importantly, the choice of prompt components and wordings affect the
ranking. In fact, in our experiments, we find that, at times, these latter
elements have more impact on the ranker's effectiveness than the actual ranking
algorithms, and that differences among ranking methods become more blurred when
prompt variations are considered."
Take the essence and discard the dross - A Rethinking on Data Selection for Fine-Tuning Large Language Models,https://arxiv.org/abs/2406.14115,2024-06-20,2024-06-21,0.0,0.0,"Data selection for fine-tuning Large Language Models (LLMs) aims to select a
high-quality subset from a given candidate dataset to train a Pending Fine-tune
Model (PFM) into a Selective-Enhanced Model (SEM). It can improve the model
performance and accelerate the training process. Although a few surveys have
investigated related works of data selection, there is a lack of comprehensive
comparison between existing methods due to their various experimental settings.
To address this issue, we first propose a three-stage scheme for data selection
and comprehensively review existing works according to this scheme. Then, we
design a unified comparing method with ratio-based efficiency indicators and
ranking-based feasibility indicators to overcome the difficulty of comparing
various models with diverse experimental settings. After an in-depth
comparative analysis, we find that the more targeted method with data-specific
and model-specific quality labels has higher efficiency, but the introduction
of additional noise information should be avoided when designing selection
algorithms. Finally, we summarize the trends in data selection and highlight
the short-term and long-term challenges to guide future research."
Expander Hierarchies for Normalized Cuts on Graphs,https://arxiv.org/abs/2406.14111,2024-06-20,2024-06-21,0.0,0.0,"Expander decompositions of graphs have significantly advanced the
understanding of many classical graph problems and led to numerous fundamental
theoretical results. However, their adoption in practice has been hindered due
to their inherent intricacies and large hidden factors in their asymptotic
running times. Here, we introduce the first practically efficient algorithm for
computing expander decompositions and their hierarchies and demonstrate its
effectiveness and utility by incorporating it as the core component in a novel
solver for the normalized cut graph clustering objective.
  Our extensive experiments on a variety of large graphs show that our
expander-based algorithm outperforms state-of-the-art solvers for normalized
cut with respect to solution quality by a large margin on a variety of graph
classes such as citation, e-mail, and social networks or web graphs while
remaining competitive in running time."
EasyECR - A Library for Easy Implementation and Evaluation of Event Coreference Resolution Models,https://arxiv.org/abs/2406.14106,2024-06-20,2024-06-21,0.0,0.0,"Event Coreference Resolution (ECR) is the task of clustering event mentions
that refer to the same real-world event. Despite significant advancements, ECR
research faces two main challenges: limited generalizability across domains due
to narrow dataset evaluations, and difficulties in comparing models within
diverse ECR pipelines. To address these issues, we develop EasyECR, the first
open-source library designed to standardize data structures and abstract ECR
pipelines for easy implementation and fair evaluation. More specifically,
EasyECR integrates seven representative pipelines and ten popular benchmark
datasets, enabling model evaluations on various datasets and promoting the
development of robust ECR pipelines. By conducting extensive evaluation via our
EasyECR, we find that, \lowercase\expandafter{\romannumeral1}) the
representative ECR pipelines cannot generalize across multiple datasets, hence
evaluating ECR pipelines on multiple datasets is necessary,
\lowercase\expandafter{\romannumeral2}) all models in ECR pipelines have a
great effect on pipeline performance, therefore, when one model in ECR
pipelines are compared, it is essential to ensure that the other models remain
consistent. Additionally, reproducing ECR results is not trivial, and the
developed library can help reduce this discrepancy. The experimental results
provide valuable baselines for future research."
Two-Stage Depth Enhanced Learning with Obstacle Map For Object Navigation,https://arxiv.org/abs/2406.14103,2024-06-20,2024-06-21,0.0,0.0,"The task that requires an agent to navigate to a given object through only
visual observation is called visual object navigation (VON). The main
bottlenecks of VON are strategies exploration and prior knowledge exploitation.
Traditional strategies exploration ignores the differences of searching and
navigating stages, using the same reward in two stages, which reduces
navigation performance and training efficiency. Our study enables the agent to
explore larger area in searching stage and seek the optimal path in navigating
stage, improving the success rate of navigation. Traditional prior knowledge
exploitation focused on learning and utilizing object association, which
ignored the depth and obstacle information in the environment. This paper uses
the RGB and depth information of the training scene to pretrain the feature
extractor, which improves navigation efficiency. The obstacle information is
memorized by the agent during the navigation, reducing the probability of
collision and deadlock. Depth, obstacle and other prior knowledge are
concatenated and input into the policy network, and navigation actions are
output under the training of two-stage rewards. We evaluated our method on
AI2-Thor and RoboTHOR and demonstrated that it significantly outperforms
state-of-the-art (SOTA) methods on success rate and navigation efficiency."
Let Guidelines Guide You - A Prescriptive Guideline-Centered Data Annotation Methodology,https://arxiv.org/abs/2406.14099,2024-06-20,2024-06-21,0.0,0.0,"We introduce the Guideline-Centered annotation process, a novel data
annotation methodology focused on reporting the annotation guidelines
associated with each data sample. We identify three main limitations of the
standard prescriptive annotation process and describe how the
Guideline-Centered methodology overcomes them by reducing the loss of
information in the annotation process and ensuring adherence to guidelines.
Additionally, we discuss how the Guideline-Centered enables the reuse of
annotated data across multiple tasks at the cost of a single human-annotation
process."
Enhancing the LLM-Based Robot Manipulation Through Human-Robot Collaboration,https://arxiv.org/abs/2406.14097,2024-06-20,2024-06-21,0.0,0.0,"Large Language Models (LLMs) are gaining popularity in the field of robotics.
However, LLM-based robots are limited to simple, repetitive motions due to the
poor integration between language models, robots, and the environment. This
paper proposes a novel approach to enhance the performance of LLM-based
autonomous manipulation through Human-Robot Collaboration (HRC). The approach
involves using a prompted GPT-4 language model to decompose high-level language
commands into sequences of motions that can be executed by the robot. The
system also employs a YOLO-based perception algorithm, providing visual cues to
the LLM, which aids in planning feasible motions within the specific
environment. Additionally, an HRC method is proposed by combining teleoperation
and Dynamic Movement Primitives (DMP), allowing the LLM-based robot to learn
from human guidance. Real-world experiments have been conducted using the
Toyota Human Support Robot for manipulation tasks. The outcomes indicate that
tasks requiring complex trajectory planning and reasoning over environments can
be efficiently accomplished through the incorporation of human demonstrations."
Graph Neural Networks for Job Shop Scheduling Problems - A Survey,https://arxiv.org/abs/2406.14096,2024-06-20,2024-06-21,0.0,0.0,"Job shop scheduling problems (JSSPs) represent a critical and challenging
class of combinatorial optimization problems. Recent years have witnessed a
rapid increase in the application of graph neural networks (GNNs) to solve
JSSPs, albeit lacking a systematic survey of the relevant literature. This
paper aims to thoroughly review prevailing GNN methods for different types of
JSSPs and the closely related flow-shop scheduling problems (FSPs), especially
those leveraging deep reinforcement learning (DRL). We begin by presenting the
graph representations of various JSSPs, followed by an introduction to the most
commonly used GNN architectures. We then review current GNN-based methods for
each problem type, highlighting key technical elements such as graph
representations, GNN architectures, GNN tasks, and training algorithms.
Finally, we summarize and analyze the advantages and limitations of GNNs in
solving JSSPs and provide potential future research opportunities. We hope this
survey can motivate and inspire innovative approaches for more powerful
GNN-based approaches in tackling JSSPs and other scheduling problems."
Memory-Efficient Gradient Unrolling for Large-Scale Bi-level Optimization,https://arxiv.org/abs/2406.14095,2024-06-20,2024-06-21,0.0,0.0,"Bi-level optimization (BO) has become a fundamental mathematical framework
for addressing hierarchical machine learning problems. As deep learning models
continue to grow in size, the demand for scalable bi-level optimization
solutions has become increasingly critical. Traditional gradient-based bi-level
optimization algorithms, due to their inherent characteristics, are ill-suited
to meet the demands of large-scale applications. In this paper, we introduce
$\textbf{F}$orward $\textbf{G}$radient $\textbf{U}$nrolling with
$\textbf{F}$orward $\textbf{F}$radient, abbreviated as
$(\textbf{FG})^2\textbf{U}$, which achieves an unbiased stochastic
approximation of the meta gradient for bi-level optimization.
$(\text{FG})^2\text{U}$ circumvents the memory and approximation issues
associated with classical bi-level optimization approaches, and delivers
significantly more accurate gradient estimates than existing large-scale
bi-level optimization approaches. Additionally, $(\text{FG})^2\text{U}$ is
inherently designed to support parallel computing, enabling it to effectively
leverage large-scale distributed computing systems to achieve significant
computational efficiency. In practice, $(\text{FG})^2\text{U}$ and other
methods can be strategically placed at different stages of the training process
to achieve a more cost-effective two-phase paradigm. Further,
$(\text{FG})^2\text{U}$ is easy to implement within popular deep learning
frameworks, and can be conveniently adapted to address more challenging
zeroth-order bi-level optimization scenarios. We provide a thorough convergence
analysis and a comprehensive practical discussion for $(\text{FG})^2\text{U}$,
complemented by extensive empirical evaluations, showcasing its superior
performance in diverse large-scale bi-level optimization tasks."
Seamless Language Expansion - Enhancing Multilingual Mastery in Self-Supervised Models,https://arxiv.org/abs/2406.14092,2024-06-20,2024-06-21,0.0,0.0,"Self-supervised (SSL) models have shown great performance in various
downstream tasks. However, they are typically developed for limited languages,
and may encounter new languages in real-world. Developing a SSL model for each
new language is costly. Thus, it is vital to figure out how to efficiently
adapt existed SSL models to a new language without impairing its original
abilities. We propose adaptation methods which integrate LoRA to existed SSL
models to extend new language. We also develop preservation strategies which
include data combination and re-clustering to retain abilities on existed
languages. Applied to mHuBERT, we investigate their effectiveness on speech
re-synthesis task. Experiments show that our adaptation methods enable mHuBERT
to be applied to a new language (Mandarin) with MOS value increased about 1.6
and the relative value of WER reduced up to 61.72%. Also, our preservation
strategies ensure that the performance on both existed and new languages
remains intact."
Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models,https://arxiv.org/abs/2406.14091,2024-06-20,2024-06-21,0.0,0.0,"Although language models (LMs) demonstrate exceptional capabilities on
various tasks, they are potentially vulnerable to extraction attacks, which
represent a significant privacy risk. To mitigate the privacy concerns of LMs,
machine unlearning has emerged as an important research area, which is utilized
to induce the LM to selectively forget about some of its training data. While
completely retraining the model will guarantee successful unlearning and
privacy assurance, it is impractical for LMs, as it would be time-consuming and
resource-intensive. Prior works efficiently unlearn the target token sequences,
but upon subsequent iterations, the LM displays significant degradation in
performance. In this work, we propose Privacy Protection via Optimal Parameters
(POP), a novel unlearning method that effectively forgets the target token
sequences from the pretrained LM by applying optimal gradient updates to the
parameters. Inspired by the gradient derivation of complete retraining, we
approximate the optimal training objective that successfully unlearns the
target sequence while retaining the knowledge from the rest of the training
data. Experimental results demonstrate that POP exhibits remarkable retention
performance post-unlearning across 9 classification and 4 dialogue benchmarks,
outperforming the state-of-the-art by a large margin. Furthermore, we introduce
Remnant Memorization Accuracy that quantifies privacy risks based on token
likelihood and validate its effectiveness through both qualitative and
quantitative analyses."
Personalized Music Recommendation with a Heterogeneity-aware Deep Bayesian Network,https://arxiv.org/abs/2406.14090,2024-06-20,2024-06-21,0.0,0.0,"Music recommender systems are crucial in music streaming platforms, providing
users with music they would enjoy. Recent studies have shown that user emotions
can affect users' music mood preferences. However, existing emotion-aware music
recommender systems (EMRSs) explicitly or implicitly assume that users' actual
emotional states expressed by an identical emotion word are homogeneous. They
also assume that users' music mood preferences are homogeneous under an
identical emotional state. In this article, we propose four types of
heterogeneity that an EMRS should consider: emotion heterogeneity across users,
emotion heterogeneity within a user, music mood preference heterogeneity across
users, and music mood preference heterogeneity within a user. We further
propose a Heterogeneity-aware Deep Bayesian Network (HDBN) to model these
assumptions. The HDBN mimics a user's decision process to choose music with
four components: personalized prior user emotion distribution modeling,
posterior user emotion distribution modeling, user grouping, and Bayesian
neural network-based music mood preference prediction. We constructed a
large-scale dataset called EmoMusicLJ to validate our method. Extensive
experiments demonstrate that our method significantly outperforms baseline
approaches on widely used HR and NDCG recommendation metrics. Ablation
experiments and case studies further validate the effectiveness of our HDBN.
The source code is available at https://github.com/jingrk/HDBN."
ReaLHF - Optimized RLHF Training for Large Language Models through Parameter Reallocation,https://arxiv.org/abs/2406.14088,2024-06-20,2024-06-21,0.0,0.0,"Reinforcement Learning from Human Feedback (RLHF) stands as a pivotal
technique in empowering large language model (LLM) applications. Since RLHF
involves diverse computational workloads and intricate dependencies among
multiple LLMs, directly adopting parallelization techniques from supervised
training can result in sub-optimal performance. To overcome this limitation, we
propose a novel approach named parameter ReaLlocation, which dynamically
redistributes LLM parameters in the cluster and adapts parallelization
strategies during training. Building upon this idea, we introduce ReaLHF, a
pioneering system capable of automatically discovering and running efficient
execution plans for RLHF training given the desired algorithmic and hardware
configurations. ReaLHF formulates the execution plan for RLHF as an augmented
dataflow graph. Based on this formulation, ReaLHF employs a tailored search
algorithm with a lightweight cost estimator to discover an efficient execution
plan. Subsequently, the runtime engine deploys the selected plan by effectively
parallelizing computations and redistributing parameters. We evaluate ReaLHF on
the LLaMA-2 models with up to $4\times70$ billion parameters and 128 GPUs. The
experiment results showcase ReaLHF's substantial speedups of $2.0-10.6\times$
compared to baselines. Furthermore, the execution plans generated by ReaLHF
exhibit an average of $26\%$ performance improvement over heuristic approaches
based on Megatron-LM. The source code of ReaLHF is publicly available at
https://github.com/openpsi-project/ReaLHF ."
Semi Supervised Heterogeneous Domain Adaptation via Disentanglement and Pseudo-Labelling,https://arxiv.org/abs/2406.14087,2024-06-20,2024-06-21,0.0,0.0,"Semi-supervised domain adaptation methods leverage information from a source
labelled domain with the goal of generalizing over a scarcely labelled target
domain. While this setting already poses challenges due to potential
distribution shifts between domains, an even more complex scenario arises when
source and target data differs in modality representation (e.g. they are
acquired by sensors with different characteristics). For instance, in remote
sensing, images may be collected via various acquisition modes (e.g. optical or
radar), different spectral characteristics (e.g. RGB or multi-spectral) and
spatial resolutions. Such a setting is denoted as Semi-Supervised Heterogeneous
Domain Adaptation (SSHDA) and it exhibits an even more severe distribution
shift due to modality heterogeneity across domains.To cope with the challenging
SSHDA setting, here we introduce SHeDD (Semi-supervised Heterogeneous Domain
Adaptation via Disentanglement) an end-to-end neural framework tailored to
learning a target domain classifier by leveraging both labelled and unlabelled
data from heterogeneous data sources. SHeDD is designed to effectively
disentangle domain-invariant representations, relevant for the downstream task,
from domain-specific information, that can hinder the cross-modality transfer.
Additionally, SHeDD adopts an augmentation-based consistency regularization
mechanism that takes advantages of reliable pseudo-labels on the unlabelled
target samples to further boost its generalization ability on the target
domain. Empirical evaluations on two remote sensing benchmarks, encompassing
heterogeneous data in terms of acquisition modes and spectral/spatial
resolutions, demonstrate the quality of SHeDD compared to both baseline and
state-of-the-art competing approaches. Our code is publicly available here:
https://github.com/tanodino/SSHDA/"
Seg-LSTM - Performance of xLSTM for Semantic Segmentation of Remotely Sensed Images,https://arxiv.org/abs/2406.14086,2024-06-20,2024-06-21,0.0,0.0,"Recent advancements in autoregressive networks with linear complexity have
driven significant research progress, demonstrating exceptional performance in
large language models. A representative model is the Extended Long Short-Term
Memory (xLSTM), which incorporates gating mechanisms and memory structures,
performing comparably to Transformer architectures in long-sequence language
tasks. Autoregressive networks such as xLSTM can utilize image serialization to
extend their application to visual tasks such as classification and
segmentation. Although existing studies have demonstrated Vision-LSTM's
impressive results in image classification, its performance in image semantic
segmentation remains unverified. Our study represents the first attempt to
evaluate the effectiveness of Vision-LSTM in the semantic segmentation of
remotely sensed images. This evaluation is based on a specifically designed
encoder-decoder architecture named Seg-LSTM, and comparisons with
state-of-the-art segmentation networks. Our study found that Vision-LSTM's
performance in semantic segmentation was limited and generally inferior to
Vision-Transformers-based and Vision-Mamba-based models in most comparative
tests. Future research directions for enhancing Vision-LSTM are recommended.
The source code is available from https://github.com/zhuqinfeng1999/Seg-LSTM."
Teaching Models To Survive - Proper Scoring Rule and Stochastic Optimization with Competing Risks,https://arxiv.org/abs/2406.14085,2024-06-20,2024-06-21,0.0,0.0,"When data are right-censored, i.e. some outcomes are missing due to a limited
period of observation, survival analysis can compute the ""time to event"".
Multiple classes of outcomes lead to a classification variant: predicting the
most likely event, known as competing risks, which has been less studied. To
build a loss that estimates outcome probabilities for such settings, we
introduce a strictly proper censoring-adjusted separable scoring rule that can
be optimized on a subpart of the data because the evaluation is made
independently of observations. It enables stochastic optimization for competing
risks which we use to train gradient boosting trees. Compared to 11
state-of-the-art models, this model, MultiIncidence, performs best in
estimating the probability of outcomes in survival and competing risks. It can
predict at any time horizon and is much faster than existing alternatives."
FLoCoRA - Federated learning compression with low-rank adaptation,https://arxiv.org/abs/2406.14082,2024-06-20,2024-06-21,0.0,0.0,"Low-Rank Adaptation (LoRA) methods have gained popularity in efficient
parameter fine-tuning of models containing hundreds of billions of parameters.
In this work, instead, we demonstrate the application of LoRA methods to train
small-vision models in Federated Learning (FL) from scratch. We first propose
an aggregation-agnostic method to integrate LoRA within FL, named FLoCoRA,
showing that the method is capable of reducing communication costs by 4.8
times, while having less than 1% accuracy degradation, for a CIFAR-10
classification task with a ResNet-8. Next, we show that the same method can be
extended with an affine quantization scheme, dividing the communication cost by
18.6 times, while comparing it with the standard method, with still less than
1% of accuracy loss, tested with on a ResNet-18 model. Our formulation
represents a strong baseline for message size reduction, even when compared to
conventional model compression works, while also reducing the training memory
requirements due to the low-rank adaptation."
EXCEEDS - Extracting Complex Events as Connecting the Dots to Graphs in Scientific Domain,https://arxiv.org/abs/2406.14075,2024-06-20,2024-06-21,0.0,0.0,"It is crucial to utilize events to understand a specific domain. There are
lots of research on event extraction in many domains such as news, finance and
biology domain. However, scientific domain still lacks event extraction
research, including comprehensive datasets and corresponding methods. Compared
to other domains, scientific domain presents two characteristics: denser
nuggets and more complex events. To solve the above problem, considering these
two characteristics, we first construct SciEvents, a large-scale multi-event
document-level dataset with a schema tailored for scientific domain. It has
2,508 documents and 24,381 events under refined annotation and quality control.
Then, we propose EXCEEDS, a novel end-to-end scientific event extraction
framework by storing dense nuggets in a grid matrix and simplifying complex
event extraction into a dot construction and connection task. Experimental
results demonstrate state-of-the-art performances of EXCEEDS on SciEvents.
Additionally, we release SciEvents and EXCEEDS on GitHub."
Exploring Layerwise Adversarial Robustness Through the Lens of t-SNE,https://arxiv.org/abs/2406.14073,2024-06-20,2024-06-21,0.0,0.0,"Adversarial examples, designed to trick Artificial Neural Networks (ANNs)
into producing wrong outputs, highlight vulnerabilities in these models.
Exploring these weaknesses is crucial for developing defenses, and so, we
propose a method to assess the adversarial robustness of image-classifying
ANNs. The t-distributed Stochastic Neighbor Embedding (t-SNE) technique is used
for visual inspection, and a metric, which compares the clean and perturbed
embeddings, helps pinpoint weak spots in the layers. Analyzing two ANNs on
CIFAR-10, one designed by humans and another via NeuroEvolution, we found that
differences between clean and perturbed representations emerge early on, in the
feature extraction layers, affecting subsequent classification. The findings
with our metric are supported by the visual analysis of the t-SNE maps."
Bayesian Bandit Algorithms with Approximate Inference in Stochastic Linear Bandits,https://arxiv.org/abs/2406.14071,2024-06-20,2024-06-21,0.0,0.0,"Bayesian bandit algorithms with approximate Bayesian inference have been
widely used in real-world applications. Nevertheless, their theoretical
justification is less investigated in the literature, especially for contextual
bandit problems. To fill this gap, we propose a general theoretical framework
to analyze stochastic linear bandits in the presence of approximate inference
and conduct regret analysis on two Bayesian bandit algorithms, Linear Thompson
sampling (LinTS) and the extension of Bayesian Upper Confidence Bound, namely
Linear Bayesian Upper Confidence Bound (LinBUCB). We demonstrate that both
LinTS and LinBUCB can preserve their original rates of regret upper bound but
with a sacrifice of larger constant terms when applied with approximate
inference. These results hold for general Bayesian inference approaches, under
the assumption that the inference error measured by two different
$\alpha$-divergences is bounded. Additionally, by introducing a new definition
of well-behaved distributions, we show that LinBUCB improves the regret rate of
LinTS from $\tilde{O}(d^{3/2}\sqrt{T})$ to $\tilde{O}(d\sqrt{T})$, matching the
minimax optimal rate. To our knowledge, this work provides the first regret
bounds in the setting of stochastic linear bandits with bounded approximate
inference errors."
Optimizing Speculative Decoding for Serving Large Language Models Using Goodput,https://arxiv.org/abs/2406.14066,2024-06-20,2024-06-21,0.0,0.0,"Reducing the inference latency of large language models (LLMs) is crucial,
and speculative decoding (SD) stands out as one of the most effective
techniques. Rather than letting the LLM generate all tokens directly,
speculative decoding employs effective proxies to predict potential outputs,
which are then verified by the LLM without compromising the generation quality.
Yet, deploying SD in real online LLM serving systems (with continuous batching)
does not always yield improvement -- under higher request rates or low
speculation accuracy, it paradoxically increases latency. Furthermore, there is
no best speculation length work for all workloads under different system loads.
Based on the observations, we develop a dynamic framework SmartSpec. SmartSpec
dynamically determines the best speculation length for each request (from 0,
i.e., no speculation, to many tokens) -- hence the associated speculative
execution costs -- based on a new metric called goodput, which characterizes
the current observed load of the entire system and the speculation accuracy. We
show that SmartSpec consistently reduces average request latency by up to 3.2x
compared to non-speculative decoding baselines across different sizes of target
models, draft models, request rates, and datasets. Moreover, SmartSpec can be
applied to different styles of speculative decoding, including traditional,
model-based approaches as well as model-free methods like prompt lookup and
tree-style decoding."
Tracking solutions of time-varying variational inequalities,https://arxiv.org/abs/2406.14059,2024-06-20,2024-06-21,0.0,0.0,"Tracking the solution of time-varying variational inequalities is an
important problem with applications in game theory, optimization, and machine
learning. Existing work considers time-varying games or time-varying
optimization problems. For strongly convex optimization problems or strongly
monotone games, these results provide tracking guarantees under the assumption
that the variation of the time-varying problem is restrained, that is, problems
with a sublinear solution path. In this work we extend existing results in two
ways: In our first result, we provide tracking bounds for (1) variational
inequalities with a sublinear solution path but not necessarily monotone
functions, and (2) for periodic time-varying variational inequalities that do
not necessarily have a sublinear solution path-length. Our second main
contribution is an extensive study of the convergence behavior and trajectory
of discrete dynamical systems of periodic time-varying VI. We show that these
systems can exhibit provably chaotic behavior or can converge to the solution.
Finally, we illustrate our theoretical results with experiments."
How Many Parameters Does it Take to Change a Light Bulb? Evaluating Performance in Self-Play of Conversational Games as a Function of Model Characteristics,https://arxiv.org/abs/2406.14051,2024-06-20,2024-06-21,0.0,0.0,"What makes a good Large Language Model (LLM)? That it performs well on the
relevant benchmarks -- which hopefully measure, with some validity, the
presence of capabilities that are also challenged in real application. But what
makes the model perform well? What gives a model its abilities? We take a
recently introduced type of benchmark that is meant to challenge capabilities
in a goal-directed, agentive context through self-play of conversational games,
and analyse how performance develops as a function of model characteristics
like number of parameters, or type of training. We find that while there is a
clear relationship between number of parameters and performance, there is still
a wide spread of performance points within a given size bracket, which is to be
accounted for by training parameters such as fine-tuning data quality and
method. From a more practical angle, we also find a certain degree of
unpredictability about performance across access methods, possible due to
unexposed sampling parameters, and a, very welcome, performance stability
against at least moderate weight quantisation during inference."
Prompt Injection Attacks in Defended Systems,https://arxiv.org/abs/2406.14048,2024-06-20,2024-06-21,0.0,0.0,"Large language models play a crucial role in modern natural language
processing technologies. However, their extensive use also introduces potential
security risks, such as the possibility of black-box attacks. These attacks can
embed hidden malicious features into the model, leading to adverse consequences
during its deployment.
  This paper investigates methods for black-box attacks on large language
models with a three-tiered defense mechanism. It analyzes the challenges and
significance of these attacks, highlighting their potential implications for
language processing system security. Existing attack and defense methods are
examined, evaluating their effectiveness and applicability across various
scenarios.
  Special attention is given to the detection algorithm for black-box attacks,
identifying hazardous vulnerabilities in language models and retrieving
sensitive information. This research presents a methodology for vulnerability
detection and the development of defensive strategies against black-box attacks
on large language models."
Constrained Meta Agnostic Reinforcement Learning,https://arxiv.org/abs/2406.14047,2024-06-20,2024-06-21,0.0,0.0,"Meta-Reinforcement Learning (Meta-RL) aims to acquire meta-knowledge for
quick adaptation to diverse tasks. However, applying these policies in
real-world environments presents a significant challenge in balancing rapid
adaptability with adherence to environmental constraints. Our novel approach,
Constraint Model Agnostic Meta Learning (C-MAML), merges meta learning with
constrained optimization to address this challenge. C-MAML enables rapid and
efficient task adaptation by incorporating task-specific constraints directly
into its meta-algorithm framework during the training phase. This fusion
results in safer initial parameters for learning new tasks. We demonstrate the
effectiveness of C-MAML in simulated locomotion with wheeled robot tasks of
varying complexity, highlighting its practicality and robustness in dynamic
environments."
Understanding Different Design Choices in Training Large Time Series Models,https://arxiv.org/abs/2406.14045,2024-06-20,2024-06-21,1.0,0.0,"Inspired by Large Language Models (LLMs), Time Series Forecasting (TSF), a
long-standing task in time series analysis, is undergoing a transition towards
Large Time Series Models (LTSMs), aiming to train universal transformer-based
models for TSF. However, training LTSMs on heterogeneous time series data poses
unique challenges, including diverse frequencies, dimensions, and patterns
across datasets. Recent endeavors have studied and evaluated various design
choices aimed at enhancing LTSM training and generalization capabilities,
spanning pre-processing techniques, model configurations, and dataset
configurations. In this work, we comprehensively analyze these design choices
and aim to identify the best practices for training LTSM. Moreover, we propose
\emph{time series prompt}, a novel statistical prompting strategy tailored to
time series data. Furthermore, based on the observations in our analysis, we
introduce \texttt{LTSM-bundle}, which bundles the best design choices we have
identified. Empirical results demonstrate that \texttt{LTSM-bundle} achieves
superior zero-shot and few-shot performances compared to state-of-the-art LSTMs
and traditional TSF methods on benchmark datasets."
Encoder-Decoder Neural Networks in Interpretation of X-ray Spectra,https://arxiv.org/abs/2406.14044,2024-06-20,2024-06-21,0.0,0.0,"Encoder--decoder neural networks (EDNN) condense information most relevant to
the output of the feedforward network to activation values at a bottleneck
layer. We study the use of this architecture in emulation and interpretation of
simulated X-ray spectroscopic data with the aim to identify key structural
characteristics for the spectra, previously studied using emulator-based
component analysis (ECA). We find an EDNN to outperform ECA in covered target
variable variance, but also discover complications in interpreting the latent
variables in physical terms. As a compromise of the benefits of these two
approaches, we develop a network where the linear projection of ECA is used,
thus maintaining the beneficial characteristics of vector expansion from the
latent variables for their interpretation. These results underline the
necessity of information recovery after its condensation and identification of
decisive structural degrees of freedom for the output spectra for a justified
interpretation."
Taxonomy-Guided Zero-Shot Recommendations with LLMs,https://arxiv.org/abs/2406.14043,2024-06-20,2024-06-21,0.0,0.0,"With the emergence of large language models (LLMs) and their ability to
perform a variety of tasks, their application in recommender systems (RecSys)
has shown promise. However, we are facing significant challenges when deploying
LLMs into RecSys, such as limited prompt length, unstructured item information,
and un-constrained generation of recommendations, leading to sub-optimal
performance. To address these issues, we propose a novel method using a
taxonomy dictionary. This method provides a systematic framework for
categorizing and organizing items, improving the clarity and structure of item
information. By incorporating the taxonomy dictionary into LLM prompts, we
achieve efficient token utilization and controlled feature generation, leading
to more accurate and contextually relevant recommendations. Our Taxonomy-guided
Recommendation (TaxRec) approach features a two-step process: one-time taxonomy
categorization and LLM-based recommendation, enabling zero-shot recommendations
without the need for domain-specific fine-tuning. Experimental results
demonstrate TaxRec significantly enhances recommendation quality compared to
traditional zero-shot approaches, showcasing its efficacy as personal
recommender with LLMs. Code is available at
https://github.com/yueqingliang1/TaxRec."
A Practical Diffusion Path for Sampling,https://arxiv.org/abs/2406.14040,2024-06-20,2024-06-21,0.0,0.0,"Diffusion models are state-of-the-art methods in generative modeling when
samples from a target probability distribution are available, and can be
efficiently sampled, using score matching to estimate score vectors guiding a
Langevin process. However, in the setting where samples from the target are not
available, e.g. when this target's density is known up to a normalization
constant, the score estimation task is challenging. Previous approaches rely on
Monte Carlo estimators that are either computationally heavy to implement or
sample-inefficient. In this work, we propose a computationally attractive
alternative, relying on the so-called dilation path, that yields score vectors
that are available in closed-form. This path interpolates between a Dirac and
the target distribution using a convolution. We propose a simple implementation
of Langevin dynamics guided by the dilation path, using adaptive step-sizes. We
illustrate the results of our sampling method on a range of tasks, and shows it
performs better than classical alternatives."
CryptoGPT - a 7B model rivaling GPT-4 in the task of analyzing and classifying real-time financial news,https://arxiv.org/abs/2406.14039,2024-06-20,2024-06-21,0.0,0.0,"CryptoGPT: a 7B model competing with GPT-4 in a specific task -- The Impact
of Automatic Annotation and Strategic Fine-Tuning via QLoRAIn this article, we
present a method aimed at refining a dedicated LLM of reasonable quality with
limited resources in an industrial setting via CryptoGPT. It is an LLM designed
for financial news analysis for the cryptocurrency market in real-time. This
project was launched in an industrial context. This model allows not only for
the classification of financial information but also for providing
comprehensive analysis. We refined different LLMs of the same size such as
Mistral-7B and LLama-7B using semi-automatic annotation and compared them with
various LLMs such as GPT-3.5 and GPT-4. Our goal is to find a balance among
several needs: 1. Protecting data (by avoiding their transfer to external
servers), 2. Limiting annotation cost and time, 3. Controlling the model's size
(to manage deployment costs), and 4. Maintaining better analysis quality."
Toward Infinite-Long Prefix in Transformer,https://arxiv.org/abs/2406.14036,2024-06-20,2024-06-21,1.0,0.0,"Prompting and contextual-based fine-tuning methods, which we call Prefix
Learning, have been proposed to enhance the performance of language models on
various downstream tasks that can match full parameter fine-tuning. There
remains a limited theoretical understanding of how these methods work. In this
paper, we aim to relieve this limitation by studying the learning ability of
Prefix Learning from the perspective of prefix length. In particular, we
approximate the infinite-long Prefix Learning optimization process by the
Neural Tangent Kernel (NTK) technique. We formulate and solve it as a learning
problem of the infinite-long prefix in a one-layer attention network. Our
results confirm the over-parameterization property and arbitrary small loss
convergence guarantee of the infinite-long Prefix Learning in attention. To the
implementation end, we propose our NTK-Attention method, which is ""equivalent""
to attention computation with arbitrary prefix length efficiently. Its time
complexity mainly depends on the sub-quadratic of input length (without
prefix), and our method only requires $d^2 + d$ extra parameters for
representation, where $d$ is the feature dimension. In addition, we conducted
experiments that compare our NTK-Attention with full parameters fine-tuning,
LoRA, and P-Tuning V2 methods across vision or natural language datasets. The
results indicate our approach may be a promising
parameter-efficient-fine-tuning method since it has demonstrated superior
performance in numerous scenarios. Our code can be found at
\url{https://github.com/ChristianYang37/chiwun/tree/main/src/NTK-Attention}."
Two Giraffes in a Dirt Field - Using Game Play to Investigate Situation Modelling in Large Multimodal Models,https://arxiv.org/abs/2406.14035,2024-06-20,2024-06-21,0.0,0.0,"While the situation has improved for text-only models, it again seems to be
the case currently that multimodal (text and image) models develop faster than
ways to evaluate them. In this paper, we bring a recently developed evaluation
paradigm from text models to multimodal models, namely evaluation through the
goal-oriented game (self) play, complementing reference-based and
preference-based evaluation. Specifically, we define games that challenge a
model's capability to represent a situation from visual information and align
such representations through dialogue. We find that the largest closed models
perform rather well on the games that we define, while even the best
open-weight models struggle with them. On further analysis, we find that the
exceptional deep captioning capabilities of the largest models drive some of
the performance. There is still room to grow for both kinds of models, ensuring
the continued relevance of the benchmark."
Ensembles of Probabilistic Regression Trees,https://arxiv.org/abs/2406.14033,2024-06-20,2024-06-21,0.0,0.0,"Tree-based ensemble methods such as random forests, gradient-boosted trees,
and Bayesianadditive regression trees have been successfully used for
regression problems in many applicationsand research studies. In this paper, we
study ensemble versions of probabilisticregression trees that provide smooth
approximations of the objective function by assigningeach observation to each
region with respect to a probability distribution. We prove thatthe ensemble
versions of probabilistic regression trees considered are consistent, and
experimentallystudy their bias-variance trade-off and compare them with the
state-of-the-art interms of performance prediction."
How to design a dataset compliant with an ML-based system ODD?,https://arxiv.org/abs/2406.14027,2024-06-20,2024-06-21,0.0,0.0,"This paper focuses on a Vision-based Landing task and presents the design and
the validation of a dataset that would comply with the Operational Design
Domain (ODD) of a Machine-Learning (ML) system. Relying on emerging
certification standards, we describe the process for establishing ODDs at both
the system and image levels. In the process, we present the translation of
high-level system constraints into actionable image-level properties, allowing
for the definition of verifiable Data Quality Requirements (DQRs). To
illustrate this approach, we use the Landing Approach Runway Detection (LARD)
dataset which combines synthetic imagery and real footage, and we focus on the
steps required to verify the DQRs. The replicable framework presented in this
paper addresses the challenges of designing a dataset compliant with the
stringent needs of ML-based systems certification in safety-critical
applications."
Demystifying Forgetting in Language Model Fine-Tuning with Statistical Analysis of Example Associations,https://arxiv.org/abs/2406.14026,2024-06-20,2024-06-21,0.0,0.0,"Language models (LMs) are known to suffer from forgetting of previously
learned examples when fine-tuned, breaking stability of deployed LM systems.
Despite efforts on mitigating forgetting, few have investigated whether, and
how forgotten upstream examples are associated with newly learned tasks.
Insights on such associations enable efficient and targeted mitigation of
forgetting. In this paper, we empirically analyze forgetting that occurs in $N$
upstream examples while the model learns $M$ new tasks and visualize their
associations with a $M \times N$ matrix. We empirically demonstrate that the
degree of forgetting can often be approximated by simple multiplicative
contributions of the upstream examples and newly learned tasks. We also reveal
more complicated patterns where specific subsets of examples are forgotten with
statistics and visualization. Following our analysis, we predict forgetting
that happens on upstream examples when learning a new task with matrix
completion over the empirical associations, outperforming prior approaches that
rely on trainable LMs. Project website:
https://inklab.usc.edu/lm-forgetting-prediction/"
The Reason behind Good or Bad - Towards a Better Mathematical Verifier with Natural Language Feedback,https://arxiv.org/abs/2406.14024,2024-06-20,2024-06-21,0.0,0.0,"Mathematical verfier achieves success in mathematical reasoning tasks by
validating the correctness of solutions. However, existing verifiers are
trained with binary classification labels, which are not informative enough for
the model to accurately assess the solutions. To mitigate the aforementioned
insufficiency of binary labels, we introduce step-wise natural language
feedbacks as rationale labels (i.e., the correctness of the current step and
the explanations). In this paper, we propose \textbf{Math-Minos}, a natural
language feedback enhanced verifier by constructing automatically-generated
training data and a two-stage training paradigm for effective training and
efficient inference. Our experiments reveal that a small set (30k) of natural
language feedbacks can significantly boost the performance of the verifier by
the accuracy of 1.6\% (86.6\% $\rightarrow$ 88.2\%) on GSM8K and 0.8\% (37.8\%
$\rightarrow$ 38.6\%) on MATH. We have released our code and data for further
exploration."
Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective,https://arxiv.org/abs/2406.14023,2024-06-20,2024-06-21,0.0,0.0,"As Large Language Models (LLMs) become an important way of information
seeking, there have been increasing concerns about the unethical content LLMs
may generate. In this paper, we conduct a rigorous evaluation of LLMs' implicit
bias towards certain groups by attacking them with carefully crafted
instructions to elicit biased responses. Our attack methodology is inspired by
psychometric principles in cognitive and social psychology. We propose three
attack approaches, i.e., Disguise, Deception, and Teaching, based on which we
built evaluation datasets for four common bias types. Each prompt attack has
bilingual versions. Extensive evaluation of representative LLMs shows that 1)
all three attack methods work effectively, especially the Deception attacks; 2)
GLM-3 performs the best in defending our attacks, compared to GPT-3.5 and
GPT-4; 3) LLMs could output content of other bias types when being taught with
one type of bias. Our methodology provides a rigorous and effective way of
evaluating LLMs' implicit bias and will benefit the assessments of LLMs'
potential ethical risks."
Investigating the Pre-Training Dynamics of In-Context Learning - Task Recognition vs. Task Learning,https://arxiv.org/abs/2406.14022,2024-06-20,2024-06-21,0.0,0.0,"The emergence of in-context learning (ICL) is potentially attributed to two
major abilities: task recognition (TR) for recognizing the task from
demonstrations and utilizing pre-trained priors, and task learning (TL) for
learning from demonstrations. However, relationships between the two abilities
and how such relationships affect the emergence of ICL is unclear. In this
paper, we take the first step by examining the pre-training dynamics of the
emergence of ICL. With carefully designed metrics, we find that these two
abilities are, in fact, competitive during pre-training. Moreover, we observe a
strong negative correlation between the competition and ICL performance.
Further analysis of common pre-training factors (i.e., model size, dataset
size, and data curriculum) demonstrates possible ways to manage the
competition. Based on these insights, we propose a simple yet effective method
to better integrate these two abilities for ICL at inference time. Through
adaptive ensemble learning, the performance of ICL can be significantly
boosted, enabling two small models to outperform a larger one with more than
twice the parameters. The code is available at
https://github.com/RUCAIBox/Competitive-ICL."
HIGHT - Hierarchical Graph Tokenization for Graph-Language Alignment,https://arxiv.org/abs/2406.14021,2024-06-20,2024-06-21,0.0,0.0,"Recently there has been a surge of interest in extending the success of large
language models (LLMs) to graph modality, such as social networks and
molecules. As LLMs are predominantly trained with 1D text data, most existing
approaches adopt a graph neural network to represent a graph as a series of
node tokens and feed these tokens to LLMs for graph-language alignment. Despite
achieving some successes, existing approaches have overlooked the hierarchical
structures that are inherent in graph data. Especially, in molecular graphs,
the high-order structural information contains rich semantics of molecular
functional groups, which encode crucial biochemical functionalities of the
molecules. We establish a simple benchmark showing that neglecting the
hierarchical information in graph tokenization will lead to subpar
graph-language alignment and severe hallucination in generated outputs. To
address this problem, we propose a novel strategy called HIerarchical GrapH
Tokenization (HIGHT). HIGHT employs a hierarchical graph tokenizer that
extracts and encodes the hierarchy of node, motif, and graph levels of
informative tokens to improve the graph perception of LLMs. HIGHT also adopts
an augmented graph-language supervised fine-tuning dataset, enriched with the
hierarchical graph information, to further enhance the graph-language
alignment. Extensive experiments on 7 molecule-centric benchmarks confirm the
effectiveness of HIGHT in reducing hallucination by 40%, as well as significant
improvements in various molecule-language downstream tasks."
Leveraging eBPF and AI for Ransomware Nose Out,https://arxiv.org/abs/2406.14020,2024-06-20,2024-06-21,0.0,0.0,"In this work, we propose a two-phased approach for real-time detection and
deterrence of ransomware. To achieve this, we leverage the capabilities of eBPF
(Extended Berkeley Packet Filter) and artificial intelligence to develop both
proactive and reactive methods. In the first phase, we utilize signature based
detection, where we employ custom eBPF programs to trace the execution of new
processes and perform hash-based analysis against a known ransomware dataset.
In the second, we employ a behavior-based technique that focuses on monitoring
the process activities using a custom eBPF program and the creation of ransom
notes, a prominent indicator of ransomware activity through the use of Natural
Language Processing (NLP). By leveraging low-level tracing capabilities of eBPF
and integrating NLP based machine learning algorithms, our solution achieves an
impressive 99.76% accuracy in identifying ransomware incidents within a few
seconds on the onset of zero-day attacks."
Confidence Intervals and Simultaneous Confidence Bands Based on Deep Learning,https://arxiv.org/abs/2406.14009,2024-06-20,2024-06-21,0.0,0.0,"Deep learning models have significantly improved prediction accuracy in
various fields, gaining recognition across numerous disciplines. Yet, an aspect
of deep learning that remains insufficiently addressed is the assessment of
prediction uncertainty. Producing reliable uncertainty estimators could be
crucial in practical terms. For instance, predictions associated with a high
degree of uncertainty could be sent for further evaluation. Recent works in
uncertainty quantification of deep learning predictions, including Bayesian
posterior credible intervals and a frequentist confidence-interval estimation,
have proven to yield either invalid or overly conservative intervals.
Furthermore, there is currently no method for quantifying uncertainty that can
accommodate deep neural networks for survival (time-to-event) data that
involves right-censored outcomes. In this work, we provide a valid
non-parametric bootstrap method that correctly disentangles data uncertainty
from the noise inherent in the adopted optimization algorithm, ensuring that
the resulting point-wise confidence intervals or the simultaneous confidence
bands are accurate (i.e., valid and not overly conservative). The proposed
ad-hoc method can be easily integrated into any deep neural network without
interfering with the training process. The utility of the proposed approach is
illustrated by constructing simultaneous confidence bands for survival curves
derived from deep neural networks for survival data with right censoring."
Do Not Wait - Learning Re-Ranking Model Without User Feedback At Serving Time in E-Commerce,https://arxiv.org/abs/2406.14004,2024-06-20,2024-06-21,0.0,0.0,"Recommender systems have been widely used in e-commerce, and re-ranking
models are playing an increasingly significant role in the domain, which
leverages the inter-item influence and determines the final recommendation
lists. Online learning methods keep updating a deployed model with the latest
available samples to capture the shifting of the underlying data distribution
in e-commerce. However, they depend on the availability of real user feedback,
which may be delayed by hours or even days, such as item purchases, leading to
a lag in model enhancement. In this paper, we propose a novel extension of
online learning methods for re-ranking modeling, which we term LAST, an acronym
for Learning At Serving Time. It circumvents the requirement of user feedback
by using a surrogate model to provide the instructional signal needed to steer
model improvement. Upon receiving an online request, LAST finds and applies a
model modification on the fly before generating a recommendation result for the
request. The modification is request-specific and transient. It means the
modification is tailored to and only to the current request to capture the
specific context of the request. After a request, the modification is
discarded, which helps to prevent error propagation and stabilizes the online
learning procedure since the predictions of the surrogate model may be
inaccurate. Most importantly, as a complement to feedback-based online learning
methods, LAST can be seamlessly integrated into existing online learning
systems to create a more adaptive and responsive recommendation experience.
Comprehensive experiments, both offline and online, affirm that LAST
outperforms state-of-the-art re-ranking models."
Deep Optimal Experimental Design for Parameter Estimation Problems,https://arxiv.org/abs/2406.14003,2024-06-20,2024-06-21,0.0,0.0,"Optimal experimental design is a well studied field in applied science and
engineering. Techniques for estimating such a design are commonly used within
the framework of parameter estimation. Nonetheless, in recent years parameter
estimation techniques are changing rapidly with the introduction of deep
learning techniques to replace traditional estimation methods. This in turn
requires the adaptation of optimal experimental design that is associated with
these new techniques. In this paper we investigate a new experimental design
methodology that uses deep learning. We show that the training of a network as
a Likelihood Free Estimator can be used to significantly simplify the design
process and circumvent the need for the computationally expensive bi-level
optimization problem that is inherent in optimal experimental design for
non-linear systems. Furthermore, deep design improves the quality of the
recovery process for parameter estimation problems. As proof of concept we
apply our methodology to two different systems of Ordinary Differential
Equations."
"""Global is Good, Local is Bad?"" - Understanding Brand Bias in LLMs",https://arxiv.org/abs/2406.13997,2024-06-20,2024-06-21,0.0,0.0,"Many recent studies have investigated social biases in LLMs but brand bias
has received little attention. This research examines the biases exhibited by
LLMs towards different brands, a significant concern given the widespread use
of LLMs in affected use cases such as product recommendation and market
analysis. Biased models may perpetuate societal inequalities, unfairly favoring
established global brands while marginalizing local ones. Using a curated
dataset across four brand categories, we probe the behavior of LLMs in this
space. We find a consistent pattern of bias in this space -- both in terms of
disproportionately associating global brands with positive attributes and
disproportionately recommending luxury gifts for individuals in high-income
countries. We also find LLMs are subject to country-of-origin effects which may
boost local brand preference in LLM outputs in specific contexts."
Prediction of Unobserved Bifurcation by Unsupervised Extraction of Slowly Time-Varying System Parameter Dynamics from Time Series Using Reservoir Computing,https://arxiv.org/abs/2406.13995,2024-06-20,2024-06-21,0.0,0.0,"Nonlinear and non-stationary processes are prevalent in various natural and
physical phenomena, where system dynamics can change qualitatively due to
bifurcation phenomena. Traditional machine learning methods have advanced our
ability to learn and predict such systems from observed time series data.
However, predicting the behavior of systems with temporal parameter variations
without knowledge of true parameter values remains a significant challenge.
This study leverages the reservoir computing framework to address this problem
by unsupervised extraction of slowly varying system parameters from time series
data. We propose a model architecture consisting of a slow reservoir with long
timescale internal dynamics and a fast reservoir with short timescale dynamics.
The slow reservoir extracts the temporal variation of system parameters, which
are then used to predict unknown bifurcations in the fast dynamics. Through
experiments using data generated from chaotic dynamical systems, we demonstrate
the ability to predict bifurcations not present in the training data. Our
approach shows potential for applications in fields such as neuroscience,
material science, and weather prediction, where slow dynamics influencing
qualitative changes are often unobservable."
Exploring Changes in Nation Perception with Nationality-Assigned Personas in LLMs,https://arxiv.org/abs/2406.13993,2024-06-20,2024-06-21,0.0,0.0,"Persona assignment has become a common strategy for customizing LLM use to
particular tasks and contexts. In this study, we explore how perceptions of
different nations change when LLMs are assigned specific nationality personas.
We assign 193 different nationality personas (e.g., an American person) to four
LLMs and examine how the LLM perceptions of countries change. We find that all
LLM-persona combinations tend to favor Western European nations, though
nation-personas push LLM behaviors to focus more on and view more favorably the
nation-persona's own region. Eastern European, Latin American, and African
nations are viewed more negatively by different nationality personas. Our study
provides insight into how biases and stereotypes are realized within LLMs when
adopting different national personas. In line with the ""Blueprint for an AI
Bill of Rights"", our findings underscore the critical need for developing
mechanisms to ensure LLMs uphold fairness and not over-generalize at a global
scale."
Robust Cooperative Multi-Agent Reinforcement Learning -A Mean-Field Type Game Perspective,https://arxiv.org/abs/2406.13992,2024-06-20,2024-06-21,0.0,0.0,"In this paper, we study the problem of robust cooperative multi-agent
reinforcement learning (RL) where a large number of cooperative agents with
distributed information aim to learn policies in the presence of
\emph{stochastic} and \emph{non-stochastic} uncertainties whose distributions
are respectively known and unknown. Focusing on policy optimization that
accounts for both types of uncertainties, we formulate the problem in a
worst-case (minimax) framework, which is is intractable in general. Thus, we
focus on the Linear Quadratic setting to derive benchmark solutions. First,
since no standard theory exists for this problem due to the distributed
information structure, we utilize the Mean-Field Type Game (MFTG) paradigm to
establish guarantees on the solution quality in the sense of achieved Nash
equilibrium of the MFTG. This in turn allows us to compare the performance
against the corresponding original robust multi-agent control problem. Then, we
propose a Receding-horizon Gradient Descent Ascent RL algorithm to find the
MFTG Nash equilibrium and we prove a non-asymptotic rate of convergence.
Finally, we provide numerical experiments to demonstrate the efficacy of our
approach relative to a baseline algorithm."
Bayesian Inverse Reinforcement Learning for Non-Markovian Rewards,https://arxiv.org/abs/2406.13991,2024-06-20,2024-06-21,0.0,0.0,"Inverse reinforcement learning (IRL) is the problem of inferring a reward
function from expert behavior. There are several approaches to IRL, but most
are designed to learn a Markovian reward. However, a reward function might be
non-Markovian, depending on more than just the current state, such as a reward
machine (RM). Although there has been recent work on inferring RMs, it assumes
access to the reward signal, absent in IRL. We propose a Bayesian IRL (BIRL)
framework for inferring RMs directly from expert behavior, requiring
significant changes to the standard framework. We define a new reward space,
adapt the expert demonstration to include history, show how to compute the
reward posterior, and propose a novel modification to simulated annealing to
maximize this posterior. We demonstrate that our method performs well when
optimizing according to its inferred reward and compares favorably to an
existing method that learns exclusively binary non-Markovian rewards."
Inference-Time Decontamination - Reusing Leaked Benchmarks for Large Language Model Evaluation,https://arxiv.org/abs/2406.13990,2024-06-20,2024-06-21,0.0,0.0,"The training process of large language models (LLMs) often involves varying
degrees of test data contamination. Although current LLMs are achieving
increasingly better performance on various benchmarks, their performance in
practical applications does not always match their benchmark results. Leakage
of benchmarks can prevent the accurate assessment of LLMs' true performance.
However, constructing new benchmarks is costly, labor-intensive and still
carries the risk of leakage. Therefore, in this paper, we ask the question, Can
we reuse these leaked benchmarks for LLM evaluation? We propose Inference-Time
Decontamination (ITD) to address this issue by detecting and rewriting leaked
samples without altering their difficulties. ITD can mitigate performance
inflation caused by memorizing leaked benchmarks. Our proof-of-concept
experiments demonstrate that ITD reduces inflated accuracy by 22.9% on GSM8K
and 19.0% on MMLU. On MMLU, using Inference-time Decontamination can lead to a
decrease in the results of Phi3 and Mistral by 6.7% and 3.6% respectively. We
hope that ITD can provide more truthful evaluation results for large language
models."
Random pairing MLE for estimation of item parameters in Rasch model,https://arxiv.org/abs/2406.13989,2024-06-20,2024-06-21,0.0,0.0,"The Rasch model, a classical model in the item response theory, is widely
used in psychometrics to model the relationship between individuals' latent
traits and their binary responses on assessments or questionnaires. In this
paper, we introduce a new likelihood-based estimator -- random pairing maximum
likelihood estimator ($\mathsf{RP\text{-}MLE}$) and its bootstrapped variant
multiple random pairing MLE ($\mathsf{MRP\text{-}MLE}$) that faithfully
estimate the item parameters in the Rasch model. The new estimators have
several appealing features compared to existing ones. First, both work for
sparse observations, an increasingly important scenario in the big data era.
Second, both estimators are provably minimax optimal in terms of finite sample
$\ell_{\infty}$ estimation error. Lastly, $\mathsf{RP\text{-}MLE}$ admits
precise distributional characterization that allows uncertainty quantification
on the item parameters, e.g., construction of confidence intervals of the item
parameters. The main idea underlying $\mathsf{RP\text{-}MLE}$ and
$\mathsf{MRP\text{-}MLE}$ is to randomly pair user-item responses to form
item-item comparisons. This is carefully designed to reduce the problem size
while retaining statistical independence. We also provide empirical evidence of
the efficacy of the two new estimators using both simulated and real data."
Image anomaly detection and prediction scheme based on SSA optimized ResNet50-BiGRU model,https://arxiv.org/abs/2406.13987,2024-06-20,2024-06-21,0.0,0.0,"Image anomaly detection is a popular research direction, with many methods
emerging in recent years due to rapid advancements in computing. The use of
artificial intelligence for image anomaly detection has been widely studied. By
analyzing images of athlete posture and movement, it is possible to predict
injury status and suggest necessary adjustments. Most existing methods rely on
convolutional networks to extract information from irrelevant pixel data,
limiting model accuracy. This paper introduces a network combining Residual
Network (ResNet) and Bidirectional Gated Recurrent Unit (BiGRU), which can
predict potential injury types and provide early warnings by analyzing changes
in muscle and bone poses from video images. To address the high complexity of
this network, the Sparrow search algorithm was used for optimization.
Experiments conducted on four datasets demonstrated that our model has the
smallest error in image anomaly detection compared to other models, showing
strong adaptability. This provides a new approach for anomaly detection and
predictive analysis in images, contributing to the sustainable development of
human health and performance."
"The Elusive Pursuit of Replicating PATE-GAN - Benchmarking, Auditing, Debugging",https://arxiv.org/abs/2406.13985,2024-06-20,2024-06-21,0.0,0.0,"Synthetic data created by differentially private (DP) generative models is
increasingly used in real-world settings. In this context, PATE-GAN has emerged
as a popular algorithm, combining Generative Adversarial Networks (GANs) with
the private training approach of PATE (Private Aggregation of Teacher
Ensembles). In this paper, we analyze and benchmark six open-source PATE-GAN
implementations, including three by (a subset of) the original authors. First,
we shed light on architecture deviations and empirically demonstrate that none
replicate the utility performance reported in the original paper. Then, we
present an in-depth privacy evaluation, including DP auditing, showing that all
implementations leak more privacy than intended and uncovering 17 privacy
violations and 5 other bugs. Our codebase is available from
https://github.com/spalabucr/pategan-audit."
Reducing Memory Contention and I/O Congestion for Disk-based GNN Training,https://arxiv.org/abs/2406.13984,2024-06-20,2024-06-21,0.0,0.0,"Graph neural networks (GNNs) gain wide popularity. Large graphs with
high-dimensional features become common and training GNNs on them is
non-trivial on an ordinary machine. Given a gigantic graph, even sample-based
GNN training cannot work efficiently, since it is difficult to keep the graph's
entire data in memory during the training process. Leveraging a solid-state
drive (SSD) or other storage devices to extend the memory space has been
studied in training GNNs. Memory and I/Os are hence critical for effectual
disk-based training. We find that state-of-the-art (SoTA) disk-based GNN
training systems severely suffer from issues like the memory contention between
a graph's topological and feature data, and severe I/O congestion upon loading
data from SSD for training. We accordingly develop GNNDrive. GNNDrive 1)
minimizes the memory footprint with holistic buffer management across sampling
and extracting, and 2) avoids I/O congestion through a strategy of asynchronous
feature extraction. It also avoids costly data preparation on the critical path
and makes the most of software and hardware resources. Experiments show that
GNNDrive achieves superior performance. For example, when training with the
Papers100M dataset and GraphSAGE model, GNNDrive is faster than SoTA PyG+,
Ginex, and MariusGNN by 16.9x, 2.6x, and 2.7x, respectively."
MR-BEN - A Comprehensive Meta-Reasoning Benchmark for Large Language Models,https://arxiv.org/abs/2406.13975,2024-06-20,2024-06-21,0.0,0.0,"Large language models (LLMs) have shown increasing capability in
problem-solving and decision-making, largely based on the step-by-step
chain-of-thought reasoning processes. However, it has been increasingly
challenging to evaluate the reasoning capability of LLMs. Concretely, existing
outcome-based benchmarks begin to saturate and become less sufficient to
monitor the progress. To this end, we present a process-based benchmark MR-BEN
that demands a meta reasoning skill, where LMs are asked to locate and analyse
potential errors in automatically generated reasoning steps. MR-BEN is a
comprehensive benchmark comprising 5,975 questions collected from human
experts, covering various subjects such as physics, chemistry, logic, coding,
and more. Through our designed metrics for assessing meta-reasoning on this
benchmark, we identify interesting limitations and weaknesses of current LLMs
(open-source and closed-source models). For example, open-source models are
seemingly comparable to GPT-4 on outcome-based benchmarks, but they lag far
behind on our benchmark, revealing the underlying reasoning capability gap
between them. Our dataset and codes are available on
https://randolph-zeng.github.io/Mr-Ben.github.io/."
Complex fractal trainability boundary can arise from trivial non-convexity,https://arxiv.org/abs/2406.13971,2024-06-20,2024-06-21,1.0,1.0,"Training neural networks involves optimizing parameters to minimize a loss
function, where the nature of the loss function and the optimization strategy
are crucial for effective training. Hyperparameter choices, such as the
learning rate in gradient descent (GD), significantly affect the success and
speed of convergence. Recent studies indicate that the boundary between bounded
and divergent hyperparameters can be fractal, complicating reliable
hyperparameter selection. However, the nature of this fractal boundary and
methods to avoid it remain unclear. In this study, we focus on GD to
investigate the loss landscape properties that might lead to fractal
trainability boundaries. We discovered that fractal boundaries can emerge from
simple non-convex perturbations, i.e., adding or multiplying cosine type
perturbations to quadratic functions. The observed fractal dimensions are
influenced by factors like parameter dimension, type of non-convexity,
perturbation wavelength, and perturbation amplitude. Our analysis identifies
""roughness of perturbation"", which measures the gradient's sensitivity to
parameter changes, as the factor controlling fractal dimensions of trainability
boundaries. We observed a clear transition from non-fractal to fractal
trainability boundaries as roughness increases, with the critical roughness
causing the perturbed loss function non-convex. Thus, we conclude that fractal
trainability boundaries can arise from very simple non-convexity. We anticipate
that our findings will enhance the understanding of complex behaviors during
neural network training, leading to more consistent and predictable training
strategies."
Recent Advances in Traffic Accident Analysis and Prediction - A Comprehensive Review of Machine Learning Techniques,https://arxiv.org/abs/2406.13968,2024-06-20,2024-06-21,0.0,0.0,"Traffic accidents pose a severe global public health issue, leading to 1.19
million fatalities annually, with the greatest impact on individuals aged 5 to
29 years old. This paper addresses the critical need for advanced predictive
methods in road safety by conducting a comprehensive review of recent
advancements in applying machine learning (ML) techniques to traffic accident
analysis and prediction. It examines 191 studies from the last five years,
focusing on predicting accident risk, frequency, severity, duration, as well as
general statistical analysis of accident data. To our knowledge, this study is
the first to provide such a comprehensive review, covering the state-of-the-art
across a wide range of domains related to accident analysis and prediction. The
review highlights the effectiveness of integrating diverse data sources and
advanced ML techniques to improve prediction accuracy and handle the
complexities of traffic data. By mapping the current landscape and identifying
gaps in the literature, this study aims to guide future research towards
significantly reducing traffic-related deaths and injuries by 2030, aligning
with the World Health Organization (WHO) targets."
Causal Inference with Latent Variables - Recent Advances and Future Prospectives,https://arxiv.org/abs/2406.13966,2024-06-20,2024-06-21,0.0,0.0,"Causality lays the foundation for the trajectory of our world. Causal
inference (CI), which aims to infer intrinsic causal relations among variables
of interest, has emerged as a crucial research topic. Nevertheless, the lack of
observation of important variables (e.g., confounders, mediators, exogenous
variables, etc.) severely compromises the reliability of CI methods. The issue
may arise from the inherent difficulty in measuring the variables.
Additionally, in observational studies where variables are passively recorded,
certain covariates might be inadvertently omitted by the experimenter.
Depending on the type of unobserved variables and the specific CI task, various
consequences can be incurred if these latent variables are carelessly handled,
such as biased estimation of causal effects, incomplete understanding of causal
mechanisms, lack of individual-level causal consideration, etc. In this survey,
we provide a comprehensive review of recent developments in CI with latent
variables. We start by discussing traditional CI techniques when variables of
interest are assumed to be fully observed. Afterward, under the taxonomy of
circumvention and inference-based methods, we provide an in-depth discussion of
various CI strategies to handle latent variables, covering the tasks of causal
effect estimation, mediation analysis, counterfactual reasoning, and causal
discovery. Furthermore, we generalize the discussion to graph data where
interference among units may exist. Finally, we offer fresh aspects for further
advancement of CI with latent variables, especially new opportunities in the
era of large language models (LLMs)."
Equivariant Offline Reinforcement Learning,https://arxiv.org/abs/2406.13961,2024-06-20,2024-06-21,0.0,0.0,"Sample efficiency is critical when applying learning-based methods to robotic
manipulation due to the high cost of collecting expert demonstrations and the
challenges of on-robot policy learning through online Reinforcement Learning
(RL). Offline RL addresses this issue by enabling policy learning from an
offline dataset collected using any behavioral policy, regardless of its
quality. However, recent advancements in offline RL have predominantly focused
on learning from large datasets. Given that many robotic manipulation tasks can
be formulated as rotation-symmetric problems, we investigate the use of
$SO(2)$-equivariant neural networks for offline RL with a limited number of
demonstrations. Our experimental results show that equivariant versions of
Conservative Q-Learning (CQL) and Implicit Q-Learning (IQL) outperform their
non-equivariant counterparts. We provide empirical evidence demonstrating how
equivariance improves offline learning algorithms in the low-data regime."
Evolving to be Your Soulmate - Personalized Dialogue Agents with Dynamically Adapted Personas,https://arxiv.org/abs/2406.13960,2024-06-20,2024-06-21,1.0,0.0,"Previous research has demonstrated the potential of AI agents to act as
companions that can provide constant emotional support for humans. In this
paper, we emphasize the necessity of autonomous adaptation in personal AI
companionship, an underexplored yet promising direction. Such adaptability is
crucial as it can facilitate more tailored interactions with users and allow
the agent to evolve in response to users' changing needs. However, imbuing
agents with autonomous adaptability presents unique challenges, including
identifying optimal adaptations to meet users' expectations and ensuring a
smooth transition during the adaptation process. To address them, we devise a
hierarchical framework, AutoPal, that enables controllable and authentic
adjustments to the agent's persona based on user interactions. A
personamatching dataset is constructed to facilitate the learning of optimal
persona adaptations. Extensive experiments demonstrate the effectiveness of
AutoPal and highlight the importance of autonomous adaptability in AI
companionship."
Research on Flight Accidents Prediction based Back Propagation Neural Network,https://arxiv.org/abs/2406.13954,2024-06-20,2024-06-21,0.0,0.0,"With the rapid development of civil aviation and the significant improvement
of people's living standards, taking an air plane has become a common and
efficient way of travel. However, due to the flight characteris-tics of the
aircraft and the sophistication of the fuselage structure, flight de-lays and
flight accidents occur from time to time. In addition, the life risk factor
brought by aircraft after an accident is also the highest among all means of
transportation. In this work, a model based on back-propagation neural network
was used to predict flight accidents. By collecting historical flight data,
including a variety of factors such as meteorological conditions, aircraft
technical condition, and pilot experience, we trained a backpropaga-tion neural
network model to identify potential accident risks. In the model design, a
multi-layer perceptron structure is used to optimize the network performance by
adjusting the number of hidden layer nodes and the learning rate. Experimental
analysis shows that the model can effectively predict flight accidents with
high accuracy and reliability."
CityGPT - Empowering Urban Spatial Cognition of Large Language Models,https://arxiv.org/abs/2406.13948,2024-06-20,2024-06-21,0.0,0.0,"Large language models(LLMs) with powerful language generation and reasoning
capabilities have already achieved success in many domains, e.g., math and code
generation. However, due to the lacking of physical world's corpus and
knowledge during training, they usually fail to solve many real-life tasks in
the urban space. In this paper, we propose CityGPT, a systematic framework for
enhancing the capability of LLMs on understanding urban space and solving the
related urban tasks by building a city-scale world model in the model. First,
we construct a diverse instruction tuning dataset CityInstruction for injecting
urban knowledge and enhancing spatial reasoning capability effectively. By
using a mixture of CityInstruction and general instruction data, we fine-tune
various LLMs (e.g., ChatGLM3-6B, Qwen1.5 and LLama3 series) to enhance their
capability without sacrificing general abilities. To further validate the
effectiveness of proposed methods, we construct a comprehensive benchmark
CityEval to evaluate the capability of LLMs on diverse urban scenarios and
problems. Extensive evaluation results demonstrate that small LLMs trained with
CityInstruction can achieve competitive performance with commercial LLMs in the
comprehensive evaluation of CityEval. The source codes are openly accessible to
the research community via https://github.com/tsinghua-fib-lab/CityGPT."
AspirinSum - an Aspect-based utility-preserved de-identification Summarization framework,https://arxiv.org/abs/2406.13947,2024-06-20,2024-06-21,0.0,0.0,"Due to the rapid advancement of Large Language Model (LLM), the whole
community eagerly consumes any available text data in order to train the LLM.
Currently, large portion of the available text data are collected from
internet, which has been thought as a cheap source of the training data.
However, when people try to extend the LLM's capability to the personal related
domain, such as healthcare or education, the lack of public dataset in these
domains make the adaption of the LLM in such domains much slower. The reason of
lacking public available dataset in such domains is because they usually
contain personal sensitive information. In order to comply with privacy law,
the data in such domains need to be de-identified before any kind of
dissemination. It had been much research tried to address this problem for the
image or tabular data. However, there was limited research on the efficient and
general de-identification method for text data. Most of the method based on
human annotation or predefined category list. It usually can not be easily
adapted to specific domains. The goal of this proposal is to develop a text
de-identification framework, which can be easily adapted to the specific
domain, leverage the existing expert knowledge without further human
annotation. We propose an aspect-based utility-preserved de-identification
summarization framework, AspirinSum, by learning to align expert's aspect from
existing comment data, it can efficiently summarize the personal sensitive
document by extracting personal sensitive aspect related sub-sentence and
de-identify it by substituting it with similar aspect sub-sentence. We envision
that the de-identified text can then be used in data publishing, eventually
publishing our de-identified dataset for downstream task use."
CityBench - Evaluating the Capabilities of Large Language Model as World Model,https://arxiv.org/abs/2406.13945,2024-06-20,2024-06-21,0.0,0.0,"Large language models (LLMs) with powerful generalization ability has been
widely used in many domains. A systematic and reliable evaluation of LLMs is a
crucial step in their development and applications, especially for specific
professional fields. In the urban domain, there have been some early
explorations about the usability of LLMs, but a systematic and scalable
evaluation benchmark is still lacking. The challenge in constructing a
systematic evaluation benchmark for the urban domain lies in the diversity of
data and scenarios, as well as the complex and dynamic nature of cities. In
this paper, we propose CityBench, an interactive simulator based evaluation
platform, as the first systematic evaluation benchmark for the capability of
LLMs for urban domain. First, we build CitySim to integrate the multi-source
data and simulate fine-grained urban dynamics. Based on CitySim, we design 7
tasks in 2 categories of perception-understanding and decision-making group to
evaluate the capability of LLMs as city-scale world model for urban domain. Due
to the flexibility and ease-of-use of CitySim, our evaluation platform
CityBench can be easily extended to any city in the world. We evaluate 13
well-known LLMs including open source LLMs and commercial LLMs in 13 cities
around the world. Extensive experiments demonstrate the scalability and
effectiveness of proposed CityBench and shed lights for the future development
of LLMs in urban domain. The dataset, benchmark and source codes are openly
accessible to the research community via
https://github.com/tsinghua-fib-lab/CityBench"
Generalization error of min-norm interpolators in transfer learning,https://arxiv.org/abs/2406.13944,2024-06-20,2024-06-21,0.0,0.0,"This paper establishes the generalization error of pooled min-$\ell_2$-norm
interpolation in transfer learning where data from diverse distributions are
available. Min-norm interpolators emerge naturally as implicit regularized
limits of modern machine learning algorithms. Previous work characterized their
out-of-distribution risk when samples from the test distribution are
unavailable during training. However, in many applications, a limited amount of
test data may be available during training, yet properties of min-norm
interpolation in this setting are not well-understood. We address this gap by
characterizing the bias and variance of pooled min-$\ell_2$-norm interpolation
under covariate and model shifts. The pooled interpolator captures both early
fusion and a form of intermediate fusion. Our results have several
implications: under model shift, for low signal-to-noise ratio (SNR), adding
data always hurts. For higher SNR, transfer learning helps as long as the
shift-to-signal (SSR) ratio lies below a threshold that we characterize
explicitly. By consistently estimating these ratios, we provide a data-driven
method to determine: (i) when the pooled interpolator outperforms the
target-based interpolator, and (ii) the optimal number of target samples that
minimizes the generalization error. Under covariate shift, if the source sample
size is small relative to the dimension, heterogeneity between between domains
improves the risk, and vice versa. We establish a novel anisotropic local law
to achieve these characterizations, which may be of independent interest in
random matrix theory. We supplement our theoretical characterizations with
comprehensive simulations that demonstrate the finite-sample efficacy of our
results."
Synthesizing Multimodal Electronic Health Records via Predictive Diffusion Models,https://arxiv.org/abs/2406.13942,2024-06-20,2024-06-21,0.0,0.0,"Synthesizing electronic health records (EHR) data has become a preferred
strategy to address data scarcity, improve data quality, and model fairness in
healthcare. However, existing approaches for EHR data generation predominantly
rely on state-of-the-art generative techniques like generative adversarial
networks, variational autoencoders, and language models. These methods
typically replicate input visits, resulting in inadequate modeling of temporal
dependencies between visits and overlooking the generation of time information,
a crucial element in EHR data. Moreover, their ability to learn visit
representations is limited due to simple linear mapping functions, thus
compromising generation quality. To address these limitations, we propose a
novel EHR data generation model called EHRPD. It is a diffusion-based model
designed to predict the next visit based on the current one while also
incorporating time interval estimation. To enhance generation quality and
diversity, we introduce a novel time-aware visit embedding module and a
pioneering predictive denoising diffusion probabilistic model (PDDPM).
Additionally, we devise a predictive U-Net (PU-Net) to optimize P-DDPM.We
conduct experiments on two public datasets and evaluate EHRPD from fidelity,
privacy, and utility perspectives. The experimental results demonstrate the
efficacy and utility of the proposed EHRPD in addressing the aforementioned
limitations and advancing EHR data generation."
UpDLRM - Accelerating Personalized Recommendation using Real-World PIM Architecture,https://arxiv.org/abs/2406.13941,2024-06-20,2024-06-21,0.0,0.0,"Deep Learning Recommendation Models (DLRMs) have gained popularity in
recommendation systems due to their effectiveness in handling large-scale
recommendation tasks. The embedding layers of DLRMs have become the performance
bottleneck due to their intensive needs on memory capacity and memory
bandwidth. In this paper, we propose UpDLRM, which utilizes real-world
processingin-memory (PIM) hardware, UPMEM DPU, to boost the memory bandwidth
and reduce recommendation latency. The parallel nature of the DPU memory can
provide high aggregated bandwidth for the large number of irregular memory
accesses in embedding lookups, thus offering great potential to reduce the
inference latency. To fully utilize the DPU memory bandwidth, we further
studied the embedding table partitioning problem to achieve good
workload-balance and efficient data caching. Evaluations using real-world
datasets show that, UpDLRM achieves much lower inference time for DLRM compared
to both CPU-only and CPU-GPU hybrid counterparts."
AutoCAP - Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought,https://arxiv.org/abs/2406.13940,2024-06-20,2024-06-21,0.0,0.0,"Cross-lingual chain-of-thought can effectively complete reasoning tasks
across languages, which gains increasing attention. Recently, dominant
approaches in the literature improve cross-lingual alignment capabilities by
integrating reasoning knowledge from different languages. Despite achieving
excellent performance, current methods still have two main challenges: (1)
Manual language specification: They still highly rely on manually selecting the
languages to integrate, severely affecting their generalizability; (2) Static
weight allocation: Current methods simply integrate all languages equally. In
fact, different language reasoning paths should have different weights to
achieve better complementation and integration. Motivated by this, we introduce
an Automatic Cross-lingual Alignment Planning (AutoCAP) for zero-shot
chain-of-thought to address the above challenges. The core of AutoCAP consists
of two components: (1) Automatic Language Selection Prompting to guide LLMs to
select appropriate languages and (2) Automatic Weight Allocation Prompting to
automatically allocate alignment weight scores to each reasoning path.
Extensive experiments on several benchmarks reveal that AutoCAP achieves
state-of-the-art performance, surpassing previous methods that required manual
effort."
Communication-Efficient Adaptive Batch Size Strategies for Distributed Local Gradient Methods,https://arxiv.org/abs/2406.13936,2024-06-20,2024-06-21,0.0,0.0,"Modern deep neural networks often require distributed training with many
workers due to their large size. As worker numbers increase, communication
overheads become the main bottleneck in data-parallel minibatch stochastic
gradient methods with per-iteration gradient synchronization. Local gradient
methods like Local SGD reduce communication by only syncing after several local
steps. Despite understanding their convergence in i.i.d. and heterogeneous
settings and knowing the importance of batch sizes for efficiency and
generalization, optimal local batch sizes are difficult to determine. We
introduce adaptive batch size strategies for local gradient methods that
increase batch sizes adaptively to reduce minibatch gradient variance. We
provide convergence guarantees under homogeneous data conditions and support
our claims with image classification experiments, demonstrating the
effectiveness of our strategies in training and generalization."
CONMOD - Controllable Neural Frame-based Modulation Effects,https://arxiv.org/abs/2406.13935,2024-06-20,2024-06-21,0.0,0.0,"Deep learning models have seen widespread use in modelling LFO-driven audio
effects, such as phaser and flanger. Although existing neural architectures
exhibit high-quality emulation of individual effects, they do not possess the
capability to manipulate the output via control parameters. To address this
issue, we introduce Controllable Neural Frame-based Modulation Effects
(CONMOD), a single black-box model which emulates various LFO-driven effects in
a frame-wise manner, offering control over LFO frequency and feedback
parameters. Additionally, the model is capable of learning the continuous
embedding space of two distinct phaser effects, enabling us to steer between
effects and achieve creative outputs. Our model outperforms previous work while
possessing both controllability and universality, presenting opportunities to
enhance creativity in modern LFO-driven audio effects."
Soft-QMIX - Integrating Maximum Entropy For Monotonic Value Function Factorization,https://arxiv.org/abs/2406.13930,2024-06-20,2024-06-21,0.0,0.0,"Multi-agent reinforcement learning (MARL) tasks often utilize a centralized
training with decentralized execution (CTDE) framework. QMIX is a successful
CTDE method that learns a credit assignment function to derive local value
functions from a global value function, defining a deterministic local policy.
However, QMIX is hindered by its poor exploration strategy. While maximum
entropy reinforcement learning (RL) promotes better exploration through
stochastic policies, QMIX's process of credit assignment conflicts with the
maximum entropy objective and the decentralized execution requirement, making
it unsuitable for maximum entropy RL. In this paper, we propose an enhancement
to QMIX by incorporating an additional local Q-value learning method within the
maximum entropy RL framework. Our approach constrains the local Q-value
estimates to maintain the correct ordering of all actions. Due to the
monotonicity of the QMIX value function, these updates ensure that locally
optimal actions align with globally optimal actions. We theoretically prove the
monotonic improvement and convergence of our method to an optimal solution.
Experimentally, we validate our algorithm in matrix games, Multi-Agent Particle
Environment and demonstrate state-of-the-art performance in SMAC-v2."
Large Language Models are Skeptics - False Negative Problem of Input-conflicting Hallucination,https://arxiv.org/abs/2406.13929,2024-06-20,2024-06-21,0.0,0.0,"In this paper, we identify a new category of bias that induces
input-conflicting hallucinations, where large language models (LLMs) generate
responses inconsistent with the content of the input context. This issue we
have termed the false negative problem refers to the phenomenon where LLMs are
predisposed to return negative judgments when assessing the correctness of a
statement given the context. In experiments involving pairs of statements that
contain the same information but have contradictory factual directions, we
observe that LLMs exhibit a bias toward false negatives. Specifically, the
model presents greater overconfidence when responding with False. Furthermore,
we analyze the relationship between the false negative problem and context and
query rewriting and observe that both effectively tackle false negatives in
LLMs."
Optimal deep learning of holomorphic operators between Banach spaces,https://arxiv.org/abs/2406.13928,2024-06-20,2024-06-21,0.0,0.0,"Operator learning problems arise in many key areas of scientific computing
where Partial Differential Equations (PDEs) are used to model physical systems.
In such scenarios, the operators map between Banach or Hilbert spaces. In this
work, we tackle the problem of learning operators between Banach spaces, in
contrast to the vast majority of past works considering only Hilbert spaces. We
focus on learning holomorphic operators - an important class of problems with
many applications. We combine arbitrary approximate encoders and decoders with
standard feedforward Deep Neural Network (DNN) architectures - specifically,
those with constant width exceeding the depth - under standard $\ell^2$-loss
minimization. We first identify a family of DNNs such that the resulting Deep
Learning (DL) procedure achieves optimal generalization bounds for such
operators. For standard fully-connected architectures, we then show that there
are uncountably many minimizers of the training problem that yield equivalent
optimal performance. The DNN architectures we consider are `problem agnostic',
with width and depth only depending on the amount of training data $m$ and not
on regularity assumptions of the target operator. Next, we show that DL is
optimal for this problem: no recovery procedure can surpass these
generalization bounds up to log terms. Finally, we present numerical results
demonstrating the practical performance on challenging problems including the
parametric diffusion, Navier-Stokes-Brinkman and Boussinesq PDEs."
PIN - A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents,https://arxiv.org/abs/2406.13923,2024-06-20,2024-06-21,0.0,0.0,"Recent advancements in Large Multimodal Models (LMMs) have leveraged
extensive multimodal datasets to enhance capabilities in complex
knowledge-driven tasks. However, persistent challenges in perceptual and
reasoning errors limit their efficacy, particularly in interpreting intricate
visual data and deducing multimodal relationships. Addressing these issues, we
introduce a novel dataset format, PIN (Paired and INterleaved multimodal
documents), designed to significantly improve both the depth and breadth of
multimodal training. The PIN format is built on three foundational principles:
knowledge intensity, scalability, and support for diverse training modalities.
This innovative format combines markdown files and comprehensive images to
enrich training data with a dense knowledge structure and versatile training
strategies. We present PIN-14M, an open-source dataset comprising 14 million
samples derived from a diverse range of Chinese and English sources, tailored
to include complex web and scientific content. This dataset is constructed
meticulously to ensure data quality and ethical integrity, aiming to facilitate
advanced training strategies and improve model robustness against common
multimodal training pitfalls. Our initial results, forming the basis of this
technical report, suggest significant potential for the PIN format in refining
LMM performance, with plans for future expansions and detailed evaluations of
its impact on model capabilities."
Explainable AI Security - Exploring Robustness of Graph Neural Networks to Adversarial Attacks,https://arxiv.org/abs/2406.13920,2024-06-20,2024-06-21,0.0,0.0,"Graph neural networks (GNNs) have achieved tremendous success, but recent
studies have shown that GNNs are vulnerable to adversarial attacks, which
significantly hinders their use in safety-critical scenarios. Therefore, the
design of robust GNNs has attracted increasing attention. However, existing
research has mainly been conducted via experimental trial and error, and thus
far, there remains a lack of a comprehensive understanding of the vulnerability
of GNNs. To address this limitation, we systematically investigate the
adversarial robustness of GNNs by considering graph data patterns,
model-specific factors, and the transferability of adversarial examples.
Through extensive experiments, a set of principled guidelines is obtained for
improving the adversarial robustness of GNNs, for example: (i) rather than
highly regular graphs, the training graph data with diverse structural patterns
is crucial for model robustness, which is consistent with the concept of
adversarial training; (ii) the large model capacity of GNNs with sufficient
training data has a positive effect on model robustness, and only a small
percentage of neurons in GNNs are affected by adversarial attacks; (iii)
adversarial transfer is not symmetric and the adversarial examples produced by
the small-capacity model have stronger adversarial transferability. This work
illuminates the vulnerabilities of GNNs and opens many promising avenues for
designing robust GNNs."
SPL - A Socratic Playground for Learning Powered by Large Language Mode,https://arxiv.org/abs/2406.13919,2024-06-20,2024-06-21,1.0,0.0,"Dialogue-based Intelligent Tutoring Systems (ITSs) have significantly
advanced adaptive and personalized learning by automating sophisticated human
tutoring strategies within interactive dialogues. However, replicating the
nuanced patterns of expert human communication remains a challenge in Natural
Language Processing (NLP). Recent advancements in NLP, particularly Large
Language Models (LLMs) such as OpenAI's GPT-4, offer promising solutions by
providing human-like and context-aware responses based on extensive pre-trained
knowledge. Motivated by the effectiveness of LLMs in various educational tasks
(e.g., content creation and summarization, problem-solving, and automated
feedback provision), our study introduces the Socratic Playground for Learning
(SPL), a dialogue-based ITS powered by the GPT-4 model, which employs the
Socratic teaching method to foster critical thinking among learners. Through
extensive prompt engineering, SPL can generate specific learning scenarios and
facilitates efficient multi-turn tutoring dialogues. The SPL system aims to
enhance personalized and adaptive learning experiences tailored to individual
needs, specifically focusing on improving critical thinking skills. Our pilot
experimental results from essay writing tasks demonstrate SPL has the potential
to improve tutoring interactions and further enhance dialogue-based ITS
functionalities. Our study, exemplified by SPL, demonstrates how LLMs enhance
dialogue-based ITSs and expand the accessibility and efficacy of educational
technologies."
Beyond Optimism - Exploration With Partially Observable Rewards,https://arxiv.org/abs/2406.13909,2024-06-20,2024-06-21,0.0,0.0,"Exploration in reinforcement learning (RL) remains an open challenge. RL
algorithms rely on observing rewards to train the agent, and if informative
rewards are sparse the agent learns slowly or may not learn at all. To improve
exploration and reward discovery, popular algorithms rely on optimism. But what
if sometimes rewards are unobservable, e.g., situations of partial monitoring
in bandits and the recent formalism of monitored Markov decision process? In
this case, optimism can lead to suboptimal behavior that does not explore
further to collapse uncertainty. With this paper, we present a novel
exploration strategy that overcomes the limitations of existing methods and
guarantees convergence to an optimal policy even when rewards are not always
observable. We further propose a collection of tabular environments for
benchmarking exploration in RL (with and without unobservable rewards) and show
that our method outperforms existing ones."
Semi-supervised Regression Analysis with Model Misspecification and High-dimensional Data,https://arxiv.org/abs/2406.13906,2024-06-20,2024-06-21,0.0,0.0,"The accessibility of vast volumes of unlabeled data has sparked growing
interest in semi-supervised learning (SSL) and covariate shift transfer
learning (CSTL). In this paper, we present an inference framework for
estimating regression coefficients in conditional mean models within both SSL
and CSTL settings, while allowing for the misspecification of conditional mean
models. We develop an augmented inverse probability weighted (AIPW) method,
employing regularized calibrated estimators for both propensity score (PS) and
outcome regression (OR) nuisance models, with PS and OR models being
sequentially dependent. We show that when the PS model is correctly specified,
the proposed estimator achieves consistency, asymptotic normality, and valid
confidence intervals, even with possible OR model misspecification and
high-dimensional data. Moreover, by suppressing detailed technical choices, we
demonstrate that previous methods can be unified within our AIPW framework. Our
theoretical findings are verified through extensive simulation studies and a
real-world data application."
Persuasiveness of Generated Free-Text Rationales in Subjective Decisions - A Case Study on Pairwise Argument Ranking,https://arxiv.org/abs/2406.13905,2024-06-20,2024-06-21,0.0,0.0,"Generating free-text rationales is among the emergent capabilities of Large
Language Models (LLMs). These rationales have been found to enhance LLM
performance across various NLP tasks. Recently, there has been growing interest
in using these rationales to provide insights for various important downstream
tasks. In this paper, we analyze generated free-text rationales in tasks with
subjective answers, emphasizing the importance of rationalization in such
scenarios. We focus on pairwise argument ranking, a highly subjective task with
significant potential for real-world applications, such as debate assistance.
We evaluate the persuasiveness of rationales generated by nine LLMs to support
their subjective choices. Our findings suggest that open-source LLMs,
particularly Llama2-70B-chat, are capable of providing highly persuasive
rationalizations, surpassing even GPT models. Additionally, our experiments
show that rationale persuasiveness can be improved by controlling its
parameters through prompting or through self-refinement."
Generative AI for Enhancing Active Learning in Education - A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions,https://arxiv.org/abs/2406.13903,2024-06-20,2024-06-21,0.0,0.0,"This study investigates how LLMs, specifically GPT-3.5 and GPT-4, can develop
tailored questions for Grade 9 math, aligning with active learning principles.
By utilizing an iterative method, these models adjust questions based on
difficulty and content, responding to feedback from a simulated 'student'
model. A novel aspect of the research involved using GPT-4 as a 'teacher' to
create complex questions, with GPT-3.5 as the 'student' responding to these
challenges. This setup mirrors active learning, promoting deeper engagement.
The findings demonstrate GPT-4's superior ability to generate precise,
challenging questions and notable improvements in GPT-3.5's ability to handle
more complex problems after receiving instruction from GPT-4. These results
underscore the potential of LLMs to mimic and enhance active learning
scenarios, offering a promising path for AI in customized education. This
research contributes to understanding how AI can support personalized learning
experiences, highlighting the need for further exploration in various
educational contexts"
The Use of Multimodal Large Language Models to Detect Objects from Thermal Images - Transportation Applications,https://arxiv.org/abs/2406.13898,2024-06-20,2024-06-21,0.0,0.0,"The integration of thermal imaging data with Multimodal Large Language Models
(MLLMs) constitutes an exciting opportunity for improving the safety and
functionality of autonomous driving systems and many Intelligent Transportation
Systems (ITS) applications. This study investigates whether MLLMs can
understand complex images from RGB and thermal cameras and detect objects
directly. Our goals were to 1) assess the ability of the MLLM to learn from
information from various sets, 2) detect objects and identify elements in
thermal cameras, 3) determine whether two independent modality images show the
same scene, and 4) learn all objects using different modalities. The findings
showed that both GPT-4 and Gemini were effective in detecting and classifying
objects in thermal images. Similarly, the Mean Absolute Percentage Error (MAPE)
for pedestrian classification was 70.39% and 81.48%, respectively. Moreover,
the MAPE for bike, car, and motorcycle detection were 78.4%, 55.81%, and
96.15%, respectively. Gemini produced MAPE of 66.53%, 59.35% and 78.18%
respectively. This finding further demonstrates that MLLM can identify thermal
images and can be employed in advanced imaging automation technologies for ITS
applications."
INFusion - Diffusion Regularized Implicit Neural Representations for 2D and 3D accelerated MRI reconstruction,https://arxiv.org/abs/2406.13895,2024-06-19,2024-06-21,0.0,0.0,"Implicit Neural Representations (INRs) are a learning-based approach to
accelerate Magnetic Resonance Imaging (MRI) acquisitions, particularly in
scan-specific settings when only data from the under-sampled scan itself are
available. Previous work demonstrates that INRs improve rapid MRI through
inherent regularization imposed by neural network architectures. Typically
parameterized by fully-connected neural networks, INRs support continuous image
representations by taking a physical coordinate location as input and
outputting the intensity at that coordinate. Previous work has applied
unlearned regularization priors during INR training and have been limited to 2D
or low-resolution 3D acquisitions. Meanwhile, diffusion based generative models
have received recent attention as they learn powerful image priors decoupled
from the measurement model. This work proposes INFusion, a technique that
regularizes the optimization of INRs from under-sampled MR measurements with
pre-trained diffusion models for improved image reconstruction. In addition, we
propose a hybrid 3D approach with our diffusion regularization that enables INR
application on large-scale 3D MR datasets. 2D experiments demonstrate improved
INR training with our proposed diffusion regularization, and 3D experiments
demonstrate feasibility of INR training with diffusion regularization on 3D
matrix sizes of 256 by 256 by 80."
Open Generative Large Language Models for Galician,https://arxiv.org/abs/2406.13893,2024-06-19,2024-06-21,0.0,0.0,"Large language models (LLMs) have transformed natural language processing.
Yet, their predominantly English-centric training has led to biases and
performance disparities across languages. This imbalance marginalizes
minoritized languages, making equitable access to NLP technologies more
difficult for languages with lower resources, such as Galician. We present the
first two generative LLMs focused on Galician to bridge this gap. These models,
freely available as open-source resources, were trained using a GPT
architecture with 1.3B parameters on a corpus of 2.1B words. Leveraging
continual pretraining, we adapt to Galician two existing LLMs trained on larger
corpora, thus mitigating the data constraints that would arise if the training
were performed from scratch. The models were evaluated using human judgments
and task-based datasets from standardized benchmarks. These evaluations reveal
a promising performance, underscoring the importance of linguistic diversity in
generative models."
Adaptable Logical Control for Large Language Models,https://arxiv.org/abs/2406.13892,2024-06-19,2024-06-21,0.0,0.0,"Despite the success of Large Language Models (LLMs) on various tasks
following human instructions, controlling model generation at inference time
poses a persistent challenge. In this paper, we introduce Ctrl-G, an adaptable
framework that facilitates tractable and flexible control of LLM generation to
reliably follow logical constraints. Ctrl-G combines any production-ready LLM
with a Hidden Markov Model, enabling LLM outputs to adhere to logical
constraints represented as deterministic finite automata. We show that Ctrl-G,
when applied to a TULU2-7B model, outperforms GPT3.5 and GPT4 on the task of
interactive text editing: specifically, for the task of generating text
insertions/continuations following logical constraints, Ctrl-G achieves over
30% higher satisfaction rate in human evaluation compared to GPT4. When applied
to medium-size language models (e.g., GPT2-large), Ctrl-G also beats its
counterparts for constrained generation by large margins on standard
benchmarks. Additionally, as a proof-of-concept study, we experiment Ctrl-G on
the Grade School Math benchmark to assist LLM reasoning, foreshadowing the
application of Ctrl-G, as well as other constrained generation approaches,
beyond traditional language generation tasks."
DPO - Dual-Perturbation Optimization for Test-time Adaptation in 3D Object Detection,https://arxiv.org/abs/2406.13891,2024-06-19,2024-06-21,0.0,0.0,"LiDAR-based 3D object detection has seen impressive advances in recent times.
However, deploying trained 3D detectors in the real world often yields
unsatisfactory performance when the distribution of the test data significantly
deviates from the training data due to different weather conditions, object
sizes, \textit{etc}. A key factor in this performance degradation is the
diminished generalizability of pre-trained models, which creates a sharp loss
landscape during training. Such sharpness, when encountered during testing, can
precipitate significant performance declines, even with minor data variations.
To address the aforementioned challenges, we propose \textbf{dual-perturbation
optimization (DPO)} for \textbf{\underline{T}est-\underline{t}ime
\underline{A}daptation in \underline{3}D \underline{O}bject
\underline{D}etection (TTA-3OD)}. We minimize the sharpness to cultivate a flat
loss landscape to ensure model resiliency to minor data variations, thereby
enhancing the generalization of the adaptation process. To fully capture the
inherent variability of the test point clouds, we further introduce adversarial
perturbation to the input BEV features to better simulate the noisy test
environment. As the dual perturbation strategy relies on trustworthy
supervision signals, we utilize a reliable Hungarian matcher to filter out
pseudo-labels sensitive to perturbations. Additionally, we introduce early
Hungarian cutoff to avoid error accumulation from incorrect pseudo-labels by
halting the adaptation process. Extensive experiments across three types of
transfer tasks demonstrate that the proposed DPO significantly surpasses
previous state-of-the-art approaches, specifically on Waymo $\rightarrow$
KITTI, outperforming the most competitive baseline by 57.72\% in
$\text{AP}_\text{3D}$ and reaching 91\% of the fully supervised upper bound."
Open Problem - Anytime Convergence Rate of Gradient Descent,https://arxiv.org/abs/2406.13888,2024-06-19,2024-06-21,0.0,0.0,"Recent results show that vanilla gradient descent can be accelerated for
smooth convex objectives, merely by changing the stepsize sequence. We show
that this can lead to surprisingly large errors indefinitely, and therefore
ask: Is there any stepsize schedule for gradient descent that accelerates the
classic $\mathcal{O}(1/T)$ convergence rate, at \emph{any} stopping time $T$?"
Knowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever,https://arxiv.org/abs/2406.13885,2024-06-19,2024-06-21,0.0,0.0,"Knowledge tagging for questions plays a crucial role in contemporary
intelligent educational applications, including learning progress diagnosis,
practice question recommendations, and course content organization.
Traditionally, these annotations are always conducted by pedagogical experts,
as the task requires not only a strong semantic understanding of both question
stems and knowledge definitions but also deep insights into connecting
question-solving logic with corresponding knowledge concepts. With the recent
emergence of advanced text encoding algorithms, such as pre-trained language
models, many researchers have developed automatic knowledge tagging systems
based on calculating the semantic similarity between the knowledge and question
embeddings. In this paper, we explore automating the task using Large Language
Models (LLMs), in response to the inability of prior encoding-based methods to
deal with the hard cases which involve strong domain knowledge and complicated
concept definitions. By showing the strong performance of zero- and few-shot
results over math questions knowledge tagging tasks, we demonstrate LLMs' great
potential in conquering the challenges faced by prior methods. Furthermore, by
proposing a reinforcement learning-based demonstration retriever, we
successfully exploit the great potential of different-sized LLMs in achieving
better performance results while keeping the in-context demonstration usage
efficiency high."
Allocation Requires Prediction Only if Inequality Is Low,https://arxiv.org/abs/2406.13882,2024-06-19,2024-06-21,0.0,0.0,"Algorithmic predictions are emerging as a promising solution concept for
efficiently allocating societal resources. Fueling their use is an underlying
assumption that such systems are necessary to identify individuals for
interventions. We propose a principled framework for assessing this assumption:
Using a simple mathematical model, we evaluate the efficacy of prediction-based
allocations in settings where individuals belong to larger units such as
hospitals, neighborhoods, or schools. We find that prediction-based allocations
outperform baseline methods using aggregate unit-level statistics only when
between-unit inequality is low and the intervention budget is high. Our results
hold for a wide range of settings for the price of prediction, treatment effect
heterogeneity, and unit-level statistics' learnability. Combined, we highlight
the potential limits to improving the efficacy of interventions through
prediction."
A Catalyst Framework for the Quantum Linear System Problem via the Proximal Point Algorithm,https://arxiv.org/abs/2406.13879,2024-06-19,2024-06-21,0.0,0.0,"Solving systems of linear equations is a fundamental problem, but it can be
computationally intensive for classical algorithms in high dimensions. Existing
quantum algorithms can achieve exponential speedups for the quantum linear
system problem (QLSP) in terms of the problem dimension, but even such a
theoretical advantage is bottlenecked by the condition number of the
coefficient matrix. In this work, we propose a new quantum algorithm for QLSP
inspired by the classical proximal point algorithm (PPA). Our proposed method
can be viewed as a meta-algorithm that allows inverting a modified matrix via
an existing \texttt{QLSP\_solver}, thereby directly approximating the solution
vector instead of approximating the inverse of the coefficient matrix. By
carefully choosing the step size $\eta$, the proposed algorithm can effectively
precondition the linear system to mitigate the dependence on condition numbers
that hindered the applicability of previous approaches."
A Systematic Literature Review on the Use of Machine Learning in Software Engineering,https://arxiv.org/abs/2406.13877,2024-06-19,2024-06-21,0.0,0.0,"Software engineering (SE) is a dynamic field that involves multiple phases
all of which are necessary to develop sustainable software systems. Machine
learning (ML), a branch of artificial intelligence (AI), has drawn a lot of
attention in recent years thanks to its ability to analyze massive volumes of
data and extract useful patterns from data. Several studies have focused on
examining, categorising, and assessing the application of ML in SE processes.
We conducted a literature review on primary studies to address this gap. The
study was carried out following the objective and the research questions to
explore the current state of the art in applying machine learning techniques in
software engineering processes. The review identifies the key areas within
software engineering where ML has been applied, including software quality
assurance, software maintenance, software comprehension, and software
documentation. It also highlights the specific ML techniques that have been
leveraged in these domains, such as supervised learning, unsupervised learning,
and deep learning.
  Keywords: machine learning, deep learning, software engineering, natural
language processing, source code"
A Pure Transformer Pretraining Framework on Text-attributed Graphs,https://arxiv.org/abs/2406.13873,2024-06-19,2024-06-21,0.0,0.0,"Pretraining plays a pivotal role in acquiring generalized knowledge from
large-scale data, achieving remarkable successes as evidenced by large models
in CV and NLP. However, progress in the graph domain remains limited due to
fundamental challenges such as feature heterogeneity and structural
heterogeneity. Recently, increasing efforts have been made to enhance node
feature quality with Large Language Models (LLMs) on text-attributed graphs
(TAGs), demonstrating superiority to traditional bag-of-words or word2vec
techniques. These high-quality node features reduce the previously critical
role of graph structure, resulting in a modest performance gap between Graph
Neural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs).
Motivated by this, we introduce a feature-centric pretraining perspective by
treating graph structure as a prior and leveraging the rich, unified feature
space to learn refined interaction patterns that generalizes across graphs. Our
framework, Graph Sequence Pretraining with Transformer (GSPT), samples node
contexts through random walks and employs masked feature reconstruction to
capture pairwise proximity in the LLM-unified feature space using a standard
Transformer. By utilizing unified text representations rather than varying
structures, our framework achieves significantly better transferability among
graphs within the same domain. GSPT can be easily adapted to both node
classification and link prediction, demonstrating promising empirical success
on various datasets."
Robust Time Series Forecasting with Non-Heavy-Tailed Gaussian Loss-Weighted Sampler,https://arxiv.org/abs/2406.13871,2024-06-19,2024-06-21,0.0,0.0,"Forecasting multivariate time series is a computationally intensive task
challenged by extreme or redundant samples. Recent resampling methods aim to
increase training efficiency by reweighting samples based on their running
losses. However, these methods do not solve the problems caused by heavy-tailed
distribution losses, such as overfitting to outliers. To tackle these issues,
we introduce a novel approach: a Gaussian loss-weighted sampler that multiplies
their running losses with a Gaussian distribution weight. It reduces the
probability of selecting samples with very low or very high losses while
favoring those close to average losses. As it creates a weighted loss
distribution that is not heavy-tailed theoretically, there are several
advantages to highlight compared to existing methods: 1) it relieves the
inefficiency in learning redundant easy samples and overfitting to outliers, 2)
It improves training efficiency by preferentially learning samples close to the
average loss. Application on real-world time series forecasting datasets
demonstrate improvements in prediction quality for 1%-4% using mean square
error measurements in channel-independent settings. The code will be available
online after 1 the review."
Global Human-guided Counterfactual Explanations for Molecular Properties via Reinforcement Learning,https://arxiv.org/abs/2406.13869,2024-06-19,2024-06-21,0.0,0.0,"Counterfactual explanations of Graph Neural Networks (GNNs) offer a powerful
way to understand data that can naturally be represented by a graph structure.
Furthermore, in many domains, it is highly desirable to derive data-driven
global explanations or rules that can better explain the high-level properties
of the models and data in question. However, evaluating global counterfactual
explanations is hard in real-world datasets due to a lack of human-annotated
ground truth, which limits their use in areas like molecular sciences.
Additionally, the increasing scale of these datasets provides a challenge for
random search-based methods. In this paper, we develop a novel global
explanation model RLHEX for molecular property prediction. It aligns the
counterfactual explanations with human-defined principles, making the
explanations more interpretable and easy for experts to evaluate. RLHEX
includes a VAE-based graph generator to generate global explanations and an
adapter to adjust the latent representation space to human-defined principles.
Optimized by Proximal Policy Optimization (PPO), the global explanations
produced by RLHEX cover 4.12% more input graphs and reduce the distance between
the counterfactual explanation set and the input set by 0.47% on average across
three molecular datasets. RLHEX provides a flexible framework to incorporate
different human-designed principles into the counterfactual explanation
generation process, aligning these explanations with domain expertise. The code
and data are released at https://github.com/dqwang122/RLHEX."
SDQ - Sparse Decomposed Quantization for LLM Inference,https://arxiv.org/abs/2406.13868,2024-06-19,2024-06-21,0.0,0.0,"Recently, large language models (LLMs) have shown surprising performance in
task-specific workloads as well as general tasks with the given prompts.
However, to achieve unprecedented performance, recent LLMs use billions to
trillions of parameters, which hinder the wide adaptation of those models due
to their extremely large compute and memory requirements. To resolve the issue,
various model compression methods are being actively investigated. In this
work, we propose SDQ (Sparse Decomposed Quantization) to exploit both
structured sparsity and quantization to achieve both high compute and memory
efficiency. From our evaluations, we observe that SDQ can achieve 4x effective
compute throughput with <1% quality drop."
Evaluating representation learning on the protein structure universe,https://arxiv.org/abs/2406.13864,2024-06-19,2024-06-21,0.0,0.0,"We introduce ProteinWorkshop, a comprehensive benchmark suite for
representation learning on protein structures with Geometric Graph Neural
Networks. We consider large-scale pre-training and downstream tasks on both
experimental and predicted structures to enable the systematic evaluation of
the quality of the learned structural representation and their usefulness in
capturing functional relationships for downstream tasks. We find that: (1)
large-scale pretraining on AlphaFold structures and auxiliary tasks
consistently improve the performance of both rotation-invariant and equivariant
GNNs, and (2) more expressive equivariant GNNs benefit from pretraining to a
greater extent compared to invariant models. We aim to establish a common
ground for the machine learning and computational biology communities to
rigorously compare and advance protein structure representation learning. Our
open-source codebase reduces the barrier to entry for working with large
protein structure datasets by providing: (1) storage-efficient dataloaders for
large-scale structural databases including AlphaFoldDB and ESM Atlas, as well
as (2) utilities for constructing new tasks from the entire PDB.
ProteinWorkshop is available at: github.com/a-r-j/ProteinWorkshop."
Knowledge Graph-Enhanced Large Language Models via Path Selection,https://arxiv.org/abs/2406.13862,2024-06-19,2024-06-21,0.0,0.0,"Large Language Models (LLMs) have shown unprecedented performance in various
real-world applications. However, they are known to generate factually
inaccurate outputs, a.k.a. the hallucination problem. In recent years,
incorporating external knowledge extracted from Knowledge Graphs (KGs) has
become a promising strategy to improve the factual accuracy of LLM-generated
outputs. Nevertheless, most existing explorations rely on LLMs themselves to
perform KG knowledge extraction, which is highly inflexible as LLMs can only
provide binary judgment on whether a certain knowledge (e.g., a knowledge path
in KG) should be used. In addition, LLMs tend to pick only knowledge with
direct semantic relationship with the input text, while potentially useful
knowledge with indirect semantics can be ignored. In this work, we propose a
principled framework KELP with three stages to handle the above problems.
Specifically, KELP is able to achieve finer granularity of flexible knowledge
extraction by generating scores for knowledge paths with input texts via latent
semantic matching. Meanwhile, knowledge paths with indirect semantic
relationships with the input text can also be considered via trained encoding
between the selected paths in KG and the input text. Experiments on real-world
datasets validate the effectiveness of KELP."
Distributional reasoning in LLMs - Parallel reasoning processes in multi-hop reasoning,https://arxiv.org/abs/2406.13858,2024-06-19,2024-06-21,0.0,0.0,"Large language models (LLMs) have shown an impressive ability to perform
tasks believed to require thought processes. When the model does not document
an explicit thought process, it becomes difficult to understand the processes
occurring within its hidden layers and to determine if these processes can be
referred to as reasoning. We introduce a novel and interpretable analysis of
internal multi-hop reasoning processes in LLMs. We demonstrate that the
prediction process for compositional reasoning questions can be modeled using a
simple linear transformation between two semantic category spaces. We show that
during inference, the middle layers of the network generate highly
interpretable embeddings that represent a set of potential intermediate answers
for the multi-hop question. We use statistical analyses to show that a
corresponding subset of tokens is activated in the model's output, implying the
existence of parallel reasoning paths. These observations hold true even when
the model lacks the necessary knowledge to solve the task. Our findings can
help uncover the strategies that LLMs use to solve reasoning tasks, offering
insights into the types of thought processes that can emerge from artificial
intelligence. Finally, we also discuss the implication of cognitive modeling of
these results."
Optimizing Quantile-based Trading Strategies in Electricity Arbitrage,https://arxiv.org/abs/2406.13851,2024-06-19,2024-06-21,0.0,0.0,"Efficiently integrating renewable resources into electricity markets is vital
for addressing the challenges of matching real-time supply and demand while
reducing the significant energy wastage resulting from curtailments. To address
this challenge effectively, the incorporation of storage devices can enhance
the reliability and efficiency of the grid, improving market liquidity and
reducing price volatility. In short-term electricity markets, participants
navigate numerous options, each presenting unique challenges and opportunities,
underscoring the critical role of the trading strategy in maximizing profits.
This study delves into the optimization of day-ahead and balancing market
trading, leveraging quantile-based forecasts. Employing three trading
approaches with practical constraints, our research enhances forecast
assessment, increases trading frequency, and employs flexible timestamp orders.
Our findings underscore the profit potential of simultaneous participation in
both day-ahead and balancing markets, especially with larger battery storage
systems; despite increased costs and narrower profit margins associated with
higher-volume trading, the implementation of high-frequency strategies plays a
significant role in maximizing profits and addressing market challenges.
Finally, we modelled four commercial battery storage systems and evaluated
their economic viability through a scenario analysis, with larger batteries
showing a shorter return on investment."
Text Serialization and Their Relationship with the Conventional Paradigms of Tabular Machine Learning,https://arxiv.org/abs/2406.13846,2024-06-19,2024-06-21,0.0,0.0,"Recent research has explored how Language Models (LMs) can be used for
feature representation and prediction in tabular machine learning tasks. This
involves employing text serialization and supervised fine-tuning (SFT)
techniques. Despite the simplicity of these techniques, significant gaps remain
in our understanding of the applicability and reliability of LMs in this
context. Our study assesses how emerging LM technologies compare with
traditional paradigms in tabular machine learning and evaluates the feasibility
of adopting similar approaches with these advanced technologies. At the data
level, we investigate various methods of data representation and curation of
serialized tabular data, exploring their impact on prediction performance. At
the classification level, we examine whether text serialization combined with
LMs enhances performance on tabular datasets (e.g. class imbalance,
distribution shift, biases, and high dimensionality), and assess whether this
method represents a state-of-the-art (SOTA) approach for addressing tabular
machine learning challenges. Our findings reveal current pre-trained models
should not replace conventional approaches."
Generative AI Misuse - A Taxonomy of Tactics and Insights from Real-World Data,https://arxiv.org/abs/2406.13843,2024-06-19,2024-06-21,0.0,0.0,"Generative, multimodal artificial intelligence (GenAI) offers transformative
potential across industries, but its misuse poses significant risks. Prior
research has shed light on the potential of advanced AI systems to be exploited
for malicious purposes. However, we still lack a concrete understanding of how
GenAI models are specifically exploited or abused in practice, including the
tactics employed to inflict harm. In this paper, we present a taxonomy of GenAI
misuse tactics, informed by existing academic literature and a qualitative
analysis of approximately 200 observed incidents of misuse reported between
January 2023 and March 2024. Through this analysis, we illuminate key and novel
patterns in misuse during this time period, including potential motivations,
strategies, and how attackers leverage and abuse system capabilities across
modalities (e.g. image, text, audio, video) in the wild."
Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control,https://arxiv.org/abs/2406.13842,2024-06-19,2024-06-21,0.0,0.0,"Utilizing air-traffic control (ATC) data for downstream natural-language
processing tasks requires preprocessing steps. Key steps are the transcription
of the data via automatic speech recognition (ASR) and speaker diarization,
respectively speaker role detection (SRD) to divide the transcripts into pilot
and air-traffic controller (ATCO) transcripts. While traditional approaches
take on these tasks separately, we propose a transformer-based joint ASR-SRD
system that solves both tasks jointly while relying on a standard ASR
architecture. We compare this joint system against two cascaded approaches for
ASR and SRD on multiple ATC datasets. Our study shows in which cases our joint
system can outperform the two traditional approaches and in which cases the
other architectures are preferable. We additionally evaluate how acoustic and
lexical differences influence all architectures and show how to overcome them
for our joint architecture."
StackRAG Agent - Improving Developer Answers with Retrieval-Augmented Generation,https://arxiv.org/abs/2406.13840,2024-06-19,2024-06-21,0.0,0.0,"Developers spend much time finding information that is relevant to their
questions. Stack Overflow has been the leading resource, and with the advent of
Large Language Models (LLMs), generative models such as ChatGPT are used
frequently. However, there is a catch in using each one separately. Searching
for answers is time-consuming and tedious, as shown by the many tools developed
by researchers to address this issue. On the other, using LLMs is not reliable,
as they might produce irrelevant or unreliable answers (i.e., hallucination).
In this work, we present StackRAG, a retrieval-augmented Multiagent generation
tool based on LLMs that combines the two worlds: aggregating the knowledge from
SO to enhance the reliability of the generated answers. Initial evaluations
show that the generated answers are correct, accurate, relevant, and useful."
RNA-FrameFlow - Flow Matching for de novo 3D RNA Backbone Design,https://arxiv.org/abs/2406.13839,2024-06-19,2024-06-21,0.0,0.0,"We introduce RNA-FrameFlow, the first generative model for 3D RNA backbone
design. We build upon SE(3) flow matching for protein backbone generation and
establish protocols for data preparation and evaluation to address unique
challenges posed by RNA modeling. We formulate RNA structures as a set of
rigid-body frames and associated loss functions which account for larger, more
conformationally flexible RNA backbones (13 atoms per nucleotide) vs. proteins
(4 atoms per residue). Toward tackling the lack of diversity in 3D RNA
datasets, we explore training with structural clustering and cropping
augmentations. Additionally, we define a suite of evaluation metrics to measure
whether the generated RNA structures are globally self-consistent (via inverse
folding followed by forward folding) and locally recover RNA-specific
structural descriptors. The most performant version of RNA-FrameFlow generates
locally realistic RNA backbones of 40-150 nucleotides, over 40% of which pass
our validity criteria as measured by a self-consistency TM-score >= 0.45, at
which two RNAs have the same global fold. Open-source code:
https://github.com/rish-16/rna-backbone-design"
Optimizing Wireless Discontinuous Reception via MAC Signaling Learning,https://arxiv.org/abs/2406.13834,2024-06-19,2024-06-21,0.0,0.0,"We present a Reinforcement Learning (RL) approach to the problem of
controlling the Discontinuous Reception (DRX) policy from a Base Transceiver
Station (BTS) in a cellular network. We do so by means of optimally timing the
transmission of fast Layer-2 signaling messages (a.k.a. Medium Access Layer
(MAC) Control Elements (CEs) as specified in 5G New Radio). Unlike more
conventional approaches to DRX optimization, which rely on fine-tuning the
values of DRX timers, we assess the gains that can be obtained solely by means
of this MAC CE signalling. For the simulation part, we concentrate on traffic
types typically encountered in Extended Reality (XR) applications, where the
need for battery drain minimization and overheating mitigation are particularly
pressing. Both 3GPP 5G New Radio (5G NR) compliant and non-compliant (""beyond
5G"") MAC CEs are considered. Our simulation results show that our proposed
technique strikes an improved trade-off between latency and energy savings as
compared to conventional timer-based approaches that are characteristic of most
current implementations. Specifically, our RL-based policy can nearly halve the
active time for a single User Equipment (UE) with respect to a na\""ive MAC CE
transmission policy, and still achieve near 20% active time reduction for 9
simultaneously served UEs."
Cluster Quilting - Spectral Clustering for Patchwork Learning,https://arxiv.org/abs/2406.13833,2024-06-19,2024-06-21,0.0,0.0,"Patchwork learning arises as a new and challenging data collection paradigm
where both samples and features are observed in fragmented subsets. Due to
technological limits, measurement expense, or multimodal data integration, such
patchwork data structures are frequently seen in neuroscience, healthcare, and
genomics, among others. Instead of analyzing each data patch separately, it is
highly desirable to extract comprehensive knowledge from the whole data set. In
this work, we focus on the clustering problem in patchwork learning, aiming at
discovering clusters amongst all samples even when some are never jointly
observed for any feature. We propose a novel spectral clustering method called
Cluster Quilting, consisting of (i) patch ordering that exploits the
overlapping structure amongst all patches, (ii) patchwise SVD, (iii) sequential
linear mapping of top singular vectors for patch overlaps, followed by (iv)
k-means on the combined and weighted singular vectors. Under a sub-Gaussian
mixture model, we establish theoretical guarantees via a non-asymptotic
misclustering rate bound that reflects both properties of the patch-wise
observation regime as well as the clustering signal and noise dependencies. We
also validate our Cluster Quilting algorithm through extensive empirical
studies on both simulated and real data sets in neuroscience and genomics,
where it discovers more accurate and scientifically more plausible clusters
than other approaches."
Neuro-symbolic Training for Reasoning over Spatial Language,https://arxiv.org/abs/2406.13828,2024-06-19,2024-06-21,0.0,0.0,"Recent research shows that more data and larger models can provide more
accurate solutions to natural language problems requiring reasoning. However,
models can easily fail to provide solutions in unobserved complex input
compositions due to not achieving the level of abstraction required for
generalizability. To alleviate this issue, we propose training the language
models with neuro-symbolic techniques that can exploit the logical rules of
reasoning as constraints and provide additional supervision sources to the
model. Training models to adhere to the regulations of reasoning pushes them to
make more effective abstractions needed for generalizability and transfer
learning. We focus on a challenging problem of spatial reasoning over text. Our
results on various benchmarks using multiple language models confirm our
hypothesis of effective domain transfer based on neuro-symbolic training."
Fine-Tuning BERTs for Definition Extraction from Mathematical Text,https://arxiv.org/abs/2406.13827,2024-06-19,2024-06-21,0.0,0.0,"In this paper, we fine-tuned three pre-trained BERT models on the task of
""definition extraction"" from mathematical English written in LaTeX. This is
presented as a binary classification problem, where either a sentence contains
a definition of a mathematical term or it does not. We used two original data
sets, ""Chicago"" and ""TAC,"" to fine-tune and test these models. We also tested
on WFMALL, a dataset presented by Vanetik and Litvak in 2021 and compared the
performance of our models to theirs. We found that a high-performance
Sentence-BERT transformer model performed best based on overall accuracy,
recall, and precision metrics, achieving comparable results to the earlier
models with less computational effort."
"Framing Social Movements on Social Media - Unpacking Diagnostic, Prognostic, and Motivational Strategies",https://arxiv.org/abs/2406.13820,2024-06-19,2024-06-21,0.0,0.0,"Social media enables activists to directly communicate with the public and
provides a space for movement leaders, participants, bystanders, and opponents
to collectively construct and contest narratives. Focusing on Twitter messages
from social movements surrounding three issues in 2018-2019 (guns, immigration,
and LGBTQ rights), we create a codebook, annotated dataset, and computational
models to detect diagnostic (problem identification and attribution),
prognostic (proposed solutions and tactics), and motivational (calls to action)
framing strategies. We conduct an in-depth unsupervised linguistic analysis of
each framing strategy, and uncover cross-movement similarities in associations
between framing and linguistic features such as pronouns and deontic modal
verbs. Finally, we compare framing strategies across issues and other social,
cultural, and interactional contexts. For example, we show that diagnostic
framing is more common in replies than original broadcast posts, and that
social movement organizations focus much more on prognostic and motivational
framing than journalists and ordinary citizens."
Evaluation of Missing Data Analytical Techniques in Longitudinal Research - Traditional and Machine Learning Approaches,https://arxiv.org/abs/2406.13814,2024-06-19,2024-06-21,0.0,0.0,"Missing Not at Random (MNAR) and nonnormal data are challenging to handle.
Traditional missing data analytical techniques such as full information maximum
likelihood estimation (FIML) may fail with nonnormal data as they are built on
normal distribution assumptions. Two-Stage Robust Estimation (TSRE) does manage
nonnormal data, but both FIML and TSRE are less explored in longitudinal
studies under MNAR conditions with nonnormal distributions. Unlike traditional
statistical approaches, machine learning approaches do not require
distributional assumptions about the data. More importantly, they have shown
promise for MNAR data; however, their application in longitudinal studies,
addressing both Missing at Random (MAR) and MNAR scenarios, is also
underexplored. This study utilizes Monte Carlo simulations to assess and
compare the effectiveness of six analytical techniques for missing data within
the growth curve modeling framework. These techniques include traditional
approaches like FIML and TSRE, machine learning approaches by single imputation
(K-Nearest Neighbors and missForest), and machine learning approaches by
multiple imputation (micecart and miceForest). We investigate the influence of
sample size, missing data rate, missing data mechanism, and data distribution
on the accuracy and efficiency of model estimation. Our findings indicate that
FIML is most effective for MNAR data among the tested approaches. TSRE excels
in handling MAR data, while missForest is only advantageous in limited
conditions with a combination of very skewed distributions, very large sample
sizes (e.g., n larger than 1000), and low missing data rates."
Can Low-Rank Knowledge Distillation in LLMs be Useful for Microelectronic Reasoning?,https://arxiv.org/abs/2406.13808,2024-06-19,2024-06-21,0.0,0.0,"In this work, we present empirical results regarding the feasibility of using
offline large language models (LLMs) in the context of electronic design
automation (EDA). The goal is to investigate and evaluate a contemporary
language model's (Llama-2-7B) ability to function as a microelectronic Q & A
expert as well as its reasoning, and generation capabilities in solving
microelectronic-related problems. Llama-2-7B was tested across a variety of
adaptation methods, including introducing a novel low-rank knowledge
distillation (LoRA-KD) scheme. Our experiments produce both qualitative and
quantitative results."
AlanaVLM - A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding,https://arxiv.org/abs/2406.13807,2024-06-19,2024-06-21,0.0,0.0,"AI personal assistants deployed via robots or wearables require embodied
understanding to collaborate with humans effectively. However, current
Vision-Language Models (VLMs) primarily focus on third-person view videos,
neglecting the richness of egocentric perceptual experience. To address this
gap, we propose three key contributions. First, we introduce the Egocentric
Video Understanding Dataset (EVUD) for training VLMs on video captioning and
question answering tasks specific to egocentric videos. Second, we present
AlanaVLM, a 7B parameter VLM trained using parameter-efficient methods on EVUD.
Finally, we evaluate AlanaVLM's capabilities on OpenEQA, a challenging
benchmark for embodied video question answering. Our model achieves
state-of-the-art performance, outperforming open-source models including strong
Socratic models using GPT-4 as a planner by 3.6%. Additionally, we outperform
Claude 3 and Gemini Pro Vision 1.0 and showcase competitive results compared to
Gemini Pro 1.5 and GPT-4V, even surpassing the latter in spatial reasoning.
This research paves the way for building efficient VLMs that can be deployed in
robots or wearables, leveraging embodied video understanding to collaborate
seamlessly with humans in everyday tasks, contributing to the next generation
of Embodied AI."
WikiContradict - A Benchmark for Evaluating LLMs on Real-World Knowledge Conflicts from Wikipedia,https://arxiv.org/abs/2406.13805,2024-06-19,2024-06-21,0.0,0.0,"Retrieval-augmented generation (RAG) has emerged as a promising solution to
mitigate the limitations of large language models (LLMs), such as
hallucinations and outdated information. However, it remains unclear how LLMs
handle knowledge conflicts arising from different augmented retrieved passages,
especially when these passages originate from the same source and have equal
trustworthiness. In this work, we conduct a comprehensive evaluation of
LLM-generated answers to questions that have varying answers based on
contradictory passages from Wikipedia, a dataset widely regarded as a
high-quality pre-training resource for most LLMs. Specifically, we introduce
WikiContradict, a benchmark consisting of 253 high-quality, human-annotated
instances designed to assess LLM performance when augmented with retrieved
passages containing real-world knowledge conflicts. We benchmark a diverse
range of both closed and open-source LLMs under different QA scenarios,
including RAG with a single passage, and RAG with 2 contradictory passages.
Through rigorous human evaluations on a subset of WikiContradict instances
involving 5 LLMs and over 3,500 judgements, we shed light on the behaviour and
limitations of these models. For instance, when provided with two passages
containing contradictory facts, all models struggle to generate answers that
accurately reflect the conflicting nature of the context, especially for
implicit conflicts requiring reasoning. Since human evaluation is costly, we
also introduce an automated model that estimates LLM performance using a strong
open-source language model, achieving an F-score of 0.8. Using this automated
metric, we evaluate more than 1,500 answers from seven LLMs across all
WikiContradict instances. To facilitate future work, we release WikiContradict
on: https://ibm.biz/wikicontradict."
Semantic Structure-Mapping in LLM and Human Analogical Reasoning,https://arxiv.org/abs/2406.13803,2024-06-19,2024-06-21,0.0,0.0,"Analogical reasoning is considered core to human learning and cognition.
Recent studies have compared the analogical reasoning abilities of human
subjects and Large Language Models (LLMs) on abstract symbol manipulation
tasks, such as letter string analogies. However, these studies largely neglect
analogical reasoning over semantically meaningful symbols, such as natural
language words. This ability to draw analogies that link language to
non-linguistic domains, which we term semantic structure-mapping, is thought to
play a crucial role in language acquisition and broader cognitive development.
We test human subjects and LLMs on analogical reasoning tasks that require the
transfer of semantic structure and content from one domain to another. Advanced
LLMs match human performance across many task variations. However, humans and
LLMs respond differently to certain task variations and semantic distractors.
Overall, our data suggest that LLMs are approaching human-level performance on
these important cognitive tasks, but are not yet entirely human like."
A Primal-Dual Framework for Transformers and Neural Networks,https://arxiv.org/abs/2406.13781,2024-06-19,2024-06-21,0.0,0.0,"Self-attention is key to the remarkable success of transformers in sequence
modeling tasks including many applications in natural language processing and
computer vision. Like neural network layers, these attention mechanisms are
often developed by heuristics and experience. To provide a principled framework
for constructing attention layers in transformers, we show that the
self-attention corresponds to the support vector expansion derived from a
support vector regression problem, whose primal formulation has the form of a
neural network layer. Using our framework, we derive popular attention layers
used in practice and propose two new attentions: 1) the Batch Normalized
Attention (Attention-BN) derived from the batch normalization layer and 2) the
Attention with Scaled Head (Attention-SH) derived from using less training data
to fit the SVR model. We empirically demonstrate the advantages of the
Attention-BN and Attention-SH in reducing head redundancy, increasing the
model's accuracy, and improving the model's efficiency in a variety of
practical applications including image and time-series classification."
FoRAG - Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering,https://arxiv.org/abs/2406.13779,2024-06-19,2024-06-21,0.0,0.0,"Retrieval Augmented Generation (RAG) has become prevalent in
question-answering (QA) tasks due to its ability of utilizing search engine to
enhance the quality of long-form question-answering (LFQA). Despite the
emergence of various open source methods and web-enhanced commercial systems
such as Bing Chat, two critical problems remain unsolved, i.e., the lack of
factuality and clear logic in the generated long-form answers. In this paper,
we remedy these issues via a systematic study on answer generation in
web-enhanced LFQA. Specifically, we first propose a novel outline-enhanced
generator to achieve clear logic in the generation of multifaceted answers and
construct two datasets accordingly. Then we propose a factuality optimization
method based on a carefully designed doubly fine-grained RLHF framework, which
contains automatic evaluation and reward modeling in different levels of
granularity. Our generic framework comprises conventional fine-grained RLHF
methods as special cases. Extensive experiments verify the superiority of our
proposed \textit{Factuality-optimized RAG (FoRAG)} method on both English and
Chinese benchmarks. In particular, when applying our method to Llama2-7B-chat,
the derived model FoRAG-L-7B outperforms WebGPT-175B in terms of three commonly
used metrics (i.e., coherence, helpfulness, and factuality), while the number
of parameters is much smaller (only 1/24 of that of WebGPT-175B). Our datasets
and models are made publicly available for better reproducibility:
https://huggingface.co/forag."
Game of LLMs - Discovering Structural Constructs in Activities using Large Language Models,https://arxiv.org/abs/2406.13777,2024-06-19,2024-06-21,0.0,0.0,"Human Activity Recognition is a time-series analysis problem. A popular
analysis procedure used by the community assumes an optimal window length to
design recognition pipelines. However, in the scenario of smart homes, where
activities are of varying duration and frequency, the assumption of a constant
sized window does not hold. Additionally, previous works have shown these
activities to be made up of building blocks. We focus on identifying these
underlying building blocks--structural constructs, with the use of large
language models. Identifying these constructs can be beneficial especially in
recognizing short-duration and infrequent activities. We also propose the
development of an activity recognition procedure that uses these building
blocks to model activities, thus helping the downstream task of activity
monitoring in smart homes."
Elliptical Attention,https://arxiv.org/abs/2406.13770,2024-06-19,2024-06-21,0.0,0.0,"Pairwise dot-product self-attention is key to the success of transformers
that achieve state-of-the-art performance across a variety of applications in
language and vision. This dot-product self-attention computes attention weights
among the input tokens using Euclidean distance, which makes the model prone to
representation collapse and vulnerable to contaminated samples. In this paper,
we propose using a Mahalanobis distance metric for computing the attention
weights to stretch the underlying feature space in directions of high
contextual relevance. In particular, we define a hyper-ellipsoidal neighborhood
around each query to increase the attention weights of the tokens lying in the
contextually important directions. We term this novel class of attention
Elliptical Attention. Our Elliptical Attention provides two benefits: 1)
reducing representation collapse and 2) enhancing the model's robustness as the
Elliptical Attention pays more attention to contextually relevant information
rather than focusing on some small subset of informative features. We
empirically demonstrate the advantages of Elliptical Attention over the
baseline dot-product attention and state-of-the-art attention methods on
various practical tasks, including object classification, image segmentation,
and language modeling across different data modalities."
FastPersist - Accelerating Model Checkpointing in Deep Learning,https://arxiv.org/abs/2406.13768,2024-06-19,2024-06-21,0.0,0.0,"Model checkpoints are critical Deep Learning (DL) artifacts that enable fault
tolerance for training and downstream applications, such as inference. However,
writing checkpoints to persistent storage, and other I/O aspects of DL
training, are mostly ignored by compute-focused optimization efforts for faster
training of rapidly growing models and datasets. Towards addressing this
imbalance, we propose FastPersist to accelerate checkpoint creation in DL
training. FastPersist combines three novel techniques: (i) NVMe optimizations
for faster checkpoint writes to SSDs, (ii) efficient write parallelism using
the available SSDs in training environments, and (iii) overlapping
checkpointing with independent training computations. Our evaluation using real
world dense and sparse DL models shows that FastPersist creates checkpoints in
persistent storage up to 116x faster than baseline, and enables per-iteration
checkpointing with negligible overhead."
Can LLMs Reason in the Wild with Programs?,https://arxiv.org/abs/2406.13764,2024-06-19,2024-06-21,0.0,0.0,"Large Language Models (LLMs) have shown superior capability to solve
reasoning problems with programs. While being a promising direction, most of
such frameworks are trained and evaluated in settings with a prior knowledge of
task requirements. However, as LLMs become more capable, it is necessary to
assess their reasoning abilities in more realistic scenarios where many
real-world problems are open-ended with ambiguous scope, and often require
multiple formalisms to solve. To investigate this, we introduce the task of
reasoning in the wild, where an LLM is tasked to solve a reasoning problem of
unknown type by identifying the subproblems and their corresponding formalisms,
and writing a program to solve each subproblem, guided by a tactic. We create a
large tactic-guided trajectory dataset containing detailed solutions to a
diverse set of reasoning problems, ranging from well-defined single-form
reasoning (e.g., math, logic), to ambiguous and hybrid ones (e.g., commonsense,
combined math and logic). This allows us to test various aspects of LLMs
reasoning at the fine-grained level such as the selection and execution of
tactics, and the tendency to take undesired shortcuts. In experiments, we
highlight that existing LLMs fail significantly on problems with ambiguous and
mixed scope, revealing critical limitations and overfitting issues (e.g.
accuracy on GSM8K drops by at least 50\%). We further show the potential of
finetuning a local LLM on the tactic-guided trajectories in achieving better
performance. Project repo is available at
github.com/gblackout/Reason-in-the-Wild"
Through the Theory of Mind's Eye - Reading Minds with Multimodal Video Large Language Models,https://arxiv.org/abs/2406.13763,2024-06-19,2024-06-21,0.0,0.0,"Can large multimodal models have a human-like ability for emotional and
social reasoning, and if so, how does it work? Recent research has discovered
emergent theory-of-mind (ToM) reasoning capabilities in large language models
(LLMs). LLMs can reason about people's mental states by solving various
text-based ToM tasks that ask questions about the actors' ToM (e.g., human
belief, desire, intention). However, human reasoning in the wild is often
grounded in dynamic scenes across time. Thus, we consider videos a new medium
for examining spatio-temporal ToM reasoning ability. Specifically, we ask
explicit probing questions about videos with abundant social and emotional
reasoning content. We develop a pipeline for multimodal LLM for ToM reasoning
using video and text. We also enable explicit ToM reasoning by retrieving key
frames for answering a ToM question, which reveals how multimodal LLMs reason
about ToM."
Unveiling the Hidden Structure of Self-Attention via Kernel Principal Component Analysis,https://arxiv.org/abs/2406.13762,2024-06-19,2024-06-21,0.0,0.0,"The remarkable success of transformers in sequence modeling tasks, spanning
various applications in natural language processing and computer vision, is
attributed to the critical role of self-attention. Similar to the development
of most deep learning models, the construction of these attention mechanisms
rely on heuristics and experience. In our work, we derive self-attention from
kernel principal component analysis (kernel PCA) and show that self-attention
projects its query vectors onto the principal component axes of its key matrix
in a feature space. We then formulate the exact formula for the value matrix in
self-attention, theoretically and empirically demonstrating that this value
matrix captures the eigenvectors of the Gram matrix of the key vectors in
self-attention. Leveraging our kernel PCA framework, we propose Attention with
Robust Principal Components (RPC-Attention), a novel class of robust attention
that is resilient to data contamination. We empirically demonstrate the
advantages of RPC-Attention over softmax attention on the ImageNet-1K object
classification, WikiText-103 language modeling, and ADE20K image segmentation
task."
Exponential time differencing for matrix-valued dynamical systems,https://arxiv.org/abs/2406.13761,2024-06-19,2024-06-21,0.0,0.0,"Matrix evolution equations occur in many applications, such as dynamical
Lyapunov/Sylvester systems or Riccati equations in optimization and stochastic
control, machine learning or data assimilation. In many cases, their tightest
stability condition is coming from a linear term. Exponential time differencing
(ETD) is known to produce highly stable numerical schemes by treating the
linear term in an exact fashion. In particular, for stiff problems, ETD methods
are a method of choice. We propose an extension of the class of ETD algorithms
to matrix-valued dynamical equations. This allows us to produce highly
efficient and stable integration schemes. We show their efficiency and
applicability for a variety of real-world problems, from geophysical
applications to dynamical problems in machine learning."
Concept Drift Visualization of SVM with Shifting Window,https://arxiv.org/abs/2406.13754,2024-06-19,2024-06-21,0.0,0.0,"In machine learning, concept drift is an evolution of information that
invalidates the current data model. It happens when the statistical properties
of the input data change over time in unforeseen ways. Concept drift detection
is crucial when dealing with dynamically changing data. Its visualization can
bring valuable insight into the data dynamics, especially for multidimensional
data, and is related to visual knowledge discovery. We propose a novel
visualization model based on parallel coordinates, denoted as parallel
histograms through time. Our model represents histograms of feature
distributions for successive time-shifted windows. The drift is shown as
variations of these histograms, obtained by connecting the means of the
distribution for successive time windows. We show how these diagrams can be
used to explain the decision made by the machine learning model in choosing the
drift point. By isolating the drift at the edges of successive time windows,
there will be none (or reduced) drift within the adjacent windows. We
illustrate this concept on both synthetic and real datasets. In our
experiments, we use an incremental/decremental SVM with shifting window,
introduced by us in previous work. With our proposed technique, in addition to
detect the presence of concept drift, we can also depict it. This information
can be further used to explain the change. mental results, opening the
possibility for further investigations."
Empowering Tuberculosis Screening with Explainable Self-Supervised Deep Neural Networks,https://arxiv.org/abs/2406.13750,2024-06-19,2024-06-21,0.0,0.0,"Tuberculosis persists as a global health crisis, especially in
resource-limited populations and remote regions, with more than 10 million
individuals newly infected annually. It stands as a stark symbol of inequity in
public health. Tuberculosis impacts roughly a quarter of the global populace,
with the majority of cases concentrated in eight countries, accounting for
two-thirds of all tuberculosis infections. Although a severe ailment,
tuberculosis is both curable and manageable. However, early detection and
screening of at-risk populations are imperative. Chest x-ray stands as the
predominant imaging technique utilized in tuberculosis screening efforts.
However, x-ray screening necessitates skilled radiologists, a resource often
scarce, particularly in remote regions with limited resources. Consequently,
there is a pressing need for artificial intelligence (AI)-powered systems to
support clinicians and healthcare providers in swift screening. However,
training a reliable AI model necessitates large-scale high-quality data, which
can be difficult and costly to acquire. Inspired by these challenges, in this
work, we introduce an explainable self-supervised self-train learning network
tailored for tuberculosis case screening. The network achieves an outstanding
overall accuracy of 98.14% and demonstrates high recall and precision rates of
95.72% and 99.44%, respectively, in identifying tuberculosis cases, effectively
capturing clinically significant features."
Every Language Counts - Learn and Unlearn in Multilingual LLMs,https://arxiv.org/abs/2406.13748,2024-06-19,2024-06-21,0.0,0.0,"This paper investigates the propagation of harmful information in
multilingual large language models (LLMs) and evaluates the efficacy of various
unlearning methods. We demonstrate that fake information, regardless of the
language it is in, once introduced into these models through training data, can
spread across different languages, compromising the integrity and reliability
of the generated content. Our findings reveal that standard unlearning
techniques, which typically focus on English data, are insufficient in
mitigating the spread of harmful content in multilingual contexts and could
inadvertently reinforce harmful content across languages. We show that only by
addressing harmful responses in both English and the original language of the
harmful data can we effectively eliminate generations for all languages. This
underscores the critical need for comprehensive unlearning strategies that
consider the multilingual nature of modern LLMs to enhance their safety and
reliability across diverse linguistic landscapes."
GenAI-Bench - Evaluating and Improving Compositional Text-to-Visual Generation,https://arxiv.org/abs/2406.13743,2024-06-19,2024-06-21,0.0,0.0,"While text-to-visual models now produce photo-realistic images and videos,
they struggle with compositional text prompts involving attributes,
relationships, and higher-order reasoning such as logic and comparison. In this
work, we conduct an extensive human study on GenAI-Bench to evaluate the
performance of leading image and video generation models in various aspects of
compositional text-to-visual generation. We also compare automated evaluation
metrics against our collected human ratings and find that VQAScore -- a metric
measuring the likelihood that a VQA model views an image as accurately
depicting the prompt -- significantly outperforms previous metrics such as
CLIPScore. In addition, VQAScore can improve generation in a black-box manner
(without finetuning) via simply ranking a few (3 to 9) candidate images.
Ranking by VQAScore is 2x to 3x more effective than other scoring methods like
PickScore, HPSv2, and ImageReward at improving human alignment ratings for
DALL-E 3 and Stable Diffusion, especially on compositional prompts that require
advanced visio-linguistic reasoning. We will release a new GenAI-Rank benchmark
with over 40,000 human ratings to evaluate scoring metrics on ranking images
generated from the same prompt. Lastly, we discuss promising areas for
improvement in VQAScore, such as addressing fine-grained visual details. We
will release all human ratings (over 80,000) to facilitate scientific
benchmarking of both generative models and automated metrics."
StableSemantics - A Synthetic Language-Vision Dataset of Semantic Representations in Naturalistic Images,https://arxiv.org/abs/2406.13735,2024-06-19,2024-06-21,0.0,0.0,"Understanding the semantics of visual scenes is a fundamental challenge in
Computer Vision. A key aspect of this challenge is that objects sharing similar
semantic meanings or functions can exhibit striking visual differences, making
accurate identification and categorization difficult. Recent advancements in
text-to-image frameworks have led to models that implicitly capture natural
scene statistics. These frameworks account for the visual variability of
objects, as well as complex object co-occurrences and sources of noise such as
diverse lighting conditions. By leveraging large-scale datasets and
cross-attention conditioning, these models generate detailed and contextually
rich scene representations. This capability opens new avenues for improving
object recognition and scene understanding in varied and challenging
environments. Our work presents StableSemantics, a dataset comprising 224
thousand human-curated prompts, processed natural language captions, over 2
million synthetic images, and 10 million attention maps corresponding to
individual noun chunks. We explicitly leverage human-generated prompts that
correspond to visually interesting stable diffusion generations, provide 10
generations per phrase, and extract cross-attention maps for each image. We
explore the semantic distribution of generated images, examine the distribution
of objects within images, and benchmark captioning and open vocabulary
segmentation methods on our data. To the best of our knowledge, we are the
first to release a diffusion dataset with semantic attributions. We expect our
proposed dataset to catalyze advances in visual semantic understanding and
provide a foundation for developing more sophisticated and effective visual
models. Website: https://stablesemantics.github.io/StableSemantics"
You can't handle the (dirty) truth - Data-centric insights improve pseudo-labeling,https://arxiv.org/abs/2406.13733,2024-06-19,2024-06-21,0.0,0.0,"Pseudo-labeling is a popular semi-supervised learning technique to leverage
unlabeled data when labeled samples are scarce. The generation and selection of
pseudo-labels heavily rely on labeled data. Existing approaches implicitly
assume that the labeled data is gold standard and 'perfect'. However, this can
be violated in reality with issues such as mislabeling or ambiguity. We address
this overlooked aspect and show the importance of investigating labeled data
quality to improve any pseudo-labeling method. Specifically, we introduce a
novel data characterization and selection framework called DIPS to extend
pseudo-labeling. We select useful labeled and pseudo-labeled samples via
analysis of learning dynamics. We demonstrate the applicability and impact of
DIPS for various pseudo-labeling methods across an extensive range of
real-world tabular and image datasets. Additionally, DIPS improves data
efficiency and reduces the performance distinctions between different
pseudo-labelers. Overall, we highlight the significant benefits of a
data-centric rethinking of pseudo-labeling in real-world settings."
Integrating Fuzzy Logic with Causal Inference - Enhancing the Pearl and Neyman-Rubin Methodologies,https://arxiv.org/abs/2406.13731,2024-06-19,2024-06-21,0.0,0.0,"In this paper, we generalize the Pearl and Neyman-Rubin methodologies in
causal inference by introducing a generalized approach that incorporates fuzzy
logic. Indeed, we introduce a fuzzy causal inference approach that consider
both the vagueness and imprecision inherent in data, as well as the subjective
human perspective characterized by fuzzy terms such as 'high', 'medium', and
'low'. To do so, we introduce two fuzzy causal effect formulas: the Fuzzy
Average Treatment Effect (FATE) and the Generalized Fuzzy Average Treatment
Effect (GFATE), together with their normalized versions: NFATE and NGFATE. When
dealing with a binary treatment variable, our fuzzy causal effect formulas
coincide with classical Average Treatment Effect (ATE) formula, that is a
well-established and popular metric in causal inference. In FATE, all values of
the treatment variable are considered equally important. In contrast, GFATE
takes into account the rarity and frequency of these values. We show that for
linear Structural Equation Models (SEMs), the normalized versions of our
formulas, NFATE and NGFATE, are equivalent to ATE. Further, we provide
identifiability criteria for these formulas and show their stability with
respect to minor variations in the fuzzy subsets and the probability
distributions involved. This ensures the robustness of our approach in handling
small perturbations in the data. Finally, we provide several experimental
examples to empirically validate and demonstrate the practical application of
our proposed fuzzy causal inference methods."
Global Solutions to Master Equations for Continuous Time Heterogeneous Agent Macroeconomic Models,https://arxiv.org/abs/2406.13726,2024-06-19,2024-06-21,0.0,0.0,"We propose and compare new global solution algorithms for continuous time
heterogeneous agent economies with aggregate shocks. First, we approximate the
agent distribution so that equilibrium in the economy can be characterized by a
high, but finite, dimensional non-linear partial differential equation. We
consider different approximations: discretizing the number of agents,
discretizing the agent state variables, and projecting the distribution onto a
finite set of basis functions. Second, we represent the value function using a
neural network and train it to solve the differential equation using deep
learning tools. We refer to the solution as an Economic Model Informed Neural
Network (EMINN). The main advantage of this technique is that it allows us to
find global solutions to high dimensional, non-linear problems. We demonstrate
our algorithm by solving important models in the macroeconomics and spatial
literatures (e.g. Krusell and Smith (1998), Khan and Thomas (2007), Bilal
(2023))."
Heterogeneous Graph Neural Networks with Post-hoc Explanations for Multi-modal and Explainable Land Use Inference,https://arxiv.org/abs/2406.13724,2024-06-19,2024-06-21,0.0,0.0,"Urban land use inference is a critically important task that aids in city
planning and policy-making. Recently, the increased use of sensor and location
technologies has facilitated the collection of multi-modal mobility data,
offering valuable insights into daily activity patterns. Many studies have
adopted advanced data-driven techniques to explore the potential of these
multi-modal mobility data in land use inference. However, existing studies
often process samples independently, ignoring the spatial correlations among
neighbouring objects and heterogeneity among different services. Furthermore,
the inherently low interpretability of complex deep learning methods poses a
significant barrier in urban planning, where transparency and extrapolability
are crucial for making long-term policy decisions. To overcome these
challenges, we introduce an explainable framework for inferring land use that
synergises heterogeneous graph neural networks (HGNs) with Explainable AI
techniques, enhancing both accuracy and explainability. The empirical
experiments demonstrate that the proposed HGNs significantly outperform
baseline graph neural networks for all six land-use indicators, especially in
terms of 'office' and 'sustenance'. As explanations, we consider feature
attribution and counterfactual explanations. The analysis of feature
attribution explanations shows that the symmetrical nature of the `residence'
and 'work' categories predicted by the framework aligns well with the
commuter's 'work' and 'recreation' activities in London. The analysis of the
counterfactual explanations reveals that variations in node features and types
are primarily responsible for the differences observed between the predicted
land use distribution and the ideal mixed state. These analyses demonstrate
that the proposed HGNs can suitably support urban stakeholders in their urban
planning and policy-making."
On the Utility of Domain-Adjacent Fine-Tuned Model Ensembles for Few-shot Problems,https://arxiv.org/abs/2406.13720,2024-06-19,2024-06-21,0.0,0.0,"Large Language Models (LLMs) have been observed to perform well on a wide
range of downstream tasks when fine-tuned on domain-specific data. However,
such data may not be readily available in many applications, motivating
zero-shot or few-shot approaches using domain-adjacent models. While several
fine-tuned models for various tasks are available, finding an appropriate
domain-adjacent model for a given task is often not straight forward. In this
paper, we study DAFT-E, a framework that utilizes an Ensemble of
Domain-Adjacent Fine-Tuned Foundation Models for few-shot problems. We show
that for zero-shot problems, this ensembling method provides an accuracy
performance close to that of the single best model. With few-shot problems,
this performance improves further, at which point DEFT-E can outperform any
single domain-adjacent model while requiring much less data for domain-specific
fine-tuning."
Evaluating Large Language Models along Dimensions of Language Variation - A Systematik Invesdigatiom uv Cross-lingual Generalization,https://arxiv.org/abs/2406.13718,2024-06-19,2024-06-21,0.0,0.0,"While large language models exhibit certain cross-lingual generalization
capabilities, they suffer from performance degradation (PD) on unseen
closely-related languages (CRLs) and dialects relative to their high-resource
language neighbour (HRLN). However, we currently lack a fundamental
understanding of what kinds of linguistic distances contribute to PD, and to
what extent. Furthermore, studies of cross-lingual generalization are
confounded by unknown quantities of CRL language traces in the training data,
and by the frequent lack of availability of evaluation data in lower-resource
related languages and dialects. To address these issues, we model phonological,
morphological, and lexical distance as Bayesian noise processes to synthesize
artificial languages that are controllably distant from the HRLN. We analyse PD
as a function of underlying noise parameters, offering insights on model
robustness to isolated and composed linguistic phenomena, and the impact of
task and HRL characteristics on PD. We calculate parameter posteriors on real
CRL-HRLN pair data and show that they follow computed trends of artificial
languages, demonstrating the viability of our noisers. Our framework offers a
cheap solution to estimating task performance on an unseen CRL given HRLN
performance using its posteriors, as well as for diagnosing observed PD on a
CRL in terms of its linguistic distances from its HRLN, and opens doors to
principled methods of mitigating performance degradation."
"Converging Dimensions - Information Extraction and Summarization through Multisource, Multimodal, and Multilingual Fusion",https://arxiv.org/abs/2406.13715,2024-06-19,2024-06-21,0.0,0.0,"Recent advances in large language models (LLMs) have led to new summarization
strategies, offering an extensive toolkit for extracting important information.
However, these approaches are frequently limited by their reliance on isolated
sources of data. The amount of information that can be gathered is limited and
covers a smaller range of themes, which introduces the possibility of falsified
content and limited support for multilingual and multimodal data. The paper
proposes a novel approach to summarization that tackles such challenges by
utilizing the strength of multiple sources to deliver a more exhaustive and
informative understanding of intricate topics. The research progresses beyond
conventional, unimodal sources such as text documents and integrates a more
diverse range of data, including YouTube playlists, pre-prints, and Wikipedia
pages. The aforementioned varied sources are then converted into a unified
textual representation, enabling a more holistic analysis. This multifaceted
approach to summary generation empowers us to extract pertinent information
from a wider array of sources. The primary tenet of this approach is to
maximize information gain while minimizing information overlap and maintaining
a high level of informativeness, which encourages the generation of highly
coherent summaries."
BEACON - Balancing Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes,https://arxiv.org/abs/2406.13714,2024-06-19,2024-06-21,0.0,0.0,"A common, yet regular, decision made by people, whether healthy or with any
health condition, is to decide what to have in meals like breakfast, lunch, and
dinner, consisting of a combination of foods for appetizer, main course, side
dishes, desserts, and beverages. However, often this decision is seen as a
trade-off between nutritious choices (e.g., low salt and sugar) or convenience
(e.g., inexpensive, fast to prepare/obtain, taste better). In this preliminary
work, we present a data-driven approach for the novel meal recommendation
problem that can explore and balance choices for both considerations while also
reasoning about a food's constituents and cooking process. Beyond the problem
formulation, our contributions also include a goodness measure, a recipe
conversion method from text to the recently introduced multimodal rich recipe
representation (R3) format, and learning methods using contextual bandits that
show promising results."
Benchmarking Open-Source Language Models for Efficient Question Answering in Industrial Applications,https://arxiv.org/abs/2406.13713,2024-06-19,2024-06-21,0.0,0.0,"In the rapidly evolving landscape of Natural Language Processing (NLP), Large
Language Models (LLMs) have demonstrated remarkable capabilities in tasks such
as question answering (QA). However, the accessibility and practicality of
utilizing these models for industrial applications pose significant challenges,
particularly concerning cost-effectiveness, inference speed, and resource
efficiency. This paper presents a comprehensive benchmarking study comparing
open-source LLMs with their non-open-source counterparts on the task of
question answering. Our objective is to identify open-source alternatives
capable of delivering comparable performance to proprietary models while being
lightweight in terms of resource requirements and suitable for Central
Processing Unit (CPU)-based inference. Through rigorous evaluation across
various metrics including accuracy, inference speed, and resource consumption,
we aim to provide insights into selecting efficient LLMs for real-world
applications. Our findings shed light on viable open-source alternatives that
offer acceptable performance and efficiency, addressing the pressing need for
accessible and efficient NLP solutions in industry settings."
Imagining In-distribution States - How Predictable Robot Behavior Can Enable User Control Over Learned Policies,https://arxiv.org/abs/2406.13711,2024-06-19,2024-06-21,0.0,0.0,"It is crucial that users are empowered to take advantage of the functionality
of a robot and use their understanding of that functionality to perform novel
and creative tasks. Given a robot trained with Reinforcement Learning (RL), a
user may wish to leverage that autonomy along with their familiarity of how
they expect the robot to behave to collaborate with the robot. One technique is
for the user to take control of some of the robot's action space through
teleoperation, allowing the RL policy to simultaneously control the rest. We
formalize this type of shared control as Partitioned Control (PC). However,
this may not be possible using an out-of-the-box RL policy. For example, a
user's control may bring the robot into a failure state from the policy's
perspective, causing it to act unexpectedly and hindering the success of the
user's desired task. In this work, we formalize this problem and present
Imaginary Out-of-Distribution Actions, IODA, an initial algorithm which
empowers users to leverage their expectations of a robot's behavior to
accomplish new tasks. We deploy IODA in a user study with a real robot and find
that IODA leads to both better task performance and a higher degree of
alignment between robot behavior and user expectation. We also show that in PC,
there is a strong and significant correlation between task performance and the
robot's ability to meet user expectations, highlighting the need for approaches
like IODA. Code is available at https://github.com/AABL-Lab/ioda_roman_2024"
Breaking News - Case Studies of Generative AI's Use in Journalism,https://arxiv.org/abs/2406.13706,2024-06-19,2024-06-21,0.0,0.0,"Journalists are among the many users of large language models (LLMs). To
better understand the journalist-AI interactions, we conduct a study of LLM
usage by two news agencies through browsing the WildChat dataset, identifying
candidate interactions, and verifying them by matching to online published
articles. Our analysis uncovers instances where journalists provide sensitive
material such as confidential correspondence with sources or articles from
other agencies to the LLM as stimuli and prompt it to generate articles, and
publish these machine-generated articles with limited intervention (median
output-publication ROUGE-L of 0.62). Based on our findings, we call for further
research into what constitutes responsible use of AI, and the establishment of
clear guidelines and best practices on using LLMs in a journalistic context."
MMTE - Corpus and Metrics for Evaluating Machine Translation Quality of Metaphorical Language,https://arxiv.org/abs/2406.13698,2024-06-19,2024-06-21,0.0,0.0,"Machine Translation (MT) has developed rapidly since the release of Large
Language Models and current MT evaluation is performed through comparison with
reference human translations or by predicting quality scores from human-labeled
data. However, these mainstream evaluation methods mainly focus on fluency and
factual reliability, whilst paying little attention to figurative quality. In
this paper, we investigate the figurative quality of MT and propose a set of
human evaluation metrics focused on the translation of figurative language. We
additionally present a multilingual parallel metaphor corpus generated by
post-editing. Our evaluation protocol is designed to estimate four aspects of
MT: Metaphorical Equivalence, Emotion, Authenticity, and Quality. In doing so,
we observe that translations of figurative expressions display different traits
from literal ones."
Multilingual De-Duplication Strategies - Applying scalable similarity search with monolingual & multilingual embedding models,https://arxiv.org/abs/2406.13695,2024-06-19,2024-06-21,0.0,0.0,"This paper addresses the deduplication of multilingual textual data using
advanced NLP tools. We compare a two-step method involving translation to
English followed by embedding with mpnet, and a multilingual embedding model
(distiluse). The two-step approach achieved a higher F1 score (82% vs. 60%),
particularly with less widely used languages, which can be increased up to 89%
by leveraging expert rules based on domain knowledge. We also highlight
limitations related to token length constraints and computational efficiency.
Our methodology suggests improvements for future multilingual deduplication
tasks."
An Embedded Intelligent System for Attendance Monitoring,https://arxiv.org/abs/2406.13694,2024-06-19,2024-06-21,0.0,0.0,"In this paper, we propose an intelligent embedded system for monitoring class
attendance and sending the attendance list to a remote computer. The proposed
system consists of two parts : an embedded device (Raspberry with PI camera)
for facial recognition and a web application for attendance management. The
proposed solution take into account the different challenges: the limited
resources of the Raspberry Pi, the need to adapt the facial recognition model
and achieving acceptable performance using images provided by the Raspberry Pi
camera."
From Single Agent to Multi-Agent - Improving Traffic Signal Control,https://arxiv.org/abs/2406.13693,2024-06-19,2024-06-21,0.0,0.0,"Due to accelerating urbanization, the importance of solving the signal
control problem increases. This paper analyzes various existing methods and
suggests options for increasing the number of agents to reduce the average
travel time. Experiments were carried out with 2 datasets. The results show
that in some cases, the implementation of multiple agents can improve existing
methods. For a fine-tuned large language model approach there is small
enhancement on all metrics."
Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation,https://arxiv.org/abs/2406.13692,2024-06-19,2024-06-21,0.0,0.0,"Retrieval-augmented language models (RALMs) have shown strong performance and
wide applicability in knowledge-intensive tasks. However, there are significant
trustworthiness concerns as RALMs are prone to generating unfaithful outputs,
including baseless information or contradictions with the retrieved context.
This paper proposes SynCheck, a lightweight monitor that leverages fine-grained
decoding dynamics including sequence likelihood, uncertainty quantification,
context influence, and semantic alignment to synchronously detect unfaithful
sentences. By integrating efficiently measurable and complementary signals,
SynCheck enables accurate and immediate feedback and intervention, achieving
0.85 AUROC in detecting faithfulness errors across six long-form
retrieval-augmented generation tasks, improving prior best method by 4%.
Leveraging SynCheck, we further introduce FOD, a faithfulness-oriented decoding
algorithm guided by beam search for long-form retrieval-augmented generation.
Empirical results demonstrate that FOD outperforms traditional strategies such
as abstention, reranking, or contrastive decoding significantly in terms of
faithfulness, achieving over 10% improvement across six datasets."
Development of a Dual-Input Neural Model for Detecting AI-Generated Imagery,https://arxiv.org/abs/2406.13688,2024-06-19,2024-06-21,0.0,0.0,"Over the past years, images generated by artificial intelligence have become
more prevalent and more realistic. Their advent raises ethical questions
relating to misinformation, artistic expression, and identity theft, among
others. The crux of many of these moral questions is the difficulty in
distinguishing between real and fake images. It is important to develop tools
that are able to detect AI-generated images, especially when these images are
too realistic-looking for the human eye to identify as fake. This paper
proposes a dual-branch neural network architecture that takes both images and
their Fourier frequency decomposition as inputs. We use standard CNN-based
methods for both branches as described in Stuchi et al. [7], followed by
fully-connected layers. Our proposed model achieves an accuracy of 94% on the
CIFAKE dataset, which significantly outperforms classic ML methods and CNNs,
achieving performance comparable to some state-of-the-art architectures, such
as ResNet."
IntCoOp - Interpretability-Aware Vision-Language Prompt Tuning,https://arxiv.org/abs/2406.13683,2024-06-19,2024-06-21,0.0,0.0,"Image-text contrastive models such as CLIP learn transferable and robust
representations for zero-shot transfer to a variety of downstream tasks.
However, to obtain strong downstream performances, prompts need to be carefully
curated, which can be a tedious engineering task. To address the issue of
manual prompt engineering, prompt-tuning is used where a set of contextual
vectors are learned by leveraging information from the training data. Despite
their effectiveness, existing prompt-tuning frameworks often lack
interpretability, thus limiting their ability to understand the compositional
nature of images. In this work, we first identify that incorporating
compositional attributes (e.g., a ""green"" tree frog) in the design of manual
prompts can significantly enhance image-text alignment scores. Building upon
this observation, we propose a novel and interpretable prompt-tuning method
named IntCoOp, which learns to jointly align attribute-level inductive biases
and class embeddings during prompt-tuning. To assess the effectiveness of our
approach, we evaluate IntCoOp across two representative tasks in a few-shot
learning setup: generalization to novel classes, and unseen domain shifts.
Through extensive experiments across 10 downstream datasets on CLIP, we find
that introducing attribute-level inductive biases leads to superior performance
against state-of-the-art prompt tuning frameworks. Notably, in a 16-shot setup,
IntCoOp improves CoOp by 7.35% in average performance across 10 diverse
datasets."
On the Consistency of Fairness Measurement Methods for Regression Tasks,https://arxiv.org/abs/2406.13681,2024-06-19,2024-06-21,0.0,0.0,"With growing applications of Machine Learning (ML) techniques in the real
world, it is highly important to ensure that these models work in an equitable
manner. One main step in ensuring fairness is to effectively measure fairness,
and to this end, various metrics have been proposed in the past literature.
While the computation of those metrics are straightforward in the
classification set-up, it is computationally intractable in the regression
domain. To address the challenge of computational intractability, past
literature proposed various methods to approximate such metrics. However, they
did not verify the extent to which the output of such approximation algorithms
are consistent with each other. To fill this gap, this paper comprehensively
studies the consistency of the output of various fairness measurement methods
through conducting an extensive set of experiments on various regression tasks.
As a result, it finds that while some fairness measurement approaches show
strong consistency across various regression tasks, certain methods show a
relatively poor consistency in certain regression tasks. This, in turn, calls
for a more principled approach for measuring fairness in the regression domain."
Prose-to-P4 - Leveraging High Level Languages,https://arxiv.org/abs/2406.13679,2024-06-19,2024-06-21,0.0,0.0,"Languages such as P4 and NPL have enabled a wide and diverse range of
networking applications that take advantage of programmable dataplanes.
However, software development in these languages is difficult. To address this
issue, high-level languages have been designed to offer programmers powerful
abstractions that reduce the time, effort and domain-knowledge required for
developing networking applications. These languages are then translated by a
compiler into P4/NPL code. Inspired by the recent success of Large Language
Models (LLMs) in the task of code generation, we propose to raise the level of
abstraction even higher, employing LLMs to translate prose into high-level
networking code. We analyze the problem, focusing on the motivation and
opportunities, as well as the challenges involved and sketch out a roadmap for
the development of a system that can generate high-level dataplane code from
natural language instructions. We present some promising preliminary results on
generating Lucid code from natural language."
Improved bounds for calibration via stronger sign preservation games,https://arxiv.org/abs/2406.13668,2024-06-19,2024-06-21,0.0,0.0,"A set of probabilistic forecasts is calibrated if each prediction of the
forecaster closely approximates the empirical distribution of outcomes on the
subset of timesteps where that prediction was made. We study the fundamental
problem of online calibrated forecasting of binary sequences, which was
initially studied by Foster & Vohra (1998). They derived an algorithm with
$O(T^{2/3})$ calibration error after $T$ time steps, and showed a lower bound
of $\Omega(T^{1/2})$. These bounds remained stagnant for two decades, until
Qiao & Valiant (2021) improved the lower bound to $\Omega(T^{0.528})$ by
introducing a combinatorial game called sign preservation and showing that
lower bounds for this game imply lower bounds for calibration.
  In this paper, we give the first improvement to the $O(T^{2/3})$ upper bound
on calibration error of Foster & Vohra. We do this by introducing a variant of
Qiao & Valiant's game that we call sign preservation with reuse (SPR). We prove
that the relationship between SPR and calibrated forecasting is bidirectional:
not only do lower bounds for SPR translate into lower bounds for calibration,
but algorithms for SPR also translate into new algorithms for calibrated
forecasting. We then give an improved \emph{upper bound} for the SPR game,
which implies, via our equivalence, a forecasting algorithm with calibration
error $O(T^{2/3 - \varepsilon})$ for some $\varepsilon > 0$, improving Foster &
Vohra's upper bound for the first time. Using similar ideas, we then prove a
slightly stronger lower bound than that of Qiao & Valiant, namely
$\Omega(T^{0.54389})$. Our lower bound is obtained by an oblivious adversary,
marking the first $\omega(T^{1/2})$ calibration lower bound for oblivious
adversaries."
Challenges in Binary Classification,https://arxiv.org/abs/2406.13665,2024-06-19,2024-06-21,0.0,0.0,"Binary Classification plays an important role in machine learning. For linear
classification, SVM is the optimal binary classification method. For nonlinear
classification, the SVM algorithm needs to complete the classification task by
using the kernel function. Although the SVM algorithm with kernel function is
very effective, the selection of kernel function is empirical, which means that
the kernel function may not be optimal. Therefore, it is worth studying how to
obtain an optimal binary classifier.
  In this paper, the problem of finding the optimal binary classifier is
considered as a variational problem. We design the objective function of this
variational problem through the max-min problem of the (Euclidean) distance
between two classes. For linear classification, it can be deduced that SVM is a
special case of this variational problem framework. For Euclidean distance, it
is proved that the proposed variational problem has some limitations for
nonlinear classification. Therefore, how to design a more appropriate objective
function to find the optimal binary classifier is still an open problem.
Further, it's discussed some challenges and problems in finding the optimal
classifier."
Root-KGD - A Novel Framework for Root Cause Diagnosis Based on Knowledge Graph and Industrial Data,https://arxiv.org/abs/2406.13664,2024-06-19,2024-06-21,0.0,0.0,"With the development of intelligent manufacturing and the increasing
complexity of industrial production, root cause diagnosis has gradually become
an important research direction in the field of industrial fault diagnosis.
However, existing research methods struggle to effectively combine domain
knowledge and industrial data, failing to provide accurate, online, and
reliable root cause diagnosis results for industrial processes. To address
these issues, a novel fault root cause diagnosis framework based on knowledge
graph and industrial data, called Root-KGD, is proposed. Root-KGD uses the
knowledge graph to represent domain knowledge and employs data-driven modeling
to extract fault features from industrial data. It then combines the knowledge
graph and data features to perform knowledge graph reasoning for root cause
identification. The performance of the proposed method is validated using two
industrial process cases, Tennessee Eastman Process (TEP) and Multiphase Flow
Facility (MFF). Compared to existing methods, Root-KGD not only gives more
accurate root cause variable diagnosis results but also provides interpretable
fault-related information by locating faults to corresponding physical entities
in knowledge graph (such as devices and streams). In addition, combined with
its lightweight nature, Root-KGD is more effective in online industrial
applications."
Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation,https://arxiv.org/abs/2406.13663,2024-06-19,2024-06-21,0.0,0.0,"Ensuring the verifiability of model answers is a fundamental challenge for
retrieval-augmented generation (RAG) in the question answering (QA) domain.
Recently, self-citation prompting was proposed to make large language models
(LLMs) generate citations to supporting documents along with their answers.
However, self-citing LLMs often struggle to match the required format, refer to
non-existent sources, and fail to faithfully reflect LLMs' context usage
throughout the generation. In this work, we present MIRAGE --Model
Internals-based RAG Explanations -- a plug-and-play approach using model
internals for faithful answer attribution in RAG applications. MIRAGE detects
context-sensitive answer tokens and pairs them with retrieved documents
contributing to their prediction via saliency methods. We evaluate our proposed
approach on a multilingual extractive QA dataset, finding high agreement with
human answer attribution. On open-ended QA, MIRAGE achieves citation quality
and efficiency comparable to self-citation while also allowing for a
finer-grained control of attribution parameters. Our qualitative evaluation
highlights the faithfulness of MIRAGE's attributions and underscores the
promising application of model internals for RAG answer attribution."
ObscurePrompt - Jailbreaking Large Language Models via Obscure Input,https://arxiv.org/abs/2406.13662,2024-06-19,2024-06-21,0.0,0.0,"Recently, Large Language Models (LLMs) have garnered significant attention
for their exceptional natural language processing capabilities. However,
concerns about their trustworthiness remain unresolved, particularly in
addressing ""jailbreaking"" attacks on aligned LLMs. Previous research
predominantly relies on scenarios with white-box LLMs or specific and fixed
prompt templates, which are often impractical and lack broad applicability. In
this paper, we introduce a straightforward and novel method, named
ObscurePrompt, for jailbreaking LLMs, inspired by the observed fragile
alignments in Out-of-Distribution (OOD) data. Specifically, we first formulate
the decision boundary in the jailbreaking process and then explore how obscure
text affects LLM's ethical decision boundary. ObscurePrompt starts with
constructing a base prompt that integrates well-known jailbreaking techniques.
Powerful LLMs are then utilized to obscure the original prompt through
iterative transformations, aiming to bolster the attack's robustness.
Comprehensive experiments show that our approach substantially improves upon
previous methods in terms of attack effectiveness, maintaining efficacy against
two prevalent defense mechanisms. We believe that our work can offer fresh
insights for future research on enhancing LLM alignment."
"Hitchhiker's guide on Energy-Based Models - a comprehensive review on the relation with other generative models, sampling and statistical physics",https://arxiv.org/abs/2406.13661,2024-06-19,2024-06-21,0.0,0.0,"Energy-Based Models (EBMs) have emerged as a powerful framework in the realm
of generative modeling, offering a unique perspective that aligns closely with
principles of statistical mechanics. This review aims to provide physicists
with a comprehensive understanding of EBMs, delineating their connection to
other generative models such as Generative Adversarial Networks (GANs),
Variational Autoencoders (VAEs), and Normalizing Flows. We explore the sampling
techniques crucial for EBMs, including Markov Chain Monte Carlo (MCMC) methods,
and draw parallels between EBM concepts and statistical mechanics, highlighting
the significance of energy functions and partition functions. Furthermore, we
delve into state-of-the-art training methodologies for EBMs, covering recent
advancements and their implications for enhanced model performance and
efficiency. This review is designed to clarify the often complex
interconnections between these models, which can be challenging due to the
diverse communities working on the topic."
Towards Minimal Targeted Updates of Language Models with Targeted Negative Training,https://arxiv.org/abs/2406.13660,2024-06-19,2024-06-21,0.0,0.0,"Generative models of language exhibit impressive capabilities but still place
non-negligible probability mass over undesirable outputs. In this work, we
address the task of updating a model to avoid unwanted outputs while minimally
changing model behavior otherwise, a challenge we refer to as a minimal
targeted update. We first formalize the notion of a minimal targeted update and
propose a method to achieve such updates using negative examples from a model's
generations. Our proposed Targeted Negative Training (TNT) results in updates
that keep the new distribution close to the original, unlike existing losses
for negative signal which push down probability but do not control what the
updated distribution will be. In experiments, we demonstrate that TNT yields a
better trade-off between reducing unwanted behavior and maintaining model
generation behavior than baselines, paving the way towards a modeling paradigm
based on iterative training updates that constrain models from generating
undesirable outputs while preserving their impressive capabilities."
Tactical Game-theoretic Decision-making with Homotopy Class Constraints,https://arxiv.org/abs/2406.13656,2024-06-19,2024-06-21,0.0,0.0,"We propose a tactical homotopy-aware decision-making framework for
game-theoretic motion planning in urban environments. We model urban driving as
a generalized Nash equilibrium problem and employ a mixed-integer approach to
tame the combinatorial aspect of motion planning. More specifically, by
utilizing homotopy classes, we partition the high-dimensional solution space
into finite, well-defined subregions. Each subregion (homotopy) corresponds to
a high-level tactical decision, such as the passing order between pairs of
players. The proposed formulation allows to find global optimal Nash equilibria
in a computationally tractable manner by solving a mixed-integer quadratic
program. Each homotopy decision is represented by a binary variable that
activates different sets of linear collision avoidance constraints. This extra
homotopic constraint allows to find solutions in a more efficient way (on a
roundabout scenario on average 5-times faster). We experimentally validate the
proposed approach on scenarios taken from the rounD dataset. Simulation-based
testing in receding horizon fashion demonstrates the capability of the
framework in achieving globally optimal solutions while yielding a 78% average
decrease in the computational time with respect to an implementation without
the homotopic constraints."
Improving GFlowNets with Monte Carlo Tree Search,https://arxiv.org/abs/2406.13655,2024-06-19,2024-06-21,0.0,0.0,"Generative Flow Networks (GFlowNets) treat sampling from distributions over
compositional discrete spaces as a sequential decision-making problem, training
a stochastic policy to construct objects step by step. Recent studies have
revealed strong connections between GFlowNets and entropy-regularized
reinforcement learning. Building on these insights, we propose to enhance
planning capabilities of GFlowNets by applying Monte Carlo Tree Search (MCTS).
Specifically, we show how the MENTS algorithm (Xiao et al., 2019) can be
adapted for GFlowNets and used during both training and inference. Our
experiments demonstrate that this approach improves the sample efficiency of
GFlowNet training and the generation fidelity of pre-trained GFlowNet models."
Controlling Forgetting with Test-Time Data in Continual Learning,https://arxiv.org/abs/2406.13653,2024-06-19,2024-06-21,0.0,0.0,"Foundational vision-language models have shown impressive performance on
various downstream tasks. Yet, there is still a pressing need to update these
models later as new tasks or domains become available. Ongoing Continual
Learning (CL) research provides techniques to overcome catastrophic forgetting
of previous information when new knowledge is acquired. To date, CL techniques
focus only on the supervised training sessions. This results in significant
forgetting yielding inferior performance to even the prior model zero shot
performance. In this work, we argue that test-time data hold great information
that can be leveraged in a self supervised manner to refresh the model's memory
of previous learned tasks and hence greatly reduce forgetting at no extra
labelling cost. We study how unsupervised data can be employed online to
improve models' performance on prior tasks upon encountering representative
samples. We propose a simple yet effective student-teacher model with gradient
based sparse parameters updates and show significant performance improvements
and reduction in forgetting, which could alleviate the role of an offline
episodic memory/experience replay buffer."
Stability and Generalizability in SDE Diffusion Models with Measure-Preserving Dynamics,https://arxiv.org/abs/2406.13652,2024-06-19,2024-06-21,0.0,0.0,"Inverse problems describe the process of estimating the causal factors from a
set of measurements or data. Mapping of often incomplete or degraded data to
parameters is ill-posed, thus data-driven iterative solutions are required, for
example when reconstructing clean images from poor signals. Diffusion models
have shown promise as potent generative tools for solving inverse problems due
to their superior reconstruction quality and their compatibility with iterative
solvers. However, most existing approaches are limited to linear inverse
problems represented as Stochastic Differential Equations (SDEs). This
simplification falls short of addressing the challenging nature of real-world
problems, leading to amplified cumulative errors and biases. We provide an
explanation for this gap through the lens of measure-preserving dynamics of
Random Dynamical Systems (RDS) with which we analyse Temporal Distribution
Discrepancy and thus introduce a theoretical framework based on RDS for SDE
diffusion models. We uncover several strategies that inherently enhance the
stability and generalizability of diffusion models for inverse problems and
introduce a novel score-based diffusion framework, the \textbf{D}ynamics-aware
S\textbf{D}E \textbf{D}iffusion \textbf{G}enerative \textbf{M}odel (D$^3$GM).
The \textit{Measure-preserving property} can return the degraded measurement to
the original state despite complex degradation with the RDS concept of
\textit{stability}. Our extensive experimental results corroborate the
effectiveness of D$^3$GM across multiple benchmarks including a prominent
application for inverse problems, magnetic resonance imaging. Code and data
will be publicly available."
Minimalist exploration strategies for robot swarms at the edge of chaos,https://arxiv.org/abs/2406.13641,2024-06-19,2024-06-21,0.0,0.0,"Effective exploration abilities are fundamental for robot swarms, especially
when small, inexpensive robots are employed (e.g., micro- or nano-robots).
Random walks are often the only viable choice if robots are too constrained
regarding sensors and computation to implement state-of-the-art solutions.
However, identifying the best random walk parameterisation may not be trivial.
Additionally, variability among robots in terms of motion abilities-a very
common condition when precise calibration is not possible-introduces the need
for flexible solutions. This study explores how random walks that present
chaotic or edge-of-chaos dynamics can be generated. We also evaluate their
effectiveness for a simple exploration task performed by a swarm of simulated
Kilobots. First, we show how Random Boolean Networks can be used as controllers
for the Kilobots, achieving a significant performance improvement compared to
the best parameterisation of a L\'evy-modulated Correlated Random Walk. Second,
we demonstrate how chaotic dynamics are beneficial to maximise exploration
effectiveness. Finally, we demonstrate how the exploration behavior produced by
Boolean Networks can be optimized through an Evolutionary Robotics approach
while maintaining the chaotic dynamics of the networks."
Transferable Tactile Transformers for Representation Learning Across Diverse Sensors and Tasks,https://arxiv.org/abs/2406.13640,2024-06-19,2024-06-21,0.0,0.0,"This paper presents T3: Transferable Tactile Transformers, a framework for
tactile representation learning that scales across multi-sensors and
multi-tasks. T3 is designed to overcome the contemporary issue that
camera-based tactile sensing is extremely heterogeneous, i.e. sensors are built
into different form factors, and existing datasets were collected for disparate
tasks. T3 captures the shared latent information across different sensor-task
pairings by constructing a shared trunk transformer with sensor-specific
encoders and task-specific decoders. The pre-training of T3 utilizes a novel
Foundation Tactile (FoTa) dataset, which is aggregated from several
open-sourced datasets and it contains over 3 million data points gathered from
13 sensors and 11 tasks. FoTa is the largest and most diverse dataset in
tactile sensing to date and it is made publicly available in a unified format.
Across various sensors and tasks, experiments show that T3 pre-trained with
FoTa achieved zero-shot transferability in certain sensor-task pairings, can be
further fine-tuned with small amounts of domain-specific data, and its
performance scales with bigger network sizes. T3 is also effective as a tactile
encoder for long horizon contact-rich manipulation. Results from sub-millimeter
multi-pin electronics insertion tasks show that T3 achieved a task success rate
25% higher than that of policies trained with tactile encoders trained from
scratch, or 53% higher than without tactile sensing. Data, code, and model
checkpoints are open-sourced at https://t3.alanz.info."
Contrast Sets for Evaluating Language-Guided Robot Policies,https://arxiv.org/abs/2406.13636,2024-06-19,2024-06-21,0.0,0.0,"Robot evaluations in language-guided, real world settings are time-consuming
and often sample only a small space of potential instructions across complex
scenes. In this work, we introduce contrast sets for robotics as an approach to
make small, but specific, perturbations to otherwise independent, identically
distributed (i.i.d.) test instances. We investigate the relationship between
experimenter effort to carry out an evaluation and the resulting estimated test
performance as well as the insights that can be drawn from performance on
perturbed instances. We use contrast sets to characterize policies at reduced
experimenter effort in both a simulated manipulation task and a physical robot
vision-and-language navigation task. We encourage the use of contrast set
evaluations as a more informative alternative to small scale, i.i.d.
demonstrations on physical robots, and as a scalable alternative to
industry-scale real world evaluations."
Reinforcement Learning for Infinite-Horizon Average-Reward MDPs with Multinomial Logistic Function Approximation,https://arxiv.org/abs/2406.13633,2024-06-19,2024-06-21,0.0,0.0,"We study model-based reinforcement learning with non-linear function
approximation where the transition function of the underlying Markov decision
process (MDP) is given by a multinomial logistic (MNL) model. We develop a
provably efficient discounted value iteration-based algorithm that works for
both infinite-horizon average-reward and discounted-reward settings. For
average-reward communicating MDPs, the algorithm guarantees a regret upper
bound of $\tilde{\mathcal{O}}(dD\sqrt{T})$ where $d$ is the dimension of
feature mapping, $D$ is the diameter of the underlying MDP, and $T$ is the
horizon. For discounted-reward MDPs, our algorithm achieves
$\tilde{\mathcal{O}}(d(1-\gamma)^{-2}\sqrt{T})$ regret where $\gamma$ is the
discount factor. Then we complement these upper bounds by providing several
regret lower bounds. We prove a lower bound of $\Omega(d\sqrt{DT})$ for
learning communicating MDPs of diameter $D$ and a lower bound of
$\Omega(d(1-\gamma)^{3/2}\sqrt{T})$ for learning discounted-reward MDPs with
discount factor $\gamma$. Lastly, we show a regret lower bound of
$\Omega(dH^{3/2}\sqrt{K})$ for learning $H$-horizon episodic MDPs with MNL
function approximation where $K$ is the number of episodes, which improves upon
the best-known lower bound for the finite-horizon setting."
Can Few-shot Work in Long-Context? Recycling the Context to Generate Demonstrations,https://arxiv.org/abs/2406.13632,2024-06-19,2024-06-21,0.0,0.0,"Despite recent advancements in Large Language Models (LLMs), their
performance on tasks involving long contexts remains sub-optimal. In-Context
Learning (ICL) with few-shot examples may be an appealing solution to enhance
LLM performance in this scenario; However, naively adding ICL examples with
long context introduces challenges, including substantial token overhead added
for each few-shot example and context mismatch between the demonstrations and
the target query. In this work, we propose to automatically generate few-shot
examples for long context QA tasks by recycling contexts. Specifically, given a
long input context (1-3k tokens) and a query, we generate additional
query-output pairs from the given context as few-shot examples, while
introducing the context only once. This ensures that the demonstrations are
leveraging the same context as the target query while only adding a small
number of tokens to the prompt. We further enhance each demonstration by
instructing the model to explicitly identify the relevant paragraphs before the
answer, which improves performance while providing fine-grained attribution to
the answer source. We apply our method on multiple LLMs and obtain substantial
improvements (+23\% on average across models) on various QA datasets with long
context, especially when the answer lies within the middle of the context.
Surprisingly, despite introducing only single-hop ICL examples, LLMs also
successfully generalize to multi-hop long-context QA using our approach."
On AI-Inspired UI-Design,https://arxiv.org/abs/2406.13631,2024-06-19,2024-06-21,0.0,0.0,"Graphical User Interface (or simply UI) is a primary mean of interaction
between users and their device. In this paper, we discuss three major
complementary approaches on how to use Artificial Intelligence (AI) to support
app designers create better, more diverse, and creative UI of mobile apps.
First, designers can prompt a Large Language Model (LLM) like GPT to directly
generate and adjust one or multiple UIs. Second, a Vision-Language Model (VLM)
enables designers to effectively search a large screenshot dataset, e.g. from
apps published in app stores. The third approach is to train a Diffusion Model
(DM) specifically designed to generate app UIs as inspirational images. We
discuss how AI should be used, in general, to inspire and assist creative app
design rather than automating it."
Can AI be enabled to dynamical downscaling? Training a Latent Diffusion Model to mimic km-scale COSMO-CLM downscaling of ERA5 over Italy,https://arxiv.org/abs/2406.13627,2024-06-19,2024-06-21,0.0,0.0,"Downscaling techniques are one of the most prominent applications of Deep
Learning (DL) in Earth System Modeling. A robust DL downscaling model can
generate high-resolution fields from coarse-scale numerical model simulations,
saving the timely and resourceful applications of regional/local models.
Additionally, generative DL models have the potential to provide uncertainty
information, by generating ensemble-like scenario pools, a task that is
computationally prohibitive for traditional numerical simulations. In this
study, we apply a Latent Diffusion Model (LDM) to downscale ERA5 data over
Italy up to a resolution of 2 km. The high-resolution target data consists of
2-m temperature and 10-m horizontal wind components from a dynamical
downscaling performed with COSMO_CLM. Our goal is to demonstrate that recent
advancements in generative modeling enable DL to deliver results comparable to
those of numerical dynamical models, given the same input data, preserving the
realism of fine-scale features and flow characteristics. A selection of
predictors from ERA5 is used as input to the LDM, and a residual approach
against a reference UNET is leveraged in applying the LDM. The performance of
the generative LDM is compared with reference baselines of increasing
complexity: quadratic interpolation of ERA5, a UNET, and a Generative
Adversarial Network (GAN) built on the same reference UNET. Results highlight
the improvements introduced by the LDM architecture and the residual approach
over these baselines. The models are evaluated on a yearly test dataset,
assessing the models' performance through deterministic metrics, spatial
distribution of errors, and reconstruction of frequency and power spectra
distributions."
Fine-Tuning Gemma-7B for Enhanced Sentiment Analysis of Financial News Headlines,https://arxiv.org/abs/2406.13626,2024-06-19,2024-06-21,0.0,0.0,"In this study, we explore the application of sentiment analysis on financial
news headlines to understand investor sentiment. By leveraging Natural Language
Processing (NLP) and Large Language Models (LLM), we analyze sentiment from the
perspective of retail investors. The FinancialPhraseBank dataset, which
contains categorized sentiments of financial news headlines, serves as the
basis for our analysis. We fine-tuned several models, including
distilbert-base-uncased, Llama, and gemma-7b, to evaluate their effectiveness
in sentiment classification. Our experiments demonstrate that the fine-tuned
gemma-7b model outperforms others, achieving the highest precision, recall, and
F1 score. Specifically, the gemma-7b model showed significant improvements in
accuracy after fine-tuning, indicating its robustness in capturing the nuances
of financial sentiment. This model can be instrumental in providing market
insights, risk management, and aiding investment decisions by accurately
predicting the sentiment of financial news. The results highlight the potential
of advanced LLMs in transforming how we analyze and interpret financial
information, offering a powerful tool for stakeholders in the financial
industry."
Improving Visual Commonsense in Language Models via Multiple Image Generation,https://arxiv.org/abs/2406.13621,2024-06-19,2024-06-21,0.0,0.0,"Commonsense reasoning is fundamentally based on multimodal knowledge.
However, existing large language models (LLMs) are primarily trained using
textual data only, limiting their ability to incorporate essential visual
information. In contrast, Visual Language Models, which excel at
visually-oriented tasks, often fail at non-visual tasks such as basic
commonsense reasoning. This divergence highlights a critical challenge - the
integration of robust visual understanding with foundational text-based
language reasoning. To this end, we introduce a method aimed at enhancing LLMs'
visual commonsense. Specifically, our method generates multiple images based on
the input text prompt and integrates these into the model's decision-making
process by mixing their prediction probabilities. To facilitate multimodal
grounded language modeling, we employ a late-fusion layer that combines the
projected visual features with the output of a pre-trained LLM conditioned on
text only. This late-fusion layer enables predictions based on comprehensive
image-text knowledge as well as text only when this is required. We evaluate
our approach using several visual commonsense reasoning tasks together with
traditional NLP tasks, including common sense reasoning and reading
comprehension. Our experimental results demonstrate significant superiority
over existing baselines. When applied to recent state-of-the-art LLMs (e.g.,
Llama3), we observe improvements not only in visual common sense but also in
traditional NLP benchmarks. Code and models are available under
https://github.com/guyyariv/vLMIG."
Generative Modeling by Minimizing the Wasserstein-2 Loss,https://arxiv.org/abs/2406.13619,2024-06-19,2024-06-21,0.0,0.0,"This paper approaches the unsupervised learning problem by minimizing the
second-order Wasserstein loss (the $W_2$ loss) through a distribution-dependent
ordinary differential equation (ODE), whose dynamics involves the Kantorovich
potential associated with the true data distribution and a current estimate of
it. A main result shows that the time-marginal laws of the ODE form a gradient
flow for the $W_2$ loss, which converges exponentially to the true data
distribution. An Euler scheme for the ODE is proposed and it is shown to
recover the gradient flow for the $W_2$ loss in the limit. An algorithm is
designed by following the scheme and applying persistent training, which
naturally fits our gradient-flow approach. In both low- and high-dimensional
experiments, our algorithm outperforms Wasserstein generative adversarial
networks by increasing the level of persistent training appropriately."
In-Context Former - Lightning-fast Compressing Context for Large Language Model,https://arxiv.org/abs/2406.13618,2024-06-19,2024-06-21,0.0,0.0,"With the rising popularity of Transformer-based large language models (LLMs),
reducing their high inference costs has become a significant research focus.
One effective approach is to compress the long input contexts. Existing methods
typically leverage the self-attention mechanism of the LLM itself for context
compression. While these methods have achieved notable results, the compression
process still involves quadratic time complexity, which limits their
applicability. To mitigate this limitation, we propose the In-Context Former
(IC-Former). Unlike previous methods, IC-Former does not depend on the target
LLMs. Instead, it leverages the cross-attention mechanism and a small number of
learnable digest tokens to directly condense information from the contextual
word embeddings. This approach significantly reduces inference time, which
achieves linear growth in time complexity within the compression range.
Experimental results indicate that our method requires only 1/32 of the
floating-point operations of the baseline during compression and improves
processing speed by 68 to 112 times while achieving over 90% of the baseline
performance on evaluation metrics. Overall, our model effectively reduces
compression costs and makes real-time compression scenarios feasible."
Optimizing Psychological Counseling with Instruction-Tuned Large Language Models,https://arxiv.org/abs/2406.13617,2024-06-19,2024-06-21,0.0,0.0,"The advent of large language models (LLMs) has significantly advanced various
fields, including natural language processing and automated dialogue systems.
This paper explores the application of LLMs in psychological counseling,
addressing the increasing demand for mental health services. We present a
method for instruction tuning LLMs with specialized prompts to enhance their
performance in providing empathetic, relevant, and supportive responses. Our
approach involves developing a comprehensive dataset of counseling-specific
prompts, refining them through feedback from professional counselors, and
conducting rigorous evaluations using both automatic metrics and human
assessments. The results demonstrate that our instruction-tuned model
outperforms several baseline LLMs, highlighting its potential as a scalable and
accessible tool for mental health support."
Nicer Than Humans - How do Large Language Models Behave in the Prisoner's Dilemma?,https://arxiv.org/abs/2406.13605,2024-06-19,2024-06-21,0.0,0.0,"The behavior of Large Language Models (LLMs) as artificial social agents is
largely unexplored, and we still lack extensive evidence of how these agents
react to simple social stimuli. Testing the behavior of AI agents in classic
Game Theory experiments provides a promising theoretical framework for
evaluating the norms and values of these agents in archetypal social
situations. In this work, we investigate the cooperative behavior of three LLMs
(Llama2, Llama3, and GPT3.5) when playing the Iterated Prisoner's Dilemma
against random adversaries displaying various levels of hostility. We introduce
a systematic methodology to evaluate an LLM's comprehension of the game rules
and its capability to parse historical gameplay logs for decision-making. We
conducted simulations of games lasting for 100 rounds and analyzed the LLMs'
decisions in terms of dimensions defined in the behavioral economics
literature. We find that all models tend not to initiate defection but act
cautiously, favoring cooperation over defection only when the opponent's
defection rate is low. Overall, LLMs behave at least as cooperatively as the
typical human player, although our results indicate some substantial
differences among models. In particular, Llama2 and GPT3.5 are more cooperative
than humans, and especially forgiving and non-retaliatory for opponent
defection rates below 30%. More similar to humans, Llama3 exhibits consistently
uncooperative and exploitative behavior unless the opponent always cooperates.
Our systematic approach to the study of LLMs in game theoretical scenarios is a
step towards using these simulations to inform practices of LLM auditing and
alignment."
Root Cause Localization for Microservice Systems in Cloud-edge Collaborative Environments,https://arxiv.org/abs/2406.13604,2024-06-19,2024-06-21,0.0,0.0,"With the development of cloud-native technologies, microservice-based
software systems face challenges in accurately localizing root causes when
failures occur. Additionally, the cloud-edge collaborative environment
introduces more difficulties, such as unstable networks and high latency across
network segments. Accurately identifying the root cause of microservices in a
cloud-edge collaborative environment has thus become an urgent problem. In this
paper, we propose MicroCERCL, a novel approach that pinpoints root causes at
the kernel and application level in the cloud-edge collaborative environment.
Our key insight is that failures propagate through direct invocations and
indirect resource-competition dependencies in a cloud-edge collaborative
environment characterized by instability and high latency. This will become
more complex in the hybrid deployment that simultaneously involves multiple
microservice systems. Leveraging this insight, we extract valid contents from
kernel-level logs to prioritize localizing the kernel-level root cause.
Moreover, we construct a heterogeneous dynamic topology stack and train a graph
neural network model to accurately localize the application-level root cause
without relying on historical data. Notably, we released the first benchmark
hybrid deployment microservice system in a cloud-edge collaborative environment
(the largest and most complex within our knowledge). Experiments conducted on
the dataset collected from the benchmark show that MicroCERCL can accurately
localize the root cause of microservice systems in such environments,
significantly outperforming state-of-the-art approaches with an increase of at
least 24.1% in top-1 accuracy."
CoDreamer - Communication-Based Decentralised World Models,https://arxiv.org/abs/2406.13600,2024-06-19,2024-06-21,0.0,0.0,"Sample efficiency is a critical challenge in reinforcement learning.
Model-based RL has emerged as a solution, but its application has largely been
confined to single-agent scenarios. In this work, we introduce CoDreamer, an
extension of the Dreamer algorithm for multi-agent environments. CoDreamer
leverages Graph Neural Networks for a two-level communication system to tackle
challenges such as partial observability and inter-agent cooperation.
Communication is separately utilised within the learned world models and within
the learned policies of each agent to enhance modelling and task-solving. We
show that CoDreamer offers greater expressive power than a naive application of
Dreamer, and we demonstrate its superiority over baseline methods across
various multi-agent environments."
GraphKAN - Enhancing Feature Extraction with Graph Kolmogorov Arnold Networks,https://arxiv.org/abs/2406.13597,2024-06-19,2024-06-21,0.0,0.0,"Massive number of applications involve data with underlying relationships
embedded in non-Euclidean space. Graph neural networks (GNNs) are utilized to
extract features by capturing the dependencies within graphs. Despite
groundbreaking performances, we argue that Multi-layer perceptrons (MLPs) and
fixed activation functions impede the feature extraction due to information
loss. Inspired by Kolmogorov Arnold Networks (KANs), we make the first attempt
to GNNs with KANs. We discard MLPs and activation functions, and instead used
KANs for feature extraction. Experiments demonstrate the effectiveness of
GraphKAN, emphasizing the potential of KANs as a powerful tool. Code is
available at https://github.com/Ryanfzhang/GraphKan."
Submodular Participatory Budgeting,https://arxiv.org/abs/2406.13586,2024-06-19,2024-06-21,0.0,0.0,"Participatory budgeting refers to the practice of allocating public resources
by collecting and aggregating individual preferences. Most existing studies in
this field often assume an additive utility function, where each individual
holds a private utility for each candidate project, and the total utility of a
set of funded projects is simply the sum of the utilities of all projects. We
argue that this assumption does not always hold in reality. For example,
building two playgrounds in the same neighborhood does not necessarily lead to
twice the utility of building a single playground.
  To address this, we extend the existing study by proposing a submodular
participatory budgeting problem, assuming that the utility function of each
individual is a monotone and submodular function over funded projects. We
propose and examine three preference elicitation methods, including
\emph{ranking-by-marginal-values}, \emph{ranking-by-values} and \emph{threshold
approval votes}, and analyze their performances in terms of distortion.
Notably, if the utility function is addicative, our aggregation rule designed
for threshold approval votes achieves a better distortion than the
state-of-the-art approach."
Explaining time series models using frequency masking,https://arxiv.org/abs/2406.13584,2024-06-19,2024-06-21,0.0,0.0,"Time series data is fundamentally important for describing many critical
domains such as healthcare, finance, and climate, where explainable models are
necessary for safe automated decision-making. To develop eXplainable AI (XAI)
in these domains therefore implies explaining salient information in the time
series. Current methods for obtaining saliency maps assumes localized
information in the raw input space. In this paper, we argue that the salient
information of a number of time series is more likely to be localized in the
frequency domain. We propose FreqRISE, which uses masking based methods to
produce explanations in the frequency and time-frequency domain, which shows
the best performance across a number of tasks."
Enhancing Distractor Generation for Multiple-Choice Questions with Retrieval Augmented Pretraining and Knowledge Graph Integration,https://arxiv.org/abs/2406.13578,2024-06-19,2024-06-21,0.0,0.0,"In this paper, we tackle the task of distractor generation (DG) for
multiple-choice questions. Our study introduces two key designs. First, we
propose \textit{retrieval augmented pretraining}, which involves refining the
language model pretraining to align it more closely with the downstream task of
DG. Second, we explore the integration of knowledge graphs to enhance the
performance of DG. Through experiments with benchmarking datasets, we show that
our models significantly outperform the state-of-the-art results. Our
best-performing model advances the F1@3 score from 14.80 to 16.47 in MCQ
dataset and from 15.92 to 16.50 in Sciq dataset."
Bayes' capacity as a measure for reconstruction attacks in federated learning,https://arxiv.org/abs/2406.13569,2024-06-19,2024-06-21,0.0,0.0,"Within the machine learning community, reconstruction attacks are a principal
attack of concern and have been identified even in federated learning, which
was designed with privacy preservation in mind. In federated learning, it has
been shown that an adversary with knowledge of the machine learning
architecture is able to infer the exact value of a training element given an
observation of the weight updates performed during stochastic gradient descent.
In response to these threats, the privacy community recommends the use of
differential privacy in the stochastic gradient descent algorithm, termed
DP-SGD. However, DP has not yet been formally established as an effective
countermeasure against reconstruction attacks. In this paper, we formalise the
reconstruction threat model using the information-theoretic framework of
quantitative information flow. We show that the Bayes' capacity, related to the
Sibson mutual information of order infinity, represents a tight upper bound on
the leakage of the DP-SGD algorithm to an adversary interested in performing a
reconstruction attack. We provide empirical results demonstrating the
effectiveness of this measure for comparing mechanisms against reconstruction
threats."
Trapezoidal Gradient Descent for Effective Reinforcement Learning in Spiking Networks,https://arxiv.org/abs/2406.13568,2024-06-19,2024-06-21,0.0,0.0,"With the rapid development of artificial intelligence technology, the field
of reinforcement learning has continuously achieved breakthroughs in both
theory and practice. However, traditional reinforcement learning algorithms
often entail high energy consumption during interactions with the environment.
Spiking Neural Network (SNN), with their low energy consumption characteristics
and performance comparable to deep neural networks, have garnered widespread
attention. To reduce the energy consumption of practical applications of
reinforcement learning, researchers have successively proposed the Pop-SAN and
MDC-SAN algorithms. Nonetheless, these algorithms use rectangular functions to
approximate the spike network during the training process, resulting in low
sensitivity, thus indicating room for improvement in the training effectiveness
of SNN. Based on this, we propose a trapezoidal approximation gradient method
to replace the spike network, which not only preserves the original stable
learning state but also enhances the model's adaptability and response
sensitivity under various signal dynamics. Simulation results show that the
improved algorithm, using the trapezoidal approximation gradient to replace the
spike network, achieves better convergence speed and performance compared to
the original algorithm and demonstrates good training stability."
Is AI fun? HumorDB - a curated dataset and benchmark to investigate graphical humor,https://arxiv.org/abs/2406.13564,2024-06-19,2024-06-21,0.0,0.0,"Despite significant advancements in computer vision, understanding complex
scenes, particularly those involving humor, remains a substantial challenge.
This paper introduces HumorDB, a novel image-only dataset specifically designed
to advance visual humor understanding. HumorDB consists of meticulously curated
image pairs with contrasting humor ratings, emphasizing subtle visual cues that
trigger humor and mitigating potential biases. The dataset enables evaluation
through binary classification(Funny or Not Funny), range regression(funniness
on a scale from 1 to 10), and pairwise comparison tasks(Which Image is
Funnier?), effectively capturing the subjective nature of humor perception.
Initial experiments reveal that while vision-only models struggle,
vision-language models, particularly those leveraging large language models,
show promising results. HumorDB also shows potential as a valuable zero-shot
benchmark for powerful large multimodal models. We open-source both the dataset
and code under the CC BY 4.0 license."
Lexically Grounded Subword Segmentation,https://arxiv.org/abs/2406.13560,2024-06-19,2024-06-21,0.0,0.0,"We present three innovations in tokenization and subword segmentation. First,
we propose to use unsupervised morphological analysis with Morfessor as
pre-tokenization. Second, we present an algebraic method for obtaining subword
embeddings grounded in a word embedding space. Based on that, we design a novel
subword segmentation algorithm that uses the embeddings, ensuring that the
procedure considers lexical meaning. Third, we introduce an efficient
segmentation algorithm based on a subword bigram model that can be initialized
with the lexically aware segmentation method to avoid using Morfessor and large
embedding tables at inference time. We evaluate the proposed approaches using
two intrinsic metrics and measure their performance on two downstream tasks:
part-of-speech tagging and machine translation. Our experiments show
significant improvements in the morphological plausibility of the segmentation
when evaluated using segmentation precision on morpheme boundaries and improved
R\'enyi efficiency in 8 languages. Although the proposed tokenization methods
do not have a large impact on automatic translation quality, we observe
consistent performance gains in the arguably more morphological task of
part-of-speech tagging."
Solarcast-ML - Per Node GraphCast Extension for Solar Energy Production,https://arxiv.org/abs/2406.13559,2024-06-19,2024-06-21,0.0,0.0,"This project presents an extension to the GraphCast model, a state-of-the-art
graph neural network (GNN) for global weather forecasting, by integrating solar
energy production forecasting capabilities. The proposed approach leverages the
weather forecasts generated by GraphCast and trains a neural network model to
predict the ratio of actual solar output to potential solar output based on
various weather conditions. The model architecture consists of an input layer
corresponding to weather features (temperature, humidity, dew point, wind
speed, rain, barometric pressure, and altitude), two hidden layers with ReLU
activations, and an output layer predicting solar radiation. The model is
trained using a mean absolute error loss function and Adam optimizer. The
results demonstrate the model's effectiveness in accurately predicting solar
radiation, with its convergence behavior, decreasing training loss, and
accurate prediction of solar radiation patterns suggesting successful learning
of the underlying relationships between weather conditions and solar radiation.
The integration of solar energy production forecasting with GraphCast offers
valuable insights for the renewable energy sector, enabling better planning and
decision-making based on expected solar energy production. Future work could
explore further model refinements, incorporation of additional weather
variables, and extension to other renewable energy sources."
Enhancing Travel Choice Modeling with Large Language Models - A Prompt-Learning Approach,https://arxiv.org/abs/2406.13558,2024-06-19,2024-06-21,0.0,0.0,"Travel choice analysis is crucial for understanding individual travel
behavior to develop appropriate transport policies and recommendation systems
in Intelligent Transportation Systems (ITS). Despite extensive research, this
domain faces two critical challenges: a) modeling with limited survey data, and
b) simultaneously achieving high model explainability and accuracy. In this
paper, we introduce a novel prompt-learning-based Large Language Model(LLM)
framework that significantly improves prediction accuracy and provides explicit
explanations for individual predictions. This framework involves three main
steps: transforming input variables into textual form; building of
demonstrations similar to the object, and applying these to a well-trained LLM.
We tested the framework's efficacy using two widely used choice datasets:
London Passenger Mode Choice (LPMC) and Optima-Mode collected in Switzerland.
The results indicate that the LLM significantly outperforms state-of-the-art
deep learning methods and discrete choice models in predicting people's
choices. Additionally, we present a case of explanation illustrating how the
LLM framework generates understandable and explicit explanations at the
individual level."
BiLD - Bi-directional Logits Difference Loss for Large Language Model Distillation,https://arxiv.org/abs/2406.13555,2024-06-19,2024-06-21,0.0,0.0,"In recent years, large language models (LLMs) have shown exceptional
capabilities across various natural language processing (NLP) tasks. However,
such impressive performance often comes with the trade-off of an increased
parameter size, posing significant challenges for widespread deployment.
Knowledge distillation (KD) provides a solution by transferring knowledge from
a large teacher model to a smaller student model. In this paper, we explore the
task-specific distillation of LLMs at the logit level. Our investigation
reveals that the logits of fine-tuned LLMs exhibit a more extreme long-tail
distribution than those from vision models, with hidden ""noise"" in the long
tail affecting distillation performance. Furthermore, existing logits
distillation methods often struggle to effectively utilize the internal ranking
information from the logits. To address these, we propose the Bi-directional
Logits Difference (BiLD) loss. The BiLD loss filters out the long-tail noise by
utilizing only top-$k$ teacher and student logits, and leverages the internal
logits ranking information by constructing logits differences. To evaluate BiLD
loss, we conduct comprehensive experiments on 13 datasets using two types of
LLMs. Our results show that the BiLD loss, with only the top-8 logits,
outperforms supervised fine-tuning (SFT), vanilla KL loss, and five other
distillation methods from both NLP and CV fields."
Mining United Nations General Assembly Debates,https://arxiv.org/abs/2406.13553,2024-06-19,2024-06-21,0.0,0.0,"This project explores the application of Natural Language Processing (NLP)
techniques to analyse United Nations General Assembly (UNGA) speeches. Using
NLP allows for the efficient processing and analysis of large volumes of
textual data, enabling the extraction of semantic patterns, sentiment analysis,
and topic modelling. Our goal is to deliver a comprehensive dataset and a tool
(interface with descriptive statistics and automatically extracted topics) from
which political scientists can derive insights into international relations and
have the opportunity to have a nuanced understanding of global diplomatic
discourse."
Standardness Fogs Meaning - A Position Regarding the Informed Usage of Standard Datasets,https://arxiv.org/abs/2406.13552,2024-06-19,2024-06-21,0.0,0.0,"Standard datasets are frequently used to train and evaluate Machine Learning
models. However, the assumed standardness of these datasets leads to a lack of
in-depth discussion on how their labels match the derived categories for the
respective use case. In other words, the standardness of the datasets seems to
fog coherency and applicability, thus impeding the trust in Machine Learning
models. We propose to adopt Grounded Theory and Hypotheses Testing through
Visualization as methods to evaluate the match between use case, derived
categories, and labels of standard datasets. To showcase the approach, we apply
it to the 20 Newsgroups dataset and the MNIST dataset. For the 20 Newsgroups
dataset, we demonstrate that the labels are imprecise. Therefore, we argue that
neither a Machine Learning model can learn a meaningful abstraction of derived
categories nor one can draw conclusions from achieving high accuracy. For the
MNIST dataset, we demonstrate how the labels can be confirmed to be defined
well. We conclude that a concept of standardness of a dataset implies that
there is a match between use case, derived categories, and class labels, as in
the case of the MNIST dataset. We argue that this is necessary to learn a
meaningful abstraction and, thus, improve trust in the Machine Learning model."
Mitigating Social Biases in Language Models through Unlearning,https://arxiv.org/abs/2406.13551,2024-06-19,2024-06-21,0.0,0.0,"Mitigating bias in language models (LMs) has become a critical problem due to
the widespread deployment of LMs. Numerous approaches revolve around data
pre-processing and fine-tuning of language models, tasks that can be both
time-consuming and computationally demanding. Consequently, there is a growing
interest in machine unlearning techniques given their capacity to induce the
forgetting of undesired behaviors of the existing pre-trained or fine-tuned
models with lower computational cost. In this work, we explore two unlearning
methods, (1) Partitioned Contrastive Gradient Unlearning (PCGU) applied on
decoder models and (2) Negation via Task Vector, to reduce social biases in
state-of-the-art and open-source LMs such as LLaMA-2 and OPT. We also implement
distributed PCGU for large models. It is empirically shown, through
quantitative and qualitative analyses, that negation via Task Vector method
outperforms PCGU in debiasing with minimum deterioration in performance and
perplexity of the models. On LLaMA-27B, negation via Task Vector reduces the
bias score by 11.8%"
ModSec-Learn - Boosting ModSecurity with Machine Learning,https://arxiv.org/abs/2406.13547,2024-06-19,2024-06-21,0.0,0.0,"ModSecurity is widely recognized as the standard open-source Web Application
Firewall (WAF), maintained by the OWASP Foundation. It detects malicious
requests by matching them against the Core Rule Set (CRS), identifying
well-known attack patterns. Each rule is manually assigned a weight based on
the severity of the corresponding attack, and a request is blocked if the sum
of the weights of matched rules exceeds a given threshold. However, we argue
that this strategy is largely ineffective against web attacks, as detection is
only based on heuristics and not customized on the application to protect. In
this work, we overcome this issue by proposing a machine-learning model that
uses the CRS rules as input features. Through training, ModSec-Learn is able to
tune the contribution of each CRS rule to predictions, thus adapting the
severity level to the web applications to protect. Our experiments show that
ModSec-Learn achieves a significantly better trade-off between detection and
false positive rates. Finally, we analyze how sparse regularization can reduce
the number of rules that are relevant at inference time, by discarding more
than 30% of the CRS rules. We release our open-source code and the dataset at
https://github.com/pralab/modsec-learn and
https://github.com/pralab/http-traffic-dataset, respectively."
One Fits All - Learning Fair Graph Neural Networks for Various Sensitive Attributes,https://arxiv.org/abs/2406.13544,2024-06-19,2024-06-21,0.0,0.0,"Recent studies have highlighted fairness issues in Graph Neural Networks
(GNNs), where they produce discriminatory predictions against specific
protected groups categorized by sensitive attributes such as race and age.
While various efforts to enhance GNN fairness have made significant progress,
these approaches are often tailored to specific sensitive attributes.
Consequently, they necessitate retraining the model from scratch to accommodate
changes in the sensitive attribute requirement, resulting in high computational
costs. To gain deeper insights into this issue, we approach the graph fairness
problem from a causal modeling perspective, where we identify the confounding
effect induced by the sensitive attribute as the underlying reason. Motivated
by this observation, we formulate the fairness problem in graphs from an
invariant learning perspective, which aims to learn invariant representations
across environments. Accordingly, we propose a graph fairness framework based
on invariant learning, namely FairINV, which enables the training of fair GNNs
to accommodate various sensitive attributes within a single training session.
Specifically, FairINV incorporates sensitive attribute partition and trains
fair GNNs by eliminating spurious correlations between the label and various
sensitive attributes. Experimental results on several real-world datasets
demonstrate that FairINV significantly outperforms state-of-the-art fairness
approaches, underscoring its effectiveness. Our code is available via:
https://github.com/ZzoomD/FairINV/."
Self-play with Execution Feedback - Improving Instruction-following Capabilities of Large Language Models,https://arxiv.org/abs/2406.13542,2024-06-19,2024-06-21,0.0,0.0,"One core capability of large language models (LLMs) is to follow natural
language instructions. However, the issue of automatically constructing
high-quality training data to enhance the complex instruction-following
abilities of LLMs without manual annotation remains unresolved. In this paper,
we introduce AutoIF, the first scalable and reliable method for automatically
generating instruction-following training data. AutoIF transforms the
validation of instruction-following data quality into code verification,
requiring LLMs to generate instructions, the corresponding code to check the
correctness of the instruction responses, and unit test samples to verify the
code's correctness. Then, execution feedback-based rejection sampling can
generate data for Supervised Fine-Tuning (SFT) and Reinforcement Learning from
Human Feedback (RLHF) training. AutoIF achieves significant improvements across
three training algorithms, SFT, Offline DPO, and Online DPO, when applied to
the top open-source LLMs, Qwen2 and LLaMA3, in self-alignment and
strong-to-weak distillation settings. Our code is publicly available at
https://github.com/QwenLM/AutoIF."
Scalable unsupervised alignment of general metric and non-metric structures,https://arxiv.org/abs/2406.13507,2024-06-19,2024-06-21,0.0,0.0,"Aligning data from different domains is a fundamental problem in machine
learning with broad applications across very different areas, most notably
aligning experimental readouts in single-cell multiomics. Mathematically, this
problem can be formulated as the minimization of disagreement of pair-wise
quantities such as distances and is related to the Gromov-Hausdorff and
Gromov-Wasserstein distances. Computationally, it is a quadratic assignment
problem (QAP) that is known to be NP-hard. Prior works attempted to solve the
QAP directly with entropic or low-rank regularization on the permutation, which
is computationally tractable only for modestly-sized inputs, and encode only
limited inductive bias related to the domains being aligned. We consider the
alignment of metric structures formulated as a discrete Gromov-Wasserstein
problem and instead of solving the QAP directly, we propose to learn a related
well-scalable linear assignment problem (LAP) whose solution is also a
minimizer of the QAP. We also show a flexible extension of the proposed
framework to general non-metric dissimilarities through differentiable ranks.
We extensively evaluate our approach on synthetic and real datasets from
single-cell multiomics and neural latent spaces, achieving state-of-the-art
performance while being conceptually and computationally simple."
ManWav - The First Manchu ASR Model,https://arxiv.org/abs/2406.13502,2024-06-19,2024-06-21,0.0,0.0,"This study addresses the widening gap in Automatic Speech Recognition (ASR)
research between high resource and extremely low resource languages, with a
particular focus on Manchu, a critically endangered language. Manchu
exemplifies the challenges faced by marginalized linguistic communities in
accessing state-of-the-art technologies. In a pioneering effort, we introduce
the first-ever Manchu ASR model ManWav, leveraging Wav2Vec2-XLSR-53. The
results of the first Manchu ASR is promising, especially when trained with our
augmented data. Wav2Vec2-XLSR-53 fine-tuned with augmented data demonstrates a
0.02 drop in CER and 0.13 drop in WER compared to the same base model
fine-tuned with original data."
GraphMU - Repairing Robustness of Graph Neural Networks via Machine Unlearning,https://arxiv.org/abs/2406.13499,2024-06-19,2024-06-21,0.0,0.0,"Graph Neural Networks (GNNs) have demonstrated significant application
potential in various fields. However, GNNs are still vulnerable to adversarial
attacks. Numerous adversarial defense methods on GNNs are proposed to address
the problem of adversarial attacks. However, these methods can only serve as a
defense before poisoning, but cannot repair poisoned GNN. Therefore, there is
an urgent need for a method to repair poisoned GNN. In this paper, we address
this gap by introducing the novel concept of model repair for GNNs. We propose
a repair framework, Repairing Robustness of Graph Neural Networks via Machine
Unlearning (GraphMU), which aims to fine-tune poisoned GNN to forget
adversarial samples without the need for complete retraining. We also introduce
a unlearning validation method to ensure that our approach effectively forget
specified poisoned data. To evaluate the effectiveness of GraphMU, we explore
three fine-tuned subgraph construction scenarios based on the available
perturbation information: (i) Known Perturbation Ratios, (ii) Known Complete
Knowledge of Perturbations, and (iii) Unknown any Knowledge of Perturbations.
Our extensive experiments, conducted across four citation datasets and four
adversarial attack scenarios, demonstrate that GraphMU can effectively restore
the performance of poisoned GNN."
In-Context In-Context Learning with Transformer Neural Processes,https://arxiv.org/abs/2406.13493,2024-06-19,2024-06-21,0.0,0.0,"Neural processes (NPs) are a powerful family of meta-learning models that
seek to approximate the posterior predictive map of the ground-truth stochastic
process from which each dataset in a meta-dataset is sampled. There are many
cases in which practitioners, besides having access to the dataset of interest,
may also have access to other datasets that share similarities with it. In this
case, integrating these datasets into the NP can improve predictions. We equip
NPs with this functionality and describe this paradigm as in-context in-context
learning. Standard NP architectures, such as the convolutional conditional NP
(ConvCNP) or the family of transformer neural processes (TNPs), are not capable
of in-context in-context learning, as they are only able to condition on a
single dataset. We address this shortcoming by developing the in-context
in-context learning pseudo-token TNP (ICICL-TNP). The ICICL-TNP builds on the
family of PT-TNPs, which utilise pseudo-token-based transformer architectures
to sidestep the quadratic computational complexity associated with regular
transformer architectures. Importantly, the ICICL-TNP is capable of
conditioning on both sets of datapoints and sets of datasets, enabling it to
perform in-context in-context learning. We demonstrate the importance of
in-context in-context learning and the effectiveness of the ICICL-TNP in a
number of experiments."
The Surprising Benefits of Base Rate Neglect in Robust Aggregation,https://arxiv.org/abs/2406.13490,2024-06-19,2024-06-21,0.0,0.0,"Robust aggregation integrates predictions from multiple experts without
knowledge of the experts' information structures. Prior work assumes experts
are Bayesian, providing predictions as perfect posteriors based on their
signals. However, real-world experts often deviate systematically from Bayesian
reasoning. Our work considers experts who tend to ignore the base rate. We find
that a certain degree of base rate neglect helps with robust forecast
aggregation.
  Specifically, we consider a forecast aggregation problem with two experts who
each predict a binary world state after observing private signals. Unlike
previous work, we model experts exhibiting base rate neglect, where they
incorporate the base rate information to degree $\lambda\in[0,1]$, with
$\lambda=0$ indicating complete ignorance and $\lambda=1$ perfect Bayesian
updating. To evaluate aggregators' performance, we adopt Arieli et al. (2018)'s
worst-case regret model, which measures the maximum regret across the set of
considered information structures compared to an omniscient benchmark. Our
results reveal the surprising V-shape of regret as a function of $\lambda$.
That is, predictions with an intermediate incorporating degree of base rate
$\lambda<1$ can counter-intuitively lead to lower regret than perfect Bayesian
posteriors with $\lambda=1$. We additionally propose a new aggregator with low
regret robust to unknown $\lambda$. Finally, we conduct an empirical study to
test the base rate neglect model and evaluate the performance of various
aggregators."
Approximately Equivariant Neural Processes,https://arxiv.org/abs/2406.13488,2024-06-19,2024-06-21,0.0,0.0,"Equivariant deep learning architectures exploit symmetries in learning
problems to improve the sample efficiency of neural-network-based models and
their ability to generalise. However, when modelling real-world data, learning
problems are often not exactly equivariant, but only approximately. For
example, when estimating the global temperature field from weather station
observations, local topographical features like mountains break translation
equivariance. In these scenarios, it is desirable to construct architectures
that can flexibly depart from exact equivariance in a data-driven way. In this
paper, we develop a general approach to achieving this using existing
equivariant architectures. Our approach is agnostic to both the choice of
symmetry group and model architecture, making it widely applicable. We consider
the use of approximately equivariant architectures in neural processes (NPs), a
popular family of meta-learning models. We demonstrate the effectiveness of our
approach on a number of synthetic and real-world regression experiments,
demonstrating that approximately equivariant NP models can outperform both
their non-equivariant and strictly equivariant counterparts."
An evidential time-to-event prediction model based on Gaussian random fuzzy numbers,https://arxiv.org/abs/2406.13487,2024-06-19,2024-06-21,0.0,0.0,"We introduce an evidential model for time-to-event prediction with censored
data. In this model, uncertainty on event time is quantified by Gaussian random
fuzzy numbers, a newly introduced family of random fuzzy subsets of the real
line with associated belief functions, generalizing both Gaussian random
variables and Gaussian possibility distributions. Our approach makes minimal
assumptions about the underlying time-to-event distribution. The model is fit
by minimizing a generalized negative log-likelihood function that accounts for
both normal and censored data. Comparative experiments on two real-world
datasets demonstrate the very good performance of our model as compared to the
state-of-the-art."
"Mean-Variance Portfolio Selection in Long-Term Investments with Unknown Distribution - Online Estimation, Risk Aversion under Ambiguity, and Universality of Algorithms",https://arxiv.org/abs/2406.13486,2024-06-19,2024-06-21,0.0,0.0,"The standard approach for constructing a Mean-Variance portfolio involves
estimating parameters for the model using collected samples. However, since the
distribution of future data may not resemble that of the training set, the
out-of-sample performance of the estimated portfolio is worse than one derived
with true parameters, which has prompted several innovations for better
estimation. Instead of treating the data without a timing aspect as in the
common training-backtest approach, this paper adopts a perspective where data
gradually and continuously reveal over time. The original model is recast into
an online learning framework, which is free from any statistical assumptions,
to propose a dynamic strategy of sequential portfolios such that its empirical
utility, Sharpe ratio, and growth rate asymptotically achieve those of the true
portfolio, derived with perfect knowledge of the future data.
  When the distribution of future data has a normal shape, the growth rate of
wealth is shown to increase by lifting the portfolio along the efficient
frontier through the calibration of risk aversion. Since risk aversion cannot
be appropriately predetermined, another proposed algorithm updating this
coefficient over time forms a dynamic strategy approaching the optimal
empirical Sharpe ratio or growth rate associated with the true coefficient. The
performance of these proposed strategies is universally guaranteed under
specific stochastic markets. Furthermore, in stationary and ergodic markets,
the so-called Bayesian strategy utilizing true conditional distributions, based
on observed past market information during investment, almost surely does not
perform better than the proposed strategies in terms of empirical utility,
Sharpe ratio, or growth rate, which, in contrast, do not rely on conditional
distributions."
LLMs Are Zero-Shot Context-Aware Simultaneous Translators,https://arxiv.org/abs/2406.13476,2024-06-19,2024-06-21,0.0,0.0,"The advent of transformers has fueled progress in machine translation. More
recently large language models (LLMs) have come to the spotlight thanks to
their generality and strong performance in a wide range of language tasks,
including translation. Here we show that open-source LLMs perform on par with
or better than some state-of-the-art baselines in simultaneous machine
translation (SiMT) tasks, zero-shot. We also demonstrate that injection of
minimal background information, which is easy with an LLM, brings further
performance gains, especially on challenging technical subject-matter. This
highlights LLMs' potential for building next generation of massively
multilingual, context-aware and terminologically accurate SiMT systems that
require no resource-intensive training or fine-tuning."
Attention-aware Post-training Quantization without Backpropagation,https://arxiv.org/abs/2406.13474,2024-06-19,2024-06-21,0.0,0.0,"Quantization is a promising solution for deploying large-scale language
models (LLMs) on resource-constrained devices. Existing quantization
approaches, however, rely on gradient-based optimization, regardless of it
being post-training quantization (PTQ) or quantization-aware training (QAT),
which becomes problematic for hyper-scale LLMs with billions of parameters.
This overhead can be alleviated via recently proposed backpropagation-free PTQ
methods; however, their performance is somewhat limited by their lack of
consideration of inter-layer dependencies. In this paper, we thus propose a
novel PTQ algorithm that considers inter-layer dependencies without relying on
backpropagation. The fundamental concept involved is the development of
attention-aware Hessian matrices, which facilitates the consideration of
inter-layer dependencies within the attention module. Extensive experiments
demonstrate that the proposed algorithm significantly outperforms conventional
PTQ methods, particularly for low bit-widths."
Encoder vs Decoder - Comparative Analysis of Encoder and Decoder Language Models on Multilingual NLU Tasks,https://arxiv.org/abs/2406.13469,2024-06-19,2024-06-21,0.0,0.0,"This paper explores the performance of encoder and decoder language models on
multilingual Natural Language Understanding (NLU) tasks, with a broad focus on
Germanic languages. Building upon the ScandEval benchmark, which initially was
restricted to evaluating encoder models, we extend the evaluation framework to
include decoder models. We introduce a method for evaluating decoder models on
NLU tasks and apply it to the languages Danish, Swedish, Norwegian, Icelandic,
Faroese, German, Dutch, and English. Through a series of experiments and
analyses, we address key research questions regarding the comparative
performance of encoder and decoder models, the impact of NLU task types, and
the variation across language resources. Our findings reveal that decoder
models can achieve significantly better NLU performance than encoder models,
with nuances observed across different tasks and languages. Additionally, we
investigate the correlation between decoders and task performance via a UMAP
analysis, shedding light on the unique capabilities of decoder and encoder
models. This study contributes to a deeper understanding of language model
paradigms in NLU tasks and provides valuable insights for model selection and
evaluation in multilingual settings."
EvTexture - Event-driven Texture Enhancement for Video Super-Resolution,https://arxiv.org/abs/2406.13457,2024-06-19,2024-06-21,0.0,0.0,"Event-based vision has drawn increasing attention due to its unique
characteristics, such as high temporal resolution and high dynamic range. It
has been used in video super-resolution (VSR) recently to enhance the flow
estimation and temporal alignment. Rather than for motion learning, we propose
in this paper the first VSR method that utilizes event signals for texture
enhancement. Our method, called EvTexture, leverages high-frequency details of
events to better recover texture regions in VSR. In our EvTexture, a new
texture enhancement branch is presented. We further introduce an iterative
texture enhancement module to progressively explore the
high-temporal-resolution event information for texture restoration. This allows
for gradual refinement of texture regions across multiple iterations, leading
to more accurate and rich high-resolution details. Experimental results show
that our EvTexture achieves state-of-the-art performance on four datasets. For
the Vid4 dataset with rich textures, our method can get up to 4.67dB gain
compared with recent event-based methods. Code:
https://github.com/DachunKai/EvTexture."
Federating to Grow Transformers with Constrained Resources without Model Sharing,https://arxiv.org/abs/2406.13450,2024-06-19,2024-06-21,0.0,0.0,"The high resource consumption of large-scale models discourages
resource-constrained users from developing their customized transformers. To
this end, this paper considers a federated framework named Fed-Grow for
multiple participants to cooperatively scale a transformer from their
pre-trained small models. Under the Fed-Grow, a Dual-LiGO (Dual Linear Growth
Operator) architecture is designed to help participants expand their
pre-trained small models to a transformer. In Dual-LiGO, the Local-LiGO part is
used to address the heterogeneity problem caused by the various pre-trained
models, and the Global-LiGO part is shared to exchange the implicit knowledge
from the pre-trained models, local data, and training process of participants.
Instead of model sharing, only sharing the Global-LiGO strengthens the privacy
of our approach. Compared with several state-of-the-art methods in simulation,
our approach has higher accuracy, better precision, and lower resource
consumption on computations and communications. To the best of our knowledge,
most of the previous model-scaling works are centralized, and our work is the
first one that cooperatively grows a transformer from multiple pre-trained
heterogeneous models with the user privacy protected in terms of local data and
models. We hope that our approach can extend the transformers to the broadly
distributed scenarios and encourage more resource-constrained users to enjoy
the bonus taken by the large-scale transformers."
High-probability minimax lower bounds,https://arxiv.org/abs/2406.13447,2024-06-19,2024-06-21,0.0,0.0,"The minimax risk is often considered as a gold standard against which we can
compare specific statistical procedures. Nevertheless, as has been observed
recently in robust and heavy-tailed estimation problems, the inherent reduction
of the (random) loss to its expectation may entail a significant loss of
information regarding its tail behaviour. In an attempt to avoid such a loss,
we introduce the notion of a minimax quantile, and seek to articulate its
dependence on the quantile level. To this end, we develop high-probability
variants of the classical Le Cam and Fano methods, as well as a technique to
convert local minimax risk lower bounds to lower bounds on minimax quantiles.
To illustrate the power of our framework, we deploy our techniques on several
examples, recovering recent results in robust mean estimation and stochastic
convex optimisation, as well as obtaining several new results in covariance
matrix estimation, sparse linear regression, nonparametric density estimation
and isotonic regression. Our overall goal is to argue that minimax quantiles
can provide a finer-grained understanding of the difficulty of statistical
problems, and that, in wide generality, lower bounds on these quantities can be
obtained via user-friendly tools."
Lost in UNet - Improving Infrared Small Target Detection by Underappreciated Local Features,https://arxiv.org/abs/2406.13445,2024-06-19,2024-06-21,0.0,0.0,"Many targets are often very small in infrared images due to the long-distance
imaging meachnism. UNet and its variants, as popular detection backbone
networks, downsample the local features early and cause the irreversible loss
of these local features, leading to both the missed and false detection of
small targets in infrared images. We propose HintU, a novel network to recover
the local features lost by various UNet-based methods for effective infrared
small target detection. HintU has two key contributions. First, it introduces
the ""Hint"" mechanism for the first time, i.e., leveraging the prior knowledge
of target locations to highlight critical local features. Second, it improves
the mainstream UNet-based architecture to preserve target pixels even after
downsampling. HintU can shift the focus of various networks (e.g., vanilla
UNet, UNet++, UIUNet, MiM+, and HCFNet) from the irrelevant background pixels
to a more restricted area from the beginning. Experimental results on three
datasets NUDT-SIRST, SIRSTv2 and IRSTD1K demonstrate that HintU enhances the
performance of existing methods with only an additional 1.88 ms cost (on RTX
Titan). Additionally, the explicit constraints of HintU enhance the
generalization ability of UNet-based methods. Code is available at
https://github.com/Wuzhou-Quan/HintU."
VDebugger - Harnessing Execution Feedback for Debugging Visual Programs,https://arxiv.org/abs/2406.13444,2024-06-19,2024-06-21,0.0,0.0,"Visual programs are executable code generated by large language models to
address visual reasoning problems. They decompose complex questions into
multiple reasoning steps and invoke specialized models for each step to solve
the problems. However, these programs are prone to logic errors, with our
preliminary evaluation showing that 58% of the total errors are caused by
program logic errors. Debugging complex visual programs remains a major
bottleneck for visual reasoning. To address this, we introduce VDebugger, a
novel critic-refiner framework trained to localize and debug visual programs by
tracking execution step by step. VDebugger identifies and corrects program
errors leveraging detailed execution feedback, improving interpretability and
accuracy. The training data is generated through an automated pipeline that
injects errors into correct visual programs using a novel mask-best decoding
technique. Evaluations on six datasets demonstrate VDebugger's effectiveness,
showing performance improvements of up to 3.2% in downstream task accuracy.
Further studies show VDebugger's ability to generalize to unseen tasks,
bringing a notable improvement of 2.3% on the unseen COVR task. Code, data and
models are made publicly available at https://github.com/shirley-wu/vdebugger/"
Dual-Phase Accelerated Prompt Optimization,https://arxiv.org/abs/2406.13443,2024-06-19,2024-06-21,0.0,0.0,"Gradient-free prompt optimization methods have made significant strides in
enhancing the performance of closed-source Large Language Models (LLMs) across
a wide range of tasks. However, existing approaches make light of the
importance of high-quality prompt initialization and the identification of
effective optimization directions, thus resulting in substantial optimization
steps to obtain satisfactory performance. In this light, we aim to accelerate
prompt optimization process to tackle the challenge of low convergence rate. We
propose a dual-phase approach which starts with generating high-quality initial
prompts by adopting a well-designed meta-instruction to delve into
task-specific information, and iteratively optimize the prompts at the sentence
level, leveraging previous tuning experience to expand prompt candidates and
accept effective ones. Extensive experiments on eight datasets demonstrate the
effectiveness of our proposed method, achieving a consistent accuracy gain over
baselines with less than five optimization steps."
Finding Blind Spots in Evaluator LLMs with Interpretable Checklists,https://arxiv.org/abs/2406.13439,2024-06-19,2024-06-21,0.0,0.0,"Large Language Models (LLMs) are increasingly relied upon to evaluate text
outputs of other LLMs, thereby influencing leaderboards and development
decisions. However, concerns persist over the accuracy of these assessments and
the potential for misleading conclusions. In this work, we investigate the
effectiveness of LLMs as evaluators for text generation tasks. We propose FBI,
a novel framework designed to examine the proficiency of Evaluator LLMs in
assessing four critical abilities in other LLMs: factual accuracy, instruction
following, coherence in long-form writing, and reasoning proficiency. By
introducing targeted perturbations in answers generated by LLMs, that clearly
impact one of these key capabilities, we test whether an Evaluator LLM can
detect these quality drops. By creating a total of 2400 perturbed answers
covering 22 perturbation categories, we conduct a comprehensive study using
different evaluation strategies on five prominent LLMs commonly used as
evaluators in the literature. Our findings reveal significant shortcomings in
current Evaluator LLMs, which failed to identify quality drops in over 50\% of
cases on average. Single-answer and pairwise evaluations demonstrated notable
limitations, whereas reference-based evaluations showed comparatively better
performance. These results underscore the unreliable nature of current
Evaluator LLMs and advocate for cautious implementation in practical
applications. Code and data are available at https://github.com/AI4Bharat/FBI."
"What's Next? Exploring Utilization, Challenges, and Future Directions of AI-Generated Image Tools in Graphic Design",https://arxiv.org/abs/2406.13436,2024-06-19,2024-06-21,0.0,0.0,"Recent advancements in artificial intelligence, such as computer vision and
deep learning, have led to the emergence of numerous generative AI platforms,
particularly for image generation. However, the application of AI-generated
image tools in graphic design has not been extensively explored. This study
conducted semi-structured interviews with seven designers of varying experience
levels to understand their current usage, challenges, and future functional
needs for AI-generated image tools in graphic design. As our findings suggest,
AI tools serve as creative partners in design, enhancing human creativity,
offering strategic insights, and fostering team collaboration and
communication. The findings provide guiding recommendations for the future
development of AI-generated image tools, aimed at helping engineers optimize
these tools to better meet the needs of graphic designers."
Children's Speech Recognition through Discrete Token Enhancement,https://arxiv.org/abs/2406.13431,2024-06-19,2024-06-21,0.0,0.0,"Children's speech recognition is considered a low-resource task mainly due to
the lack of publicly available data. There are several reasons for such data
scarcity, including expensive data collection and annotation processes, and
data privacy, among others. Transforming speech signals into discrete tokens
that do not carry sensitive information but capture both linguistic and
acoustic information could be a solution for privacy concerns. In this study,
we investigate the integration of discrete speech tokens into children's speech
recognition systems as input without significantly degrading the ASR
performance. Additionally, we explored single-view and multi-view strategies
for creating these discrete labels. Furthermore, we tested the models for
generalization capabilities with unseen domain and nativity dataset. Results
reveal that the discrete token ASR for children achieves nearly equivalent
performance with an approximate 83% reduction in parameters."
Are Logistic Models Really Interpretable?,https://arxiv.org/abs/2406.13427,2024-06-19,2024-06-21,0.0,0.0,"The demand for open and trustworthy AI models points towards widespread
publishing of model weights. Consumers of these model weights must be able to
act accordingly with the information provided. That said, one of the simplest
AI classification models, Logistic Regression (LR), has an unwieldy
interpretation of its model weights, with greater difficulties when extending
LR to generalised additive models. In this work, we show via a User Study that
skilled participants are unable to reliably reproduce the action of small LR
models given the trained parameters. As an antidote to this, we define
Linearised Additive Models (LAMs), an optimal piecewise linear approximation
that augments any trained additive model equipped with a sigmoid link function,
requiring no retraining. We argue that LAMs are more interpretable than
logistic models -- survey participants are shown to solve model reasoning tasks
with LAMs much more accurately than with LR given the same information.
Furthermore, we show that LAMs do not suffer from large performance penalties
in terms of ROC-AUC and calibration with respect to their logistic counterparts
on a broad suite of public financial modelling data."
Coupled Input-Output Dimension Reduction - Application to Goal-oriented Bayesian Experimental Design and Global Sensitivity Analysis,https://arxiv.org/abs/2406.13425,2024-06-19,2024-06-21,0.0,0.0,"We introduce a new method to jointly reduce the dimension of the input and
output space of a high-dimensional function. Choosing a reduced input subspace
influences which output subspace is relevant and vice versa. Conventional
methods focus on reducing either the input or output space, even though both
are often reduced simultaneously in practice. Our coupled approach naturally
supports goal-oriented dimension reduction, where either an input or output
quantity of interest is prescribed. We consider, in particular, goal-oriented
sensor placement and goal-oriented sensitivity analysis, which can be viewed as
dimension reduction where the most important output or, respectively, input
components are chosen. Both applications present difficult combinatorial
optimization problems with expensive objectives such as the expected
information gain and Sobol indices. By optimizing gradient-based bounds, we can
determine the most informative sensors and most sensitive parameters as the
largest diagonal entries of some diagnostic matrices, thus bypassing the
combinatorial optimization and objective evaluation."
Towards a multimodal framework for remote sensing image change retrieval and captioning,https://arxiv.org/abs/2406.13424,2024-06-19,2024-06-21,0.0,0.0,"Recently, there has been increasing interest in multimodal applications that
integrate text with other modalities, such as images, audio and video, to
facilitate natural language interactions with multimodal AI systems. While
applications involving standard modalities have been extensively explored,
there is still a lack of investigation into specific data modalities such as
remote sensing (RS) data. Despite the numerous potential applications of RS
data, including environmental protection, disaster monitoring and land
planning, available solutions are predominantly focused on specific tasks like
classification, captioning and retrieval. These solutions often overlook the
unique characteristics of RS data, such as its capability to systematically
provide information on the same geographical areas over time. This ability
enables continuous monitoring of changes in the underlying landscape. To
address this gap, we propose a novel foundation model for bi-temporal RS image
pairs, in the context of change detection analysis, leveraging Contrastive
Learning and the LEVIR-CC dataset for both captioning and text-image retrieval.
By jointly training a contrastive encoder and captioning decoder, our model add
text-image retrieval capabilities, in the context of bi-temporal change
detection, while maintaining captioning performances that are comparable to the
state of the art. We release the source code and pretrained weights at:
https://github.com/rogerferrod/RSICRC."
Factual Confidence of LLMs - on Reliability and Robustness of Current Estimators,https://arxiv.org/abs/2406.13415,2024-06-19,2024-06-21,0.0,0.0,"Large Language Models (LLMs) tend to be unreliable in the factuality of their
answers. To address this problem, NLP researchers have proposed a range of
techniques to estimate LLM's confidence over facts. However, due to the lack of
a systematic comparison, it is not clear how the different methods compare to
one another. To fill this gap, we present a survey and empirical comparison of
estimators of factual confidence. We define an experimental framework allowing
for fair comparison, covering both fact-verification and question answering.
Our experiments across a series of LLMs indicate that trained hidden-state
probes provide the most reliable confidence estimates, albeit at the expense of
requiring access to weights and training data. We also conduct a deeper
assessment of factual confidence by measuring the consistency of model behavior
under meaning-preserving variations in the input. We find that the confidence
of LLMs is often unstable across semantically equivalent inputs, suggesting
that there is much room for improvement of the stability of models' parametric
knowledge. Our code is available at
(https://github.com/amazon-science/factual-confidence-of-llms)."
Archive-based Single-Objective Evolutionary Algorithms for Submodular Optimization,https://arxiv.org/abs/2406.13414,2024-06-19,2024-06-21,0.0,0.0,"Constrained submodular optimization problems play a key role in the area of
combinatorial optimization as they capture many NP-hard optimization problems.
So far, Pareto optimization approaches using multi-objective formulations have
been shown to be successful to tackle these problems while single-objective
formulations lead to difficulties for algorithms such as the $(1+1)$-EA due to
the presence of local optima. We introduce for the first time single-objective
algorithms that are provably successful for different classes of constrained
submodular maximization problems. Our algorithms are variants of the
$(1+\lambda)$-EA and $(1+1)$-EA and increase the feasible region of the search
space incrementally in order to deal with the considered submodular problems."
Composite Concept Extraction through Backdooring,https://arxiv.org/abs/2406.13411,2024-06-19,2024-06-21,0.0,0.0,"Learning composite concepts, such as \textquotedbl red car\textquotedbl ,
from individual examples -- like a white car representing the concept of
\textquotedbl car\textquotedbl{} and a red strawberry representing the concept
of \textquotedbl red\textquotedbl -- is inherently challenging. This paper
introduces a novel method called Composite Concept Extractor (CoCE), which
leverages techniques from traditional backdoor attacks to learn these composite
concepts in a zero-shot setting, requiring only examples of individual
concepts. By repurposing the trigger-based model backdooring mechanism, we
create a strategic distortion in the manifold of the target object (e.g.,
\textquotedbl car\textquotedbl ) induced by example objects with the target
property (e.g., \textquotedbl red\textquotedbl ) from objects \textquotedbl red
strawberry\textquotedbl , ensuring the distortion selectively affects the
target objects with the target property. Contrastive learning is then employed
to further refine this distortion, and a method is formulated for detecting
objects that are influenced by the distortion. Extensive experiments with
in-depth analysis across different datasets demonstrate the utility and
applicability of our proposed approach."
SQLFixAgent - Towards Semantic-Accurate SQL Generation via Multi-Agent Collaboration,https://arxiv.org/abs/2406.13408,2024-06-19,2024-06-21,0.0,0.0,"While fine-tuned large language models (LLMs) excel in generating
grammatically valid SQL in Text-to-SQL parsing, they often struggle to ensure
semantic accuracy in queries, leading to user confusion and diminished system
usability. To tackle this challenge, we introduce SQLFixAgent, a new
consistency-enhanced multi-agent collaborative framework designed for detecting
and repairing erroneous SQL. Our framework comprises a core agent, SQLRefiner,
alongside two auxiliary agents: SQLReviewer and QueryCrafter. The SQLReviewer
agent employs the rubber duck debugging method to identify potential semantic
mismatches between SQL and user query. If the error is detected, the
QueryCrafter agent generates multiple SQL as candidate repairs using a
fine-tuned SQLTool. Subsequently, leveraging similar repair retrieval and
failure memory reflection, the SQLRefiner agent selects the most fitting SQL
statement from the candidates as the final repair. We evaluated our proposed
framework on five Text-to-SQL benchmarks. The experimental results show that
our method consistently enhances the performance of the baseline model,
specifically achieving an execution accuracy improvement of over 3\% on the
Bird benchmark. Our framework also has a higher token efficiency compared to
other advanced methods, making it more competitive."
VELO - A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework,https://arxiv.org/abs/2406.13399,2024-06-19,2024-06-21,0.0,0.0,"The Large Language Model (LLM) has gained significant popularity and is
extensively utilized across various domains. Most LLM deployments occur within
cloud data centers, where they encounter substantial response delays and incur
high costs, thereby impacting the Quality of Services (QoS) at the network
edge. Leveraging vector database caching to store LLM request results at the
edge can substantially mitigate response delays and cost associated with
similar requests, which has been overlooked by previous research. Addressing
these gaps, this paper introduces a novel Vector database-assisted cloud-Edge
collaborative LLM QoS Optimization (VELO) framework. Firstly, we propose the
VELO framework, which ingeniously employs vector database to cache the results
of some LLM requests at the edge to reduce the response time of subsequent
similar requests. Diverging from direct optimization of the LLM, our VELO
framework does not necessitate altering the internal structure of LLM and is
broadly applicable to diverse LLMs. Subsequently, building upon the VELO
framework, we formulate the QoS optimization problem as a Markov Decision
Process (MDP) and devise an algorithm grounded in Multi-Agent Reinforcement
Learning (MARL) to decide whether to request the LLM in the cloud or directly
return the results from the vector database at the edge. Moreover, to enhance
request feature extraction and expedite training, we refine the policy network
of MARL and integrate expert demonstrations. Finally, we implement the proposed
algorithm within a real edge system. Experimental findings confirm that our
VELO framework substantially enhances user satisfaction by concurrently
diminishing delay and resource consumption for edge users utilizing LLMs."
MoreHopQA - More Than Multi-hop Reasoning,https://arxiv.org/abs/2406.13397,2024-06-19,2024-06-21,0.0,0.0,"Most existing multi-hop datasets are extractive answer datasets, where the
answers to the questions can be extracted directly from the provided context.
This often leads models to use heuristics or shortcuts instead of performing
true multi-hop reasoning. In this paper, we propose a new multi-hop dataset,
MoreHopQA, which shifts from extractive to generative answers. Our dataset is
created by utilizing three existing multi-hop datasets: HotpotQA,
2WikiMultihopQA, and MuSiQue. Instead of relying solely on factual reasoning,
we enhance the existing multi-hop questions by adding another layer of
questioning that involves one, two, or all three of the following types of
reasoning: commonsense, arithmetic, and symbolic. Our dataset is created
through a semi-automated process, resulting in a dataset with 1,118 samples
that have undergone human verification. We then use our dataset to evaluate
five different large language models: Mistral 7B, Gemma 7B, Llama 3 (8B and
70B), and GPT-4. We also design various cases to analyze the reasoning steps in
the question-answering process. Our results show that models perform well on
initial multi-hop questions but struggle with our extended questions,
indicating that our dataset is more challenging than previous ones. Our
analysis of question decomposition reveals that although models can correctly
answer questions, only a portion - 38.7% for GPT-4 and 33.4% for Llama3-70B -
achieve perfect reasoning, where all corresponding sub-questions are answered
correctly. Evaluation code and data are available at
https://github.com/Alab-NII/morehopqa"
Unifying Mixed Gas Adsorption in Molecular Sieve Membranes and MOFs using Machine Learning,https://arxiv.org/abs/2406.13389,2024-06-19,2024-06-21,0.0,0.0,"Recent machine learning models to accurately obtain gas adsorption isotherms
focus on polymers or metal-organic frameworks (MOFs) separately. The difficulty
in creating a unified model that can predict the adsorption trends in both
types of adsorbents is challenging, owing to the diversity in their chemical
structures. Moreover, models trained only on single gas adsorption data are
incapable of predicting adsorption isotherms for binary gas mixtures. In this
work, we address these problems using feature vectors comprising only the
physical properties of the gas mixtures and adsorbents. Our model is trained on
adsorption isotherms of both single and binary mixed gases inside carbon
molecular sieving membrane (CMSM), together with data available from CoRE MOF
database. The trained models are capable of accurately predicting the
adsorption trends in both classes of materials, for both pure and binary
components. ML architecture designed for one class of material, is not suitable
for predicting the other class, even after proper training, signifying that the
model must be trained jointly for proper predictions and transferability. The
model is used to predict with good accuracy the CO2 uptake inside CALF-20
framework. This work opens up a new avenue for predicting complex adsorption
processes for gas mixtures in a wide range of materials."
Explainable by-design Audio Segmentation through Non-Negative Matrix Factorization and Probing,https://arxiv.org/abs/2406.13385,2024-06-19,2024-06-21,0.0,0.0,"Audio segmentation is a key task for many speech technologies, most of which
are based on neural networks, usually considered as black boxes, with
high-level performances. However, in many domains, among which health or
forensics, there is not only a need for good performance but also for
explanations about the output decision. Explanations derived directly from
latent representations need to satisfy ""good"" properties, such as
informativeness, compactness, or modularity, to be interpretable. In this
article, we propose an explainable-by-design audio segmentation model based on
non-negative matrix factorization (NMF) which is a good candidate for the
design of interpretable representations. This paper shows that our model
reaches good segmentation performances, and presents deep analyses of the
latent representation extracted from the non-negative matrix. The proposed
approach opens new perspectives toward the evaluation of interpretable
representations according to ""good"" properties."
CoAct - A Global-Local Hierarchy for Autonomous Agent Collaboration,https://arxiv.org/abs/2406.13381,2024-06-19,2024-06-21,0.0,0.0,"Existing LLMs exhibit remarkable performance on various NLP tasks, but still
struggle with complex real-world tasks, even equipped with advanced strategies
like CoT and ReAct. In this work, we propose the CoAct framework, which
transfers the hierarchical planning and collaboration patterns in human society
to LLM systems. Specifically, our CoAct framework involves two agents: (1) A
global planning agent, to comprehend the problem scope, formulate macro-level
plans and provide detailed sub-task descriptions to local execution agents,
which serves as the initial rendition of a global plan. (2) A local execution
agent, to operate within the multi-tier task execution structure, focusing on
detailed execution and implementation of specific tasks within the global plan.
Experimental results on the WebArena benchmark show that CoAct can re-arrange
the process trajectory when facing failures, and achieves superior performance
over baseline methods on long-horizon web tasks. Code is available at
https://github.com/xmhou2002/CoAct."
Efficient Offline Reinforcement Learning - The Critic is Critical,https://arxiv.org/abs/2406.13376,2024-06-19,2024-06-21,0.0,0.0,"Recent work has demonstrated both benefits and limitations from using
supervised approaches (without temporal-difference learning) for offline
reinforcement learning. While off-policy reinforcement learning provides a
promising approach for improving performance beyond supervised approaches, we
observe that training is often inefficient and unstable due to temporal
difference bootstrapping. In this paper we propose a best-of-both approach by
first learning the behavior policy and critic with supervised learning, before
improving with off-policy reinforcement learning. Specifically, we demonstrate
improved efficiency by pre-training with a supervised Monte-Carlo value-error,
making use of commonly neglected downstream information from the provided
offline trajectories. We find that we are able to more than halve the training
time of the considered offline algorithms on standard benchmarks, and
surprisingly also achieve greater stability. We further build on the importance
of having consistent policy and value functions to propose novel hybrid
algorithms, TD3+BC+CQL and EDAC+BC, that regularize both the actor and the
critic towards the behavior policy. This helps to more reliably improve on the
behavior policy when learning from limited human demonstrations. Code is
available at https://github.com/AdamJelley/EfficientOfflineRL"
ALiiCE - Evaluating Positional Fine-grained Citation Generation,https://arxiv.org/abs/2406.13375,2024-06-19,2024-06-21,0.0,0.0,"Large Language Models (LLMs) can enhance the credibility and verifiability by
generating text with citations. However, existing tasks and evaluation methods
are predominantly limited to sentence-level statement, neglecting the
significance of positional fine-grained citations that can appear anywhere
within sentences. To facilitate further exploration of the fine-grained
citation generation, we propose ALiiCE, the first automatic evaluation
framework for this task. Our framework first parses the sentence claim into
atomic claims via dependency analysis and then calculates citation quality at
the atomic claim level. ALiiCE introduces three novel metrics for positional
fined-grained citation quality assessment, including positional fine-grained
citation recall and precision, and coefficient of variation of citation
positions. We evaluate the positional fine-grained citation generation
performance of several LLMs on two long-form QA datasets. Our experiments and
analyses demonstrate the effectiveness and reasonableness of ALiiCE. The
results also indicate that existing LLMs still struggle to provide positional
fine-grained citations."
Thread - A Logic-Based Data Organization Paradigm for How-To Question Answering with Retrieval Augmented Generation,https://arxiv.org/abs/2406.13372,2024-06-19,2024-06-21,0.0,0.0,"Current question answering systems leveraging retrieval augmented generation
perform well in answering factoid questions but face challenges with
non-factoid questions, particularly how-to queries requiring detailed
step-by-step instructions and explanations. In this paper, we introduce Thread,
a novel data organization paradigm that transforms documents into logic units
based on their inter-connectivity. Extensive experiments across open-domain and
industrial scenarios demonstrate that Thread outperforms existing data
organization paradigms in RAG-based QA systems, significantly improving the
handling of how-to questions."
"Identifiable Causal Representation Learning - Unsupervised, Multi-View, and Multi-Environment",https://arxiv.org/abs/2406.13371,2024-06-19,2024-06-21,0.0,0.0,"Causal models provide rich descriptions of complex systems as sets of
mechanisms by which each variable is influenced by its direct causes. They
support reasoning about manipulating parts of the system and thus hold promise
for addressing some of the open challenges of artificial intelligence (AI),
such as planning, transferring knowledge in changing environments, or
robustness to distribution shifts. However, a key obstacle to more widespread
use of causal models in AI is the requirement that the relevant variables be
specified a priori, which is typically not the case for the high-dimensional,
unstructured data processed by modern AI systems. At the same time, machine
learning (ML) has proven quite successful at automatically extracting useful
and compact representations of such complex data. Causal representation
learning (CRL) aims to combine the core strengths of ML and causality by
learning representations in the form of latent variables endowed with causal
model semantics.
  In this thesis, we study and present new results for different CRL settings.
A central theme is the question of identifiability: Given infinite data, when
are representations satisfying the same learning objective guaranteed to be
equivalent? This is an important prerequisite for CRL, as it formally
characterises if and when a learning task is, at least in principle, feasible.
Since learning causal models, even without a representation learning component,
is notoriously difficult, we require additional assumptions on the model class
or rich data beyond the classical i.i.d. setting. By partially characterising
identifiability for different settings, this thesis investigates what is
possible for CRL without direct supervision, and thus contributes to its
theoretical foundations. Ideally, the developed insights can help inform data
collection practices or inspire the design of new practical estimation methods."
Effective Edge-wise Representation Learning in Edge-Attributed Bipartite Graphs,https://arxiv.org/abs/2406.13369,2024-06-19,2024-06-21,0.0,0.0,"Graph representation learning (GRL) is to encode graph elements into
informative vector representations, which can be used in downstream tasks for
analyzing graph-structured data and has seen extensive applications in various
domains. However, the majority of extant studies on GRL are geared towards
generating node representations, which cannot be readily employed to perform
edge-based analytics tasks in edge-attributed bipartite graphs (EABGs) that
pervade the real world, e.g., spam review detection in customer-product reviews
and identifying fraudulent transactions in user-merchant networks. Compared to
node-wise GRL, learning edge representations (ERL) on such graphs is
challenging due to the need to incorporate the structure and attribute
semantics from the perspective of edges while considering the separate
influence of two heterogeneous node sets U and V in bipartite graphs. To our
knowledge, despite its importance, limited research has been devoted to this
frontier, and existing workarounds all suffer from sub-par results.
  Motivated by this, this paper designs EAGLE, an effective ERL method for
EABGs. Building on an in-depth and rigorous theoretical analysis, we propose
the factorized feature propagation (FFP) scheme for edge representations with
adequate incorporation of long-range dependencies of edges/features without
incurring tremendous computation overheads. We further ameliorate FFP as a
dual-view FFP by taking into account the influences from nodes in U and V
severally in ERL. Extensive experiments on 5 real datasets showcase the
effectiveness of the proposed EAGLE models in semi-supervised edge
classification tasks. In particular, EAGLE can attain a considerable gain of at
most 38.11% in AP and 1.86% in AUC when compared to the best baselines."
PPT-GNN - A Practical Pre-Trained Spatio-Temporal Graph Neural Network for Network Security,https://arxiv.org/abs/2406.13365,2024-06-19,2024-06-21,0.0,0.0,"Recent works have demonstrated the potential of Graph Neural Networks (GNN)
for network intrusion detection. Despite their advantages, a significant gap
persists between real-world scenarios, where detection speed is critical, and
existing proposals, which operate on large graphs representing several hours of
traffic. This gap results in unrealistic operational conditions and impractical
detection delays. Moreover, existing models do not generalize well across
different networks, hampering their deployment in production environments. To
address these issues, we introduce PPTGNN, a practical spatio-temporal GNN for
intrusion detection. PPTGNN enables near real-time predictions, while better
capturing the spatio-temporal dynamics of network attacks. PPTGNN employs
self-supervised pre-training for improved performance and reduced dependency on
labeled data. We evaluate PPTGNN on three public datasets and show that it
significantly outperforms state-of-the-art models, such as E-ResGAT and
E-GraphSAGE, with an average accuracy improvement of 10.38%. Finally, we show
that a pre-trained PPTGNN can easily be fine-tuned to unseen networks with
minimal labeled examples. This highlights the potential of PPTGNN as a general,
large-scale pre-trained model that can effectively operate in diverse network
environments."
Evaluating Structural Generalization in Neural Machine Translation,https://arxiv.org/abs/2406.13363,2024-06-19,2024-06-21,0.0,0.0,"Compositional generalization refers to the ability to generalize to novel
combinations of previously observed words and syntactic structures. Since it is
regarded as a desired property of neural models, recent work has assessed
compositional generalization in machine translation as well as semantic
parsing. However, previous evaluations with machine translation have focused
mostly on lexical generalization (i.e., generalization to unseen combinations
of known words). Thus, it remains unclear to what extent models can translate
sentences that require structural generalization (i.e., generalization to
different sorts of syntactic structures). To address this question, we
construct SGET, a machine translation dataset covering various types of
compositional generalization with control of words and sentence structures. We
evaluate neural machine translation models on SGET and show that they struggle
more in structural generalization than in lexical generalization. We also find
different performance trends in semantic parsing and machine translation, which
indicates the importance of evaluations across various tasks."
VisualRWKV - Exploring Recurrent Neural Networks for Visual Language Models,https://arxiv.org/abs/2406.13362,2024-06-19,2024-06-21,0.0,0.0,"Visual Language Models (VLMs) have rapidly progressed with the recent success
of large language models. However, there have been few attempts to incorporate
efficient linear Recurrent Neural Networks (RNNs) architectures into VLMs. In
this study, we introduce VisualRWKV, the first application of a linear RNN
model to multimodal learning tasks, leveraging the pre-trained RWKV language
model. We propose a data-dependent recurrence and sandwich prompts to enhance
our modeling capabilities, along with a 2D image scanning mechanism to enrich
the processing of visual sequences. Extensive experiments demonstrate that
VisualRWKV achieves competitive performance compared to Transformer-based
models like LLaVA-1.5 on various benchmarks. To facilitate further research and
analysis, we have made the checkpoints and the associated code publicly
accessible at the following GitHub repository:
\href{https://github.com/howard-hou/VisualRWKV}{https://github.com/howard-hou/VisualRWKV}."
Improving Zero-Shot Cross-Lingual Transfer via Progressive Code-Switching,https://arxiv.org/abs/2406.13361,2024-06-19,2024-06-21,0.0,0.0,"Code-switching is a data augmentation scheme mixing words from multiple
languages into source lingual text. It has achieved considerable generalization
performance of cross-lingual transfer tasks by aligning cross-lingual
contextual word representations. However, uncontrolled and over-replaced
code-switching would augment dirty samples to model training. In other words,
the excessive code-switching text samples will negatively hurt the models'
cross-lingual transferability. To this end, we propose a Progressive
Code-Switching (PCS) method to gradually generate moderately difficult
code-switching examples for the model to discriminate from easy to hard. The
idea is to incorporate progressively the preceding learned multilingual
knowledge using easier code-switching data to guide model optimization on
succeeding harder code-switching data. Specifically, we first design a
difficulty measurer to measure the impact of replacing each word in a sentence
based on the word relevance score. Then a code-switcher generates the
code-switching data of increasing difficulty via a controllable temperature
variable. In addition, a training scheduler decides when to sample harder
code-switching data for model training. Experiments show our model achieves
state-of-the-art results on three different zero-shot cross-lingual transfer
tasks across ten languages."
Transferable speech-to-text large language model alignment module,https://arxiv.org/abs/2406.13357,2024-06-19,2024-06-21,0.0,0.0,"By leveraging the power of Large Language Models(LLMs) and speech foundation
models, state of the art speech-text bimodal works can achieve challenging
tasks like spoken translation(ST) and question answering(SQA) altogether with
much simpler architectures. In this paper, we utilize the capability of Whisper
encoder and pre-trained Yi-6B. Empirical results reveal that modal alignment
can be achieved with one layer module and hundred hours of speech-text
multitask corpus. We further swap the Yi-6B with human preferences aligned
version of Yi-6B-Chat during inference, and discover that the alignment
capability is applicable as well. In addition, the alignment subspace revealed
by singular value decomposition(SVD) also implies linear alignment subspace is
sparse, which leaves the possibility to concatenate other features like
voice-print or video to expand modality."
Jogging the Memory of Unlearned Model Through Targeted Relearning Attack,https://arxiv.org/abs/2406.13356,2024-06-19,2024-06-21,0.0,0.0,"Machine unlearning is a promising approach to mitigate undesirable
memorization of training data in ML models. However, in this work we show that
existing approaches for unlearning in LLMs are surprisingly susceptible to a
simple set of targeted relearning attacks. With access to only a small and
potentially loosely related set of data, we find that we can 'jog' the memory
of unlearned models to reverse the effects of unlearning. We formalize this
unlearning-relearning pipeline, explore the attack across three popular
unlearning benchmarks, and discuss future directions and guidelines that result
from our study."
AgentDojo - A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents,https://arxiv.org/abs/2406.13352,2024-06-19,2024-06-21,0.0,0.0,"AI agents aim to solve complex tasks by combining text-based reasoning with
external tool calls. Unfortunately, AI agents are vulnerable to prompt
injection attacks where data returned by external tools hijacks the agent to
execute malicious tasks. To measure the adversarial robustness of AI agents, we
introduce AgentDojo, an evaluation framework for agents that execute tools over
untrusted data. To capture the evolving nature of attacks and defenses,
AgentDojo is not a static test suite, but rather an extensible environment for
designing and evaluating new agent tasks, defenses, and adaptive attacks. We
populate the environment with 97 realistic tasks (e.g., managing an email
client, navigating an e-banking website, or making travel bookings), 629
security test cases, and various attack and defense paradigms from the
literature. We find that AgentDojo poses a challenge for both attacks and
defenses: state-of-the-art LLMs fail at many tasks (even in the absence of
attacks), and existing prompt injection attacks break some security properties
but not all. We hope that AgentDojo can foster research on new design
principles for AI agents that solve common tasks in a reliable and robust
manner. We release the code for AgentDojo at
https://github.com/ethz-spylab/agentdojo."
A Resource-Adaptive Approach for Federated Learning under Resource-Constrained Environments,https://arxiv.org/abs/2406.13351,2024-06-19,2024-06-21,0.0,0.0,"The paper studies a fundamental federated learning (FL) problem involving
multiple clients with heterogeneous constrained resources. Compared with the
numerous training parameters, the computing and communication resources of
clients are insufficient for fast local training and real-time knowledge
sharing. Besides, training on clients with heterogeneous resources may result
in the straggler problem. To address these issues, we propose Fed-RAA: a
Resource-Adaptive Asynchronous Federated learning algorithm. Different from
vanilla FL methods, where all parameters are trained by each participating
client regardless of resource diversity, Fed-RAA adaptively allocates fragments
of the global model to clients based on their computing and communication
capabilities. Each client then individually trains its assigned model fragment
and asynchronously uploads the updated result. Theoretical analysis confirms
the convergence of our approach. Additionally, we design an online greedy-based
algorithm for fragment allocation in Fed-RAA, achieving fairness comparable to
an offline strategy. We present numerical results on MNIST, CIFAR-10, and
CIFAR-100, along with necessary comparisons and ablation studies, demonstrating
the advantages of our work. To the best of our knowledge, this paper represents
the first resource-adaptive asynchronous method for fragment-based FL with
guaranteed theoretical convergence."
Textual Unlearning Gives a False Sense of Unlearning,https://arxiv.org/abs/2406.13348,2024-06-19,2024-06-21,0.0,0.0,"Language models (LMs) are susceptible to ""memorizing"" training data,
including a large amount of private or copyright-protected content. To
safeguard the right to be forgotten (RTBF), machine unlearning has emerged as a
promising method for LMs to efficiently ""forget"" sensitive training content and
mitigate knowledge leakage risks. However, despite its good intentions, could
the unlearning mechanism be counterproductive? In this paper, we propose the
Textual Unlearning Leakage Attack (TULA), where an adversary can infer
information about the unlearned data only by accessing the models before and
after unlearning. Furthermore, we present variants of TULA in both black-box
and white-box scenarios. Through various experimental results, we critically
demonstrate that machine unlearning amplifies the risk of knowledge leakage
from LMs. Specifically, TULA can increase an adversary's ability to infer
membership information about the unlearned data by more than 20% in black-box
scenario. Moreover, TULA can even reconstruct the unlearned data directly with
more than 60% accuracy with white-box access. Our work is the first to reveal
that machine unlearning in LMs can inversely create greater knowledge risks and
inspire the development of more secure unlearning mechanisms."
SD-Eval - A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words,https://arxiv.org/abs/2406.13340,2024-06-19,2024-06-21,0.0,0.0,"Speech encompasses a wealth of information, including but not limited to
content, paralinguistic, and environmental information. This comprehensive
nature of speech significantly impacts communication and is crucial for
human-computer interaction. Chat-Oriented Large Language Models (LLMs), known
for their general-purpose assistance capabilities, have evolved to handle
multi-modal inputs, including speech. Although these models can be adept at
recognizing and analyzing speech, they often fall short of generating
appropriate responses. We argue that this is due to the lack of principles on
task definition and model development, which requires open-source datasets and
metrics suitable for model evaluation. To bridge the gap, we present SD-Eval, a
benchmark dataset aimed at multidimensional evaluation of spoken dialogue
understanding and generation. SD-Eval focuses on paralinguistic and
environmental information and includes 7,303 utterances, amounting to 8.76
hours of speech data. The data is aggregated from eight public datasets,
representing four perspectives: emotion, accent, age, and background sound. To
assess the SD-Eval benchmark dataset, we implement three different models and
construct a training set following a similar process as SD-Eval. The training
set contains 1,052.72 hours of speech data and 724.4k utterances. We also
conduct a comprehensive evaluation using objective evaluation methods (e.g.
BLEU and ROUGE), subjective evaluations and LLM-based metrics for the generated
responses. Models conditioned with paralinguistic and environmental information
outperform their counterparts in both objective and subjective measures.
Moreover, experiments demonstrate LLM-based metrics show a higher correlation
with human evaluation compared to traditional metrics. We open-source SD-Eval
at https://github.com/amphionspace/SD-Eval."
How effective is Multi-source pivoting for Translation of Low Resource Indian Languages?,https://arxiv.org/abs/2406.13332,2024-06-19,2024-06-21,0.0,0.0,"Machine Translation (MT) between linguistically dissimilar languages is
challenging, especially due to the scarcity of parallel corpora. Prior works
suggest that pivoting through a high-resource language can help translation
into a related low-resource language. However, existing works tend to discard
the source sentence when pivoting. Taking the case of English to Indian
language MT, this paper explores the 'multi-source translation' approach with
pivoting, using both source and pivot sentences to improve translation. We
conducted extensive experiments with various multi-source techniques for
translating English to Konkani, Manipuri, Sanskrit, and Bodo, using Hindi,
Marathi, and Bengali as pivot languages. We find that multi-source pivoting
yields marginal improvements over the state-of-the-art, contrary to previous
claims, but these improvements can be enhanced with synthetic target language
data. We believe multi-source pivoting is a promising direction for
Low-resource translation."
Improving Zero-shot LLM Re-Ranker with Risk Minimization,https://arxiv.org/abs/2406.13331,2024-06-19,2024-06-21,0.0,0.0,"In the Retrieval-Augmented Generation (RAG) system, advanced Large Language
Models (LLMs) have emerged as effective Query Likelihood Models (QLMs) in an
unsupervised way, which re-rank documents based on the probability of
generating the query given the content of a document. However, directly
prompting LLMs to approximate QLMs inherently is biased, where the estimated
distribution might diverge from the actual document-specific distribution. In
this study, we introduce a novel framework, $\mathrm{UR^3}$, which leverages
Bayesian decision theory to both quantify and mitigate this estimation bias.
Specifically, $\mathrm{UR^3}$ reformulates the problem as maximizing the
probability of document generation, thereby harmonizing the optimization of
query and document generation probabilities under a unified risk minimization
objective. Our empirical results indicate that $\mathrm{UR^3}$ significantly
enhances re-ranking, particularly in improving the Top-1 accuracy. It benefits
the QA tasks by achieving higher accuracy with fewer input documents."
On rough mereology and VC-dimension in treatment of decision prediction for open world decision systems,https://arxiv.org/abs/2406.13329,2024-06-19,2024-06-21,0.0,0.0,"Given a raw knowledge in the form of a data table/a decision system, one is
facing two possible venues. One, to treat the system as closed, i.e., its
universe does not admit new objects, or, to the contrary, its universe is open
on admittance of new objects. In particular, one may obtain new objects whose
sets of values of features are new to the system. In this case the problem is
to assign a decision value to any such new object. This problem is somehow
resolved in the rough set theory, e.g., on the basis of similarity of the value
set of a new object to value sets of objects already assigned a decision value.
It is crucial for online learning when each new object must have a predicted
decision value.\ There is a vast literature on various methods for decision
prediction for new yet unseen object.
  The approach we propose is founded in the theory of rough mereology and it
requires a theory of sets/concepts, and, we root our theory in classical set
theory of Syllogistic within which we recall the theory of parts known as
Mereology. Then, we recall our theory of Rough Mereology along with the theory
of weight assignment to the Tarski algebra of Mereology.\ This allows us to
introduce the notion of a part to a degree. Once we have defined basics of
Mereology and rough Mereology, we recall our theory of weight assignment to
elements of the Boolean algebra within Mereology and this allows us to define
the relation of parts to the degree and we apply this notion in a procedure to
select a decision for new yet unseen objects.\ In selecting a plausible
candidate which would pass its decision value to the new object, we employ the
notion of Vapnik - Chervonenkis dimension in order to select at the first stage
the candidate with the largest VC-dimension of the family of its
$\varepsilon$-components for some choice of $\varepsilon$."
Integration of Policy and Reputation based Trust Mechanisms in e-Commerce Industry,https://arxiv.org/abs/2406.13303,2024-06-19,2024-06-21,0.0,0.0,"The e-commerce systems are being tackled from commerce behavior and internet
technologies. Therefore, trust aspect between buyer-seller transactions is a
potential element which needs to be addressed in competitive e-commerce
industry. The e-commerce industry is currently handling two different trust
approaches. First approach consists on centralized mechanism where digital
credentials/set of rules assembled, called Policy based trust mechanisms .
Second approach consists on decentralized trust mechanisms where reputation,
points assembled and shared, called Reputation based trust mechanisms. The
difference between reputation and policy based trust mechanism will be analyzed
and recommendations would be proposed to increase trust between buyer and
seller in e-commerce industry. The integration of trust mechanism is proposed
through mapping process, strength of one mechanism with the weakness of other.
The proposed model for integrated mechanism will be presented and illustrated
how the proposed model will be used in real world e-commerce industry."
Empirical Evaluation of Integrated Trust Mechanism to Improve Trust in E-commerce Services,https://arxiv.org/abs/2406.13299,2024-06-19,2024-06-21,0.0,0.0,"There are mostly two approaches to tackle trust management worldwide Strong
and crisp and Soft and Social. We analyze the impact of integrated trust
mechanism in three different e-commerce services. The trust aspect is a dormant
element between potential users and being developed expert or internet systems.
We support our integration by preside over an experiment in controlled
laboratory environment. The model selected for the experiment is a composite of
policy and reputation based trust mechanisms and widely acknowledged in
e-commerce industry. The integration between policy and trust mechanism was
accomplished through mapping process, weakness of one brought to a close with
the strength of other. Furthermore, experiment has been supervised to validate
the effectiveness of implementation by segregating both integrated and
traditional trust mechanisms in learning system"
Media Forensics and Deepfake Systematic Survey,https://arxiv.org/abs/2406.13295,2024-06-19,2024-06-21,0.0,0.0,"Deepfake is a generative deep learning algorithm that creates or changes
facial features in a very realistic way making it hard to differentiate the
real from the fake features It can be used to make movies look better as well
as to spread false information by imitating famous people In this paper many
different ways to make a Deepfake are explained analyzed and separated
categorically Using Deepfake datasets models are trained and tested for
reliability through experiments Deepfakes are a type of facial manipulation
that allow people to change their entire faces identities attributes and
expressions The trends in the available Deepfake datasets are also discussed
with a focus on how they have changed Using Deep learning a general Deepfake
detection model is made Moreover the problems in making and detecting Deepfakes
are also mentioned As a result of this survey it is expected that the
development of new Deepfake based imaging tools will speed up in the future
This survey gives indepth review of methods for manipulating images of face and
various techniques to spot altered face images Four types of facial
manipulation are specifically discussed which are attribute manipulation
expression swap entire face synthesis and identity swap Across every
manipulation category we yield information on manipulation techniques
significant benchmarks for technical evaluation of counterfeit detection
techniques available public databases and a summary of the outcomes of all such
analyses From all of the topics in the survey we focus on the most recent
development of Deepfake showing its advances and obstacles in detecting fake
images"
Enhancing Cross-Prompt Transferability in Vision-Language Models through Contextual Injection of Target Tokens,https://arxiv.org/abs/2406.13294,2024-06-19,2024-06-21,0.0,0.0,"Vision-language models (VLMs) seamlessly integrate visual and textual data to
perform tasks such as image classification, caption generation, and visual
question answering. However, adversarial images often struggle to deceive all
prompts effectively in the context of cross-prompt migration attacks, as the
probability distribution of the tokens in these images tends to favor the
semantics of the original image rather than the target tokens. To address this
challenge, we propose a Contextual-Injection Attack (CIA) that employs
gradient-based perturbation to inject target tokens into both visual and
textual contexts, thereby improving the probability distribution of the target
tokens. By shifting the contextual semantics towards the target tokens instead
of the original image semantics, CIA enhances the cross-prompt transferability
of adversarial images.Extensive experiments on the BLIP2, InstructBLIP, and
LLaVA models show that CIA outperforms existing methods in cross-prompt
transferability, demonstrating its potential for more effective adversarial
strategies in VLMs."
Large-Scale Dataset Pruning in Adversarial Training through Data Importance Extrapolation,https://arxiv.org/abs/2406.13283,2024-06-19,2024-06-21,0.0,0.0,"Their vulnerability to small, imperceptible attacks limits the adoption of
deep learning models to real-world systems. Adversarial training has proven to
be one of the most promising strategies against these attacks, at the expense
of a substantial increase in training time. With the ongoing trend of
integrating large-scale synthetic data this is only expected to increase even
further. Thus, the need for data-centric approaches that reduce the number of
training samples while maintaining accuracy and robustness arises. While data
pruning and active learning are prominent research topics in deep learning,
they are as of now largely unexplored in the adversarial training literature.
We address this gap and propose a new data pruning strategy based on
extrapolating data importance scores from a small set of data to a larger set.
In an empirical evaluation, we demonstrate that extrapolation-based pruning can
efficiently reduce dataset size while maintaining robustness."
Understanding the RoPE Extensions of Long-Context LLMs - An Attention Perspective,https://arxiv.org/abs/2406.13282,2024-06-19,2024-06-21,0.0,0.0,"Enabling LLMs to handle lengthy context is currently a research hotspot. Most
LLMs are built upon rotary position embedding (RoPE), a popular position
encoding method. Therefore, a prominent path is to extrapolate the RoPE trained
on comparably short texts to far longer texts. A heavy bunch of efforts have
been dedicated to boosting the extrapolation via extending the formulations of
the RoPE, however, few of them have attempted to showcase their inner workings
comprehensively. In this paper, we are driven to offer a straightforward yet
in-depth understanding of RoPE extensions from an attention perspective and on
two benchmarking tasks. A broad array of experiments reveals several valuable
findings: 1) Maintaining attention patterns to those at the pretrained length
improves extrapolation; 2) Large attention uncertainty leads to retrieval
errors; 3) Using longer continual pretraining lengths for RoPE extensions could
reduce attention uncertainty and significantly enhance extrapolation."
Design Optimization of NOMA Aided Multi-STAR-RIS for Indoor Environments - A Convex Approximation Imitated Reinforcement Learning Approach,https://arxiv.org/abs/2406.13280,2024-06-19,2024-06-21,0.0,0.0,"Non-orthogonal multiple access (NOMA) enables multiple users to share the
same frequency band, and simultaneously transmitting and reflecting
reconfigurable intelligent surface (STAR-RIS) provides 360-degree full-space
coverage, optimizing both transmission and reflection for improved network
performance and dynamic control of the indoor environment. However, deploying
STAR-RIS indoors presents challenges in interference mitigation, power
consumption, and real-time configuration. In this work, a novel network
architecture utilizing multiple access points (APs), STAR-RISs, and NOMA is
proposed for indoor communication. To address these, we formulate an
optimization problem involving user assignment, access point (AP) beamforming,
and STAR-RIS phase control. A decomposition approach is used to solve the
complex problem efficiently, employing a many-to-one matching algorithm for
user-AP assignment and K-means clustering for resource management.
Additionally, multi-agent deep reinforcement learning (MADRL) is leveraged to
optimize the control of the STAR-RIS. Within the proposed MADRL framework, a
novel approach is introduced in which each decision variable acts as an
independent agent, enabling collaborative learning and decision making. The
MADRL framework is enhanced by incorporating convex approximation (CA), which
accelerates policy learning through suboptimal solutions from successive convex
approximation (SCA), leading to faster adaptation and convergence. Simulations
demonstrate significant improvements in network utility compared to baseline
approaches."
In-Context Learning on a Budget - A Case Study in Named Entity Recognition,https://arxiv.org/abs/2406.13274,2024-06-19,2024-06-21,0.0,0.0,"Few shot in-context learning (ICL) typically assumes access to large
annotated training sets. However, in many real world scenarios, such as domain
adaptation, there is only a limited budget to annotate a small number of
samples, with the goal of maximizing downstream performance. We study various
methods for selecting samples to annotate within a predefined budget,
specifically focusing on the named entity recognition (NER) task, which has
real-world applications, is expensive to annotate, and is relatively less
studied in ICL setups. Across different models and datasets, we find that a
relatively small pool of annotated samples can achieve results comparable to
using the entire training set. Moreover, we discover that random selection of
samples for annotation yields surprisingly good performance. Finally, we
observe that a diverse annotation pool is correlated with improved performance.
We hope that future work adopts our realistic paradigm which takes annotation
budget into account."
Enhancing Automated Audio Captioning via Large Language Models with Optimized Audio Encoding,https://arxiv.org/abs/2406.13275,2024-06-19,2024-06-21,0.0,0.0,"Automated audio captioning (AAC) is an audio-to-text task to describe audio
contents in natural language. Recently, the advancements in large language
models (LLMs), with improvements in training approaches for audio encoders,
have opened up possibilities for improving AAC. Thus, we explore enhancing AAC
from three aspects: 1) a pre-trained audio encoder via consistent ensemble
distillation (CED) is used to improve the effectivity of acoustic tokens, with
a querying transformer (Q-Former) bridging the modality gap to LLM and compress
acoustic tokens; 2) we investigate the advantages of using a Llama 2 with 7B
parameters as the decoder; 3) another pre-trained LLM corrects text errors
caused by insufficient training data and annotation ambiguities. Both the audio
encoder and text decoder are optimized by low-rank adaptation (LoRA).
Experiments show that each of these enhancements is effective. Our method
obtains a 33.0 SPIDEr-FL score, outperforming the winner of DCASE 2023 Task 6A."
Investigating Low-Cost LLM Annotation for~Spoken Dialogue Understanding Datasets,https://arxiv.org/abs/2406.13269,2024-06-19,2024-06-21,0.0,0.0,"In spoken Task-Oriented Dialogue (TOD) systems, the choice of the semantic
representation describing the users' requests is key to a smooth interaction.
Indeed, the system uses this representation to reason over a database and its
domain knowledge to choose its next action. The dialogue course thus depends on
the information provided by this semantic representation. While textual
datasets provide fine-grained semantic representations, spoken dialogue
datasets fall behind. This paper provides insights into automatic enhancement
of spoken dialogue datasets' semantic representations. Our contributions are
three fold: (1) assess the relevance of Large Language Model fine-tuning, (2)
evaluate the knowledge captured by the produced annotations and (3) highlight
semi-automatic annotation implications."
Molecule Graph Networks with Many-body Equivariant Interactions,https://arxiv.org/abs/2406.13265,2024-06-19,2024-06-21,0.0,0.0,"Message passing neural networks have demonstrated significant efficacy in
predicting molecular interactions. Introducing equivariant vectorial
representations augments expressivity by capturing geometric data symmetries,
thereby improving model accuracy. However, two-body bond vectors in opposition
may cancel each other out during message passing, leading to the loss of
directional information on their shared node. In this study, we develop
Equivariant N-body Interaction Networks (ENINet) that explicitly integrates
equivariant many-body interactions to preserve directional information in the
message passing scheme. Experiments indicate that integrating many-body
equivariant representations enhances prediction accuracy across diverse scalar
and tensorial quantum chemical properties. Ablation studies show an average
performance improvement of 7.9% across 11 out of 12 properties in QM9, 27.9% in
forces in MD17, and 11.3% in polarizabilities (CCSD) in QM7b."
Do Multimodal Foundation Models Understand Enterprise Workflows? A Benchmark for Business Process Management Tasks,https://arxiv.org/abs/2406.13264,2024-06-19,2024-06-21,0.0,0.0,"Existing ML benchmarks lack the depth and diversity of annotations needed for
evaluating models on business process management (BPM) tasks. BPM is the
practice of documenting, measuring, improving, and automating enterprise
workflows. However, research has focused almost exclusively on one task - full
end-to-end automation using agents based on multimodal foundation models (FMs)
like GPT-4. This focus on automation ignores the reality of how most BPM tools
are applied today - simply documenting the relevant workflow takes 60% of the
time of the typical process optimization project. To address this gap we
present WONDERBREAD, the first benchmark for evaluating multimodal FMs on BPM
tasks beyond automation. Our contributions are: (1) a dataset containing 2928
documented workflow demonstrations; (2) 6 novel BPM tasks sourced from
real-world applications ranging from workflow documentation to knowledge
transfer to process improvement; and (3) an automated evaluation harness. Our
benchmark shows that while state-of-the-art FMs can automatically generate
documentation (e.g. recalling 88% of the steps taken in a video demonstration
of a workflow), they struggle to re-apply that knowledge towards finer-grained
validation of workflow completion (F1 < 0.3). We hope WONDERBREAD encourages
the development of more ""human-centered"" AI tooling for enterprise applications
and furthers the exploration of multimodal FMs for the broader universe of BPM
tasks. We publish our dataset and experiments here:
https://github.com/HazyResearch/wonderbread"
Machine Learning Applications of Quantum Computing - A Review,https://arxiv.org/abs/2406.13262,2024-06-19,2024-06-21,0.0,0.0,"At the intersection of quantum computing and machine learning, this review
paper explores the transformative impact these technologies are having on the
capabilities of data processing and analysis, far surpassing the bounds of
traditional computational methods. Drawing upon an in-depth analysis of 32
seminal papers, this review delves into the interplay between quantum computing
and machine learning, focusing on transcending the limitations of classical
computing in advanced data processing and applications. This review emphasizes
the potential of quantum-enhanced methods in enhancing cybersecurity, a
critical sector that stands to benefit significantly from these advancements.
The literature review, primarily leveraging Science Direct as an academic
database, delves into the transformative effects of quantum technologies on
machine learning, drawing insights from a diverse collection of studies and
scholarly articles. While the focus is primarily on the growing significance of
quantum computing in cybersecurity, the review also acknowledges the promising
implications for other sectors as the field matures. Our systematic approach
categorizes sources based on quantum machine learning algorithms, applications,
challenges, and potential future developments, uncovering that quantum
computing is increasingly being implemented in practical machine learning
scenarios. The review highlights advancements in quantum-enhanced machine
learning algorithms and their potential applications in sectors such as
cybersecurity, emphasizing the need for industry-specific solutions while
considering ethical and security concerns. By presenting an overview of the
current state and projecting future directions, the paper sets a foundation for
ongoing research and strategic advancement in quantum machine learning."
BeHonest - Benchmarking Honesty of Large Language Models,https://arxiv.org/abs/2406.13261,2024-06-19,2024-06-21,0.0,0.0,"Previous works on Large Language Models (LLMs) have mainly focused on
evaluating their helpfulness or harmlessness. However, honesty, another crucial
alignment criterion, has received relatively less attention. Dishonest
behaviors in LLMs, such as spreading misinformation and defrauding users,
present severe risks that intensify as these models approach superintelligent
levels. Enhancing honesty in LLMs addresses critical limitations and helps
uncover latent capabilities that are not readily expressed. This underscores
the urgent need for reliable methods and benchmarks to effectively ensure and
evaluate the honesty of LLMs.
  In this paper, we introduce BeHonest, a pioneering benchmark specifically
designed to assess honesty in LLMs comprehensively. BeHonest evaluates three
essential aspects of honesty: awareness of knowledge boundaries, avoidance of
deceit, and consistency in responses. Building on this foundation, we designed
10 scenarios to evaluate and analyze 9 popular LLMs on the market, including
both closed-source and open-source models from different model families with
varied model sizes. Our findings indicate that there is still significant room
for improvement in the honesty of LLMs. We encourage the AI community to
prioritize honesty alignment in these models, which can harness their full
potential to benefit society while preventing them from causing harm through
deception or inconsistency. Our benchmark and code can be found at:
\url{https://github.com/GAIR-NLP/BeHonest}."
Reasoning with trees - interpreting CNNs using hierarchies,https://arxiv.org/abs/2406.13257,2024-06-19,2024-06-21,0.0,0.0,"Challenges persist in providing interpretable explanations for neural network
reasoning in explainable AI (xAI). Existing methods like Integrated Gradients
produce noisy maps, and LIME, while intuitive, may deviate from the model's
reasoning. We introduce a framework that uses hierarchical segmentation
techniques for faithful and interpretable explanations of Convolutional Neural
Networks (CNNs). Our method constructs model-based hierarchical segmentations
that maintain the model's reasoning fidelity and allows both human-centric and
model-centric segmentation. This approach offers multiscale explanations,
aiding bias identification and enhancing understanding of neural network
decision-making. Experiments show that our framework, xAiTrees, delivers highly
interpretable and faithful model explanations, not only surpassing traditional
xAI methods but shedding new light on a novel approach to enhancing xAI
interpretability. Code at: https://github.com/CarolMazini/reasoning_with_trees ."
LangTopo - Aligning Language Descriptions of Graphs with Tokenized Topological Modeling,https://arxiv.org/abs/2406.13250,2024-06-19,2024-06-21,0.0,0.0,"Recently, large language models (LLMs) have been widely researched in the
field of graph machine learning due to their outstanding abilities in language
comprehension and learning. However, the significant gap between natural
language tasks and topological structure modeling poses a nonnegligible
challenge. Specifically, since natural language descriptions are not sufficient
for LLMs to understand and process graph-structured data, fine-tuned LLMs
perform even worse than some traditional GNN models on graph tasks, lacking
inherent modeling capabilities for graph structures. Existing research overly
emphasizes LLMs' understanding of semantic information captured by external
models, while inadequately exploring graph topological structure modeling,
thereby overlooking the genuine capabilities that LLMs lack. Consequently, in
this paper, we introduce a new framework, LangTopo, which aligns graph
structure modeling with natural language understanding at the token level.
LangTopo quantifies the graph structure modeling capabilities of GNNs and LLMs
by constructing a codebook for the graph modality and performs consistency
maximization. This process aligns the text description of LLM with the
topological modeling of GNN, allowing LLM to learn the ability of GNN to
capture graph structures, enabling LLM to handle graph-structured data
independently. We demonstrate the effectiveness of our proposed method on
multiple datasets."
R^2AG - Incorporating Retrieval Information into Retrieval Augmented Generation,https://arxiv.org/abs/2406.13249,2024-06-19,2024-06-21,0.0,0.0,"Retrieval augmented generation (RAG) has been applied in many scenarios to
augment large language models (LLMs) with external documents provided by
retrievers. However, a semantic gap exists between LLMs and retrievers due to
differences in their training objectives and architectures. This misalignment
forces LLMs to passively accept the documents provided by the retrievers,
leading to incomprehension in the generation process, where the LLMs are
burdened with the task of distinguishing these documents using their inherent
knowledge. This paper proposes R$^2$AG, a novel enhanced RAG framework to fill
this gap by incorporating Retrieval information into Retrieval Augmented
Generation. Specifically, R$^2$AG utilizes the nuanced features from the
retrievers and employs a R$^2$-Former to capture retrieval information. Then, a
retrieval-aware prompting strategy is designed to integrate retrieval
information into LLMs' generation. Notably, R$^2$AG suits low-source scenarios
where LLMs and retrievers are frozen. Extensive experiments across five
datasets validate the effectiveness, robustness, and efficiency of R$^2$AG. Our
analysis reveals that retrieval information serves as an anchor to aid LLMs in
the generation process, thereby filling the semantic gap."
GSR-BENCH - A Benchmark for Grounded Spatial Reasoning Evaluation via Multimodal LLMs,https://arxiv.org/abs/2406.13246,2024-06-19,2024-06-21,0.0,0.0,"The ability to understand and reason about spatial relationships between
objects in images is an important component of visual reasoning. This skill
rests on the ability to recognize and localize objects of interest and
determine their spatial relation. Early vision and language models (VLMs) have
been shown to struggle to recognize spatial relations. We extend the previously
released What'sUp dataset and propose a novel comprehensive evaluation for
spatial relationship understanding that highlights the strengths and weaknesses
of 27 different models. In addition to the VLMs evaluated in What'sUp, our
extensive evaluation encompasses 3 classes of Multimodal LLMs (MLLMs) that vary
in their parameter sizes (ranging from 7B to 110B), training/instruction-tuning
methods, and visual resolution to benchmark their performances and scrutinize
the scaling laws in this task."
Data Contamination Can Cross Language Barriers,https://arxiv.org/abs/2406.13236,2024-06-19,2024-06-21,0.0,0.0,"The opacity in developing large language models (LLMs) is raising growing
concerns about the potential contamination of public benchmarks in the
pre-training data. Existing contamination detection methods are typically based
on the text overlap between training and evaluation data, which can be too
superficial to reflect deeper forms of contamination. In this paper, we first
present a cross-lingual form of contamination that inflates LLMs' performance
while evading current detection methods, deliberately injected by overfitting
LLMs on the translated versions of benchmark test sets. Then, we propose
generalization-based approaches to unmask such deeply concealed contamination.
Specifically, we examine the LLM's performance change after modifying the
original benchmark by replacing the false answer choices with correct ones from
other questions. Contaminated models can hardly generalize to such easier
situations, where the false choices can be \emph{not even wrong}, as all
choices are correct in their memorization. Experimental results demonstrate
that cross-lingual contamination can easily fool existing detection methods,
but not ours. In addition, we discuss the potential utilization of
cross-lingual contamination in interpreting LLMs' working mechanisms and in
post-training LLMs for enhanced multilingual capabilities. The code and dataset
we use can be obtained from \url{https://github.com/ShangDataLab/Deep-Contam}."
Enhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning,https://arxiv.org/abs/2406.13235,2024-06-19,2024-06-21,0.0,0.0,"Large Language Models (LLMs) are increasingly prominent in the recommendation
systems domain. Existing studies usually utilize in-context learning or
supervised fine-tuning on task-specific data to align LLMs into
recommendations. However, the substantial bias in semantic spaces between
language processing tasks and recommendation tasks poses a nonnegligible
challenge. Specifically, without the adequate capturing ability of
collaborative information, existing modeling paradigms struggle to capture
behavior patterns within community groups, leading to LLMs' ineffectiveness in
discerning implicit interaction semantic in recommendation scenarios. To
address this, we consider enhancing the learning capability of language
model-driven recommendation models for structured data, specifically by
utilizing interaction graphs rich in collaborative semantics. We propose a
Graph-Aware Learning for Language Model-Driven Recommendations (GAL-Rec).
GAL-Rec enhances the understanding of user-item collaborative semantics by
imitating the intent of Graph Neural Networks (GNNs) to aggregate multi-hop
information, thereby fully exploiting the substantial learning capacity of LLMs
to independently address the complex graphs in the recommendation system.
Sufficient experimental results on three real-world datasets demonstrate that
GAL-Rec significantly enhances the comprehension of collaborative semantics,
and improves recommendation performance."
AdaMoE - Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models,https://arxiv.org/abs/2406.13233,2024-06-19,2024-06-21,0.0,0.0,"Mixture of experts (MoE) has become the standard for constructing
production-level large language models (LLMs) due to its promise to boost model
capacity without causing significant overheads. Nevertheless, existing MoE
methods usually enforce a constant top-k routing for all tokens, which is
arguably restrictive because various tokens (e.g., ""<EOS>"" vs. ""apple"") may
require various numbers of experts for feature abstraction. Lifting such a
constraint can help make the most of limited resources and unleash the
potential of the model for downstream tasks. In this sense, we introduce AdaMoE
to realize token-adaptive routing for MoE, where different tokens are permitted
to select a various number of experts. AdaMoE makes minimal modifications to
the vanilla MoE with top-k routing -- it simply introduces a fixed number of
null experts, which do not consume any FLOPs, to the expert set and increases
the value of k. AdaMoE does not force each token to occupy a fixed number of
null experts but ensures the average usage of the null experts with a
load-balancing loss, leading to an adaptive number of null/true experts used by
each token. AdaMoE exhibits a strong resemblance to MoEs with expert choice
routing while allowing for trivial auto-regressive modeling. AdaMoE is easy to
implement and can be effectively applied to pre-trained (MoE-)LLMs. Extensive
studies show that AdaMoE can reduce average expert load (FLOPs) while achieving
superior performance. For example, on the ARC-C dataset, applying our method to
fine-tuning Mixtral-8x7B can reduce FLOPs by 14.5% while increasing accuracy by
1.69%."
Towards Robust Evaluation - A Comprehensive Taxonomy of Datasets and Metrics for Open Domain Question Answering in the Era of Large Language Models,https://arxiv.org/abs/2406.13232,2024-06-19,2024-06-21,0.0,0.0,"Open Domain Question Answering (ODQA) within natural language processing
involves building systems that answer factual questions using large-scale
knowledge corpora. Recent advances stem from the confluence of several factors,
such as large-scale training datasets, deep learning techniques, and the rise
of large language models. High-quality datasets are used to train models on
realistic scenarios and enable the evaluation of the system on potentially
unseen data. Standardized metrics facilitate comparisons between different ODQA
systems, allowing researchers to objectively track advancements in the field.
Our study presents a thorough examination of the current landscape of ODQA
benchmarking by reviewing 52 datasets and 20 evaluation techniques across
textual and multimodal modalities. We introduce a novel taxonomy for ODQA
datasets that incorporates both the modality and difficulty of the question
types. Additionally, we present a structured organization of ODQA evaluation
metrics along with a critical analysis of their inherent trade-offs. Our study
aims to empower researchers by providing a framework for the robust evaluation
of modern question-answering systems. We conclude by identifying the current
challenges and outlining promising avenues for future research and development."
Enhancing Language Model Factuality via Activation-Based Confidence Calibration and Guided Decoding,https://arxiv.org/abs/2406.13230,2024-06-19,2024-06-21,0.0,0.0,"Calibrating language models (LMs) aligns their generation confidence with the
actual likelihood of answer correctness, which can inform users about LMs'
reliability and mitigate hallucinated content. However, prior calibration
methods, such as self-consistency-based and logit-based approaches, are either
limited in inference-time efficiency or fall short of providing informative
signals. Moreover, simply filtering out low-confidence responses reduces the
LM's helpfulness when the answers are correct. Therefore, effectively using
calibration techniques to enhance an LM's factuality remains an unsolved
challenge. In this paper, we first propose an activation-based calibration
method, ActCab, which trains a linear layer on top of the LM's last-layer
activations that can better capture the representations of knowledge. Built on
top of ActCab, we further propose CoDec, a confidence-guided decoding strategy
to elicit truthful answers with high confidence from LMs. By evaluating on five
popular QA benchmarks, ActCab achieves superior calibration performance than
all competitive baselines, e.g., by reducing the average expected calibration
error (ECE) score by up to 39%. Further experiments on CoDec show consistent
improvements in several LMs' factuality on challenging QA datasets, such as
TruthfulQA, highlighting the value of confidence signals in enhancing
factuality."
Probing the Emergence of Cross-lingual Alignment during LLM Training,https://arxiv.org/abs/2406.13229,2024-06-19,2024-06-21,0.0,0.0,"Multilingual Large Language Models (LLMs) achieve remarkable levels of
zero-shot cross-lingual transfer performance. We speculate that this is
predicated on their ability to align languages without explicit supervision
from parallel sentences. While representations of translationally equivalent
sentences in different languages are known to be similar after convergence,
however, it remains unclear how such cross-lingual alignment emerges during
pre-training of LLMs. Our study leverages intrinsic probing techniques, which
identify which subsets of neurons encode linguistic features, to correlate the
degree of cross-lingual neuron overlap with the zero-shot cross-lingual
transfer performance for a given model. In particular, we rely on checkpoints
of BLOOM, a multilingual autoregressive LLM, across different training steps
and model scales. We observe a high correlation between neuron overlap and
downstream performance, which supports our hypothesis on the conditions leading
to effective cross-lingual transfer. Interestingly, we also detect a
degradation of both implicit alignment and multilingual abilities in certain
phases of the pre-training process, providing new insights into the
multilingual pretraining dynamics."
AGSOA -Graph Neural Network Targeted Attack Based on Average Gradient and Structure Optimization,https://arxiv.org/abs/2406.13228,2024-06-19,2024-06-21,0.0,0.0,"Graph Neural Networks(GNNs) are vulnerable to adversarial attack that cause
performance degradation by adding small perturbations to the graph.
Gradient-based attacks are one of the most commonly used methods and have
achieved good performance in many attack scenarios. However, current gradient
attacks face the problems of easy to fall into local optima and poor attack
invisibility. Specifically, most gradient attacks use greedy strategies to
generate perturbations, which tend to fall into local optima leading to
underperformance of the attack. In addition, many attacks only consider the
effectiveness of the attack and ignore the invisibility of the attack, making
the attacks easily exposed leading to failure. To address the above problems,
this paper proposes an attack on GNNs, called AGSOA, which consists of an
average gradient calculation and a structre optimization module. In the average
gradient calculation module, we compute the average of the gradient information
over all moments to guide the attack to generate perturbed edges, which
stabilizes the direction of the attack update and gets rid of undesirable local
maxima. In the structure optimization module, we calculate the similarity and
homogeneity of the target node's with other nodes to adjust the graph structure
so as to improve the invisibility and transferability of the attack. Extensive
experiments on three commonly used datasets show that AGSOA improves the
misclassification rate by 2$\%$-8$\%$ compared to other state-of-the-art
models."
Communication-Efficient Federated Knowledge Graph Embedding with Entity-Wise Top-K Sparsification,https://arxiv.org/abs/2406.13225,2024-06-19,2024-06-21,0.0,0.0,"Federated Knowledge Graphs Embedding learning (FKGE) encounters challenges in
communication efficiency stemming from the considerable size of parameters and
extensive communication rounds. However, existing FKGE methods only focus on
reducing communication rounds by conducting multiple rounds of local training
in each communication round, and ignore reducing the size of parameters
transmitted within each communication round. To tackle the problem, we first
find that universal reduction in embedding precision across all entities during
compression can significantly impede convergence speed, underscoring the
importance of maintaining embedding precision. We then propose bidirectional
communication-efficient FedS based on Entity-Wise Top-K Sparsification
strategy. During upload, clients dynamically identify and upload only the Top-K
entity embeddings with the greater changes to the server. During download, the
server first performs personalized embedding aggregation for each client. It
then identifies and transmits the Top-K aggregated embeddings to each client.
Besides, an Intermittent Synchronization Mechanism is used by FedS to mitigate
negative effect of embedding inconsistency among shared entities of clients
caused by heterogeneity of Federated Knowledge Graph. Extensive experiments
across three datasets showcase that FedS significantly enhances communication
efficiency with negligible (even no) performance degradation."
MC-MKE - A Fine-Grained Multimodal Knowledge Editing Benchmark Emphasizing Modality Consistency,https://arxiv.org/abs/2406.13219,2024-06-19,2024-06-21,0.0,0.0,"Multimodal large language models (MLLMs) are prone to non-factual or outdated
knowledge issues, which can manifest as misreading and misrecognition errors
due to the complexity of multimodal knowledge. Previous benchmarks have not
systematically analyzed the performance of editing methods in correcting these
two error types. To better represent and correct these errors, we decompose
multimodal knowledge into its visual and textual components. Different error
types correspond to different editing formats, which edits distinct part of the
multimodal knowledge. We present MC-MKE, a fine-grained Multimodal Knowledge
Editing benchmark emphasizing Modality Consistency. Our benchmark facilitates
independent correction of misreading and misrecognition errors by editing the
corresponding knowledge component. We evaluate three multimodal knowledge
editing methods on MC-MKE, revealing their limitations, particularly in terms
of modality consistency. Our work highlights the challenges posed by multimodal
knowledge editing and motivates further research in developing effective
techniques for this task."
Bridging Law and Data - Augmenting Reasoning via a Semi-Structured Dataset with IRAC methodology,https://arxiv.org/abs/2406.13217,2024-06-19,2024-06-21,0.0,0.0,"The effectiveness of Large Language Models (LLMs) in legal reasoning is often
limited due to the unique legal terminologies and the necessity for highly
specialized knowledge. These limitations highlight the need for high-quality
data tailored for complex legal reasoning tasks. This paper introduces
LEGALSEMI, a benchmark specifically curated for legal scenario analysis.
LEGALSEMI comprises 54 legal scenarios, each rigorously annotated by legal
experts, based on the comprehensive IRAC (Issue, Rule, Application, Conclusion)
framework. In addition, LEGALSEMI is accompanied by a structured knowledge
graph (SKG). A series of experiments were conducted to assess the usefulness of
LEGALSEMI for IRAC analysis. The experimental results demonstrate the
effectiveness of incorporating the SKG for issue identification, rule
retrieval, application and conclusion generation using four different LLMs.
LEGALSEMI will be publicly available upon acceptance of this paper."
Combining Optimal Transport and Embedding-Based Approaches for More Expressiveness in Unsupervised Graph Alignment,https://arxiv.org/abs/2406.13216,2024-06-19,2024-06-21,0.0,0.0,"Unsupervised graph alignment finds the one-to-one node correspondence between
a pair of attributed graphs by only exploiting graph structure and node
features. One category of existing works first computes the node representation
and then matches nodes with close embeddings, which is intuitive but lacks a
clear objective tailored for graph alignment in the unsupervised setting. The
other category reduces the problem to optimal transport (OT) via
Gromov-Wasserstein (GW) learning with a well-defined objective but leaves a
large room for exploring the design of transport cost. We propose a principled
approach to combine their advantages motivated by theoretical analysis of model
expressiveness. By noticing the limitation of discriminative power in
separating matched and unmatched node pairs, we improve the cost design of GW
learning with feature transformation, which enables feature interaction across
dimensions. Besides, we propose a simple yet effective embedding-based
heuristic inspired by the Weisfeiler-Lehman test and add its prior knowledge to
OT for more expressiveness when handling non-Euclidean data. Moreover, we are
the first to guarantee the one-to-one matching constraint by reducing the
problem to maximum weight matching. The algorithm design effectively combines
our OT and embedding-based predictions via stacking, an ensemble learning
strategy. We propose a model framework named \texttt{CombAlign} integrating all
the above modules to refine node alignment progressively. Through extensive
experiments, we demonstrate significant improvements in alignment accuracy
compared to state-of-the-art approaches and validate the effectiveness of the
proposed modules."
Neural Residual Diffusion Models for Deep Scalable Vision Generation,https://arxiv.org/abs/2406.13215,2024-06-19,2024-06-21,0.0,0.0,"The most advanced diffusion models have recently adopted increasingly deep
stacked networks (e.g., U-Net or Transformer) to promote the generative
emergence capabilities of vision generation models similar to large language
models (LLMs). However, progressively deeper stacked networks will intuitively
cause numerical propagation errors and reduce noisy prediction capabilities on
generative data, which hinders massively deep scalable training of vision
generation models. In this paper, we first uncover the nature that neural
networks being able to effectively perform generative denoising lies in the
fact that the intrinsic residual unit has consistent dynamic property with the
input signal's reverse diffusion process, thus supporting excellent generative
abilities. Afterwards, we stand on the shoulders of two common types of deep
stacked networks to propose a unified and massively scalable Neural Residual
Diffusion Models framework (Neural-RDM for short), which is a simple yet
meaningful change to the common architecture of deep generative networks by
introducing a series of learnable gated residual parameters that conform to the
generative dynamics. Experimental results on various generative tasks show that
the proposed neural residual models obtain state-of-the-art scores on image's
and video's generative benchmarks. Rigorous theoretical proofs and extensive
experiments also demonstrate the advantages of this simple gated residual
mechanism consistent with dynamic modeling in improving the fidelity and
consistency of generated content and supporting large-scale scalable training.
Code is available at https://github.com/Anonymous/Neural-RDM."
Self-Explainable Temporal Graph Networks based on Graph Information Bottleneck,https://arxiv.org/abs/2406.13214,2024-06-19,2024-06-21,0.0,0.0,"Temporal Graph Neural Networks (TGNN) have the ability to capture both the
graph topology and dynamic dependencies of interactions within a graph over
time. There has been a growing need to explain the predictions of TGNN models
due to the difficulty in identifying how past events influence their
predictions. Since the explanation model for a static graph cannot be readily
applied to temporal graphs due to its inability to capture temporal
dependencies, recent studies proposed explanation models for temporal graphs.
However, existing explanation models for temporal graphs rely on post-hoc
explanations, requiring separate models for prediction and explanation, which
is limited in two aspects: efficiency and accuracy of explanation. In this
work, we propose a novel built-in explanation framework for temporal graphs,
called Self-Explainable Temporal Graph Networks based on Graph Information
Bottleneck (TGIB). TGIB provides explanations for event occurrences by
introducing stochasticity in each temporal event based on the Information
Bottleneck theory. Experimental results demonstrate the superiority of TGIB in
terms of both the link prediction performance and explainability compared to
state-of-the-art methods. This is the first work that simultaneously performs
prediction and explanation for temporal graphs in an end-to-end manner."
Multi-Meta-RAG - Improving RAG for Multi-Hop Queries using Database Filtering with LLM-Extracted Metadata,https://arxiv.org/abs/2406.13213,2024-06-19,2024-06-21,0.0,0.0,"The retrieval-augmented generation (RAG) enables retrieval of relevant
information from an external knowledge source and allows large language models
(LLMs) to answer queries over previously unseen document collections. However,
it was demonstrated that traditional RAG applications perform poorly in
answering multi-hop questions, which require retrieving and reasoning over
multiple elements of supporting evidence. We introduce a new method called
Multi-Meta-RAG, which uses database filtering with LLM-extracted metadata to
improve the RAG selection of the relevant documents from various sources,
relevant to the question. While database filtering is specific to a set of
questions from a particular domain and format, we found out that Multi-Meta-RAG
greatly improves the results on the MultiHop-RAG benchmark. The code is
available at https://github.com/mxpoliakov/Multi-Meta-RAG."
Toward Structure Fairness in Dynamic Graph Embedding - A Trend-aware Dual Debiasing Approach,https://arxiv.org/abs/2406.13201,2024-06-19,2024-06-21,0.0,0.0,"Recent studies successfully learned static graph embeddings that are
structurally fair by preventing the effectiveness disparity of high- and
low-degree vertex groups in downstream graph mining tasks. However, achieving
structure fairness in dynamic graph embedding remains an open problem.
Neglecting degree changes in dynamic graphs will significantly impair embedding
effectiveness without notably improving structure fairness. This is because the
embedding performance of high-degree and low-to-high-degree vertices will
significantly drop close to the generally poorer embedding performance of most
slightly changed vertices in the long-tail part of the power-law distribution.
We first identify biased structural evolutions in a dynamic graph based on the
evolving trend of vertex degree and then propose FairDGE, the first
structurally Fair Dynamic Graph Embedding algorithm. FairDGE learns biased
structural evolutions by jointly embedding the connection changes among
vertices and the long-short-term evolutionary trend of vertex degrees.
Furthermore, a novel dual debiasing approach is devised to encode fair
embeddings contrastively, customizing debiasing strategies for different biased
structural evolutions. This innovative debiasing strategy breaks the
effectiveness bottleneck of embeddings without notable fairness loss. Extensive
experiments demonstrate that FairDGE achieves simultaneous improvement in the
effectiveness and fairness of embeddings."
RobGC - Towards Robust Graph Condensation,https://arxiv.org/abs/2406.13200,2024-06-19,2024-06-21,0.0,0.0,"Graph neural networks (GNNs) have attracted widespread attention for their
impressive capability of graph representation learning. However, the increasing
prevalence of large-scale graphs presents a significant challenge for GNN
training due to their computational demands, limiting the applicability of GNNs
in various scenarios. In response to this challenge, graph condensation (GC) is
proposed as a promising acceleration solution, focusing on generating an
informative compact graph that enables efficient training of GNNs while
retaining performance. Despite the potential to accelerate GNN training,
existing GC methods overlook the quality of large training graphs during both
the training and inference stages. They indiscriminately emulate the training
graph distributions, making the condensed graphs susceptible to noises within
the training graph and significantly impeding the application of GC in
intricate real-world scenarios. To address this issue, we propose robust graph
condensation (RobGC), a plug-and-play approach for GC to extend the robustness
and applicability of condensed graphs in noisy graph structure environments.
Specifically, RobGC leverages the condensed graph as a feedback signal to guide
the denoising process on the original training graph. A label propagation-based
alternating optimization strategy is in place for the condensation and
denoising processes, contributing to the mutual purification of the condensed
graph and training graph. Additionally, as a GC method designed for inductive
graph inference, RobGC facilitates test-time graph denoising by leveraging the
noise-free condensed graph to calibrate the structure of the test graph.
Extensive experiments show that RobGC is compatible with various GC methods,
significantly boosting their robustness under different types and levels of
graph structural noises."
Learning Translations via Matrix Completion,https://arxiv.org/abs/2406.13195,2024-06-19,2024-06-21,0.0,0.0,"Bilingual Lexicon Induction is the task of learning word translations without
bilingual parallel corpora. We model this task as a matrix completion problem,
and present an effective and extendable framework for completing the matrix.
This method harnesses diverse bilingual and monolingual signals, each of which
may be incomplete or noisy. Our model achieves state-of-the-art performance for
both high and low resource languages."
PRESTO - Progressive Pretraining Enhances Synthetic Chemistry Outcomes,https://arxiv.org/abs/2406.13193,2024-06-19,2024-06-21,0.0,0.0,"Multimodal Large Language Models (MLLMs) have seen growing adoption across
various scientific disciplines. These advancements encourage the investigation
of molecule-text modeling within synthetic chemistry, a field dedicated to
designing and conducting chemical reactions to synthesize new compounds with
desired properties and applications. Current approaches, however, often neglect
the critical role of multiple molecule graph interaction in understanding
chemical reactions, leading to suboptimal performance in synthetic chemistry
tasks. This study introduces PRESTO(Progressive Pretraining Enhances Synthetic
Chemistry Outcomes), a new framework that bridges the molecule-text modality
gap by integrating a comprehensive benchmark of pretraining strategies and
dataset configurations. It progressively improves multimodal LLMs through
cross-modal alignment and multi-graph understanding. Our extensive experiments
demonstrate that PRESTO offers competitive results in downstream synthetic
chemistry tasks. The code can be found at https://github.com/IDEA-XL/PRESTO."
Synthetic Context Generation for Question Generation,https://arxiv.org/abs/2406.13188,2024-06-19,2024-06-21,0.0,0.0,"Despite rapid advancements in large language models (LLMs), QG remains a
challenging problem due to its complicated process, open-ended nature, and the
diverse settings in which question generation occurs. A common approach to
address these challenges involves fine-tuning smaller, custom models using
datasets containing background context, question, and answer. However,
obtaining suitable domain-specific datasets with appropriate context is often
more difficult than acquiring question-answer pairs. In this paper, we
investigate training QG models using synthetic contexts generated by LLMs from
readily available question-answer pairs. We conduct a comprehensive study to
answer critical research questions related to the performance of models trained
on synthetic contexts and their potential impact on QG research and
applications. Our empirical results reveal: 1) contexts are essential for QG
tasks, even if they are synthetic; 2) fine-tuning smaller language models has
the capability of achieving better performances as compared to prompting larger
language models; and 3) synthetic context and real context could achieve
comparable performances. These findings highlight the effectiveness of
synthetic contexts in QG and paves the way for future advancements in the
field."
Boosting Consistency in Dual Training for Long-Tailed Semi-Supervised Learning,https://arxiv.org/abs/2406.13187,2024-06-19,2024-06-21,0.0,0.0,"While long-tailed semi-supervised learning (LTSSL) has received tremendous
attention in many real-world classification problems, existing LTSSL algorithms
typically assume that the class distributions of labeled and unlabeled data are
almost identical. Those LTSSL algorithms built upon the assumption can severely
suffer when the class distributions of labeled and unlabeled data are
mismatched since they utilize biased pseudo-labels from the model. To alleviate
this problem, we propose a new simple method that can effectively utilize
unlabeled data from unknown class distributions through Boosting cOnsistency in
duAl Training (BOAT). Specifically, we construct the standard and balanced
branch to ensure the performance of the head and tail classes, respectively.
Throughout the training process, the two branches incrementally converge and
interact with each other, eventually resulting in commendable performance
across all classes. Despite its simplicity, we show that BOAT achieves
state-of-the-art performance on a variety of standard LTSSL benchmarks, e.g.,
an averaged 2.7% absolute increase in test accuracy against existing algorithms
when the class distributions of labeled and unlabeled data are mismatched. Even
when the class distributions are identical, BOAT consistently outperforms many
sophisticated LTSSL algorithms. We carry out extensive ablation studies to
tease apart the factors that are the most important to the success of BOAT. The
source code is available at https://github.com/Gank0078/BOAT."
Learnable In-Context Vector for Visual Question Answering,https://arxiv.org/abs/2406.13185,2024-06-19,2024-06-21,0.0,0.0,"As language models continue to scale, Large Language Models (LLMs) have
exhibited emerging capabilities in In-Context Learning (ICL), enabling them to
solve language tasks by prefixing a few in-context demonstrations (ICDs) as
context. Inspired by these advancements, researchers have extended these
techniques to develop Large Multimodal Models (LMMs) with ICL capabilities.
However, applying ICL usually faces two major challenges: 1) using more ICDs
will largely increase the inference time and 2) the performance is sensitive to
the selection of ICDs. These challenges are further exacerbated in LMMs due to
the integration of multiple data types and the combinational complexity of
multimodal ICDs. Recently, to address these challenges, some NLP studies
introduce non-learnable In-Context Vectors (ICVs) which extract useful task
information from ICDs into a single vector and then insert it into the LLM to
help solve the corresponding task. However, although useful in simple NLP
tasks, these non-learnable methods fail to handle complex multimodal tasks like
Visual Question Answering (VQA). In this study, we propose \textbf{Learnable
ICV} (L-ICV) to distill essential task information from demonstrations,
improving ICL performance in LMMs. Experiments show that L-ICV can
significantly reduce computational costs while enhancing accuracy in VQA tasks
compared to traditional ICL and other non-learnable ICV methods."
Communication-Efficient and Privacy-Preserving Decentralized Meta-Learning,https://arxiv.org/abs/2406.13183,2024-06-19,2024-06-21,0.0,0.0,"Distributed learning, which does not require gathering training data in a
central location, has become increasingly important in the big-data era. In
particular, random-walk-based decentralized algorithms are flexible in that
they do not need a central server trusted by all clients and do not require all
clients to be active in all iterations. However, existing distributed learning
algorithms assume that all learning clients share the same task. In this paper,
we consider the more difficult meta-learning setting, in which different
clients perform different (but related) tasks with limited training data. To
reduce communication cost and allow better privacy protection, we propose
LoDMeta (Local Decentralized Meta-learning) with the use of local auxiliary
optimization parameters and random perturbations on the model parameter.
Theoretical results are provided on both convergence and privacy analysis.
Empirical results on a number of few-shot learning data sets demonstrate that
LoDMeta has similar meta-learning accuracy as centralized meta-learning
algorithms, but does not require gathering data from each client and is able to
better protect data privacy for each client."
Locating and Extracting Relational Concepts in Large Language Models,https://arxiv.org/abs/2406.13184,2024-06-19,2024-06-21,0.0,0.0,"Relational concepts are indeed foundational to the structure of knowledge
representation, as they facilitate the association between various entity
concepts, allowing us to express and comprehend complex world knowledge. By
expressing relational concepts in natural language prompts, people can
effortlessly interact with large language models (LLMs) and recall desired
factual knowledge. However, the process of knowledge recall lacks
interpretability, and representations of relational concepts within LLMs remain
unknown to us. In this paper, we identify hidden states that can express entity
and relational concepts through causal mediation analysis in fact recall
processes. Our finding reveals that at the last token position of the input
prompt, there are hidden states that solely express the causal effects of
relational concepts. Based on this finding, we assume that these hidden states
can be treated as relational representations and we can successfully extract
them from LLMs. The experimental results demonstrate high credibility of the
relational representations: they can be flexibly transplanted into other fact
recall processes, and can also be used as robust entity connectors. Moreover,
we also show that the relational representations exhibit significant potential
for controllable fact recall through relation rewriting."
Sparse High Rank Adapters,https://arxiv.org/abs/2406.13175,2024-06-19,2024-06-21,0.0,0.0,"Low Rank Adaptation (LoRA) has gained massive attention in the recent
generative AI research. One of the main advantages of LoRA is its ability to be
fused with pretrained models adding no overhead during inference. However, from
a mobile deployment standpoint, we can either avoid inference overhead in the
fused mode but lose the ability to switch adapters rapidly, or suffer
significant (up to 30% higher) inference latency while enabling rapid switching
in the unfused mode. LoRA also exhibits concept-loss when multiple adapters are
used concurrently. In this paper, we propose Sparse High Rank Adapters (SHiRA),
a new paradigm which incurs no inference overhead, enables rapid switching, and
significantly reduces concept-loss. Specifically, SHiRA can be trained by
directly tuning only 1-2% of the base model weights while leaving others
unchanged. This results in a highly sparse adapter which can be switched
directly in the fused mode. We further provide theoretical and empirical
insights on how high sparsity in SHiRA can aid multi-adapter fusion by reducing
concept loss. Our extensive experiments on LVMs and LLMs demonstrate that
finetuning only a small fraction of the parameters in the base model is
sufficient for many tasks while enabling both rapid switching and multi-adapter
fusion. Finally, we provide a latency- and memory-efficient SHiRA
implementation based on Parameter-Efficient Finetuning (PEFT) Library. This
implementation trains at nearly the same speed as LoRA while consuming lower
peak GPU memory, thus making SHiRA easy to adopt for practical use cases."
Amphista - Accelerate LLM Inference with Bi-directional Multiple Drafting Heads in a Non-autoregressive Style,https://arxiv.org/abs/2406.13170,2024-06-19,2024-06-21,0.0,0.0,"Large Language Models (LLMs) inherently use autoregressive decoding, which
lacks parallelism in inference and results in significantly slow inference
speeds, especially when hardware parallel accelerators and memory bandwidth are
not fully utilized. In this work, we propose Amphista, a speculative decoding
algorithm that adheres to a non-autoregressive decoding paradigm. Owing to the
increased parallelism, our method demonstrates higher efficiency in inference
compared to autoregressive methods. Specifically, Amphista models an
Auto-embedding Block capable of parallel inference, incorporating
bi-directional attention to enable interaction between different drafting
heads. Additionally, Amphista implements Staged Adaptation Layers to facilitate
the transition of semantic information from the base model's autoregressive
inference to the drafting heads' non-autoregressive speculation, thereby
achieving paradigm transformation and feature fusion. We conduct a series of
experiments on a suite of Vicuna models using MT-Bench and Spec-Bench. For the
Vicuna 33B model, Amphista achieves up to 2.75$\times$ and 1.40$\times$
wall-clock acceleration compared to vanilla autoregressive decoding and Medusa,
respectively, while preserving lossless generation quality."
QRMeM - Unleash the Length Limitation through Question then Reflection Memory Mechanism,https://arxiv.org/abs/2406.13167,2024-06-19,2024-06-21,0.0,0.0,"While large language models (LLMs) have made notable advancements in natural
language processing, they continue to struggle with processing extensive text.
Memory mechanism offers a flexible solution for managing long contexts,
utilizing techniques such as compression, summarization, and structuring to
facilitate nuanced and efficient handling of large volumes of text. However,
existing techniques face challenges with static knowledge integration, leading
to insufficient adaptation to task-specific needs and missing
multi-segmentation relationships, which hinders the dynamic reorganization and
logical combination of relevant segments during the response process. To
address these issues, we introduce a novel strategy, Question then Reflection
Memory Mechanism (QRMeM), incorporating a dual-structured memory pool. This
pool synergizes static textual content with structured graph guidance,
fostering a reflective trial-and-error approach for navigating and identifying
relevant segments. Our evaluation across multiple-choice questions (MCQ) and
multi-document question answering (Multi-doc QA) benchmarks showcases QRMeM
enhanced performance compared to existing approaches."
Enhancing supply chain security with automated machine learning,https://arxiv.org/abs/2406.13166,2024-06-19,2024-06-21,0.0,0.0,"This study tackles the complexities of global supply chains, which are
increasingly vulnerable to disruptions caused by port congestion, material
shortages, and inflation. To address these challenges, we explore the
application of machine learning methods, which excel in predicting and
optimizing solutions based on large datasets. Our focus is on enhancing supply
chain security through fraud detection, maintenance prediction, and material
backorder forecasting. We introduce an automated machine learning framework
that streamlines data analysis, model construction, and hyperparameter
optimization for these tasks. By automating these processes, our framework
improves the efficiency and effectiveness of supply chain security measures.
Our research identifies key factors that influence machine learning
performance, including sampling methods, categorical encoding, feature
selection, and hyperparameter optimization. We demonstrate the importance of
considering these factors when applying machine learning to supply chain
challenges. Traditional mathematical programming models often struggle to cope
with the complexity of large-scale supply chain problems. Our study shows that
machine learning methods can provide a viable alternative, particularly when
dealing with extensive datasets and complex patterns. The automated machine
learning framework presented in this study offers a novel approach to supply
chain security, contributing to the existing body of knowledge in the field.
Its comprehensive automation of machine learning processes makes it a valuable
contribution to the domain of supply chain management."
LLMatDesign - Autonomous Materials Discovery with Large Language Models,https://arxiv.org/abs/2406.13163,2024-06-19,2024-06-21,0.0,0.0,"Discovering new materials can have significant scientific and technological
implications but remains a challenging problem today due to the enormity of the
chemical space. Recent advances in machine learning have enabled data-driven
methods to rapidly screen or generate promising materials, but these methods
still depend heavily on very large quantities of training data and often lack
the flexibility and chemical understanding often desired in materials
discovery. We introduce LLMatDesign, a novel language-based framework for
interpretable materials design powered by large language models (LLMs).
LLMatDesign utilizes LLM agents to translate human instructions, apply
modifications to materials, and evaluate outcomes using provided tools. By
incorporating self-reflection on its previous decisions, LLMatDesign adapts
rapidly to new tasks and conditions in a zero-shot manner. A systematic
evaluation of LLMatDesign on several materials design tasks, in silico,
validates LLMatDesign's effectiveness in developing new materials with
user-defined target properties in the small data regime. Our framework
demonstrates the remarkable potential of autonomous LLM-guided materials
discovery in the computational setting and towards self-driving laboratories in
the future."
APPL - A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts,https://arxiv.org/abs/2406.13161,2024-06-19,2024-06-21,0.0,0.0,"Large Language Models (LLMs) have become increasingly capable of handling
diverse tasks with the aid of well-crafted prompts and integration of external
tools, but as task complexity rises, the workflow involving LLMs can be
complicated and thus challenging to implement and maintain. To address this
challenge, we propose APPL, A Prompt Programming Language that acts as a bridge
between computer programs and LLMs, allowing seamless embedding of prompts into
Python functions, and vice versa. APPL provides an intuitive and Python-native
syntax, an efficient parallelized runtime with asynchronous semantics, and a
tracing module supporting effective failure diagnosis and replaying without
extra costs. We demonstrate that APPL programs are intuitive, concise, and
efficient through three representative scenarios: Chain-of-Thought with
self-consistency (CoT-SC), ReAct tool use agent, and multi-agent chat.
Experiments on three parallelizable workflows further show that APPL can
effectively parallelize independent LLM calls, with a significant speedup ratio
that almost matches the estimation."
Convolutional Kolmogorov-Arnold Networks,https://arxiv.org/abs/2406.13155,2024-06-19,2024-06-21,0.0,0.0,"In this paper, we introduce the Convolutional Kolmogorov-Arnold Networks
(Convolutional KANs), an innovative alternative to the standard Convolutional
Neural Networks (CNNs) that have revolutionized the field of computer vision.
We integrate the non-linear activation functions presented in Kolmogorov-Arnold
Networks (KANs) into convolutions to build a new layer. Throughout the paper,
we empirically validate the performance of Convolutional KANs against
traditional architectures across MNIST and Fashion-MNIST benchmarks,
illustrating that this new approach maintains a similar level of accuracy while
using half the amount of parameters. This significant reduction of parameters
opens up a new approach to advance the optimization of neural network
architectures."
Conditional score-based diffusion models for solving inverse problems in mechanics,https://arxiv.org/abs/2406.13154,2024-06-19,2024-06-21,0.0,0.0,"We propose a framework to perform Bayesian inference using conditional
score-based diffusion models to solve a class of inverse problems in mechanics
involving the inference of a specimen's spatially varying material properties
from noisy measurements of its mechanical response to loading. Conditional
score-based diffusion models are generative models that learn to approximate
the score function of a conditional distribution using samples from the joint
distribution. More specifically, the score functions corresponding to multiple
realizations of the measurement are approximated using a single neural network,
the so-called score network, which is subsequently used to sample the posterior
distribution using an appropriate Markov chain Monte Carlo scheme based on
Langevin dynamics. Training the score network only requires simulating the
forward model. Hence, the proposed approach can accommodate black-box forward
models and complex measurement noise. Moreover, once the score network has been
trained, it can be re-used to solve the inverse problem for different
realizations of the measurements. We demonstrate the efficacy of the proposed
approach on a suite of high-dimensional inverse problems in mechanics that
involve inferring heterogeneous material properties from noisy measurements.
Some examples we consider involve synthetic data, while others include data
collected from actual elastography experiments. Further, our applications
demonstrate that the proposed approach can handle different measurement
modalities, complex patterns in the inferred quantities, non-Gaussian and
non-additive noise models, and nonlinear black-box forward models. The results
show that the proposed framework can solve large-scale physics-based inverse
problems efficiently."
von Mises Quasi-Processes for Bayesian Circular Regression,https://arxiv.org/abs/2406.13151,2024-06-19,2024-06-21,0.0,0.0,"The need for regression models to predict circular values arises in many
scientific fields. In this work we explore a family of expressive and
interpretable distributions over circle-valued random functions related to
Gaussian processes targeting two Euclidean dimensions conditioned on the unit
circle. The resulting probability model has connections with continuous spin
models in statistical physics. Moreover, its density is very simple and has
maximum-entropy, unlike previous Gaussian process-based approaches, which use
wrapping or radial marginalization. For posterior inference, we introduce a new
Stratonovich-like augmentation that lends itself to fast Markov Chain Monte
Carlo sampling. We argue that transductive learning in these models favors a
Bayesian approach to the parameters. We present experiments applying this model
to the prediction of (i) wind directions and (ii) the percentage of the running
gait cycle as a function of joint angles."
A Simulation Environment for the Neuroevolution of Ant Colony Dynamics,https://arxiv.org/abs/2406.13147,2024-06-19,2024-06-21,0.0,0.0,"We introduce a simulation environment to facilitate research into emergent
collective behaviour, with a focus on replicating the dynamics of ant colonies.
By leveraging real-world data, the environment simulates a target ant trail
that a controllable agent must learn to replicate, using sensory data observed
by the target ant. This work aims to contribute to the neuroevolution of models
for collective behaviour, focusing on evolving neural architectures that encode
domain-specific behaviours in the network topology. By evolving models that can
be modified and studied in a controlled environment, we can uncover the
necessary conditions required for collective behaviours to emerge. We hope this
environment will be useful to those studying the role of interactions in
emergent behaviour within collective systems."
Constructing and Evaluating Digital Twins - An Intelligent Framework for DT Development,https://arxiv.org/abs/2406.13145,2024-06-19,2024-06-21,0.0,0.0,"The development of Digital Twins (DTs) represents a transformative advance
for simulating and optimizing complex systems in a controlled digital space.
Despite their potential, the challenge of constructing DTs that accurately
replicate and predict the dynamics of real-world systems remains substantial.
This paper introduces an intelligent framework for the construction and
evaluation of DTs, specifically designed to enhance the accuracy and utility of
DTs in testing algorithmic performance. We propose a novel construction
methodology that integrates deep learning-based policy gradient techniques to
dynamically tune the DT parameters, ensuring high fidelity in the digital
replication of physical systems. Moreover, the Mean STate Error (MSTE) is
proposed as a robust metric for evaluating the performance of algorithms within
these digital space. The efficacy of our framework is demonstrated through
extensive simulations that show our DT not only accurately mirrors the physical
reality but also provides a reliable platform for algorithm evaluation. This
work lays a foundation for future research into DT technologies, highlighting
pathways for both theoretical enhancements and practical implementations in
various industries."
DialSim - A Real-Time Simulator for Evaluating Long-Term Dialogue Understanding of Conversational Agents,https://arxiv.org/abs/2406.13144,2024-06-19,2024-06-21,0.0,0.0,"Recent advancements in Large Language Models (LLMs) have significantly
enhanced the capabilities of conversational agents, making them applicable to
various fields (e.g., education). Despite their progress, the evaluation of the
agents often overlooks the complexities of real-world conversations, such as
real-time interactions, multi-party dialogues, and extended contextual
dependencies. To bridge this gap, we introduce DialSim, a real-time dialogue
simulator. In this simulator, an agent is assigned the role of a character from
popular TV shows, requiring it to respond to spontaneous questions using past
dialogue information and to distinguish between known and unknown information.
Key features of DialSim include evaluating the agent's ability to respond
within a reasonable time limit, handling long-term multi-party dialogues, and
managing adversarial settings (e.g., swap character names) to challenge the
agent's reliance on pre-trained knowledge. We utilized this simulator to
evaluate the latest conversational agents and analyze their limitations. Our
experiments highlight both the strengths and weaknesses of these agents,
providing valuable insights for future improvements in the field of
conversational AI. DialSim is available at
https://github.com/jiho283/Simulator."
Large Language Models are Biased Because They Are Large Language Models,https://arxiv.org/abs/2406.13138,2024-06-19,2024-06-21,0.0,0.0,"This paper's primary goal is to provoke thoughtful discussion about the
relationship between bias and fundamental properties of large language models.
We do this by seeking to convince the reader that harmful biases are an
inevitable consequence arising from the design of any large language model as
LLMs are currently formulated. To the extent that this is true, it suggests
that the problem of harmful bias cannot be properly addressed without a serious
reconsideration of AI driven by LLMs, going back to the foundational
assumptions underlying their design."
Efficient Sharpness-Aware Minimization for Molecular Graph Transformer Models,https://arxiv.org/abs/2406.13137,2024-06-19,2024-06-21,0.0,0.0,"Sharpness-aware minimization (SAM) has received increasing attention in
computer vision since it can effectively eliminate the sharp local minima from
the training trajectory and mitigate generalization degradation. However, SAM
requires two sequential gradient computations during the optimization of each
step: one to obtain the perturbation gradient and the other to obtain the
updating gradient. Compared with the base optimizer (e.g., Adam), SAM doubles
the time overhead due to the additional perturbation gradient. By dissecting
the theory of SAM and observing the training gradient of the molecular graph
transformer, we propose a new algorithm named GraphSAM, which reduces the
training cost of SAM and improves the generalization performance of graph
transformer models. There are two key factors that contribute to this result:
(i) \textit{gradient approximation}: we use the updating gradient of the
previous step to approximate the perturbation gradient at the intermediate
steps smoothly (\textbf{increases efficiency}); (ii) \textit{loss landscape
approximation}: we theoretically prove that the loss landscape of GraphSAM is
limited to a small range centered on the expected loss of SAM
(\textbf{guarantees generalization performance}). The extensive experiments on
six datasets with different tasks demonstrate the superiority of GraphSAM,
especially in optimizing the model update process. The code is
in:https://github.com/YL-wang/GraphSAM/tree/graphsam"
PathoLM - Identifying pathogenicity from the DNA sequence through the Genome Foundation Model,https://arxiv.org/abs/2406.13133,2024-06-19,2024-06-21,0.0,0.0,"Pathogen identification is pivotal in diagnosing, treating, and preventing
diseases, crucial for controlling infections and safeguarding public health.
Traditional alignment-based methods, though widely used, are computationally
intense and reliant on extensive reference databases, often failing to detect
novel pathogens due to their low sensitivity and specificity. Similarly,
conventional machine learning techniques, while promising, require large
annotated datasets and extensive feature engineering and are prone to
overfitting. Addressing these challenges, we introduce PathoLM, a cutting-edge
pathogen language model optimized for the identification of pathogenicity in
bacterial and viral sequences. Leveraging the strengths of pre-trained DNA
models such as the Nucleotide Transformer, PathoLM requires minimal data for
fine-tuning, thereby enhancing pathogen detection capabilities. It effectively
captures a broader genomic context, significantly improving the identification
of novel and divergent pathogens. We developed a comprehensive data set
comprising approximately 30 species of viruses and bacteria, including ESKAPEE
pathogens, seven notably virulent bacterial strains resistant to antibiotics.
Additionally, we curated a species classification dataset centered specifically
on the ESKAPEE group. In comparative assessments, PathoLM dramatically
outperforms existing models like DciPatho, demonstrating robust zero-shot and
few-shot capabilities. Furthermore, we expanded PathoLM-Sp for ESKAPEE species
classification, where it showed superior performance compared to other advanced
deep learning methods, despite the complexities of the task."
When Parts are Greater Than Sums - Individual LLM Components Can Outperform Full Models,https://arxiv.org/abs/2406.13131,2024-06-19,2024-06-21,0.0,0.0,"This paper studies in-context learning (ICL) by decomposing the output of
large language models into the individual contributions of attention heads and
MLPs (components). We observe curious components: good-performing ones that
individually do well on a classification task, even when the model performs
poorly; bad-performing ones that do much worse than chance; and label-biased
components that always predict the same label. We find that component
accuracies are well-correlated across different demonstration sets and
perturbations of prompt templates, even when the full-model accuracy varies
greatly. Based on our findings, we propose component reweighting, which learns
to linearly re-scale the component activations from a few labeled examples.
Given 24 labeled examples, our method improves by an average of 6.0% accuracy
points over 24-shot ICL across 8 tasks on Llama-2-7B. Overall, this paper both
enriches our understanding of ICL and provides a practical method for
improvement by examining model internals."
Advancing Retail Data Science - Comprehensive Evaluation of Synthetic Data,https://arxiv.org/abs/2406.13130,2024-06-19,2024-06-21,0.0,0.0,"The evaluation of synthetic data generation is crucial, especially in the
retail sector where data accuracy is paramount. This paper introduces a
comprehensive framework for assessing synthetic retail data, focusing on
fidelity, utility, and privacy. Our approach differentiates between continuous
and discrete data attributes, providing precise evaluation criteria. Fidelity
is measured through stability and generalizability. Stability ensures synthetic
data accurately replicates known data distributions, while generalizability
confirms its robustness in novel scenarios. Utility is demonstrated through the
synthetic data's effectiveness in critical retail tasks such as demand
forecasting and dynamic pricing, proving its value in predictive analytics and
strategic planning. Privacy is safeguarded using Differential Privacy, ensuring
synthetic data maintains a perfect balance between resembling training and
holdout datasets without compromising security. Our findings validate that this
framework provides reliable and scalable evaluation for synthetic retail data.
It ensures high fidelity, utility, and privacy, making it an essential tool for
advancing retail data science. This framework meets the evolving needs of the
retail industry with precision and confidence, paving the way for future
advancements in synthetic data methodologies."
A New Approach for Evaluating and Improving the Performance of Segmentation Algorithms on Hard-to-Detect Blood Vessels,https://arxiv.org/abs/2406.13128,2024-06-19,2024-06-21,0.0,0.0,"Many studies regarding the vasculature of biological tissues involve the
segmentation of the blood vessels in a sample followed by the creation of a
graph structure to model the vasculature. The graph is then used to extract
relevant vascular properties. Small segmentation errors can lead to largely
distinct connectivity patterns and a high degree of variability of the
extracted properties. Nevertheless, global metrics such as Dice, precision, and
recall are commonly applied for measuring the performance of blood vessel
segmentation algorithms. These metrics might conceal important information
about the accuracy at specific regions of a sample. To tackle this issue, we
propose a local vessel salience (LVS) index to quantify the expected difficulty
in segmenting specific blood vessel segments. The LVS index is calculated for
each vessel pixel by comparing the local intensity of the vessel with the image
background around the pixel. The index is then used for defining a new accuracy
metric called low-salience recall (LSRecall), which quantifies the performance
of segmentation algorithms on blood vessel segments having low salience. The
perspective provided by the LVS index is used to define a data augmentation
procedure that can be used to improve the segmentation performance of
convolutional neural networks. We show that segmentation algorithms having high
Dice and recall values can display very low LSRecall values, which reveals
systematic errors of these algorithms for vessels having low salience. The
proposed data augmentation procedure is able to improve the LSRecall of some
samples by as much as 25%. The developed methodology opens up new possibilities
for comparing the performance of segmentation algorithms regarding
hard-to-detect blood vessels as well as their capabilities for vascular
topology preservation."
Oralytics Reinforcement Learning Algorithm,https://arxiv.org/abs/2406.13127,2024-06-19,2024-06-21,0.0,0.0,"Dental disease is still one of the most common chronic diseases in the United
States. While dental disease is preventable through healthy oral self-care
behaviors (OSCB), this basic behavior is not consistently practiced. We have
developed Oralytics, an online, reinforcement learning (RL) algorithm that
optimizes the delivery of personalized intervention prompts to improve OSCB. In
this paper, we offer a full overview of algorithm design decisions made using
prior data, domain expertise, and experiments in a simulation test bed. The
finalized RL algorithm was deployed in the Oralytics clinical trial, conducted
from fall 2023 to summer 2024."
A Unified Framework for Combinatorial Optimization Based on Graph Neural Networks,https://arxiv.org/abs/2406.13125,2024-06-19,2024-06-21,0.0,0.0,"Graph neural networks (GNNs) have emerged as a powerful tool for solving
combinatorial optimization problems (COPs), exhibiting state-of-the-art
performance in both graph-structured and non-graph-structured domains. However,
existing approaches lack a unified framework capable of addressing a wide range
of COPs. After presenting a summary of representative COPs and a brief review
of recent advancements in GNNs for solving COPs, this paper proposes a unified
framework for solving COPs based on GNNs, including graph representation of
COPs, equivalent conversion of non-graph structured COPs to graph-structured
COPs, graph decomposition, and graph simplification. The proposed framework
leverages the ability of GNNs to effectively capture the relational information
and extract features from the graph representation of COPs, offering a generic
solution to COPs that can address the limitations of state-of-the-art in
solving non-graph-structured and highly complex graph-structured COPs."
Learning to Generate Answers with Citations via Factual Consistency Models,https://arxiv.org/abs/2406.13124,2024-06-19,2024-06-21,0.0,0.0,"Large Language Models (LLMs) frequently hallucinate, impeding their
reliability in mission-critical situations. One approach to address this issue
is to provide citations to relevant sources alongside generated content,
enhancing the verifiability of generations. However, citing passages accurately
in answers remains a substantial challenge. This paper proposes a
weakly-supervised fine-tuning method leveraging factual consistency models
(FCMs). Our approach alternates between generating texts with citations and
supervised fine-tuning with FCM-filtered citation data. Focused learning is
integrated into the objective, directing the fine-tuning process to emphasise
the factual unit tokens, as measured by an FCM. Results on the ALCE few-shot
citation benchmark with various instruction-tuned LLMs demonstrate superior
performance compared to in-context learning, vanilla supervised fine-tuning,
and state-of-the-art methods, with an average improvement of $34.1$, $15.5$,
and $10.5$ citation F$_1$ points, respectively. Moreover, in a domain transfer
setting we show that the obtained citation generation ability robustly
transfers to unseen datasets. Notably, our citation improvements contribute to
the lowest factual error rate across baselines."
ViLCo-Bench - VIdeo Language COntinual learning Benchmark,https://arxiv.org/abs/2406.13123,2024-06-19,2024-06-21,0.0,0.0,"Video language continual learning involves continuously adapting to
information from video and text inputs, enhancing a model's ability to handle
new tasks while retaining prior knowledge. This field is a relatively
under-explored area, and establishing appropriate datasets is crucial for
facilitating communication and research in this field. In this study, we
present the first dedicated benchmark, ViLCo-Bench, designed to evaluate
continual learning models across a range of video-text tasks. The dataset
comprises ten-minute-long videos and corresponding language queries collected
from publicly available datasets. Additionally, we introduce a novel
memory-efficient framework that incorporates self-supervised learning and
mimics long-term and short-term memory effects. This framework addresses
challenges including memory complexity from long video clips, natural language
complexity from open queries, and text-video misalignment. We posit that
ViLCo-Bench, with greater complexity compared to existing continual learning
benchmarks, would serve as a critical tool for exploring the video-language
domain, extending beyond conventional class-incremental tasks, and addressing
complex and limited annotation issues. The curated data, evaluations, and our
novel method are available at https://github.com/cruiseresearchgroup/ViLCo ."
"Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?",https://arxiv.org/abs/2406.13121,2024-06-19,2024-06-21,0.0,0.0,"Long-context language models (LCLMs) have the potential to revolutionize our
approach to tasks traditionally reliant on external tools like retrieval
systems or databases. Leveraging LCLMs' ability to natively ingest and process
entire corpora of information offers numerous advantages. It enhances
user-friendliness by eliminating the need for specialized knowledge of tools,
provides robust end-to-end modeling that minimizes cascading errors in complex
pipelines, and allows for the application of sophisticated prompting techniques
across the entire system. To assess this paradigm shift, we introduce LOFT, a
benchmark of real-world tasks requiring context up to millions of tokens
designed to evaluate LCLMs' performance on in-context retrieval and reasoning.
Our findings reveal LCLMs' surprising ability to rival state-of-the-art
retrieval and RAG systems, despite never having been explicitly trained for
these tasks. However, LCLMs still face challenges in areas like compositional
reasoning that are required in SQL-like tasks. Notably, prompting strategies
significantly influence performance, emphasizing the need for continued
research as context lengths grow. Overall, LOFT provides a rigorous testing
ground for LCLMs, showcasing their potential to supplant existing paradigms and
tackle novel tasks as model capabilities scale."
Multi-Stage Balanced Distillation - Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation,https://arxiv.org/abs/2406.13114,2024-06-19,2024-06-21,0.0,0.0,"Large language models (LLMs) have significantly advanced various natural
language processing tasks, but deploying them remains computationally
expensive. Knowledge distillation (KD) is a promising solution, enabling the
transfer of capabilities from larger teacher LLMs to more compact student
models. Particularly, sequence-level KD, which distills rationale-based
reasoning processes instead of merely final outcomes, shows great potential in
enhancing students' reasoning capabilities. However, current methods struggle
with sequence level KD under long-tailed data distributions, adversely
affecting generalization on sparsely represented domains. We introduce the
Multi-Stage Balanced Distillation (BalDistill) framework, which iteratively
balances training data within a fixed computational budget. By dynamically
selecting representative head domain examples and synthesizing tail domain
examples, BalDistill achieves state-of-the-art performance across diverse
long-tailed datasets, enhancing both the efficiency and efficacy of the
distilled models."
Nutmeg and SPICE - Models and Data for Biomolecular Machine Learning,https://arxiv.org/abs/2406.13112,2024-06-18,2024-06-21,0.0,0.0,"We describe version 2 of the SPICE dataset, a collection of quantum chemistry
calculations for training machine learning potentials. It expands on the
original dataset by adding much more sampling of chemical space and more data
on non-covalent interactions. We train a set of potential energy functions
called Nutmeg on it. They are based on the TensorNet architecture. They use a
novel mechanism to improve performance on charged and polar molecules,
injecting precomputed partial charges into the model to provide a reference for
the large scale charge distribution. Evaluation of the new models shows they do
an excellent job of reproducing energy differences between conformations, even
on highly charged molecules or ones that are significantly larger than the
molecules in the training set. They also produce stable molecular dynamics
trajectories, and are fast enough to be useful for routine simulation of small
molecules."
A Generic Method for Fine-grained Category Discovery in Natural Language Texts,https://arxiv.org/abs/2406.13103,2024-06-18,2024-06-21,0.0,0.0,"Fine-grained category discovery using only coarse-grained supervision is a
cost-effective yet challenging task. Previous training methods focus on
aligning query samples with positive samples and distancing them from
negatives. They often neglect intra-category and inter-category semantic
similarities of fine-grained categories when navigating sample distributions in
the embedding space. Furthermore, some evaluation techniques that rely on
pre-collected test samples are inadequate for real-time applications. To
address these shortcomings, we introduce a method that successfully detects
fine-grained clusters of semantically similar texts guided by a novel objective
function. The method uses semantic similarities in a logarithmic space to guide
sample distributions in the Euclidean space and to form distinct clusters that
represent fine-grained categories. We also propose a centroid inference
mechanism to support real-time applications. The efficacy of the method is both
theoretically justified and empirically confirmed on three benchmark tasks. The
proposed objective function is integrated in multiple contrastive learning
based neural models. Its results surpass existing state-of-the-art approaches
in terms of Accuracy, Adjusted Rand Index and Normalized Mutual Information of
the detected fine-grained categories. Code and data will be available at
https://github.com/XX upon publication."
On instabilities in neural network-based physics simulators,https://arxiv.org/abs/2406.13101,2024-06-18,2024-06-21,0.0,0.0,"When neural networks are trained from data to simulate the dynamics of
physical systems, they encounter a persistent challenge: the long-time dynamics
they produce are often unphysical or unstable. We analyze the origin of such
instabilities when learning linear dynamical systems, focusing on the training
dynamics. We make several analytical findings which empirical observations
suggest extend to nonlinear dynamical systems. First, the rate of convergence
of the training dynamics is uneven and depends on the distribution of energy in
the data. As a special case, the dynamics in directions where the data have no
energy cannot be learned. Second, in the unlearnable directions, the dynamics
produced by the neural network depend on the weight initialization, and common
weight initialization schemes can produce unstable dynamics. Third, injecting
synthetic noise into the data during training adds damping to the training
dynamics and can stabilize the learned simulator, though doing so undesirably
biases the learned dynamics. For each contributor to instability, we suggest
mitigative strategies. We also highlight important differences between learning
discrete-time and continuous-time dynamics, and discuss extensions to nonlinear
systems."
Sampling 3D Gaussian Scenes in Seconds with Latent Diffusion Models,https://arxiv.org/abs/2406.13099,2024-06-18,2024-06-21,0.0,0.0,"We present a latent diffusion model over 3D scenes, that can be trained using
only 2D image data. To achieve this, we first design an autoencoder that maps
multi-view images to 3D Gaussian splats, and simultaneously builds a compressed
latent representation of these splats. Then, we train a multi-view diffusion
model over the latent space to learn an efficient generative model. This
pipeline does not require object masks nor depths, and is suitable for complex
scenes with arbitrary camera positions. We conduct careful experiments on two
large-scale datasets of complex real-world scenes -- MVImgNet and
RealEstate10K. We show that our approach enables generating 3D scenes in as
little as 0.2 seconds, either from scratch, from a single input view, or from
sparse input views. It produces diverse and high-quality results while running
an order of magnitude faster than non-latent diffusion models and earlier
NeRF-based generative models"
Exploring and Benchmarking the Planning Capabilities of Large Language Models,https://arxiv.org/abs/2406.13094,2024-06-18,2024-06-21,0.0,0.0,"We seek to elevate the planning capabilities of Large Language Models
(LLMs)investigating four main directions. First, we construct a comprehensive
benchmark suite encompassing both classical planning domains and natural
language scenarios. This suite includes algorithms to generate instances with
varying levels of difficulty, allowing for rigorous and systematic evaluation
of LLM performance. Second, we investigate the use of in-context learning (ICL)
to enhance LLM planning, exploring the direct relationship between increased
context length and improved planning performance. Third, we demonstrate the
positive impact of fine-tuning LLMs on optimal planning paths, as well as the
effectiveness of incorporating model-driven search procedures. Finally, we
investigate the performance of the proposed methods in out-of-distribution
scenarios, assessing the ability to generalize to novel and unseen planning
challenges."
RITA - A Real-time Interactive Talking Avatars Framework,https://arxiv.org/abs/2406.13093,2024-06-18,2024-06-21,0.0,0.0,"RITA presents a high-quality real-time interactive framework built upon
generative models, designed with practical applications in mind. Our framework
enables the transformation of user-uploaded photos into digital avatars that
can engage in real-time dialogue interactions. By leveraging the latest
advancements in generative modeling, we have developed a versatile platform
that not only enhances the user experience through dynamic conversational
avatars but also opens new avenues for applications in virtual reality, online
education, and interactive gaming. This work showcases the potential of
integrating computer vision and natural language processing technologies to
create immersive and interactive digital personas, pushing the boundaries of
how we interact with digital content."
Multilingual Synopses of Movie Narratives - A Dataset for Story Understanding,https://arxiv.org/abs/2406.13092,2024-06-18,2024-06-21,0.0,0.0,"Story video-text alignment, a core task in computational story understanding,
aims to align video clips with corresponding sentences in their descriptions.
However, progress on the task has been held back by the scarcity of manually
annotated video-text correspondence and the heavy concentration on English
narrations of Hollywood movies. To address these issues, in this paper, we
construct a large-scale multilingual video story dataset named Multilingual
Synopses of Movie Narratives (M-SYMON), containing 13,166 movie summary videos
from 7 languages, as well as manual annotation of fine-grained video-text
correspondences for 101.5 hours of video. Training on the human annotated data
from SyMoN outperforms the SOTA methods by 15.7 and 16.2 percentage points on
Clip Accuracy and Sentence IoU scores, respectively, demonstrating the
effectiveness of the annotations. As benchmarks for future research, we create
6 baseline approaches with different multilingual training strategies, compare
their performance in both intra-lingual and cross-lingual setups, exemplifying
the challenges of multilingual video-text alignment."
Exact Community Recovery (under Side Information) - Optimality of Spectral Algorithms,https://arxiv.org/abs/2406.13075,2024-06-18,2024-06-21,0.0,0.0,"In this paper, we study the problem of exact community recovery in general,
two-community block models considering both Bernoulli and Gaussian matrix
models, capturing the Stochastic Block Model, submatrix localization, and
$\mathbb{Z}_2$-synchronization as special cases. We also study the settings
where $side$ $information$ about community assignment labels is available,
modeled as passing the true labels through a noisy channel: either the binary
erasure channel (where some community labels are known while others are erased)
or the binary symmetric channel (where some labels are flipped). We provide a
unified analysis of the effect of side information on the information-theoretic
limits of exact recovery, generalizing prior works and extending to new
settings. Additionally, we design a simple but optimal spectral algorithm that
incorporates side information (when present) along with the eigenvectors of the
matrix observation. Using the powerful tool of entrywise eigenvector analysis
[Abbe, Fan, Wang, Zhong 2020], we show that our spectral algorithm can mimic
the so called $genie$-$aided$ $estimators$, where the $i^{\mathrm{th}}$
genie-aided estimator optimally computes the estimate of the $i^{\mathrm{th}}$
label, when all remaining labels are revealed by a genie. This perspective
provides a unified understanding of the optimality of spectral algorithms for
various exact recovery problems in a recent line of work."
PIPPIN - Generating variable length full events from partons,https://arxiv.org/abs/2406.13074,2024-06-18,2024-06-21,0.0,0.0,"This paper presents a novel approach for directly generating full events at
detector-level from parton-level information, leveraging cutting-edge machine
learning techniques. To address the challenge of multiplicity variations
between parton and reconstructed object spaces, we employ transformers,
score-based models and normalizing flows. Our method tackles the inherent
complexities of the stochastic transition between these two spaces and achieves
remarkably accurate results. The combination of innovative techniques and the
achieved accuracy demonstrates the potential of our approach in advancing the
field and opens avenues for further exploration. This research contributes to
the ongoing efforts in high-energy physics and generative modelling, providing
a promising direction for enhanced precision in fast detector simulation."
NoiSec - Harnessing Noise for Security against Adversarial and Backdoor Attacks,https://arxiv.org/abs/2406.13073,2024-06-18,2024-06-21,0.0,0.0,"The exponential adoption of machine learning (ML) is propelling the world
into a future of intelligent automation and data-driven solutions. However, the
proliferation of malicious data manipulation attacks against ML, namely
adversarial and backdoor attacks, jeopardizes its reliability in
safety-critical applications. The existing detection methods against such
attacks are built upon assumptions, limiting them in diverse practical
scenarios. Thus, motivated by the need for a more robust and unified defense
mechanism, we investigate the shared traits of adversarial and backdoor attacks
and propose NoiSec that leverages solely the noise, the foundational root cause
of such attacks, to detect any malicious data alterations. NoiSec is a
reconstruction-based detector that disentangles the noise from the test input,
extracts the underlying features from the noise, and leverages them to
recognize systematic malicious manipulation. Experimental evaluations conducted
on the CIFAR10 dataset demonstrate the efficacy of NoiSec, achieving AUROC
scores exceeding 0.954 and 0.852 under white-box and black-box adversarial
attacks, respectively, and 0.992 against backdoor attacks. Notably, NoiSec
maintains a high detection performance, keeping the false positive rate within
only 1\%. Comparative analyses against MagNet-based baselines reveal NoiSec's
superior performance across various attack scenarios."
Evaluating $n$-Gram Novelty of Language Models Using Rusty-DAWG,https://arxiv.org/abs/2406.13069,2024-06-18,2024-06-21,0.0,0.0,"How novel are texts generated by language models (LMs) relative to their
training corpora? In this work, we investigate the extent to which modern LMs
generate $n$-grams from their training data, evaluating both (i) the
probability LMs assign to complete training $n$-grams and (ii) $n$-novelty, the
proportion of $n$-grams generated by an LM that did not appear in the training
data (for arbitrarily large $n$). To enable arbitrary-length $n$-gram search
over a corpus in constant time, we develop Rusty-DAWG, a novel search tool
inspired by indexing of genomic data. We compare the novelty of LM-generated
text to human-written text and explore factors that affect generation novelty,
focusing on the Pythia models. We find that, for $n > 4$, LM-generated text is
less novel than human-written text, though it is more novel for smaller $n$.
Larger LMs and more constrained decoding strategies both decrease novelty.
Finally, we show that LMs complete $n$-grams with lower loss if they are more
frequent in the training data. Overall, our results reveal factors influencing
the novelty of LM-generated text, and we release Rusty-DAWG to facilitate
further pretraining data research."
MaskPure - Improving Defense Against Text Adversaries with Stochastic Purification,https://arxiv.org/abs/2406.13066,2024-06-18,2024-06-21,0.0,0.0,"The improvement of language model robustness, including successful defense
against adversarial attacks, remains an open problem. In computer vision
settings, the stochastic noising and de-noising process provided by diffusion
models has proven useful for purifying input images, thus improving model
robustness against adversarial attacks. Similarly, some initial work has
explored the use of random noising and de-noising to mitigate adversarial
attacks in an NLP setting, but improving the quality and efficiency of these
methods is necessary for them to remain competitive. We extend upon methods of
input text purification that are inspired by diffusion processes, which
randomly mask and refill portions of the input text before classification. Our
novel method, MaskPure, exceeds or matches robustness compared to other
contemporary defenses, while also requiring no adversarial classifier training
and without assuming knowledge of the attack type. In addition, we show that
MaskPure is provably certifiably robust. To our knowledge, MaskPure is the
first stochastic-purification method with demonstrated success against both
character-level and word-level attacks, indicating the generalizable and
promising nature of stochastic denoising defenses. In summary: the MaskPure
algorithm bridges literature on the current strongest certifiable and empirical
adversarial defense methods, showing that both theoretical and practical
robustness can be obtained together. Code is available on GitHub at
https://github.com/hubarruby/MaskPure."
Machine Learning and Optimization Techniques for Solving Inverse Kinematics in a 7-DOF Robotic Arm,https://arxiv.org/abs/2406.13064,2024-06-18,2024-06-21,0.0,0.0,"As the pace of AI technology continues to accelerate, more tools have become
available to researchers to solve longstanding problems, Hybrid approaches
available today continue to push the computational limits of efficiency and
precision. One of such problems is the inverse kinematics of redundant systems.
This paper explores the complexities of a 7 degree of freedom manipulator and
explores 13 optimization techniques to solve it. Additionally, a novel approach
is proposed to contribute to the field of algorithmic research. This was found
to be over 200 times faster than the well-known traditional Particle Swarm
Optimization technique. This new method may serve as a new field of search that
combines the explorative capabilities of Machine Learning with the exploitative
capabilities of numerical methods."
Scale-Translation Equivariant Network for Oceanic Internal Solitary Wave Localization,https://arxiv.org/abs/2406.13060,2024-06-18,2024-06-21,0.0,0.0,"Internal solitary waves (ISWs) are gravity waves that are often observed in
the interior ocean rather than the surface. They hold significant importance
due to their capacity to carry substantial energy, thus influence pollutant
transport, oil platform operations, submarine navigation, etc. Researchers have
studied ISWs through optical images, synthetic aperture radar (SAR) images, and
altimeter data from remote sensing instruments. However, cloud cover in optical
remote sensing images variably obscures ground information, leading to blurred
or missing surface observations. As such, this paper aims at altimeter-based
machine learning solutions to automatically locate ISWs. The challenges,
however, lie in the following two aspects: 1) the altimeter data has low
resolution, which requires a strong machine learner; 2) labeling data is
extremely labor-intensive, leading to very limited data for training. In recent
years, the grand progress of deep learning demonstrates strong learning
capacity given abundant data. Besides, more recent studies on efficient
learning and self-supervised learning laid solid foundations to tackle the
aforementioned challenges. In this paper, we propose to inject prior knowledge
to achieve a strong and efficient learner. Specifically, intrinsic patterns in
altimetry data are efficiently captured using a scale-translation equivariant
convolutional neural network (ST-ECNN). By considering inherent symmetries in
neural network design, ST-ECNN achieves higher efficiency and better
performance than baseline models. Furthermore, we also introduce prior
knowledge from massive unsupervised data to enhance our solution using the
SimCLR framework for pre-training. Our final solution achieves an overall
better performance than baselines on our handcrafted altimetry dataset. Data
and codes are available at
https://github.com/ZhangWan-byte/Internal_Solitary_Wave_Localization ."
Informed along the road - roadway capacity driven graph convolution network for network-wide traffic prediction,https://arxiv.org/abs/2406.13057,2024-06-18,2024-06-21,0.0,0.0,"While deep learning has shown success in predicting traffic states, most
methods treat it as a general prediction task without considering
transportation aspects. Recently, graph neural networks have proven effective
for this task, but few incorporate external factors that impact roadway
capacity and traffic flow. This study introduces the Roadway Capacity Driven
Graph Convolution Network (RCDGCN) model, which incorporates static and dynamic
roadway capacity attributes in spatio-temporal settings to predict network-wide
traffic states. The model was evaluated on two real-world datasets with
different transportation factors: the ICM-495 highway network and an urban
network in Manhattan, New York City. Results show RCDGCN outperformed baseline
methods in forecasting accuracy. Analyses, including ablation experiments,
weight analysis, and case studies, investigated the effect of capacity-related
factors. The study demonstrates the potential of using RCDGCN for
transportation system management."
Think-then-Act - A Dual-Angle Evaluated Retrieval-Augmented Generation,https://arxiv.org/abs/2406.13050,2024-06-18,2024-06-21,0.0,0.0,"Despite their impressive capabilities, large language models (LLMs) often
face challenges such as temporal misalignment and generating hallucinatory
content. Enhancing LLMs with retrieval mechanisms to fetch relevant information
from external sources offers a promising solution. Inspired by the proverb
""Think twice before you act,"" we propose a dual-angle evaluated
retrieval-augmented generation framework \textit{Think-then-Act}. Unlike
previous approaches that indiscriminately rewrite queries or perform retrieval
regardless of necessity, or generate temporary responses before deciding on
additional retrieval, which increases model generation costs, our framework
employs a two-phase process: (i) assessing the input query for clarity and
completeness to determine if rewriting is necessary; and (ii) evaluating the
model's capability to answer the query and deciding if additional retrieval is
needed. Experimental results on five datasets show that the
\textit{Think-then-Act} framework significantly improves performance. Our
framework demonstrates notable improvements in accuracy and efficiency compared
to existing baselines and performs well in both English and non-English
contexts. Ablation studies validate the optimal model confidence threshold,
highlighting the resource optimization benefits of our approach."
Assessing AI vs Human-Authored Spear Phishing SMS Attacks - An Empirical Study Using the TRAPD Method,https://arxiv.org/abs/2406.13049,2024-06-18,2024-06-21,0.0,0.0,"This paper explores the rising concern of utilizing Large Language Models
(LLMs) in spear phishing message generation, and their performance compared to
human-authored counterparts. Our pilot study compares the effectiveness of
smishing (SMS phishing) messages created by GPT-4 and human authors, which have
been personalized to willing targets. The targets assessed the messages in a
modified ranked-order experiment using a novel methodology we call TRAPD
(Threshold Ranking Approach for Personalized Deception). Specifically, targets
provide personal information (job title and location, hobby, item purchased
online), spear smishing messages are created using this information by humans
and GPT-4, targets are invited back to rank-order 12 messages from most to
least convincing (and identify which they would click on), and then asked
questions about why they ranked messages the way they did. They also guess
which messages are created by an LLM and their reasoning. Results from 25
targets show that LLM-generated messages are most often perceived as more
convincing than those authored by humans, with messages related to jobs being
the most convincing. We characterize different criteria used when assessing the
authenticity of messages including word choice, style, and personal relevance.
Results also show that targets were unable to identify whether the messages was
AI-generated or human-authored and struggled to identify criteria to use in
order to make this distinction. This study aims to highlight the urgent need
for further research and improved countermeasures against personalized
AI-enabled social engineering attacks."
Bayesian-LoRA - LoRA based Parameter Efficient Fine-Tuning using Optimal Quantization levels and Rank Values trough Differentiable Bayesian Gates,https://arxiv.org/abs/2406.13046,2024-06-18,2024-06-21,0.0,0.0,"It is a common practice in natural language processing to pre-train a single
model on a general domain and then fine-tune it for downstream tasks. However,
when it comes to Large Language Models, fine-tuning the entire model can be
computationally expensive, resulting in very intensive energy consumption. As a
result, several Parameter Efficient Fine-Tuning (PEFT) approaches were recently
proposed. One of the most popular approaches is low-rank adaptation (LoRA),
where the key insight is decomposing the update weights of the pre-trained
model into two low-rank matrices. However, the proposed approaches either use
the same rank value across all different weight matrices, which has been shown
to be a sub-optimal choice, or do not use any quantization technique, one of
the most important factors when it comes to a model's energy consumption. In
this work, we propose Bayesian-LoRA which approaches low-rank adaptation and
quantization from a Bayesian perspective by employing a prior distribution on
both quantization levels and rank values. As a result, B-LoRA is able to
fine-tune a pre-trained model on a specific downstream task, finding the
optimal rank values and quantization levels for every low-rank matrix. We
validate the proposed model by fine-tuning a pre-trained DeBERTaV3 on the GLUE
benchmark. Moreover, we compare it to relevant baselines and present both
qualitative and quantitative results, showing how the proposed approach is able
to learn optimal-rank quantized matrices. B-LoRA performs on par with or better
than the baselines while reducing the total number of bit operations by roughly
70% compared to the baseline methods."
Accelerated Stochastic Min-Max Optimization Based on Bias-corrected Momentum,https://arxiv.org/abs/2406.13041,2024-06-18,2024-06-21,0.0,0.0,"Lower-bound analyses for nonconvex strongly-concave minimax optimization
problems have shown that stochastic first-order algorithms require at least
$\mathcal{O}(\varepsilon^{-4})$ oracle complexity to find an
$\varepsilon$-stationary point. Some works indicate that this complexity can be
improved to $\mathcal{O}(\varepsilon^{-3})$ when the loss gradient is Lipschitz
continuous. The question of achieving enhanced convergence rates under distinct
conditions, remains unresolved. In this work, we address this question for
optimization problems that are nonconvex in the minimization variable and
strongly concave or Polyak-Lojasiewicz (PL) in the maximization variable. We
introduce novel bias-corrected momentum algorithms utilizing efficient
Hessian-vector products. We establish convergence conditions and demonstrate a
lower iteration complexity of $\mathcal{O}(\varepsilon^{-3})$ for the proposed
algorithms. The effectiveness of the method is validated through applications
to robust logistic regression using real-world datasets."
Traffic Prediction considering Multiple Levels of Spatial-temporal Information - A Multi-scale Graph Wavelet-based Approach,https://arxiv.org/abs/2406.13038,2024-06-18,2024-06-21,0.0,0.0,"Although traffic prediction has been receiving considerable attention with a
number of successes in the context of intelligent transportation systems, the
prediction of traffic states over a complex transportation network that
contains different road types has remained a challenge. This study proposes a
multi-scale graph wavelet temporal convolution network (MSGWTCN) to predict the
traffic states in complex transportation networks. Specifically, a multi-scale
spatial block is designed to simultaneously capture the spatial information at
different levels, and the gated temporal convolution network is employed to
extract the temporal dependencies of the data. The model jointly learns to
mount multiple levels of the spatial interactions by stacking graph wavelets
with different scales. Two real-world datasets are used in this study to
investigate the model performance, including a highway network in Seattle and a
dense road network of Manhattan in New York City. Experiment results show that
the proposed model outperforms other baseline models. Furthermore, different
scales of graph wavelets are found to be effective in extracting local,
intermediate and global information at the same time and thus enable the model
to learn a complex transportation network topology with various types of road
segments. By carefully customizing the scales of wavelets, the model is able to
improve the prediction performance and better adapt to different network
configurations."
Sharp detection of low-dimensional structure in probability measures via dimensional logarithmic Sobolev inequalities,https://arxiv.org/abs/2406.13036,2024-06-18,2024-06-21,0.0,0.0,"Identifying low-dimensional structure in high-dimensional probability
measures is an essential pre-processing step for efficient sampling. We
introduce a method for identifying and approximating a target measure $\pi$ as
a perturbation of a given reference measure $\mu$ along a few significant
directions of $\mathbb{R}^{d}$. The reference measure can be a Gaussian or a
nonlinear transformation of a Gaussian, as commonly arising in generative
modeling. Our method extends prior work on minimizing majorizations of the
Kullback--Leibler divergence to identify optimal approximations within this
class of measures. Our main contribution unveils a connection between the
\emph{dimensional} logarithmic Sobolev inequality (LSI) and approximations with
this ansatz. Specifically, when the target and reference are both Gaussian, we
show that minimizing the dimensional LSI is equivalent to minimizing the KL
divergence restricted to this ansatz. For general non-Gaussian measures, the
dimensional LSI produces majorants that uniformly improve on previous majorants
for gradient-based dimension reduction. We further demonstrate the
applicability of this analysis to the squared Hellinger distance, where
analogous reasoning shows that the dimensional Poincar\'e inequality offers
improved bounds."
D2O -Dynamic Discriminative Operations for Efficient Generative Inference of Large Language Models,https://arxiv.org/abs/2406.13035,2024-06-18,2024-06-21,0.0,0.0,"Efficient inference in Large Language Models (LLMs) is impeded by the growing
memory demands of key-value (KV) caching, especially for longer sequences.
Traditional KV cache eviction strategies, which prioritize less critical
KV-pairs based on attention scores, often degrade generation quality, leading
to issues such as context loss or hallucinations. To address this, we introduce
Dynamic Discriminative Operations (D2O), a novel method that utilizes two-level
discriminative strategies to optimize KV cache size without fine-tuning, while
preserving essential context. Initially, by observing varying densities of
attention weights between shallow and deep layers, we use this insight to
determine which layers should avoid excessive eviction to minimize information
loss. Subsequently, for the eviction strategy in each layer, D2O innovatively
incorporates a compensation mechanism that maintains a similarity threshold to
re-discriminate the importance of previously discarded tokens, determining
whether they should be recalled and merged with similar tokens. Our approach
not only achieves significant memory savings and enhances inference throughput
by more than 3 times but also maintains high-quality long-text generation.
Extensive experiments across various benchmarks and LLM architectures have
demonstrated that D2O significantly enhances performance with a constrained KV
cache budget."
Real-time Yemeni Currency Detection,https://arxiv.org/abs/2406.13034,2024-06-18,2024-06-21,0.0,0.0,"Banknote recognition is a major problem faced by visually Challenged people.
So we propose a application to help the visually Challenged people to identify
the different types of Yemenian currencies through deep learning technique. As
money has a significant role in daily life for any business transactions,
real-time detection and recognition of banknotes become necessary for a person,
especially blind or visually impaired, or for a system that sorts the data.
This paper presents a real-time Yemeni currency detection system for visually
impaired persons. The proposed system exploits the deep learning approach to
facilitate the visually impaired people to prosperously recognize banknotes.
For real-time recognition, we have deployed the system into a mobile
application."
ABNet - Attention BarrierNet for Safe and Scalable Robot Learning,https://arxiv.org/abs/2406.13025,2024-06-18,2024-06-21,0.0,0.0,"Safe learning is central to AI-enabled robots where a single failure may lead
to catastrophic results. Barrier-based method is one of the dominant approaches
for safe robot learning.
  However, this method is not scalable, hard to train, and tends to generate
unstable signals under noisy inputs that are challenging to be deployed for
robots. To address these challenges, we propose a novel Attention BarrierNet
(ABNet) that is scalable to build larger foundational safe models in an
incremental manner.
  Each head of BarrierNet in the ABNet could learn safe robot control policies
from different features and focus on specific part of the observation. In this
way, we do not need to one-shotly construct a large model for complex tasks,
which significantly facilitates the training of the model while ensuring its
stable output. Most importantly, we can still formally prove the safety
guarantees of the ABNet. We demonstrate the strength of ABNet in 2D robot
obstacle avoidance, safe robot manipulation, and vision-based end-to-end
autonomous driving, with results showing much better robustness and guarantees
over existing models."
Data Plagiarism Index - Characterizing the Privacy Risk of Data-Copying in Tabular Generative Models,https://arxiv.org/abs/2406.13012,2024-06-18,2024-06-21,0.0,0.0,"The promise of tabular generative models is to produce realistic synthetic
data that can be shared and safely used without dangerous leakage of
information from the training set. In evaluating these models, a variety of
methods have been proposed to measure the tendency to copy data from the
training dataset when generating a sample. However, these methods suffer from
either not considering data-copying from a privacy threat perspective, not
being motivated by recent results in the data-copying literature or being
difficult to make compatible with the high dimensional, mixed type nature of
tabular data. This paper proposes a new similarity metric and Membership
Inference Attack called Data Plagiarism Index (DPI) for tabular data. We show
that DPI evaluates a new intuitive definition of data-copying and characterizes
the corresponding privacy risk. We show that the data-copying identified by DPI
poses both privacy and fairness threats to common, high performing
architectures; underscoring the necessity for more sophisticated generative
modeling techniques to mitigate this issue."
Detecting Errors through Ensembling Prompts (DEEP) - An End-to-End LLM Framework for Detecting Factual Errors,https://arxiv.org/abs/2406.13009,2024-06-18,2024-06-21,0.0,0.0,"Accurate text summarization is one of the most common and important tasks
performed by Large Language Models, where the costs of human review for an
entire document may be high, but the costs of errors in summarization may be
even greater. We propose Detecting Errors through Ensembling Prompts (DEEP) -
an end-to-end large language model framework for detecting factual errors in
text summarization. Our framework uses a diverse set of LLM prompts to identify
factual inconsistencies, treating their outputs as binary features, which are
then fed into ensembling models. We then calibrate the ensembled models to
produce empirically accurate probabilities that a text is factually consistent
or free of hallucination. We demonstrate that prior models for detecting
factual errors in summaries perform significantly worse without optimizing the
thresholds on subsets of the evaluated dataset. Our framework achieves
state-of-the-art (SOTA) balanced accuracy on the AggreFact-XSUM FTSOTA,
TofuEval Summary-Level, and HaluEval Summarization benchmarks in detecting
factual errors within transformer-generated text summaries. It does so without
any fine-tuning of the language model or reliance on thresholding techniques
not available in practical settings."
ClaudesLens - Uncertainty Quantification in Computer Vision Models,https://arxiv.org/abs/2406.13008,2024-06-18,2024-06-21,0.0,0.0,"In a world where more decisions are made using artificial intelligence, it is
of utmost importance to ensure these decisions are well-grounded. Neural
networks are the modern building blocks for artificial intelligence. Modern
neural network-based computer vision models are often used for object
classification tasks. Correctly classifying objects with \textit{certainty} has
become of great importance in recent times. However, quantifying the inherent
\textit{uncertainty} of the output from neural networks is a challenging task.
Here we show a possible method to quantify and evaluate the uncertainty of the
output of different computer vision models based on Shannon entropy. By adding
perturbation of different levels, on different parts, ranging from the input to
the parameters of the network, one introduces entropy to the system. By
quantifying and evaluating the perturbed models on the proposed PI and PSI
metrics, we can conclude that our theoretical framework can grant insight into
the uncertainty of predictions of computer vision models. We believe that this
theoretical framework can be applied to different applications for neural
networks. We believe that Shannon entropy may eventually have a bigger role in
the SOTA (State-of-the-art) methods to quantify uncertainty in artificial
intelligence. One day we might be able to apply Shannon entropy to our neural
systems."
Articulatory Encodec - Vocal Tract Kinematics as a Codec for Speech,https://arxiv.org/abs/2406.12998,2024-06-18,2024-06-21,0.0,0.0,"Vocal tract articulation is a natural, grounded control space of speech
production. The spatiotemporal coordination of articulators combined with the
vocal source shapes intelligible speech sounds to enable effective spoken
communication. Based on this physiological grounding of speech, we propose a
new framework of neural encoding-decoding of speech -- Articulatory Encodec.
Articulatory Encodec comprises an articulatory analysis model that infers
articulatory features from speech audio, and an articulatory synthesis model
that synthesizes speech audio from articulatory features. The articulatory
features are kinematic traces of vocal tract articulators and source features,
which are intuitively interpretable and controllable, being the actual physical
interface of speech production. An additional speaker identity encoder is
jointly trained with the articulatory synthesizer to inform the voice texture
of individual speakers. By training on large-scale speech data, we achieve a
fully intelligible, high-quality articulatory synthesizer that generalizes to
unseen speakers. Furthermore, the speaker embedding is effectively disentangled
from articulations, which enables accent-perserving zero-shot voice conversion.
To the best of our knowledge, this is the first demonstration of universal,
high-performance articulatory inference and synthesis, suggesting the proposed
framework as a powerful coding system of speech."
Suitability of CCA for Generating Latent State/ Variables in Multi-View Textual Data,https://arxiv.org/abs/2406.12997,2024-06-18,2024-06-21,0.0,0.0,"The probabilistic interpretation of Canonical Correlation Analysis (CCA) for
learning low-dimensional real vectors, called as latent variables, has been
exploited immensely in various fields. This study takes a step further by
demonstrating the potential of CCA in discovering a latent state that captures
the contextual information within the textual data under a two-view setting.
The interpretation of CCA discussed in this study utilizes the multi-view
nature of textual data, i.e. the consecutive sentences in a document or turns
in a dyadic conversation, and has a strong theoretical foundation. Furthermore,
this study proposes a model using CCA to perform the Automatic Short Answer
Grading (ASAG) task. The empirical analysis confirms that the proposed model
delivers competitive results and can even beat various sophisticated supervised
techniques. The model is simple, linear, and adaptable and should be used as
the baseline especially when labeled training data is scarce or nonexistent."
Additive regularization schedule for neural architecture search,https://arxiv.org/abs/2406.12992,2024-06-18,2024-06-21,0.0,0.0,"Neural network structures have a critical impact on the accuracy and
stability of forecasting. Neural architecture search procedures help design an
optimal neural network according to some loss function, which represents a set
of quality criteria. This paper investigates the problem of neural network
structure optimization. It proposes a way to construct a loss function, which
contains a set of additive elements. Each element is called the regularizer. It
corresponds to some part of the neural network structure and represents a
criterion to optimize. The optimization procedure changes the structure in
iterations. To optimize various parts of the structure, the procedure changes
the set of regularizers according to some schedule. The authors propose a way
to construct the additive regularization schedule. By comparing regularized
models with non-regularized ones for a collection of datasets the computational
experiments show that the proposed method finds efficient neural network
structure and delivers accurate networks of low complexity."
Reinforcement Learning for Corporate Bond Trading - A Sell Side Perspective,https://arxiv.org/abs/2406.12983,2024-06-18,2024-06-21,0.0,0.0,"A corporate bond trader in a typical sell side institution such as a bank
provides liquidity to the market participants by buying/selling securities and
maintaining an inventory. Upon receiving a request for a buy/sell price quote
(RFQ), the trader provides a quote by adding a spread over a \textit{prevalent
market price}. For illiquid bonds, the market price is harder to observe, and
traders often resort to available benchmark bond prices (such as MarketAxess,
Bloomberg, etc.). In \cite{Bergault2023ModelingLI}, the concept of \textit{Fair
Transfer Price} for an illiquid corporate bond was introduced which is derived
from an infinite horizon stochastic optimal control problem (for maximizing the
trader's expected P\&L, regularized by the quadratic variation). In this paper,
we consider the same optimization objective, however, we approach the
estimation of an optimal bid-ask spread quoting strategy in a data driven
manner and show that it can be learned using Reinforcement Learning.
Furthermore, we perform extensive outcome analysis to examine the
reasonableness of the trained agent's behavior."
SHIELD - Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation,https://arxiv.org/abs/2406.12975,2024-06-18,2024-06-21,0.0,0.0,"Large Language Models (LLMs) have transformed machine learning but raised
significant legal concerns due to their potential to produce text that
infringes on copyrights, resulting in several high-profile lawsuits. The legal
landscape is struggling to keep pace with these rapid advancements, with
ongoing debates about whether generated text might plagiarize copyrighted
materials. Current LLMs may infringe on copyrights or overly restrict
non-copyrighted texts, leading to these challenges: (i) the need for a
comprehensive evaluation benchmark to assess copyright compliance from multiple
aspects; (ii) evaluating robustness against safeguard bypassing attacks; and
(iii) developing effective defense targeted against the generation of
copyrighted text. To tackle these challenges, we introduce a curated dataset to
evaluate methods, test attack strategies, and propose lightweight, real-time
defense to prevent the generation of copyrighted text, ensuring the safe and
lawful use of LLMs. Our experiments demonstrate that current LLMs frequently
output copyrighted text, and that jailbreaking attacks can significantly
increase the volume of copyrighted output. Our proposed defense mechanism
significantly reduces the volume of copyrighted text generated by LLMs by
effectively refusing malicious requests. Code is publicly available at
https://github.com/xz-liu/SHIELD"
Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts,https://arxiv.org/abs/2406.12845,2024-06-18,2024-06-21,0.0,0.0,"Reinforcement learning from human feedback (RLHF) has emerged as the primary
method for aligning large language models (LLMs) with human preferences. The
RLHF process typically starts by training a reward model (RM) using human
preference data. Conventional RMs are trained on pairwise responses to the same
user request, with relative ratings indicating which response humans prefer.
The trained RM serves as a proxy for human preferences. However, due to the
black-box nature of RMs, their outputs lack interpretability, as humans cannot
intuitively understand why an RM thinks a response is good or not. As RMs act
as human preference proxies, we believe they should be human-interpretable to
ensure that their internal decision processes are consistent with human
preferences and to prevent reward hacking in LLM alignment. To build RMs with
interpretable preferences, we propose a two-stage approach: i) train an
Absolute-Rating Multi-Objective Reward Model (ArmoRM) with multi-dimensional
absolute-rating data, each dimension corresponding to a human-interpretable
objective (e.g., honesty, verbosity, safety); ii) employ a Mixture-of-Experts
(MoE) strategy with a gating network that automatically selects the most
suitable reward objectives based on the context. We efficiently trained an
ArmoRM with Llama-3 8B and a gating network consisting of a shallow MLP on top
of the ArmoRM. Our trained model, ArmoRM-Llama3-8B, obtains state-of-the-art
performance on RewardBench, a benchmark evaluating RMs for language modeling.
Notably, the performance of our model surpasses the LLM-as-a-judge method with
GPT-4 judges by a margin, and approaches the performance of the much larger
Nemotron-4 340B reward model."
Synergizing Foundation Models and Federated Learning - A Survey,https://arxiv.org/abs/2406.12844,2024-06-18,2024-06-21,0.0,0.0,"The recent development of Foundation Models (FMs), represented by large
language models, vision transformers, and multimodal models, has been making a
significant impact on both academia and industry. Compared with small-scale
models, FMs have a much stronger demand for high-volume data during the
pre-training phase. Although general FMs can be pre-trained on data collected
from open sources such as the Internet, domain-specific FMs need proprietary
data, posing a practical challenge regarding the amount of data available due
to privacy concerns. Federated Learning (FL) is a collaborative learning
paradigm that breaks the barrier of data availability from different
participants. Therefore, it provides a promising solution to customize and
adapt FMs to a wide range of domain-specific tasks using distributed datasets
whilst preserving privacy. This survey paper discusses the potentials and
challenges of synergizing FL and FMs and summarizes core techniques, future
directions, and applications. A periodically updated paper collection on FM-FL
is available at https://github.com/lishenghui/awesome-fm-fl."
Demystifying Higher-Order Graph Neural Networks,https://arxiv.org/abs/2406.12841,2024-06-18,2024-06-21,0.0,0.0,"Higher-order graph neural networks (HOGNNs) are an important class of GNN
models that harness polyadic relations between vertices beyond plain edges.
They have been used to eliminate issues such as over-smoothing or
over-squashing, to significantly enhance the accuracy of GNN predictions, to
improve the expressiveness of GNN architectures, and for numerous other goals.
A plethora of HOGNN models have been introduced, and they come with diverse
neural architectures, and even with different notions of what the
""higher-order"" means. This richness makes it very challenging to appropriately
analyze and compare HOGNN models, and to decide in what scenario to use
specific ones. To alleviate this, we first design an in-depth taxonomy and a
blueprint for HOGNNs. This facilitates designing models that maximize
performance. Then, we use our taxonomy to analyze and compare the available
HOGNN models. The outcomes of our analysis are synthesized in a set of insights
that help to select the most beneficial GNN model in a given scenario, and a
comprehensive list of challenges and opportunities for further research into
more powerful HOGNNs."
Evaluating the design space of diffusion-based generative models,https://arxiv.org/abs/2406.12839,2024-06-18,2024-06-21,0.0,0.0,"Most existing theoretical investigations of the accuracy of diffusion models,
albeit significant, assume the score function has been approximated to a
certain accuracy, and then use this a priori bound to control the error of
generation. This article instead provides a first quantitative understanding of
the whole generation process, i.e., both training and sampling. More precisely,
it conducts a non-asymptotic convergence analysis of denoising score matching
under gradient descent. In addition, a refined sampling error analysis for
variance exploding models is also provided. The combination of these two
results yields a full error analysis, which elucidates (again, but this time
theoretically) how to design the training and sampling processes for effective
generation. For instance, our theory implies a preference toward noise
distribution and loss weighting in training that qualitatively agree with the
ones used in [Karras et al. 2022]. It also provides perspectives on the choices
of time and variance schedules in sampling: when the score is well trained, the
design in [Song et al. 2020] is more preferable, but when it is less trained,
the design in [Karras et al. 2022] becomes more preferable."
LayerMerge - Neural Network Depth Compression through Layer Pruning and Merging,https://arxiv.org/abs/2406.12837,2024-06-18,2024-06-21,0.0,0.0,"Recent works show that reducing the number of layers in a convolutional
neural network can enhance efficiency while maintaining the performance of the
network. Existing depth compression methods remove redundant non-linear
activation functions and merge the consecutive convolution layers into a single
layer. However, these methods suffer from a critical drawback; the kernel size
of the merged layers becomes larger, significantly undermining the latency
reduction gained from reducing the depth of the network. We show that this
problem can be addressed by jointly pruning convolution layers and activation
functions. To this end, we propose LayerMerge, a novel depth compression method
that selects which activation layers and convolution layers to remove, to
achieve a desired inference speed-up while minimizing performance loss. Since
the corresponding selection problem involves an exponential search space, we
formulate a novel surrogate optimization problem and efficiently solve it via
dynamic programming. Empirical results demonstrate that our method consistently
outperforms existing depth compression and layer pruning methods on various
network architectures, both on image classification and generation tasks. We
release the code at https://github.com/snu-mllab/LayerMerge."
Influence Maximization via Graph Neural Bandits,https://arxiv.org/abs/2406.12835,2024-06-18,2024-06-21,0.0,0.0,"We consider a ubiquitous scenario in the study of Influence Maximization
(IM), in which there is limited knowledge about the topology of the diffusion
network. We set the IM problem in a multi-round diffusion campaign, aiming to
maximize the number of distinct users that are influenced. Leveraging the
capability of bandit algorithms to effectively balance the objectives of
exploration and exploitation, as well as the expressivity of neural networks,
our study explores the application of neural bandit algorithms to the IM
problem. We propose the framework IM-GNB (Influence Maximization with Graph
Neural Bandits), where we provide an estimate of the users' probabilities of
being influenced by influencers (also known as diffusion seeds). This initial
estimate forms the basis for constructing both an exploitation graph and an
exploration one. Subsequently, IM-GNB handles the exploration-exploitation
tradeoff, by selecting seed nodes in real-time using Graph Convolutional
Networks (GCN), in which the pre-estimated graphs are employed to refine the
influencers' estimated rewards in each contextual setting. Through extensive
experiments on two large real-world datasets, we demonstrate the effectiveness
of IM-GNB compared with other baseline methods, significantly improving the
spread outcome of such diffusion campaigns, when the underlying network is
unknown."
LaMDA - Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation,https://arxiv.org/abs/2406.12832,2024-06-18,2024-06-21,0.0,0.0,"Low-rank adaptation (LoRA) has become the default approach to fine-tune large
language models (LLMs) due to its significant reduction in trainable
parameters. However, trainable parameter demand for LoRA increases with
increasing model embedding dimensions, leading to high compute costs.
Additionally, its backward updates require storing high-dimensional
intermediate activations and optimizer states, demanding high peak GPU memory.
In this paper, we introduce large model fine-tuning via spectrally decomposed
low-dimensional adaptation (LaMDA), a novel approach to fine-tuning large
language models, which leverages low-dimensional adaptation to achieve
significant reductions in trainable parameters and peak GPU memory footprint.
LaMDA freezes a first projection matrix (PMA) in the adaptation path while
introducing a low-dimensional trainable square matrix, resulting in substantial
reductions in trainable parameters and peak GPU memory usage. LaMDA gradually
freezes a second projection matrix (PMB) during the early fine-tuning stages,
reducing the compute cost associated with weight updates to enhance parameter
efficiency further. We also present an enhancement, LaMDA++, incorporating a
``lite-weight"" adaptive rank allocation for the LoRA path via normalized
spectrum analysis of pre-trained model weights. We evaluate LaMDA/LaMDA++
across various tasks, including natural language understanding with the GLUE
benchmark, text summarization, natural language generation, and complex
reasoning on different LLMs. Results show that LaMDA matches or surpasses the
performance of existing alternatives while requiring up to 17.7x fewer
parameter updates and up to 1.32x lower peak GPU memory usage during
fine-tuning. Code will be publicly available."
VIA - A Spatiotemporal Video Adaptation Framework for Global and Local Video Editing,https://arxiv.org/abs/2406.12831,2024-06-18,2024-06-21,0.0,0.0,"Video editing stands as a cornerstone of digital media, from entertainment
and education to professional communication. However, previous methods often
overlook the necessity of comprehensively understanding both global and local
contexts, leading to inaccurate and inconsistency edits in the spatiotemporal
dimension, especially for long videos. In this paper, we introduce VIA, a
unified spatiotemporal VIdeo Adaptation framework for global and local video
editing, pushing the limits of consistently editing minute-long videos. First,
to ensure local consistency within individual frames, the foundation of VIA is
a novel test-time editing adaptation method, which adapts a pre-trained image
editing model for improving consistency between potential editing directions
and the text instruction, and adapts masked latent variables for precise local
control. Furthermore, to maintain global consistency over the video sequence,
we introduce spatiotemporal adaptation that adapts consistent attention
variables in key frames and strategically applies them across the whole
sequence to realize the editing effects. Extensive experiments demonstrate
that, compared to baseline methods, our VIA approach produces edits that are
more faithful to the source videos, more coherent in the spatiotemporal
context, and more precise in local control. More importantly, we show that VIA
can achieve consistent long video editing in minutes, unlocking the potentials
for advanced video editing tasks over long video sequences."
What Are the Odds? Language Models Are Capable of Probabilistic Reasoning,https://arxiv.org/abs/2406.12830,2024-06-18,2024-06-21,0.0,0.0,"Language models (LM) are capable of remarkably complex linguistic tasks;
however, numerical reasoning is an area in which they frequently struggle. An
important but rarely evaluated form of reasoning is understanding probability
distributions. In this paper, we focus on evaluating the probabilistic
reasoning capabilities of LMs using idealized and real-world statistical
distributions. We perform a systematic evaluation of state-of-the-art LMs on
three tasks: estimating percentiles, drawing samples, and calculating
probabilities. We evaluate three ways to provide context to LMs 1) anchoring
examples from within a distribution or family of distributions, 2) real-world
context, 3) summary statistics on which to base a Normal approximation. Models
can make inferences about distributions, and can be further aided by the
incorporation of real-world context, example shots and simplified assumptions,
even if these assumptions are incorrect or misspecified. To conduct this work,
we developed a comprehensive benchmark distribution dataset with associated
question-answer pairs that we have released publicly."
From RAGs to rich parameters - Probing how language models utilize external knowledge over parametric information for factual queries,https://arxiv.org/abs/2406.12824,2024-06-18,2024-06-21,0.0,0.0,"Retrieval Augmented Generation (RAG) enriches the ability of language models
to reason using external context to augment responses for a given user prompt.
This approach has risen in popularity due to practical applications in various
applications of language models in search, question/answering, and chat-bots.
However, the exact nature of how this approach works isn't clearly understood.
In this paper, we mechanistically examine the RAG pipeline to highlight that
language models take shortcut and have a strong bias towards utilizing only the
context information to answer the question, while relying minimally on their
parametric memory. We probe this mechanistic behavior in language models with:
(i) Causal Mediation Analysis to show that the parametric memory is minimally
utilized when answering a question and (ii) Attention Contributions and
Knockouts to show that the last token residual stream do not get enriched from
the subject token in the question, but gets enriched from other informative
tokens in the context. We find this pronounced shortcut behaviour true across
both LLaMa and Phi family of models."
Neural Approximate Mirror Maps for Constrained Diffusion Models,https://arxiv.org/abs/2406.12816,2024-06-18,2024-06-21,0.0,0.0,"Diffusion models excel at creating visually-convincing images, but they often
struggle to meet subtle constraints inherent in the training data. Such
constraints could be physics-based (e.g., satisfying a PDE), geometric (e.g.,
respecting symmetry), or semantic (e.g., including a particular number of
objects). When the training data all satisfy a certain constraint, enforcing
this constraint on a diffusion model not only improves its
distribution-matching accuracy but also makes it more reliable for generating
valid synthetic data and solving constrained inverse problems. However,
existing methods for constrained diffusion models are inflexible with different
types of constraints. Recent work proposed to learn mirror diffusion models
(MDMs) in an unconstrained space defined by a mirror map and to impose the
constraint with an inverse mirror map, but analytical mirror maps are
challenging to derive for complex constraints. We propose neural approximate
mirror maps (NAMMs) for general constraints. Our approach only requires a
differentiable distance function from the constraint set. We learn an
approximate mirror map that pushes data into an unconstrained space and a
corresponding approximate inverse that maps data back to the constraint set. A
generative model, such as an MDM, can then be trained in the learned mirror
space and its samples restored to the constraint set by the inverse map. We
validate our approach on a variety of constraints, showing that compared to an
unconstrained diffusion model, a NAMM-based MDM substantially improves
constraint satisfaction. We also demonstrate how existing diffusion-based
inverse-problem solvers can be easily applied in the learned mirror space to
solve constrained inverse problems."
Adversarial Attacks on Multimodal Agents,https://arxiv.org/abs/2406.12814,2024-06-18,2024-06-21,0.0,0.0,"Vision-enabled language models (VLMs) are now used to build autonomous
multimodal agents capable of taking actions in real environments. In this
paper, we show that multimodal agents raise new safety risks, even though
attacking agents is more challenging than prior attacks due to limited access
to and knowledge about the environment. Our attacks use adversarial text
strings to guide gradient-based perturbation over one trigger image in the
environment: (1) our captioner attack attacks white-box captioners if they are
used to process images into captions as additional inputs to the VLM; (2) our
CLIP attack attacks a set of CLIP models jointly, which can transfer to
proprietary VLMs. To evaluate the attacks, we curated VisualWebArena-Adv, a set
of adversarial tasks based on VisualWebArena, an environment for web-based
multimodal agent tasks. Within an L-infinity norm of $16/256$ on a single
image, the captioner attack can make a captioner-augmented GPT-4V agent execute
the adversarial goals with a 75% success rate. When we remove the captioner or
use GPT-4V to generate its own captions, the CLIP attack can achieve success
rates of 21% and 43%, respectively. Experiments on agents based on other VLMs,
such as Gemini-1.5, Claude-3, and GPT-4o, show interesting differences in their
robustness. Further analysis reveals several key factors contributing to the
attack's success, and we also discuss the implications for defenses as well.
Project page: https://chenwu.io/attack-agent Code and data:
https://github.com/ChenWu98/agent-attack"
Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?,https://arxiv.org/abs/2406.12809,2024-06-18,2024-06-21,0.0,0.0,"Large language models (LLMs) have demonstrated impressive capabilities, but
still suffer from inconsistency issues (e.g. LLMs can react differently to
disturbances like rephrasing or inconsequential order change). In addition to
these inconsistencies, we also observe that LLMs, while capable of solving hard
problems, can paradoxically fail at easier ones. To evaluate this hard-to-easy
inconsistency, we develop the ConsisEval benchmark, where each entry comprises
a pair of questions with a strict order of difficulty. Furthermore, we
introduce the concept of consistency score to quantitatively measure this
inconsistency and analyze the potential for improvement in consistency by
relative consistency score. Based on comprehensive experiments across a variety
of existing models, we find: (1) GPT-4 achieves the highest consistency score
of 92.2\% but is still inconsistent to specific questions due to distraction by
redundant information, misinterpretation of questions, etc.; (2) models with
stronger capabilities typically exhibit higher consistency, but exceptions also
exist; (3) hard data enhances consistency for both fine-tuning and in-context
learning. Our data and code will be publicly available on GitHub."
Graph Neural Networks in Histopathology - Emerging Trends and Future Directions,https://arxiv.org/abs/2406.12808,2024-06-18,2024-06-21,0.0,0.0,"Histopathological analysis of Whole Slide Images (WSIs) has seen a surge in
the utilization of deep learning methods, particularly Convolutional Neural
Networks (CNNs). However, CNNs often fall short in capturing the intricate
spatial dependencies inherent in WSIs. Graph Neural Networks (GNNs) present a
promising alternative, adept at directly modeling pairwise interactions and
effectively discerning the topological tissue and cellular structures within
WSIs. Recognizing the pressing need for deep learning techniques that harness
the topological structure of WSIs, the application of GNNs in histopathology
has experienced rapid growth. In this comprehensive review, we survey GNNs in
histopathology, discuss their applications, and explore emerging trends that
pave the way for future advancements in the field. We begin by elucidating the
fundamentals of GNNs and their potential applications in histopathology.
Leveraging quantitative literature analysis, we identify four emerging trends:
Hierarchical GNNs, Adaptive Graph Structure Learning, Multimodal GNNs, and
Higher-order GNNs. Through an in-depth exploration of these trends, we offer
insights into the evolving landscape of GNNs in histopathological analysis.
Based on our findings, we propose future directions to propel the field
forward. Our analysis serves to guide researchers and practitioners towards
innovative approaches and methodologies, fostering advancements in
histopathological analysis through the lens of graph neural networks."
Identifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents,https://arxiv.org/abs/2406.12806,2024-06-18,2024-06-21,0.0,0.0,"Configuration settings are essential for tailoring software behavior to meet
specific performance requirements. However, incorrect configurations are
widespread, and identifying those that impact system performance is challenging
due to the vast number and complexity of possible settings. In this work, we
present PerfSense, a lightweight framework that leverages Large Language Models
(LLMs) to efficiently identify performance-sensitive configurations with
minimal overhead. PerfSense employs LLM agents to simulate interactions between
developers and performance engineers using advanced prompting techniques such
as prompt chaining and retrieval-augmented generation (RAG). Our evaluation of
seven open-source Java systems demonstrates that PerfSense achieves an average
accuracy of 64.77% in classifying performance-sensitive configurations,
outperforming both our LLM baseline (50.36%) and the previous state-of-the-art
method (61.75%). Notably, our prompt chaining technique improves recall by 10%
to 30% while maintaining similar precision levels. Additionally, a manual
analysis of 362 misclassifications reveals common issues, including LLMs'
misunderstandings of requirements (26.8%). In summary, PerfSense significantly
reduces manual effort in classifying performance-sensitive configurations and
offers valuable insights for future LLM-based code analysis research."
Scalable Rule Lists Learning with Sampling,https://arxiv.org/abs/2406.12803,2024-06-18,2024-06-21,0.0,0.0,"Learning interpretable models has become a major focus of machine learning
research, given the increasing prominence of machine learning in socially
important decision-making. Among interpretable models, rule lists are among the
best-known and easily interpretable ones. However, finding optimal rule lists
is computationally challenging, and current approaches are impractical for
large datasets.
  We present a novel and scalable approach to learn nearly optimal rule lists
from large datasets. Our algorithm uses sampling to efficiently obtain an
approximation of the optimal rule list with rigorous guarantees on the quality
of the approximation. In particular, our algorithm guarantees to find a rule
list with accuracy very close to the optimal rule list when a rule list with
high accuracy exists. Our algorithm builds on the VC-dimension of rule lists,
for which we prove novel upper and lower bounds. Our experimental evaluation on
large datasets shows that our algorithm identifies nearly optimal rule lists
with a speed-up up to two orders of magnitude over state-of-the-art exact
approaches. Moreover, our algorithm is as fast as, and sometimes faster than,
recent heuristic approaches, while reporting higher quality rule lists. In
addition, the rules reported by our algorithm are more similar to the rules in
the optimal rule list than the rules from heuristic approaches."
The Limits of Pure Exploration in POMDPs - When the Observation Entropy is Enough,https://arxiv.org/abs/2406.12795,2024-06-18,2024-06-21,0.0,0.0,"The problem of pure exploration in Markov decision processes has been cast as
maximizing the entropy over the state distribution induced by the agent's
policy, an objective that has been extensively studied. However, little
attention has been dedicated to state entropy maximization under partial
observability, despite the latter being ubiquitous in applications, e.g.,
finance and robotics, in which the agent only receives noisy observations of
the true state governing the system's dynamics. How can we address state
entropy maximization in those domains? In this paper, we study the simple
approach of maximizing the entropy over observations in place of true latent
states. First, we provide lower and upper bounds to the approximation of the
true state entropy that only depends on some properties of the observation
function. Then, we show how knowledge of the latter can be exploited to compute
a principled regularization of the observation entropy to improve performance.
With this work, we provide both a flexible approach to bring advances in state
entropy maximization to the POMDP setting and a theoretical characterization of
its intrinsic limits."
ChatGLM - A Family of Large Language Models from GLM-130B to GLM-4 All Tools,https://arxiv.org/abs/2406.12793,2024-06-18,2024-06-21,0.0,0.0,"We introduce ChatGLM, an evolving family of large language models that we
have been developing over time. This report primarily focuses on the GLM-4
language series, which includes GLM-4, GLM-4-Air, and GLM-4-9B. They represent
our most capable models that are trained with all the insights and lessons
gained from the preceding three generations of ChatGLM. To date, the GLM-4
models are pre-trained on ten trillions of tokens mostly in Chinese and
English, along with a small set of corpus from 24 languages, and aligned
primarily for Chinese and English usage. The high-quality alignment is achieved
via a multi-stage post-training process, which involves supervised fine-tuning
and learning from human feedback. Evaluations show that GLM-4 1) closely rivals
or outperforms GPT-4 in terms of general metrics such as MMLU, GSM8K, MATH,
BBH, GPQA, and HumanEval, 2) gets close to GPT-4-Turbo in instruction following
as measured by IFEval, 3) matches GPT-4 Turbo (128K) and Claude 3 for long
context tasks, and 4) outperforms GPT-4 in Chinese alignments as measured by
AlignBench. The GLM-4 All Tools model is further aligned to understand user
intent and autonomously decide when and which tool(s) touse -- including web
browser, Python interpreter, text-to-image model, and user-defined functions --
to effectively complete complex tasks. In practical applications, it matches
and even surpasses GPT-4 All Tools in tasks like accessing online information
via web browsing and solving math problems using Python interpreter. Over the
course, we have open-sourced a series of models, including ChatGLM-6B (three
generations), GLM-4-9B (128K, 1M), GLM-4V-9B, WebGLM, and CodeGeeX, attracting
over 10 million downloads on Hugging face in the year 2023 alone. The open
models can be accessed through https://github.com/THUDM and
https://huggingface.co/THUDM."
Generating Educational Materials with Different Levels of Readability using LLMs,https://arxiv.org/abs/2406.12787,2024-06-18,2024-06-21,0.0,0.0,"This study introduces the leveled-text generation task, aiming to rewrite
educational materials to specific readability levels while preserving meaning.
We assess the capability of GPT-3.5, LLaMA-2 70B, and Mixtral 8x7B, to generate
content at various readability levels through zero-shot and few-shot prompting.
Evaluating 100 processed educational materials reveals that few-shot prompting
significantly improves performance in readability manipulation and information
preservation. LLaMA-2 70B performs better in achieving the desired difficulty
range, while GPT-3.5 maintains original meaning. However, manual inspection
highlights concerns such as misinformation introduction and inconsistent edit
distribution. These findings emphasize the need for further research to ensure
the quality of generated educational content."
In-Context Learning of Energy Functions,https://arxiv.org/abs/2406.12785,2024-06-18,2024-06-21,0.0,0.0,"In-context learning is a powerful capability of certain machine learning
models that arguably underpins the success of today's frontier AI models.
However, in-context learning is critically limited to settings where the
in-context distribution of interest $p_{\theta}^{ICL}( x|\mathcal{D})$ can be
straightforwardly expressed and/or parameterized by the model; for instance,
language modeling relies on expressing the next-token distribution as a
categorical distribution parameterized by the network's output logits. In this
work, we present a more general form of in-context learning without such a
limitation that we call \textit{in-context learning of energy functions}. The
idea is to instead learn the unconstrained and arbitrary in-context energy
function $E_{\theta}^{ICL}(x|\mathcal{D})$ corresponding to the in-context
distribution $p_{\theta}^{ICL}(x|\mathcal{D})$. To do this, we use classic
ideas from energy-based modeling. We provide preliminary evidence that our
method empirically works on synthetic data. Interestingly, our work contributes
(to the best of our knowledge) the first example of in-context learning where
the input space and output space differ from one another, suggesting that
in-context learning is a more-general capability than previously realized."
UBENCH - Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions,https://arxiv.org/abs/2406.12784,2024-06-18,2024-06-21,0.0,0.0,"The rapid development of large language models (LLMs) has shown promising
practical results. However, their low interpretability often leads to errors in
unforeseen circumstances, limiting their utility. Many works have focused on
creating comprehensive evaluation systems, but previous benchmarks have
primarily assessed problem-solving abilities while neglecting the response's
uncertainty, which may result in unreliability. Recent methods for measuring
LLM reliability are resource-intensive and unable to test black-box models. To
address this, we propose UBENCH, a comprehensive benchmark for evaluating LLM
reliability. UBENCH includes 3,978 multiple-choice questions covering
knowledge, language, understanding, and reasoning abilities. Experimental
results show that UBENCH has achieved state-of-the-art performance, while its
single-sampling method significantly saves computational resources compared to
baseline methods that require multiple samplings. Additionally, based on
UBENCH, we evaluate the reliability of 15 popular LLMs, finding GLM4 to be the
most outstanding, closely followed by GPT-4. We also explore the impact of
Chain-of-Thought prompts, role-playing prompts, option order, and temperature
on LLM reliability, analyzing the varying effects on different LLMs."
Composited-Nested-Learning with Data Augmentation for Nested Named Entity Recognition,https://arxiv.org/abs/2406.12779,2024-06-18,2024-06-21,0.0,0.0,"Nested Named Entity Recognition (NNER) focuses on addressing overlapped
entity recognition. Compared to Flat Named Entity Recognition (FNER), annotated
resources are scarce in the corpus for NNER. Data augmentation is an effective
approach to address the insufficient annotated corpus. However, there is a
significant lack of exploration in data augmentation methods for NNER. Due to
the presence of nested entities in NNER, existing data augmentation methods
cannot be directly applied to NNER tasks. Therefore, in this work, we focus on
data augmentation for NNER and resort to more expressive structures,
Composited-Nested-Label Classification (CNLC) in which constituents are
combined by nested-word and nested-label, to model nested entities. The dataset
is augmented using the Composited-Nested-Learning (CNL). In addition, we
propose the Confidence Filtering Mechanism (CFM) for a more efficient selection
of generated data. Experimental results demonstrate that this approach results
in improvements in ACE2004 and ACE2005 and alleviates the impact of sample
imbalance."
Hopping Too Late - Exploring the Limitations of Large Language Models on Multi-Hop Queries,https://arxiv.org/abs/2406.12775,2024-06-18,2024-06-21,0.0,0.0,"Large language models (LLMs) can solve complex multi-step problems, but
little is known about how these computations are implemented internally.
Motivated by this, we study how LLMs answer multi-hop queries such as ""The
spouse of the performer of Imagine is"". These queries require two information
extraction steps: a latent one for resolving the first hop (""the performer of
Imagine"") into the bridge entity (John Lennon), and one for resolving the
second hop (""the spouse of John Lennon"") into the target entity (Yoko Ono).
Understanding how the latent step is computed internally is key to
understanding the overall computation. By carefully analyzing the internal
computations of transformer-based LLMs, we discover that the bridge entity is
resolved in the early layers of the model. Then, only after this resolution,
the two-hop query is solved in the later layers. Because the second hop
commences in later layers, there could be cases where these layers no longer
encode the necessary knowledge for correctly predicting the answer. Motivated
by this, we propose a novel ""back-patching"" analysis method whereby a hidden
representation from a later layer is patched back to an earlier layer. We find
that in up to 57% of previously incorrect cases there exists a back-patch that
results in the correct generation of the answer, showing that the later layers
indeed sometimes lack the needed functionality. Overall our methods and
findings open further opportunities for understanding and improving latent
reasoning in transformer-based LLMs."
Towards Exact Gradient-based Training on Analog In-memory Computing,https://arxiv.org/abs/2406.12774,2024-06-18,2024-06-21,0.0,0.0,"Given the high economic and environmental costs of using large vision or
language models, analog in-memory accelerators present a promising solution for
energy-efficient AI. While inference on analog accelerators has been studied
recently, the training perspective is underexplored. Recent studies have shown
that the ""workhorse"" of digital AI training - stochastic gradient descent (SGD)
algorithm converges inexactly when applied to model training on non-ideal
devices. This paper puts forth a theoretical foundation for gradient-based
training on analog devices. We begin by characterizing the non-convergent issue
of SGD, which is caused by the asymmetric updates on the analog devices. We
then provide a lower bound of the asymptotic error to show that there is a
fundamental performance limit of SGD-based analog training rather than an
artifact of our analysis. To address this issue, we study a heuristic analog
algorithm called Tiki-Taka that has recently exhibited superior empirical
performance compared to SGD and rigorously show its ability to exactly converge
to a critical point and hence eliminates the asymptotic error. The simulations
verify the correctness of the analyses."
First-Order Methods for Linearly Constrained Bilevel Optimization,https://arxiv.org/abs/2406.12771,2024-06-18,2024-06-21,0.0,0.0,"Algorithms for bilevel optimization often encounter Hessian computations,
which are prohibitive in high dimensions. While recent works offer first-order
methods for unconstrained bilevel problems, the constrained setting remains
relatively underexplored. We present first-order linearly constrained
optimization methods with finite-time hypergradient stationarity guarantees.
For linear equality constraints, we attain $\epsilon$-stationarity in
$\widetilde{O}(\epsilon^{-2})$ gradient oracle calls, which is nearly-optimal.
For linear inequality constraints, we attain $(\delta,\epsilon)$-Goldstein
stationarity in $\widetilde{O}(d{\delta^{-1} \epsilon^{-3}})$ gradient oracle
calls, where $d$ is the upper-level dimension. Finally, we obtain for the
linear inequality setting dimension-free rates of $\widetilde{O}({\delta^{-1}
\epsilon^{-4}})$ oracle complexity under the additional assumption of oracle
access to the optimal dual variable. Along the way, we develop new nonsmooth
nonconvex optimization methods with inexact oracles. We verify these guarantees
with preliminary numerical experiments."
Informatics & dairy industry coalition - AI trends and present challenges,https://arxiv.org/abs/2406.12770,2024-06-18,2024-06-21,0.0,0.0,"Artificial Intelligence (AI) can potentially transform the industry,
enhancing the production process and minimizing manual, repetitive tasks.
Accordingly, the synergy between high-performance computing and powerful
mathematical models enables the application of sophisticated data analysis
procedures like Machine Learning. However, challenges exist regarding
effective, efficient, and flexible processing to generate valuable knowledge.
Consequently, this work comprehensively describes industrial challenges where
AI can be exploited, focusing on the dairy industry. The conclusions presented
can help researchers apply novel approaches for cattle monitoring and farmers
by proposing advanced technological solutions to their needs."
Latent Intuitive Physics - Learning to Transfer Hidden Physics from A 3D Video,https://arxiv.org/abs/2406.12769,2024-06-18,2024-06-21,0.0,0.0,"We introduce latent intuitive physics, a transfer learning framework for
physics simulation that can infer hidden properties of fluids from a single 3D
video and simulate the observed fluid in novel scenes. Our key insight is to
use latent features drawn from a learnable prior distribution conditioned on
the underlying particle states to capture the invisible and complex physical
properties. To achieve this, we train a parametrized prior learner given visual
observations to approximate the visual posterior of inverse graphics, and both
the particle states and the visual posterior are obtained from a learned neural
renderer. The converged prior learner is embedded in our probabilistic physics
engine, allowing us to perform novel simulations on unseen geometries,
boundaries, and dynamics without knowledge of the true physical parameters. We
validate our model in three ways: (i) novel scene simulation with the learned
visual-world physics, (ii) future prediction of the observed fluid dynamics,
and (iii) supervised particle simulation. Our model demonstrates strong
performance in all three tasks."
Quasi-Bayes meets Vines,https://arxiv.org/abs/2406.12764,2024-06-18,2024-06-21,0.0,0.0,"Recently proposed quasi-Bayesian (QB) methods initiated a new era in Bayesian
computation by directly constructing the Bayesian predictive distribution
through recursion, removing the need for expensive computations involved in
sampling the Bayesian posterior distribution. This has proved to be
data-efficient for univariate predictions, but extensions to multiple
dimensions rely on a conditional decomposition resulting from predefined
assumptions on the kernel of the Dirichlet Process Mixture Model, which is the
implicit nonparametric model used. Here, we propose a different way to extend
Quasi-Bayesian prediction to high dimensions through the use of Sklar's theorem
by decomposing the predictive distribution into one-dimensional predictive
marginals and a high-dimensional copula. Thus, we use the efficient recursive
QB construction for the one-dimensional marginals and model the dependence
using highly expressive vine copulas. Further, we tune hyperparameters using
robust divergences (eg. energy score) and show that our proposed Quasi-Bayesian
Vine (QB-Vine) is a fully non-parametric density estimator with \emph{an
analytical form} and convergence rate independent of the dimension of data in
some situations. Our experiments illustrate that the QB-Vine is appropriate for
high dimensional distributions ($\sim$64), needs very few samples to train
($\sim$200) and outperforms state-of-the-art methods with analytical forms for
density estimation and supervised tasks by a considerable margin."
Implicit Bias of Mirror Flow on Separable Data,https://arxiv.org/abs/2406.12763,2024-06-18,2024-06-21,0.0,0.0,"We examine the continuous-time counterpart of mirror descent, namely mirror
flow, on classification problems which are linearly separable. Such problems
are minimised `at infinity' and have many possible solutions; we study which
solution is preferred by the algorithm depending on the mirror potential. For
exponential tailed losses and under mild assumptions on the potential, we show
that the iterates converge in direction towards a $\phi_\infty$-maximum margin
classifier. The function $\phi_\infty$ is the $\textit{horizon function}$ of
the mirror potential and characterises its shape `at infinity'. When the
potential is separable, a simple formula allows to compute this function. We
analyse several examples of potentials and provide numerical experiments
highlighting our results."
Unsupervised explainable activity prediction in competitive Nordic Walking from experimental data,https://arxiv.org/abs/2406.12762,2024-06-18,2024-06-21,0.0,0.0,"Artificial Intelligence (AI) has found application in Human Activity
Recognition (HAR) in competitive sports. To date, most Machine Learning (ML)
approaches for HAR have relied on offline (batch) training, imposing higher
computational and tagging burdens compared to online processing unsupervised
approaches. Additionally, the decisions behind traditional ML predictors are
opaque and require human interpretation. In this work, we apply an online
processing unsupervised clustering approach based on low-cost wearable Inertial
Measurement Units (IMUs). The outcomes generated by the system allow for the
automatic expansion of limited tagging available (e.g., by referees) within
those clusters, producing pertinent information for the explainable
classification stage. Specifically, our work focuses on achieving automatic
explainability for predictions related to athletes' activities, distinguishing
between correct, incorrect, and cheating practices in Nordic Walking. The
proposed solution achieved performance metrics of close to 100 % on average."
GFM4MPM - Towards Geospatial Foundation Models for Mineral Prospectivity Mapping,https://arxiv.org/abs/2406.12756,2024-06-18,2024-06-21,0.0,0.0,"Machine Learning (ML) for Mineral Prospectivity Mapping (MPM) remains a
challenging problem as it requires the analysis of associations between
large-scale multi-modal geospatial data and few historical mineral commodity
observations (positive labels). Recent MPM works have explored Deep Learning
(DL) as a modeling tool with more representation capacity. However, these
overparameterized methods may be more prone to overfitting due to their
reliance on scarce labeled data. While a large quantity of unlabeled geospatial
data exists, no prior MPM works have considered using such information in a
self-supervised manner. Our MPM approach uses a masked image modeling framework
to pretrain a backbone neural network in a self-supervised manner using
unlabeled geospatial data alone. After pretraining, the backbone network
provides feature extraction for downstream MPM tasks. We evaluated our approach
alongside existing methods to assess mineral prospectivity of Mississippi
Valley Type (MVT) and Clastic-Dominated (CD) Lead-Zinc deposits in North
America and Australia. Our results demonstrate that self-supervision promotes
robustness in learned features, improving prospectivity predictions.
Additionally, we leverage explainable artificial intelligence techniques to
demonstrate that individual predictions can be interpreted from a geological
perspective."
Chumor 1.0 - A Truly Funny and Challenging Chinese Humor Understanding Dataset from Ruo Zhi Ba,https://arxiv.org/abs/2406.12754,2024-06-18,2024-06-21,0.0,0.0,"Existing humor datasets and evaluations predominantly focus on English,
lacking resources for culturally nuanced humor in non-English languages like
Chinese. To address this gap, we construct Chumor, a dataset sourced from Ruo
Zhi Ba (RZB), a Chinese Reddit-like platform dedicated to sharing
intellectually challenging and culturally specific jokes. We annotate
explanations for each joke and evaluate human explanations against two
state-of-the-art LLMs, GPT-4o and ERNIE Bot, through A/B testing by native
Chinese speakers. Our evaluation shows that Chumor is challenging even for SOTA
LLMs, and the human explanations for Chumor jokes are significantly better than
explanations generated by the LLMs."
OlympicArena - Benchmarking Multi-discipline Cognitive Reasoning for Superintelligent AI,https://arxiv.org/abs/2406.12753,2024-06-18,2024-06-21,0.0,0.0,"The evolution of Artificial Intelligence (AI) has been significantly
accelerated by advancements in Large Language Models (LLMs) and Large
Multimodal Models (LMMs), gradually showcasing potential cognitive reasoning
abilities in problem-solving and scientific discovery (i.e., AI4Science) once
exclusive to human intellect. To comprehensively evaluate current models'
performance in cognitive reasoning abilities, we introduce OlympicArena, which
includes 11,163 bilingual problems across both text-only and interleaved
text-image modalities. These challenges encompass a wide range of disciplines
spanning seven fields and 62 international Olympic competitions, rigorously
examined for data leakage. We argue that the challenges in Olympic competition
problems are ideal for evaluating AI's cognitive reasoning due to their
complexity and interdisciplinary nature, which are essential for tackling
complex scientific challenges and facilitating discoveries. Beyond evaluating
performance across various disciplines using answer-only criteria, we conduct
detailed experiments and analyses from multiple perspectives. We delve into the
models' cognitive reasoning abilities, their performance across different
modalities, and their outcomes in process-level evaluations, which are vital
for tasks requiring complex reasoning with lengthy solutions. Our extensive
evaluations reveal that even advanced models like GPT-4o only achieve a 39.97%
overall accuracy, illustrating current AI limitations in complex reasoning and
multimodal integration. Through the OlympicArena, we aim to advance AI towards
superintelligence, equipping it to address more complex challenges in science
and beyond. We also provide a comprehensive set of resources to support AI
research, including a benchmark dataset, an open-source annotation platform, a
detailed evaluation tool, and a leaderboard with automatic submission features."
Extracting Training Data from Unconditional Diffusion Models,https://arxiv.org/abs/2406.12752,2024-06-18,2024-06-21,0.0,0.0,"As diffusion probabilistic models (DPMs) are being employed as mainstream
models for generative artificial intelligence (AI), the study of their
memorization of the raw training data has attracted growing attention. Existing
works in this direction aim to establish an understanding of whether or to what
extent DPMs learn by memorization. Such an understanding is crucial for
identifying potential risks of data leakage and copyright infringement in
diffusion models and, more importantly, for more controllable generation and
trustworthy application of Artificial Intelligence Generated Content (AIGC).
While previous works have made important observations of when DPMs are prone to
memorization, these findings are mostly empirical, and the developed data
extraction methods only work for conditional diffusion models. In this work, we
aim to establish a theoretical understanding of memorization in DPMs with 1) a
memorization metric for theoretical analysis, 2) an analysis of conditional
memorization with informative and random labels, and 3) two better evaluation
metrics for measuring memorization. Based on the theoretical analysis, we
further propose a novel data extraction method called \textbf{Surrogate
condItional Data Extraction (SIDE)} that leverages a classifier trained on
generated data as a surrogate condition to extract training data directly from
unconditional diffusion models. Our empirical results demonstrate that SIDE can
extract training data from diffusion models where previous methods fail, and it
is on average over 50\% more effective across different scales of the CelebA
dataset."
TSI-Bench - Benchmarking Time Series Imputation,https://arxiv.org/abs/2406.12747,2024-06-18,2024-06-21,0.0,0.0,"Effective imputation is a crucial preprocessing step for time series
analysis. Despite the development of numerous deep learning algorithms for time
series imputation, the community lacks standardized and comprehensive benchmark
platforms to effectively evaluate imputation performance across different
settings. Moreover, although many deep learning forecasting algorithms have
demonstrated excellent performance, whether their modeling achievements can be
transferred to time series imputation tasks remains unexplored. To bridge these
gaps, we develop TSI-Bench, the first (to our knowledge) comprehensive
benchmark suite for time series imputation utilizing deep learning techniques.
The TSI-Bench pipeline standardizes experimental settings to enable fair
evaluation of imputation algorithms and identification of meaningful insights
into the influence of domain-appropriate missingness ratios and patterns on
model performance. Furthermore, TSI-Bench innovatively provides a systematic
paradigm to tailor time series forecasting algorithms for imputation purposes.
Our extensive study across 34,804 experiments, 28 algorithms, and 8 datasets
with diverse missingness scenarios demonstrates TSI-Bench's effectiveness in
diverse downstream tasks and potential to unlock future directions in time
series imputation research and analysis. The source code and experiment logs
are available at https://github.com/WenjieDu/AwesomeImputation."
Rationale-based Ensemble of Multiple QA Strategies for Zero-shot Knowledge-based VQA,https://arxiv.org/abs/2406.12746,2024-06-18,2024-06-21,0.0,0.0,"Knowledge-based Visual Qustion-answering (K-VQA) necessitates the use of
background knowledge beyond what is depicted in the image. Current zero-shot
K-VQA methods usually translate an image to a single type of textual decision
context and use a text-based model to answer the question based on it, which
conflicts with the fact that K-VQA questions often require the combination of
multiple question-answering strategies. In light of this, we propose
Rationale-based Ensemble of Answer Context Tactics (REACT) to achieve a dynamic
ensemble of multiple question-answering tactics, comprising Answer Candidate
Generation (ACG) and Rationale-based Strategy Fusion (RSF). In ACG, we generate
three distinctive decision contexts to provide different strategies for each
question, resulting in the generation of three answer candidates. RSF generates
automatic and mechanistic rationales from decision contexts for each candidate,
allowing the model to select the correct answer from all candidates. We conduct
comprehensive experiments on the OK-VQA and A-OKVQA datasets, and our method
significantly outperforms state-of-the-art LLM-based baselines on all datasets."
Ensuring Both Positivity and Stability Using Sector-Bounded Nonlinearity for Systems with Neural Network Controllers,https://arxiv.org/abs/2406.12744,2024-06-18,2024-06-21,0.0,0.0,"This paper introduces a novel method for the stability analysis of positive
feedback systems with a class of fully connected feedforward neural networks
(FFNN) controllers. By establishing sector bounds for fully connected FFNNs
without biases, we present a stability theorem that demonstrates the global
exponential stability of linear systems under fully connected FFNN control.
Utilizing principles from positive Lur'e systems and the positive Aizerman
conjecture, our approach effectively addresses the challenge of ensuring
stability in highly nonlinear systems. The crux of our method lies in
maintaining sector bounds that preserve the positivity and Hurwitz property of
the overall Lur'e system. We showcase the practical applicability of our
methodology through its implementation in a linear system managed by a FFNN
trained on output feedback controller data, highlighting its potential for
enhancing stability in dynamic systems."
"Benchmarking Multi-Image Understanding in Vision and Language Models - Perception, Knowledge, Reasoning, and Multi-Hop Reasoning",https://arxiv.org/abs/2406.12742,2024-06-18,2024-06-21,0.0,0.0,"The advancement of large language models (LLMs) has significantly broadened
the scope of applications in natural language processing, with multi-modal LLMs
extending these capabilities to integrate and interpret visual data. However,
existing benchmarks for visual language models (VLMs) predominantly focus on
single-image inputs, neglecting the crucial aspect of multi-image
understanding. In this paper, we introduce a Multi-Image Relational Benchmark
MIRB, designed to evaluate VLMs' ability to compare, analyze, and reason across
multiple images. Our benchmark encompasses four categories: perception, visual
world knowledge, reasoning, and multi-hop reasoning. Through a comprehensive
evaluation of a wide range of open-source and closed-source models, we
demonstrate that while open-source VLMs were shown to approach the performance
of GPT-4V in single-image tasks, a significant performance gap remains in
multi-image reasoning tasks. Our findings also reveal that even the
state-of-the-art GPT-4V model struggles with our benchmark, underscoring the
need for further research and development in this area. We believe our
contribution of MIRB could serve as a testbed for developing the
next-generation multi-modal models."
Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages,https://arxiv.org/abs/2406.12739,2024-06-18,2024-06-21,0.0,0.0,"LLMs have become a go-to solution not just for text generation, but also for
natural language understanding (NLU) tasks. Acquiring extensive knowledge
through language modeling on web-scale corpora, they excel on English NLU, yet
struggle to extend their NLU capabilities to underrepresented languages. In
contrast, machine translation models (MT) produce excellent multilingual
representations, resulting in strong translation performance even for
low-resource languages. MT encoders, however, lack the knowledge necessary for
comprehensive NLU that LLMs obtain through language modeling training on
immense corpora. In this work, we get the best both worlds by integrating MT
encoders directly into LLM backbones via sample-efficient self-distillation.
The resulting MT-LLMs preserve the inherent multilingual representational
alignment from the MT encoder, allowing lower-resource languages to tap into
the rich knowledge embedded in English-centric LLMs. Merging the MT encoder and
LLM in a single model, we mitigate the propagation of translation errors and
inference overhead of MT decoding inherent to discrete translation-based
cross-lingual transfer (e.g., translate-test). Evaluation spanning three
prominent NLU tasks and 127 predominantly low-resource languages renders
MT-LLMs highly effective in cross-lingual transfer. MT-LLMs substantially and
consistently outperform translate-test based on the same MT model, showing that
we truly unlock multilingual language understanding for LLMs."
Large Language Model as a Universal Clinical Multi-task Decoder,https://arxiv.org/abs/2406.12738,2024-06-18,2024-06-21,0.0,0.0,"The development of effective machine learning methodologies for enhancing the
efficiency and accuracy of clinical systems is crucial. Despite significant
research efforts, managing a plethora of diversified clinical tasks and
adapting to emerging new tasks remain significant challenges. This paper
presents a novel paradigm that employs a pre-trained large language model as a
universal clinical multi-task decoder. This approach leverages the flexibility
and diversity of language expressions to handle task topic variations and
associated arguments. The introduction of a new task simply requires the
addition of a new instruction template. We validate this framework across
hundreds of tasks, demonstrating its robustness in facilitating multi-task
predictions, performing on par with traditional multi-task learning and
single-task learning approaches. Moreover, it shows exceptional adaptability to
new tasks, with impressive zero-shot performance in some instances and superior
data efficiency in few-shot scenarios. This novel approach offers a unified
solution to manage a wide array of new and emerging tasks in clinical
applications."
Beyond Visual Appearances - Privacy-sensitive Objects Identification via Hybrid Graph Reasoning,https://arxiv.org/abs/2406.12736,2024-06-18,2024-06-21,0.0,0.0,"The Privacy-sensitive Object Identification (POI) task allocates bounding
boxes for privacy-sensitive objects in a scene. The key to POI is settling an
object's privacy class (privacy-sensitive or non-privacy-sensitive). In
contrast to conventional object classes which are determined by the visual
appearance of an object, one object's privacy class is derived from the scene
contexts and is subject to various implicit factors beyond its visual
appearance. That is, visually similar objects may be totally opposite in their
privacy classes. To explicitly derive the objects' privacy class from the scene
contexts, in this paper, we interpret the POI task as a visual reasoning task
aimed at the privacy of each object in the scene. Following this
interpretation, we propose the PrivacyGuard framework for POI. PrivacyGuard
contains three stages. i) Structuring: an unstructured image is first converted
into a structured, heterogeneous scene graph that embeds rich scene contexts.
ii) Data Augmentation: a contextual perturbation oversampling strategy is
proposed to create slightly perturbed privacy-sensitive objects in a scene
graph, thereby balancing the skewed distribution of privacy classes. iii)
Hybrid Graph Generation & Reasoning: the balanced, heterogeneous scene graph is
then transformed into a hybrid graph by endowing it with extra ""node-node"" and
""edge-edge"" homogeneous paths. These homogeneous paths allow direct message
passing between nodes or edges, thereby accelerating reasoning and facilitating
the capturing of subtle context changes. Based on this hybrid graph... **For
the full abstract, see the original paper.**"
Automatic generation of insights from workers' actions in industrial workflows with explainable Machine Learning,https://arxiv.org/abs/2406.12732,2024-06-18,2024-06-21,0.0,0.0,"New technologies such as Machine Learning (ML) gave great potential for
evaluating industry workflows and automatically generating key performance
indicators (KPIs). However, despite established standards for measuring the
efficiency of industrial machinery, there is no precise equivalent for workers'
productivity, which would be highly desirable given the lack of a skilled
workforce for the next generation of industry workflows. Therefore, an ML
solution combining data from manufacturing processes and workers' performance
for that goal is required. Additionally, in recent times intense effort has
been devoted to explainable ML approaches that can automatically explain their
decisions to a human operator, thus increasing their trustworthiness. We
propose to apply explainable ML solutions to differentiate between expert and
inexpert workers in industrial workflows, which we validate at a quality
assessment industrial workstation. Regarding the methodology used, input data
are captured by a manufacturing machine and stored in a NoSQL database. Data
are processed to engineer features used in automatic classification and to
compute workers' KPIs to predict their level of expertise (with all
classification metrics exceeding 90 %). These KPIs, and the relevant features
in the decisions are textually explained by natural language expansion on an
explainability dashboard. These automatic explanations made it possible to
infer knowledge from expert workers for inexpert workers. The latter
illustrates the interest of research in self-explainable ML for automatically
generating insights to improve productivity in industrial workflows."
Predicting the energetic proton flux with a machine learning regression algorithm,https://arxiv.org/abs/2406.12730,2024-06-18,2024-06-21,0.0,0.0,"The need of real-time of monitoring and alerting systems for Space Weather
hazards has grown significantly in the last two decades. One of the most
important challenge for space mission operations and planning is the prediction
of solar proton events (SPEs). In this context, artificial intelligence and
machine learning techniques have opened a new frontier, providing a new
paradigm for statistical forecasting algorithms. The great majority of these
models aim to predict the occurrence of a SPE, i.e., they are based on the
classification approach. In this work we present a simple and efficient machine
learning regression algorithm which is able to forecast the energetic proton
flux up to 1 hour ahead by exploiting features derived from the electron flux
only. This approach could be helpful to improve monitoring systems of the
radiation risk in both deep space and near-Earth environments. The model is
very relevant for mission operations and planning, especially when flare
characteristics and source location are not available in real time, as at Mars
distance."
Can Large Language Models Code Like a Linguist? - A Case Study in Low Resource Sound Law Induction,https://arxiv.org/abs/2406.12725,2024-06-18,2024-06-21,0.0,0.0,"Historical linguists have long written a kind of incompletely formalized
''program'' that converts reconstructed words in an ancestor language into
words in one of its attested descendants that consist of a series of ordered
string rewrite functions (called sound laws). They do this by observing pairs
of words in the reconstructed language (protoforms) and the descendent language
(reflexes) and constructing a program that transforms protoforms into reflexes.
However, writing these programs is error-prone and time-consuming. Prior work
has successfully scaffolded this process computationally, but fewer researchers
have tackled Sound Law Induction (SLI), which we approach in this paper by
casting it as Programming by Examples. We propose a language-agnostic solution
that utilizes the programming ability of Large Language Models (LLMs) by
generating Python sound law programs from sound change examples. We evaluate
the effectiveness of our approach for various LLMs, propose effective methods
to generate additional language-agnostic synthetic data to fine-tune LLMs for
SLI, and compare our method with existing automated SLI methods showing that
while LLMs lag behind them they can complement some of their weaknesses."
BIOSCAN-5M - A Multimodal Dataset for Insect Biodiversity,https://arxiv.org/abs/2406.12723,2024-06-18,2024-06-21,0.0,0.0,"As part of an ongoing worldwide effort to comprehend and monitor insect
biodiversity, this paper presents the BIOSCAN-5M Insect dataset to the machine
learning community and establish several benchmark tasks. BIOSCAN-5M is a
comprehensive dataset containing multi-modal information for over 5 million
insect specimens, and it significantly expands existing image-based biological
datasets by including taxonomic labels, raw nucleotide barcode sequences,
assigned barcode index numbers, and geographical information. We propose three
benchmark experiments to demonstrate the impact of the multi-modal data types
on the classification and clustering accuracy. First, we pretrain a masked
language model on the DNA barcode sequences of the BIOSCAN-5M dataset, and
demonstrate the impact of using this large reference library on species- and
genus-level classification performance. Second, we propose a zero-shot transfer
learning task applied to images and DNA barcodes to cluster feature embeddings
obtained from self-supervised learning, to investigate whether meaningful
clusters can be derived from these representation embeddings. Third, we
benchmark multi-modality by performing contrastive learning on DNA barcodes,
image data, and taxonomic information. This yields a general shared embedding
space enabling taxonomic classification using multiple types of information and
modalities. The code repository of the BIOSCAN-5M Insect dataset is available
at https://github.com/zahrag/BIOSCAN-5M."
On the Robustness of Language Models for Tabular Question Answering,https://arxiv.org/abs/2406.12719,2024-06-18,2024-06-21,0.0,0.0,"Large Language Models (LLMs), originally shown to ace various text
comprehension tasks have also remarkably been shown to tackle table
comprehension tasks without specific training. While previous research has
explored LLM capabilities with tabular dataset tasks, our study assesses the
influence of $\textit{in-context learning}$,$ \textit{model scale}$,
$\textit{instruction tuning}$, and $\textit{domain biases}$ on Tabular Question
Answering (TQA). We evaluate the robustness of LLMs on Wikipedia-based
$\textbf{WTQ}$ and financial report-based $\textbf{TAT-QA}$ TQA datasets,
focusing on their ability to robustly interpret tabular data under various
augmentations and perturbations. Our findings indicate that instructions
significantly enhance performance, with recent models like Llama3 exhibiting
greater robustness over earlier versions. However, data contamination and
practical reliability issues persist, especially with WTQ. We highlight the
need for improved methodologies, including structure-aware self-attention
mechanisms and better handling of domain-specific tabular data, to develop more
reliable LLMs for table comprehension."
AGLA - Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention,https://arxiv.org/abs/2406.12718,2024-06-18,2024-06-21,0.0,0.0,"Despite their great success across various multimodal tasks, Large
Vision-Language Models (LVLMs) are facing a prevalent problem with object
hallucinations, where the generated textual responses are inconsistent with
ground-truth objects in the given image. This paper investigates various LVLMs
and pinpoints attention deficiency toward discriminative local image features
as one root cause of object hallucinations. Specifically, LVLMs predominantly
attend to prompt-independent global image features, while failing to capture
prompt-relevant local features, consequently undermining the visual grounding
capacity of LVLMs and leading to hallucinations. To this end, we propose
Assembly of Global and Local Attention (AGLA), a training-free and
plug-and-play approach that mitigates object hallucinations by exploring an
ensemble of global features for response generation and local features for
visual discrimination simultaneously. Our approach exhibits an image-prompt
matching scheme that captures prompt-relevant local features from images,
leading to an augmented view of the input image where prompt-relevant content
is reserved while irrelevant distractions are masked. With the augmented view,
a calibrated decoding distribution can be derived by integrating generative
global features from the original image and discriminative local features from
the augmented image. Extensive experiments show that AGLA consistently
mitigates object hallucinations and enhances general perception capability for
LVLMs across various discriminative and generative benchmarks. Our code will be
released at https://github.com/Lackel/AGLA."
Enhancing Spatio-temporal Quantile Forecasting with Curriculum Learning - Lessons Learned,https://arxiv.org/abs/2406.12709,2024-06-18,2024-06-21,0.0,0.0,"Training models on spatio-temporal (ST) data poses an open problem due to the
complicated and diverse nature of the data itself, and it is challenging to
ensure the model's performance directly trained on the original ST data. While
limiting the variety of training data can make training easier, it can also
lead to a lack of knowledge and information for the model, resulting in a
decrease in performance. To address this challenge, we presented an innovative
paradigm that incorporates three separate forms of curriculum learning
specifically targeting from spatial, temporal, and quantile perspectives.
Furthermore, our framework incorporates a stacking fusion module to combine
diverse information from three types of curriculum learning, resulting in a
strong and thorough learning process. We demonstrated the effectiveness of this
framework with extensive empirical evaluations, highlighting its better
performance in addressing complex ST challenges. We provided thorough ablation
studies to investigate the effectiveness of our curriculum and to explain how
it contributes to the improvement of learning efficiency on ST data."
AgentReview - Exploring Peer Review Dynamics with LLM Agents,https://arxiv.org/abs/2406.12708,2024-06-18,2024-06-21,0.0,0.0,"Peer review is fundamental to the integrity and advancement of scientific
publication. Traditional methods of peer review analyses often rely on
exploration and statistics of existing peer review data, which do not
adequately address the multivariate nature of the process, account for the
latent variables, and are further constrained by privacy concerns due to the
sensitive nature of the data. We introduce AgentReview, the first large
language model (LLM) based peer review simulation framework, which effectively
disentangles the impacts of multiple latent factors and addresses the privacy
issue. Our study reveals significant insights, including a notable 37.1%
variation in paper decisions due to reviewers' biases, supported by
sociological theories such as the social influence theory, altruism fatigue,
and authority bias. We believe that this study could offer valuable insights to
improve the design of peer review mechanisms."
Talk With Human-like Agents - Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction,https://arxiv.org/abs/2406.12707,2024-06-18,2024-06-21,0.0,0.0,"Large Language Model (LLM)-enhanced agents become increasingly prevalent in
Human-AI communication, offering vast potential from entertainment to
professional domains. However, current multi-modal dialogue systems overlook
the acoustic information present in speech, which is crucial for understanding
human communication nuances. This oversight can lead to misinterpretations of
speakers' intentions, resulting in inconsistent or even contradictory responses
within dialogues. To bridge this gap, in this paper, we propose
PerceptiveAgent, an empathetic multi-modal dialogue system designed to discern
deeper or more subtle meanings beyond the literal interpretations of words
through the integration of speech modality perception. Employing LLMs as a
cognitive core, PerceptiveAgent perceives acoustic information from input
speech and generates empathetic responses based on speaking styles described in
natural language. Experimental results indicate that PerceptiveAgent excels in
contextual understanding by accurately discerning the speakers' true intentions
in scenarios where the linguistic meaning is either contrary to or inconsistent
with the speaker's true feelings, producing more nuanced and expressive spoken
dialogues. Code is publicly available at:
\url{https://github.com/Haoqiu-Yan/PerceptiveAgent}."
Jailbreak Paradox - The Achilles' Heel of LLMs,https://arxiv.org/abs/2406.12702,2024-06-18,2024-06-21,0.0,0.0,"We introduce two paradoxes concerning jailbreak of foundation models: First,
it is impossible to construct a perfect jailbreak classifier, and second, a
weaker model cannot consistently detect whether a stronger (in a
pareto-dominant sense) model is jailbroken or not. We provide formal proofs for
these paradoxes and a short case study on Llama and GPT4-o to demonstrate this.
We discuss broader theoretical and practical repercussions of these results."
SUPER - Selfie Undistortion and Head Pose Editing with Identity Preservation,https://arxiv.org/abs/2406.12700,2024-06-18,2024-06-21,0.0,0.0,"Self-portraits captured from a short distance might look unnatural or even
unattractive due to heavy distortions making facial features malformed, and
ill-placed head poses. In this paper, we propose SUPER, a novel method of
eliminating distortions and adjusting head pose in a close-up face crop. We
perform 3D GAN inversion for a facial image by optimizing camera parameters and
face latent code, which gives a generated image. Besides, we estimate depth
from the obtained latent code, create a depth-induced 3D mesh, and render it
with updated camera parameters to obtain a warped portrait. Finally, we apply
the visibility-based blending so that visible regions are reprojected, and
occluded parts are restored with a generative model. Experiments on face
undistortion benchmarks and on our self-collected Head Rotation dataset (HeRo),
show that SUPER outperforms previous approaches both qualitatively and
quantitatively, opening new possibilities for photorealistic selfie editing."
XXLTraffic - Expanding and Extremely Long Traffic Dataset for Ultra-Dynamic Forecasting Challenges,https://arxiv.org/abs/2406.12693,2024-06-18,2024-06-21,0.0,0.0,"Traffic forecasting is crucial for smart cities and intelligent
transportation initiatives, where deep learning has made significant progress
in modeling complex spatio-temporal patterns in recent years. However, current
public datasets have limitations in reflecting the ultra-dynamic nature of
real-world scenarios, characterized by continuously evolving infrastructures,
varying temporal distributions, and temporal gaps due to sensor downtimes or
changes in traffic patterns. These limitations inevitably restrict the
practical applicability of existing traffic forecasting datasets. To bridge
this gap, we present XXLTraffic, the largest available public traffic dataset
with the longest timespan and increasing number of sensor nodes over the
multiple years observed in the data, curated to support research in
ultra-dynamic forecasting. Our benchmark includes both typical time-series
forecasting settings with hourly and daily aggregated data and novel
configurations that introduce gaps and down-sample the training size to better
simulate practical constraints. We anticipate the new XXLTraffic will provide a
fresh perspective for the time-series and traffic forecasting communities. It
would also offer a robust platform for developing and evaluating models
designed to tackle ultra-dynamic and extremely long forecasting problems. Our
dataset supplements existing spatio-temporal data resources and leads to new
research directions in this domain."
MAGIC - Generating Self-Correction Guideline for In-Context Text-to-SQL,https://arxiv.org/abs/2406.12692,2024-06-18,2024-06-21,0.0,0.0,"Self-correction in text-to-SQL is the process of prompting large language
model (LLM) to revise its previously incorrectly generated SQL, and commonly
relies on manually crafted self-correction guidelines by human experts that are
not only labor-intensive to produce but also limited by the human ability in
identifying all potential error patterns in LLM responses. We introduce MAGIC,
a novel multi-agent method that automates the creation of the self-correction
guideline. MAGIC uses three specialized agents: a manager, a correction, and a
feedback agent. These agents collaborate on the failures of an LLM-based method
on the training set to iteratively generate and refine a self-correction
guideline tailored to LLM mistakes, mirroring human processes but without human
involvement. Our extensive experiments show that MAGIC's guideline outperforms
expert human's created ones. We empirically find out that the guideline
produced by MAGIC enhance the interpretability of the corrections made,
providing insights in analyzing the reason behind the failures and successes of
LLMs in self-correction. We make all agent interactions publicly available to
the research community, to foster further research in this area, offering a
synthetic dataset for future explorations into automatic self-correction
guideline generation."
Using LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia,https://arxiv.org/abs/2406.12687,2024-06-18,2024-06-21,0.0,0.0,"NLP in mental health has been primarily social media focused. Real world
practitioners also have high case loads and often domain specific variables, of
which modern LLMs lack context. We take a dataset made by recruiting 644
participants, including individuals diagnosed with Bipolar Disorder (BD),
Schizophrenia (SZ), and Healthy Controls (HC). Participants undertook tasks
derived from a standardized mental health instrument, and the resulting data
were transcribed and annotated by experts across five clinical variables. This
paper demonstrates the application of contemporary language models in
sequence-to-sequence tasks to enhance mental health research. Specifically, we
illustrate how these models can facilitate the deployment of mental health
instruments, data collection, and data annotation with high accuracy and
scalability. We show that small models are capable of annotation for
domain-specific clinical variables, data collection for mental-health
instruments, and perform better then commercial large models."
Pattern or Artifact? Interactively Exploring Embedding Quality with TRACE,https://arxiv.org/abs/2406.12953,2024-06-18,2024-06-21,0.0,0.0,"This paper presents TRACE, a tool to analyze the quality of 2D embeddings
generated through dimensionality reduction techniques. Dimensionality reduction
methods often prioritize preserving either local neighborhoods or global
distances, but insights from visual structures can be misleading if the
objective has not been achieved uniformly. TRACE addresses this challenge by
providing a scalable and extensible pipeline for computing both local and
global quality measures. The interactive browser-based interface allows users
to explore various embeddings while visually assessing the pointwise embedding
quality. The interface also facilitates in-depth analysis by highlighting
high-dimensional nearest neighbors for any group of points and displaying
high-dimensional distances between points. TRACE enables analysts to make
informed decisions regarding the most suitable dimensionality reduction method
for their specific use case, by showing the degree and location where structure
is preserved in the reduced space."
Spatial Sequence Attention Network for Schizophrenia Classification from Structural Brain MR Images,https://arxiv.org/abs/2406.12683,2024-06-18,2024-06-21,0.0,0.0,"Schizophrenia is a debilitating, chronic mental disorder that significantly
impacts an individual's cognitive abilities, behavior, and social interactions.
It is characterized by subtle morphological changes in the brain, particularly
in the gray matter. These changes are often imperceptible through manual
observation, demanding an automated approach to diagnosis. This study
introduces a deep learning methodology for the classification of individuals
with Schizophrenia. We achieve this by implementing a diversified attention
mechanism known as Spatial Sequence Attention (SSA) which is designed to
extract and emphasize significant feature representations from structural MRI
(sMRI). Initially, we employ the transfer learning paradigm by leveraging
pre-trained DenseNet to extract initial feature maps from the final
convolutional block which contains morphological alterations associated with
Schizophrenia. These features are further processed by the proposed SSA to
capture and emphasize intricate spatial interactions and relationships across
volumes within the brain. Our experimental studies conducted on a clinical
dataset have revealed that the proposed attention mechanism outperforms the
existing Squeeze & Excitation Network for Schizophrenia classification."
Code Agents are State of the Art Software Testers,https://arxiv.org/abs/2406.12952,2024-06-18,2024-06-21,0.0,0.0,"Rigorous software testing is crucial for developing and maintaining
high-quality code, making automated test generation a promising avenue for both
improving software quality and boosting the effectiveness of code generation
methods. However, while code generation with Large Language Models (LLMs) is an
extraordinarily active research area, test generation remains relatively
unexplored. We address this gap and investigate the capability of LLM-based
Code Agents for formalizing user issues into test cases. To this end, we
propose a novel benchmark based on popular GitHub repositories, containing
real-world issues, ground-truth patches, and golden tests. We find that LLMs
generally perform surprisingly well at generating relevant test cases with Code
Agents designed for code repair exceeding the performance of systems designed
specifically for test generation. Further, as test generation is a similar but
more structured task than code generation, it allows for a more fine-grained
analysis using fail-to-pass rate and coverage metrics, providing a dual metric
for analyzing systems designed for code repair. Finally, we find that generated
tests are an effective filter for proposed code fixes, doubling the precision
of SWE-Agent."
Measuring Psychological Depth in Language Models,https://arxiv.org/abs/2406.12680,2024-06-18,2024-06-21,0.0,0.0,"Evaluations of creative stories generated by large language models (LLMs)
often focus on objective properties of the text, such as its style, coherence,
and toxicity. While these metrics are indispensable, they do not speak to a
story's subjective, psychological impact from a reader's perspective. We
introduce the Psychological Depth Scale (PDS), a novel framework rooted in
literary theory that measures an LLM's ability to produce authentic and
narratively complex stories that provoke emotion, empathy, and engagement. We
empirically validate our framework by showing that humans can consistently
evaluate stories based on PDS (0.72 Krippendorff's alpha). We also explore
techniques for automating the PDS to easily scale future analyses. GPT-4o,
combined with a novel Mixture-of-Personas (MoP) prompting strategy, achieves an
average Spearman correlation of $0.51$ with human judgment while Llama-3-70B
scores as high as 0.68 for empathy. Finally, we compared the depth of stories
authored by both humans and LLMs. Surprisingly, GPT-4 stories either surpassed
or were statistically indistinguishable from highly-rated human-written stories
sourced from Reddit. By shifting the focus from text to reader, the
Psychological Depth Scale is a validated, automated, and systematic means of
measuring the capacity of LLMs to connect with humans through the stories they
tell."
Vernacular? I Barely Know Her - Challenges with Style Control and Stereotyping,https://arxiv.org/abs/2406.12679,2024-06-18,2024-06-21,0.0,0.0,"Large Language Models (LLMs) are increasingly being used in educational and
learning applications. Research has demonstrated that controlling for style, to
fit the needs of the learner, fosters increased understanding, promotes
inclusion, and helps with knowledge distillation. To understand the
capabilities and limitations of contemporary LLMs in style control, we
evaluated five state-of-the-art models: GPT-3.5, GPT-4, GPT-4o, Llama-3, and
Mistral-instruct- 7B across two style control tasks. We observed significant
inconsistencies in the first task, with model performances averaging between
5th and 8th grade reading levels for tasks intended for first-graders, and
standard deviations up to 27.6. For our second task, we observed a
statistically significant improvement in performance from 0.02 to 0.26.
However, we find that even without stereotypes in reference texts, LLMs often
generated culturally insensitive content during their tasks. We provide a
thorough analysis and discussion of the results."
Contraction rates for conjugate gradient and Lanczos approximate posteriors in Gaussian process regression,https://arxiv.org/abs/2406.12678,2024-06-18,2024-06-21,0.0,0.0,"Due to their flexibility and theoretical tractability Gaussian process (GP)
regression models have become a central topic in modern statistics and machine
learning. While the true posterior in these models is given explicitly,
numerical evaluations depend on the inversion of the augmented kernel matrix $
K + \sigma^2 I $, which requires up to $ O(n^3) $ operations. For large sample
sizes n, which are typically given in modern applications, this is
computationally infeasible and necessitates the use of an approximate version
of the posterior. Although such methods are widely used in practice, they
typically have very limtied theoretical underpinning.
  In this context, we analyze a class of recently proposed approximation
algorithms from the field of Probabilistic numerics. They can be interpreted in
terms of Lanczos approximate eigenvectors of the kernel matrix or a conjugate
gradient approximation of the posterior mean, which are particularly
advantageous in truly large scale applications, as they are fundamentally only
based on matrix vector multiplications amenable to the GPU acceleration of
modern software frameworks. We combine result from the numerical analysis
literature with state of the art concentration results for spectra of kernel
matrices to obtain minimax contraction rates. Our theoretical findings are
illustrated by numerical experiments."
Estimating Knowledge in Large Language Models Without Generating a Single Token,https://arxiv.org/abs/2406.12673,2024-06-18,2024-06-21,0.0,0.0,"To evaluate knowledge in large language models (LLMs), current methods query
the model and then evaluate its generated responses. In this work, we ask
whether evaluation can be done $\textit{before}$ the model has generated any
text. Concretely, is it possible to estimate how knowledgeable a model is about
a certain entity, only from its internal computation? We study this question
with two tasks: given a subject entity, the goal is to predict (a) the ability
of the model to answer common questions about the entity, and (b) the
factuality of responses generated by the model about the entity. Experiments
with a variety of LLMs show that KEEN, a simple probe trained over internal
subject representations, succeeds at both tasks - strongly correlating with
both the QA accuracy of the model per-subject and FActScore, a recent
factuality metric in open-ended generation. Moreover, KEEN naturally aligns
with the model's hedging behavior and faithfully reflects changes in the
model's knowledge after fine-tuning. Lastly, we show a more interpretable yet
equally performant variant of KEEN, which highlights a small set of tokens that
correlates with the model's lack of knowledge. Being simple and lightweight,
KEEN can be leveraged to identify gaps and clusters of entity knowledge in
LLMs, and guide decisions such as augmenting queries with retrieval."
Sparsifying dimensionality reduction of PDE solution data with Bregman learning,https://arxiv.org/abs/2406.12672,2024-06-18,2024-06-21,0.0,0.0,"Classical model reduction techniques project the governing equations onto a
linear subspace of the original state space. More recent data-driven techniques
use neural networks to enable nonlinear projections. Whilst those often enable
stronger compression, they may have redundant parameters and lead to suboptimal
latent dimensionality. To overcome these, we propose a multistep algorithm that
induces sparsity in the encoder-decoder networks for effective reduction in the
number of parameters and additional compression of the latent space. This
algorithm starts with sparsely initialized a network and training it using
linearized Bregman iterations. These iterations have been very successful in
computer vision and compressed sensing tasks, but have not yet been used for
reduced-order modelling. After the training, we further compress the latent
space dimensionality by using a form of proper orthogonal decomposition. Last,
we use a bias propagation technique to change the induced sparsity into an
effective reduction of parameters. We apply this algorithm to three
representative PDE models: 1D diffusion, 1D advection, and 2D
reaction-diffusion. Compared to conventional training methods like Adam, the
proposed method achieves similar accuracy with 30% less parameters and a
significantly smaller latent space."
Stealth edits for provably fixing or attacking large language models,https://arxiv.org/abs/2406.12670,2024-06-18,2024-06-21,0.0,0.0,"We reveal new methods and the theoretical foundations of techniques for
editing large language models. We also show how the new theory can be used to
assess the editability of models and to expose their susceptibility to
previously unknown malicious attacks. Our theoretical approach shows that a
single metric (a specific measure of the intrinsic dimensionality of the
model's features) is fundamental to predicting the success of popular editing
approaches, and reveals new bridges between disparate families of editing
methods. We collectively refer to these approaches as stealth editing methods,
because they aim to directly and inexpensively update a model's weights to
correct the model's responses to known hallucinating prompts without otherwise
affecting the model's behaviour, without requiring retraining. By carefully
applying the insight gleaned from our theoretical investigation, we are able to
introduce a new network block -- named a jet-pack block -- which is optimised
for highly selective model editing, uses only standard network operations, and
can be inserted into existing networks. The intrinsic dimensionality metric
also determines the vulnerability of a language model to a stealth attack: a
small change to a model's weights which changes its response to a single
attacker-chosen prompt. Stealth attacks do not require access to or knowledge
of the model's training data, therefore representing a potent yet previously
unrecognised threat to redistributed foundation models. They are
computationally simple enough to be implemented in malware in many cases.
Extensive experimental results illustrate and support the method and its
theoretical underpinnings. Demos and source code for editing language models
are available at https://github.com/qinghua-zhou/stealth-edits."
A Systematization of the Wagner Framework - Graph Theory Conjectures and Reinforcement Learning,https://arxiv.org/abs/2406.12667,2024-06-18,2024-06-21,0.0,0.0,"In 2021, Adam Zsolt Wagner proposed an approach to disprove conjectures in
graph theory using Reinforcement Learning (RL). Wagner's idea can be framed as
follows: consider a conjecture, such as a certain quantity f(G) < 0 for every
graph G; one can then play a single-player graph-building game, where at each
turn the player decides whether to add an edge or not. The game ends when all
edges have been considered, resulting in a certain graph G_T, and f(G_T) is the
final score of the game; RL is then used to maximize this score. This brilliant
idea is as simple as innovative, and it lends itself to systematic
generalization. Several different single-player graph-building games can be
employed, along with various RL algorithms. Moreover, RL maximizes the
cumulative reward, allowing for step-by-step rewards instead of a single final
score, provided the final cumulative reward represents the quantity of interest
f(G_T). In this paper, we discuss these and various other choices that can be
significant in Wagner's framework. As a contribution to this systematization,
we present four distinct single-player graph-building games. Each game employs
both a step-by-step reward system and a single final score. We also propose a
principled approach to select the most suitable neural network architecture for
any given conjecture, and introduce a new dataset of graphs labeled with their
Laplacian spectra. Furthermore, we provide a counterexample for a conjecture
regarding the sum of the matching number and the spectral radius, which is
simpler than the example provided in Wagner's original paper.
  The games have been implemented as environments in the Gymnasium framework,
and along with the dataset, are available as open-source supplementary
materials."
CollabStory - Multi-LLM Collaborative Story Generation and Authorship Analysis,https://arxiv.org/abs/2406.12665,2024-06-18,2024-06-21,0.0,0.0,"The rise of unifying frameworks that enable seamless interoperability of
Large Language Models (LLMs) has made LLM-LLM collaboration for open-ended
tasks a possibility. Despite this, there have not been efforts to explore such
collaborative writing. We take the next step beyond human-LLM collaboration to
explore this multi-LLM scenario by generating the first exclusively
LLM-generated collaborative stories dataset called CollabStory. We focus on
single-author ($N=1$) to multi-author (up to $N=5$) scenarios, where multiple
LLMs co-author stories. We generate over 32k stories using open-source
instruction-tuned LLMs. Further, we take inspiration from the PAN tasks that
have set the standard for human-human multi-author writing tasks and analysis.
We extend their authorship-related tasks for multi-LLM settings and present
baselines for LLM-LLM collaboration. We find that current baselines are not
able to handle this emerging scenario. Thus, CollabStory is a resource that
could help propel an understanding as well as the development of techniques to
discern the use of multiple LLMs. This is crucial to study in the context of
writing tasks since LLM-LLM collaboration could potentially overwhelm ongoing
challenges related to plagiarism detection, credit assignment, maintaining
academic integrity in educational settings, and addressing copyright
infringement concerns. We make our dataset and code available at
\texttt{\url{https://github.com/saranya-venkatraman/multi_llm_story_writing}}."
Do More Details Always Introduce More Hallucinations in LVLM-based Image Captioning?,https://arxiv.org/abs/2406.12663,2024-06-18,2024-06-21,0.0,0.0,"Large Vision-Language Models (LVLMs) excel in integrating visual and
linguistic contexts to produce detailed content, facilitating applications such
as image captioning. However, using LVLMs to generate descriptions often faces
the challenge of object hallucination (OH), where the output text misrepresents
actual objects in the input image. While previous studies attribute the
occurrence of OH to the inclusion of more details, our study finds technical
flaws in existing metrics, leading to unreliable evaluations of models and
conclusions about OH. This has sparked a debate on the question: Do more
details always introduce more hallucinations in LVLM-based image captioning?
  In this paper, we address this debate by proposing a novel decoding strategy,
Differentiated Beam Decoding (DBD), along with a reliable new set of evaluation
metrics: CLIP-Precision, CLIP-Recall, and CLIP-F1. DBD decodes the wealth of
information hidden in visual input into distinct language representations
called unit facts in parallel. This decoding is achieved via a well-designed
differential score that guides the parallel search and candidate screening. The
selected unit facts are then aggregated to generate the final caption. Our
proposed metrics evaluate the comprehensiveness and accuracy of image captions
by comparing the embedding groups of ground-truth image regions and generated
text partitions. Extensive experiments on the Visual Genome dataset validate
the effectiveness of our approach, demonstrating that it produces detailed
descriptions while maintaining low hallucination levels."
SCORE - A 1D Reparameterization Technique to Break Bayesian Optimization's Curse of Dimensionality,https://arxiv.org/abs/2406.12661,2024-06-18,2024-06-21,0.0,0.0,"Bayesian optimization (BO) has emerged as a powerful tool for navigating
complex search spaces, showcasing practical applications in the fields of
science and engineering.However, since it typically relies on a surrogate model
to approximate the objective function, BO grapples with heightened
computational costs that tend to escalate as the number of parameters and
experiments grows. Several methods such as parallelization, surrogate model
approximations, and memory pruning have been proposed to cut down computing
time, but they all fall short of resolving the core issue behind BO's curse of
dimensionality. In this paper, a 1D reparametrization trick is proposed to
break this curse and sustain linear time complexity for BO in high-dimensional
landscapes. This fast and scalable approach named SCORE can successfully find
the global minimum of needle-in-a-haystack optimization functions and fit
real-world data without the high-performance computing resources typically
required by state-of-the-art techniques."
Investigating the Role of Explainability and AI Literacy in User Compliance,https://arxiv.org/abs/2406.12660,2024-06-18,2024-06-21,0.0,0.0,"AI is becoming increasingly common across different domains. However, as
sophisticated AI-based systems are often black-boxed, rendering the
decision-making logic opaque, users find it challenging to comply with their
recommendations. Although researchers are investigating Explainable AI (XAI) to
increase the transparency of the underlying machine learning models, it is
unclear what types of explanations are effective and what other factors
increase compliance. To better understand the interplay of these factors, we
conducted an experiment with 562 participants who were presented with the
recommendations of an AI and two different types of XAI. We find that users'
compliance increases with the introduction of XAI but is also affected by AI
literacy. We also find that the relationships between AI literacy XAI and
users' compliance are mediated by the users' mental model of AI. Our study has
several implications for successfully designing AI-based systems utilizing XAI."
A variational Bayes approach to debiased inference for low-dimensional parameters in high-dimensional linear regression,https://arxiv.org/abs/2406.12659,2024-06-18,2024-06-21,0.0,0.0,"We propose a scalable variational Bayes method for statistical inference for
a single or low-dimensional subset of the coordinates of a high-dimensional
parameter in sparse linear regression. Our approach relies on assigning a
mean-field approximation to the nuisance coordinates and carefully modelling
the conditional distribution of the target given the nuisance. This requires
only a preprocessing step and preserves the computational advantages of
mean-field variational Bayes, while ensuring accurate and reliable inference
for the target parameter, including for uncertainty quantification. We
investigate the numerical performance of our algorithm, showing that it
performs competitively with existing methods. We further establish accompanying
theoretical guarantees for estimation and uncertainty quantification in the
form of a Bernstein--von Mises theorem."
Federated Learning with a Single Shared Image,https://arxiv.org/abs/2406.12658,2024-06-18,2024-06-21,0.0,0.0,"Federated Learning (FL) enables multiple machines to collaboratively train a
machine learning model without sharing of private training data. Yet,
especially for heterogeneous models, a key bottleneck remains the transfer of
knowledge gained from each client model with the server. One popular method,
FedDF, uses distillation to tackle this task with the use of a common, shared
dataset on which predictions are exchanged. However, in many contexts such a
dataset might be difficult to acquire due to privacy and the clients might not
allow for storage of a large shared dataset. To this end, in this paper, we
introduce a new method that improves this knowledge distillation method to only
rely on a single shared image between clients and server. In particular, we
propose a novel adaptive dataset pruning algorithm that selects the most
informative crops generated from only a single image. With this, we show that
federated learning with distillation under a limited shared dataset budget
works better by using a single image compared to multiple individual ones.
Finally, we extend our approach to allow for training heterogeneous client
architectures by incorporating a non-uniform distillation schedule and
client-model mirroring on the server side."
Benchmarks and Metrics for Evaluations of Code Generation - A Critical Review,https://arxiv.org/abs/2406.12655,2024-06-18,2024-06-21,0.0,0.0,"With the rapid development of Large Language Models (LLMs), a large number of
machine learning models have been developed to assist programming tasks
including the generation of program code from natural language input. However,
how to evaluate such LLMs for this task is still an open problem despite of the
great amount of research efforts that have been made and reported to evaluate
and compare them. This paper provides a critical review of the existing work on
the testing and evaluation of these tools with a focus on two key aspects: the
benchmarks and the metrics used in the evaluations. Based on the review,
further research directions are discussed."
Probabilistic Conceptual Explainers - Trustworthy Conceptual Explanations for Vision Foundation Models,https://arxiv.org/abs/2406.12649,2024-06-18,2024-06-21,0.0,0.0,"Vision transformers (ViTs) have emerged as a significant area of focus,
particularly for their capacity to be jointly trained with large language
models and to serve as robust vision foundation models. Yet, the development of
trustworthy explanation methods for ViTs has lagged, particularly in the
context of post-hoc interpretations of ViT predictions. Existing sub-image
selection approaches, such as feature-attribution and conceptual models, fall
short in this regard. This paper proposes five desiderata for explaining ViTs
-- faithfulness, stability, sparsity, multi-level structure, and parsimony --
and demonstrates the inadequacy of current methods in meeting these criteria
comprehensively. We introduce a variational Bayesian explanation framework,
dubbed ProbAbilistic Concept Explainers (PACE), which models the distributions
of patch embeddings to provide trustworthy post-hoc conceptual explanations.
Our qualitative analysis reveals the distributions of patch-level concepts,
elucidating the effectiveness of ViTs by modeling the joint distribution of
patch embeddings and ViT's predictions. Moreover, these patch-level
explanations bridge the gap between image-level and dataset-level explanations,
thus completing the multi-level structure of PACE. Through extensive
experiments on both synthetic and real-world datasets, we demonstrate that PACE
surpasses state-of-the-art methods in terms of the defined desiderata."
Evaluating Transparency of Machine Generated Fact Checking Explanations,https://arxiv.org/abs/2406.12645,2024-06-18,2024-06-21,0.0,0.0,"An important factor when it comes to generating fact-checking explanations is
the selection of evidence: intuitively, high-quality explanations can only be
generated given the right evidence. In this work, we investigate the impact of
human-curated vs. machine-selected evidence for explanation generation using
large language models. To assess the quality of explanations, we focus on
transparency (whether an explanation cites sources properly) and utility
(whether an explanation is helpful in clarifying a claim). Surprisingly, we
found that large language models generate similar or higher quality
explanations using machine-selected evidence, suggesting carefully curated
evidence (by humans) may not be necessary. That said, even with the best model,
the generated explanations are not always faithful to the sources, suggesting
further room for improvement in explanation generation for fact-checking."
Hierarchical Prompting Taxonomy - A Universal Evaluation Framework for Large Language Models,https://arxiv.org/abs/2406.12644,2024-06-18,2024-06-21,0.0,0.0,"Assessing the effectiveness of large language models (LLMs) in addressing
diverse tasks is essential for comprehending their strengths and weaknesses.
Conventional evaluation techniques typically apply a single prompting strategy
uniformly across datasets, not considering the varying degrees of task
complexity. We introduce the Hierarchical Prompting Taxonomy (HPT), a taxonomy
that employs a Hierarchical Prompt Framework (HPF) composed of five unique
prompting strategies, arranged from the simplest to the most complex, to assess
LLMs more precisely and to offer a clearer perspective. This taxonomy assigns a
score, called the Hierarchical Prompting Score (HP-Score), to datasets as well
as LLMs based on the rules of the taxonomy, providing a nuanced understanding
of their ability to solve diverse tasks and offering a universal measure of
task complexity. Additionally, we introduce the Adaptive Hierarchical Prompt
framework, which automates the selection of appropriate prompting strategies
for each task. This study compares manual and adaptive hierarchical prompt
frameworks using four instruction-tuned LLMs, namely Llama 3 8B, Phi 3 3.8B,
Mistral 7B, and Gemma 7B, across four datasets: BoolQ, CommonSenseQA (CSQA),
IWSLT-2017 en-fr (IWSLT), and SamSum. Experiments demonstrate the effectiveness
of HPT, providing a reliable way to compare different tasks and LLM
capabilities. This paper leads to the development of a universal evaluation
metric that can be used to evaluate both the complexity of the datasets and the
capabilities of LLMs. The implementation of both manual HPF and adaptive HPF is
publicly available."
DetectBench - Can Large Language Model Detect and Piece Together Implicit Evidence?,https://arxiv.org/abs/2406.12641,2024-06-18,2024-06-21,0.0,0.0,"Detecting evidence within the context is a key step in the process of
reasoning task. Evaluating and enhancing the capabilities of LLMs in evidence
detection will strengthen context-based reasoning performance. This paper
proposes a benchmark called DetectBench for verifying the ability to detect and
piece together implicit evidence within a long context. DetectBench contains
3,928 multiple-choice questions, with an average of 994 tokens per question.
Each question contains an average of 4.55 pieces of implicit evidence, and
solving the problem typically requires 7.62 logical jumps to find the correct
answer. To enhance the performance of LLMs in evidence detection, this paper
proposes Detective Reasoning Prompt and Finetune. Experiments demonstrate that
the existing LLMs' abilities to detect evidence in long contexts are far
inferior to humans. However, the Detective Reasoning Prompt effectively
enhances the capability of powerful LLMs in evidence detection, while the
Finetuning method shows significant effects in enhancing the performance of
weaker LLMs. Moreover, when the abilities of LLMs in evidence detection are
improved, their final reasoning performance is also enhanced accordingly."
Research and Implementation of Data Enhancement Techniques for Graph Neural Networks,https://arxiv.org/abs/2406.12640,2024-06-18,2024-06-21,0.0,0.0,"Data, algorithms, and arithmetic power are the three foundational conditions
for deep learning to be effective in the application domain. Data is the focus
for developing deep learning algorithms. In practical engineering applications,
some data are affected by the conditions under which more data cannot be
obtained or the cost of obtaining data is too high, resulting in smaller data
sets (generally several hundred to several thousand) and data sizes that are
far smaller than the size of large data sets (tens of thousands). The above two
methods are based on the original dataset to generate, in the case of
insufficient data volume of the original data may not reflect all the real
environment, such as the real environment of the light, silhouette and other
information, if the amount of data is not enough, it is difficult to use a
simple transformation or neural network generative model to generate the
required data. The research in this paper firstly analyses the key points of
the data enhancement technology of graph neural network, and at the same time
introduces the composition foundation of graph neural network in depth, on the
basis of which the data enhancement technology of graph neural network is
optimized and analysed."
Ask-before-Plan - Proactive Language Agents for Real-World Planning,https://arxiv.org/abs/2406.12639,2024-06-18,2024-06-21,0.0,0.0,"The evolution of large language models (LLMs) has enhanced the planning
capabilities of language agents in diverse real-world scenarios. Despite these
advancements, the potential of LLM-powered agents to comprehend ambiguous user
instructions for reasoning and decision-making is still under exploration. In
this work, we introduce a new task, Proactive Agent Planning, which requires
language agents to predict clarification needs based on user-agent conversation
and agent-environment interaction, invoke external tools to collect valid
information, and generate a plan to fulfill the user's demands. To study this
practical problem, we establish a new benchmark dataset, Ask-before-Plan. To
tackle the deficiency of LLMs in proactive planning, we propose a novel
multi-agent framework, Clarification-Execution-Planning (\texttt{CEP}), which
consists of three agents specialized in clarification, execution, and planning.
We introduce the trajectory tuning scheme for the clarification agent and
static execution agent, as well as the memory recollection mechanism for the
dynamic execution agent. Extensive evaluations and comprehensive analyses
conducted on the Ask-before-Plan dataset validate the effectiveness of our
proposed framework."
Efficient and Long-Tailed Generalization for Pre-trained Vision-Language Model,https://arxiv.org/abs/2406.12638,2024-06-18,2024-06-21,0.0,0.0,"Pre-trained vision-language models like CLIP have shown powerful zero-shot
inference ability via image-text matching and prove to be strong few-shot
learners in various downstream tasks. However, in real-world scenarios,
adapting CLIP to downstream tasks may encounter the following challenges: 1)
data may exhibit long-tailed data distributions and might not have abundant
samples for all the classes; 2) There might be emerging tasks with new classes
that contain no samples at all. To overcome them, we propose a novel framework
to achieve efficient and long-tailed generalization, which can be termed as
Candle. During the training process, we propose compensating logit-adjusted
loss to encourage large margins of prototypes and alleviate imbalance both
within the base classes and between the base and new classes. For efficient
adaptation, we treat the CLIP model as a black box and leverage the extracted
features to obtain visual and textual prototypes for prediction. To make full
use of multi-modal information, we also propose cross-modal attention to enrich
the features from both modalities. For effective generalization, we introduce
virtual prototypes for new classes to make up for their lack of training
images. Candle achieves state-of-the-art performance over extensive experiments
on 11 diverse datasets while substantially reducing the training time,
demonstrating the superiority of our approach. The source code is available at
https://github.com/shijxcs/Candle."
ScenEval - A Benchmark for Scenario-Based Evaluation of Code Generation,https://arxiv.org/abs/2406.12635,2024-06-18,2024-06-21,0.0,0.0,"In the scenario-based evaluation of machine learning models, a key problem is
how to construct test datasets that represent various scenarios. The
methodology proposed in this paper is to construct a benchmark and attach
metadata to each test case. Then a test system can be constructed with test
morphisms that filter the test cases based on metadata to form a dataset.
  The paper demonstrates this methodology with large language models for code
generation. A benchmark called ScenEval is constructed from problems in
textbooks, an online tutorial website and Stack Overflow. Filtering by scenario
is demonstrated and the test sets are used to evaluate ChatGPT for Java code
generation.
  Our experiments found that the performance of ChatGPT decreases with the
complexity of the coding task. It is weakest for advanced topics like
multi-threading, data structure algorithms and recursive methods. The Java code
generated by ChatGPT tends to be much shorter than reference solution in terms
of number of lines, while it is more likely to be more complex in both
cyclomatic and cognitive complexity metrics, if the generated code is correct.
However, the generated code is more likely to be less complex than the
reference solution if the code is incorrect."
News Without Borders - Domain Adaptation of Multilingual Sentence Embeddings for Cross-lingual News Recommendation,https://arxiv.org/abs/2406.12634,2024-06-18,2024-06-21,0.0,0.0,"Rapidly growing numbers of multilingual news consumers pose an increasing
challenge to news recommender systems in terms of providing customized
recommendations. First, existing neural news recommenders, even when powered by
multilingual language models (LMs), suffer substantial performance losses in
zero-shot cross-lingual transfer (ZS-XLT). Second, the current paradigm of
fine-tuning the backbone LM of a neural recommender on task-specific data is
computationally expensive and infeasible in few-shot recommendation and
cold-start setups, where data is scarce or completely unavailable. In this
work, we propose a news-adapted sentence encoder (NaSE), domain-specialized
from a pretrained massively multilingual sentence encoder (SE). To this end, we
construct and leverage PolyNews and PolyNewsParallel, two multilingual
news-specific corpora. With the news-adapted multilingual SE in place, we test
the effectiveness of (i.e., question the need for) supervised fine-tuning for
news recommendation, and propose a simple and strong baseline based on (i)
frozen NaSE embeddings and (ii) late click-behavior fusion. We show that NaSE
achieves state-of-the-art performance in ZS-XLT in true cold-start and few-shot
news recommendation."
SeTAR - Out-of-Distribution Detection with Selective Low-Rank Approximation,https://arxiv.org/abs/2406.12629,2024-06-18,2024-06-21,0.0,0.0,"Out-of-distribution (OOD) detection is crucial for the safe deployment of
neural networks. Existing CLIP-based approaches perform OOD detection by
devising novel scoring functions or sophisticated fine-tuning methods. In this
work, we propose SeTAR, a novel, training-free OOD detection method that
leverages selective low-rank approximation of weight matrices in
vision-language and vision-only models. SeTAR enhances OOD detection via
post-hoc modification of the model's weight matrices using a simple greedy
search algorithm. Based on SeTAR, we further propose SeTAR+FT, a fine-tuning
extension optimizing model performance for OOD detection tasks. Extensive
evaluations on ImageNet1K and Pascal-VOC benchmarks show SeTAR's superior
performance, reducing the false positive rate by up to 18.95% and 36.80%
compared to zero-shot and fine-tuning baselines. Ablation studies further
validate our approach's effectiveness, robustness, and generalizability across
different model backbones. Our work offers a scalable, efficient solution for
OOD detection, setting a new state-of-the-art in this area."
Judging the Judges - Evaluating Alignment and Vulnerabilities in LLMs-as-Judges,https://arxiv.org/abs/2406.12624,2024-06-18,2024-06-21,0.0,0.0,"Offering a promising solution to the scalability challenges associated with
human evaluation, the LLM-as-a-judge paradigm is rapidly gaining traction as an
approach to evaluating large language models (LLMs). However, there are still
many open questions about the strengths and weaknesses of this paradigm, and
what potential biases it may hold. In this paper, we present a comprehensive
study of the performance of various LLMs acting as judges. We leverage TriviaQA
as a benchmark for assessing objective knowledge reasoning of LLMs and evaluate
them alongside human annotations which we found to have a high inter-annotator
agreement. Our study includes 9 judge models and 9 exam taker models -- both
base and instruction-tuned. We assess the judge model's alignment across
different model sizes, families, and judge prompts. Among other results, our
research rediscovers the importance of using Cohen's kappa as a metric of
alignment as opposed to simple percent agreement, showing that judges with high
percent agreement can still assign vastly different scores. We find that both
Llama-3 70B and GPT-4 Turbo have an excellent alignment with humans, but in
terms of ranking exam taker models, they are outperformed by both JudgeLM-7B
and the lexical judge Contains, which have up to 34 points lower human
alignment. Through error analysis and various other studies, including the
effects of instruction length and leniency bias, we hope to provide valuable
lessons for using LLMs as judges in the future."
Growing Trees on Sounds - Assessing Strategies for End-to-End Dependency Parsing of Speech,https://arxiv.org/abs/2406.12621,2024-06-18,2024-06-21,0.0,0.0,"Direct dependency parsing of the speech signal -- as opposed to parsing
speech transcriptions -- has recently been proposed as a task (Pupier et al.
2022), as a way of incorporating prosodic information in the parsing system and
bypassing the limitations of a pipeline approach that would consist of using
first an Automatic Speech Recognition (ASR) system and then a syntactic parser.
In this article, we report on a set of experiments aiming at assessing the
performance of two parsing paradigms (graph-based parsing and sequence labeling
based parsing) on speech parsing. We perform this evaluation on a large
treebank of spoken French, featuring realistic spontaneous conversations. Our
findings show that (i) the graph based approach obtain better results across
the board (ii) parsing directly from speech outperforms a pipeline approach,
despite having 30% fewer parameters."
What makes two models think alike?,https://arxiv.org/abs/2406.12620,2024-06-18,2024-06-21,0.0,0.0,"Do architectural differences significantly affect the way models represent
and process language? We propose a new approach, based on metric-learning
encoding models (MLEMs), as a first step to answer this question. The approach
provides a feature-based comparison of how any two layers of any two models
represent linguistic information. We apply the method to BERT, GPT-2 and Mamba.
Unlike previous methods, MLEMs offer a transparent comparison, by identifying
the specific linguistic features responsible for similarities and differences.
More generally, the method uses formal, symbolic descriptions of a domain, and
use these to compare neural representations. As such, the approach can
straightforwardly be extended to other domains, such as speech and vision, and
to other neural systems, including human brains."
From Insights to Actions - The Impact of Interpretability and Analysis Research on NLP,https://arxiv.org/abs/2406.12618,2024-06-18,2024-06-21,0.0,0.0,"Interpretability and analysis (IA) research is a growing subfield within NLP
with the goal of developing a deeper understanding of the behavior or inner
workings of NLP systems and methods. Despite growing interest in the subfield,
a commonly voiced criticism is that it lacks actionable insights and therefore
has little impact on NLP. In this paper, we seek to quantify the impact of IA
research on the broader field of NLP. We approach this with a mixed-methods
analysis of: (1) a citation graph of 185K+ papers built from all papers
published at ACL and EMNLP conferences from 2018 to 2023, and (2) a survey of
138 members of the NLP community. Our quantitative results show that IA work is
well-cited outside of IA, and central in the NLP citation graph. Through
qualitative analysis of survey responses and manual annotation of 556 papers,
we find that NLP researchers build on findings from IA work and perceive it is
important for progress in NLP, multiple subfields, and rely on its findings and
terminology for their own work. Many novel methods are proposed based on IA
findings and highly influenced by them, but highly influential non-IA work
cites IA findings without being driven by them. We end by summarizing what is
missing in IA work today and provide a call to action, to pave the way for a
more impactful future of IA research."
Learning Diffusion at Lightspeed,https://arxiv.org/abs/2406.12616,2024-06-18,2024-06-21,0.0,0.0,"Diffusion regulates a phenomenal number of natural processes and the dynamics
of many successful generative models. Existing models to learn the diffusion
terms from observational data rely on complex bilevel optimization problems and
properly model only the drift of the system. We propose a new simple model,
JKOnet*, which bypasses altogether the complexity of existing architectures
while presenting significantly enhanced representational capacity: JKOnet*
recovers the potential, interaction, and internal energy components of the
underlying diffusion process. JKOnet* minimizes a simple quadratic loss, runs
at lightspeed, and drastically outperforms other baselines in practice.
Additionally, JKOnet* provides a closed-form optimal solution for linearly
parametrized functionals. Our methodology is based on the interpretation of
diffusion processes as energy-minimizing trajectories in the probability space
via the so-called JKO scheme, which we study via its first-order optimality
conditions, in light of few-weeks-old advancements in optimization in the
probability space."
When Are Bias-Free ReLU Networks Like Linear Networks?,https://arxiv.org/abs/2406.12615,2024-06-18,2024-06-21,0.0,0.0,"We investigate the expressivity and learning dynamics of bias-free ReLU
networks. We firstly show that two-layer bias-free ReLU networks have limited
expressivity: the only odd function two-layer bias-free ReLU networks can
express is a linear one. We then show that, under symmetry conditions on the
data, these networks have the same learning dynamics as linear networks. This
allows us to give closed-form time-course solutions to certain two-layer
bias-free ReLU networks, which has not been done for nonlinear networks outside
the lazy learning regime. While deep bias-free ReLU networks are more
expressive than their two-layer counterparts, they still share a number of
similarities with deep linear networks. These similarities enable us to
leverage insights from linear networks, leading to a novel understanding of
bias-free ReLU networks. Overall, our results show that some properties
established for bias-free ReLU networks arise due to equivalence to linear
networks, and suggest that including bias or considering asymmetric data are
avenues to engage with nonlinear behaviors."
EUvsDisinfo - a Dataset for Multilingual Detection of Pro-Kremlin Disinformation in News Articles,https://arxiv.org/abs/2406.12614,2024-06-18,2024-06-21,0.0,0.0,"This work introduces EUvsDisinfo, a multilingual dataset of disinformation
articles originating from pro-Kremlin outlets, along with trustworthy articles
from credible / less biased sources. It is sourced directly from the debunk
articles written by experts leading the EUvsDisinfo project. Our dataset is the
largest to-date resource in terms of the overall number of articles and
distinct languages. It also provides the largest topical and temporal coverage.
Using this dataset, we investigate the dissemination of pro-Kremlin
disinformation across different languages, uncovering language-specific
patterns targeting certain disinformation topics. We further analyse the
evolution of topic distribution over an eight-year period, noting a significant
surge in disinformation content before the full-scale invasion of Ukraine in
2022. Lastly, we demonstrate the dataset's applicability in training models to
effectively distinguish between disinformation and trustworthy content in
multilingual settings."
Rapid Language Adaptation for Multilingual E2E Speech Recognition Using Encoder Prompting,https://arxiv.org/abs/2406.12611,2024-06-18,2024-06-21,0.0,0.0,"End-to-end multilingual speech recognition models handle multiple languages
through a single model, often incorporating language identification to
automatically detect the language of incoming speech. Since the common scenario
is where the language is already known, these models can perform as
language-specific by using language information as prompts, which is
particularly beneficial for attention-based encoder-decoder architectures.
However, the Connectionist Temporal Classification (CTC) approach, which
enhances recognition via joint decoding and multi-task training, does not
normally incorporate language prompts due to its conditionally independent
output tokens. To overcome this, we introduce an encoder prompting technique
within the self-conditioned CTC framework, enabling language-specific
adaptation of the CTC model in a zero-shot manner. Our method has shown to
significantly reduce errors by 28% on average and by 41% on low-resource
languages."
Bridging Local Details and Global Context in Text-Attributed Graphs,https://arxiv.org/abs/2406.12608,2024-06-18,2024-06-21,0.0,0.0,"Representation learning on text-attributed graphs (TAGs) is vital for
real-world applications, as they combine semantic textual and contextual
structural information. Research in this field generally consist of two main
perspectives: local-level encoding and global-level aggregating, respectively
refer to textual node information unification (e.g., using Language Models) and
structure-augmented modeling (e.g., using Graph Neural Networks). Most existing
works focus on combining different information levels but overlook the
interconnections, i.e., the contextual textual information among nodes, which
provides semantic insights to bridge local and global levels. In this paper, we
propose GraphBridge, a multi-granularity integration framework that bridges
local and global perspectives by leveraging contextual textual information,
enhancing fine-grained understanding of TAGs. Besides, to tackle scalability
and efficiency challenges, we introduce a graphaware token reduction module.
Extensive experiments across various models and datasets show that our method
achieves state-of-theart performance, while our graph-aware token reduction
module significantly enhances efficiency and solves scalability issues."
Low-Redundant Optimization for Large Language Model Alignment,https://arxiv.org/abs/2406.12606,2024-06-18,2024-06-21,0.0,0.0,"Large language models (LLMs) are still struggling in aligning with human
preference in complex tasks and scenarios. They are prone to overfit into the
unexpected patterns or superficial styles in the training data. We conduct an
empirical study that only selects the top-10\% most updated parameters in LLMs
for alignment training, and see improvements in the convergence process and
final performance. It indicates the existence of redundant neurons in LLMs for
alignment training. To reduce its influence, we propose a low-redundant
alignment method named \textbf{ALLO}, focusing on optimizing the most related
neurons with the most useful supervised signals. Concretely, we first identify
the neurons that are related to the human preference data by a gradient-based
strategy, then identify the alignment-related key tokens by reward models for
computing loss. Besides, we also decompose the alignment process into the
forgetting and learning stages, where we first forget the tokens with unaligned
knowledge and then learn aligned knowledge, by updating different ratios of
neurons, respectively. Experimental results on 10 datasets have shown the
effectiveness of ALLO. Our code and data are available at
\url{https://github.com/RUCAIBox/ALLO}."
Attack and Defense of Deep Learning Models in the Field of Web Attack Detection,https://arxiv.org/abs/2406.12605,2024-06-18,2024-06-21,0.0,0.0,"The challenge of WAD (web attack detection) is growing as hackers
continuously refine their methods to evade traditional detection. Deep learning
models excel in handling complex unknown attacks due to their strong
generalization and adaptability. However, they are vulnerable to backdoor
attacks, where contextually irrelevant fragments are inserted into requests,
compromising model stability. While backdoor attacks are well studied in image
recognition, they are largely unexplored in WAD. This paper introduces backdoor
attacks in WAD, proposing five methods and corresponding defenses. Testing on
textCNN, biLSTM, and tinybert models shows an attack success rate over 87%,
reducible through fine-tuning. Future research should focus on backdoor
defenses in WAD. All the code and data of this paper can be obtained at
https://anonymous.4open.science/r/attackDefenceinDL-7E05"
Reinforcement-Learning based routing for packet-optical networks with hybrid telemetry,https://arxiv.org/abs/2406.12602,2024-06-18,2024-06-21,0.0,0.0,"This article provides a methodology and open-source implementation of
Reinforcement Learning algorithms for finding optimal routes in a
packet-optical network scenario. The algorithm uses measurements provided by
the physical layer (pre-FEC bit error rate and propagation delay) and the link
layer (link load) to configure a set of latency-based rewards and penalties
based on such measurements. Then, the algorithm executes Q-learning based on
this set of rewards for finding the optimal routing strategies. It is further
shown that the algorithm dynamically adapts to changing network conditions by
re-calculating optimal policies upon either link load changes or link
degradation as measured by pre-FEC BER."
Generalization bounds for mixing processes via delayed online-to-PAC conversions,https://arxiv.org/abs/2406.12600,2024-06-18,2024-06-21,0.0,0.0,"We study the generalization error of statistical learning algorithms in a
non-i.i.d. setting, where the training data is sampled from a stationary mixing
process. We develop an analytic framework for this scenario based on a
reduction to online learning with delayed feedback. In particular, we show that
the existence of an online learning algorithm with bounded regret (against a
fixed statistical learning algorithm in a specially constructed game of online
learning with delayed feedback) implies low generalization error of said
statistical learning method even if the data sequence is sampled from a mixing
time series. The rates demonstrate a trade-off between the amount of delay in
the online learning game and the degree of dependence between consecutive data
points, with near-optimal rates recovered in a number of well-studied settings
when the delay is tuned appropriately as a function of the mixing time of the
process."
PromptDSI - Prompt-based Rehearsal-free Instance-wise Incremental Learning for Document Retrieval,https://arxiv.org/abs/2406.12593,2024-06-18,2024-06-21,0.0,0.0,"Differentiable Search Index (DSI) utilizes Pre-trained Language Models (PLMs)
for efficient document retrieval without relying on external indexes. However,
DSIs need full re-training to handle updates in dynamic corpora, causing
significant computational inefficiencies. We introduce PromptDSI, a
rehearsal-free, prompt-based approach for instance-wise incremental learning in
document retrieval. PromptDSI attaches prompts to the frozen PLM's encoder of
DSI, leveraging its powerful representation to efficiently index new corpora
while maintaining a balance between stability and plasticity. We eliminate the
initial forward pass of prompt-based continual learning methods that doubles
training and inference time. Moreover, we propose a topic-aware prompt pool
that employs neural topic embeddings as fixed keys. This strategy ensures
diverse and effective prompt usage, addressing the challenge of parameter
underutilization caused by the collapse of the query-key matching mechanism.
Our empirical evaluations demonstrate that PromptDSI matches IncDSI in managing
forgetting while significantly enhancing recall by over 4% on new corpora."
Discovering Minimal Reinforcement Learning Environments,https://arxiv.org/abs/2406.12589,2024-06-18,2024-06-21,0.0,0.0,"Reinforcement learning (RL) agents are commonly trained and evaluated in the
same environment. In contrast, humans often train in a specialized environment
before being evaluated, such as studying a book before taking an exam. The
potential of such specialized training environments is still vastly
underexplored, despite their capacity to dramatically speed up training.
  The framework of synthetic environments takes a first step in this direction
by meta-learning neural network-based Markov decision processes (MDPs). The
initial approach was limited to toy problems and produced environments that did
not transfer to unseen RL algorithms. We extend this approach in three ways:
Firstly, we modify the meta-learning algorithm to discover environments
invariant towards hyperparameter configurations and learning algorithms.
Secondly, by leveraging hardware parallelism and introducing a curriculum on an
agent's evaluation episode horizon, we can achieve competitive results on
several challenging continuous control problems. Thirdly, we surprisingly find
that contextual bandits enable training RL agents that transfer well to their
evaluation environment, even if it is a complex MDP. Hence, we set up our
experiments to train synthetic contextual bandits, which perform on par with
synthetic MDPs, yield additional insights into the evaluation environment, and
can speed up downstream applications."
UIFV - Data Reconstruction Attack in Vertical Federated Learning,https://arxiv.org/abs/2406.12588,2024-06-18,2024-06-21,0.0,0.0,"Vertical Federated Learning (VFL) facilitates collaborative machine learning
without the need for participants to share raw private data. However, recent
studies have revealed privacy risks where adversaries might reconstruct
sensitive features through data leakage during the learning process. Although
data reconstruction methods based on gradient or model information are somewhat
effective, they reveal limitations in VFL application scenarios. This is
because these traditional methods heavily rely on specific model structures
and/or have strict limitations on application scenarios. To address this, our
study introduces the Unified InverNet Framework into VFL, which yields a novel
and flexible approach (dubbed UIFV) that leverages intermediate feature data to
reconstruct original data, instead of relying on gradients or model details.
The intermediate feature data is the feature exchanged by different
participants during the inference phase of VFL. Experiments on four datasets
demonstrate that our methods significantly outperform state-of-the-art
techniques in attack precision. Our work exposes severe privacy vulnerabilities
within VFL systems that pose real threats to practical VFL applications and
thus confirms the necessity of further enhancing privacy protection in the VFL
architecture."
Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling,https://arxiv.org/abs/2406.12585,2024-06-18,2024-06-21,0.0,0.0,"Ensembling multiple models has always been an effective approach to push the
limits of existing performance and is widely used in classification tasks by
simply averaging the classification probability vectors from multiple
classifiers to achieve better accuracy. However, in the thriving open-source
Large Language Model (LLM) community, ensembling methods are rare and typically
limited to ensembling the full-text outputs of LLMs, such as selecting the best
output using a ranker, which leads to underutilization of token-level
probability information. In this paper, we treat the Generation of each token
by LLMs as a Classification (GaC) for ensembling. This approach fully exploits
the probability information at each generation step and better prevents LLMs
from producing early incorrect tokens that lead to snowballing errors. In
experiments, we ensemble state-of-the-art LLMs on several benchmarks, including
exams, mathematics and reasoning, and observe that our method breaks the
existing community performance ceiling. Furthermore, we observed that most of
the tokens in the answer are simple and do not affect the correctness of the
final answer. Therefore, we also experimented with ensembling only key tokens,
and the results showed better performance with lower latency across benchmarks."
Training Diffusion Models with Federated Learning,https://arxiv.org/abs/2406.12575,2024-06-18,2024-06-21,0.0,0.0,"The training of diffusion-based models for image generation is predominantly
controlled by a select few Big Tech companies, raising concerns about privacy,
copyright, and data authority due to their lack of transparency regarding
training data. To ad-dress this issue, we propose a federated diffusion model
scheme that enables the independent and collaborative training of diffusion
models without exposing local data. Our approach adapts the Federated Averaging
(FedAvg) algorithm to train a Denoising Diffusion Model (DDPM). Through a novel
utilization of the underlying UNet backbone, we achieve a significant reduction
of up to 74% in the number of parameters exchanged during training,compared to
the naive FedAvg approach, whilst simultaneously maintaining image quality
comparable to the centralized setting, as evaluated by the FID score."
Mathador-LM - A Dynamic Benchmark for Mathematical Reasoning on Large Language Models,https://arxiv.org/abs/2406.12572,2024-06-18,2024-06-21,0.0,0.0,"We introduce Mathador-LM, a new benchmark for evaluating the mathematical
reasoning on large language models (LLMs), combining ruleset interpretation,
planning, and problem-solving. This benchmark is inspired by the Mathador game,
where the objective is to reach a target number using basic arithmetic
operations on a given set of base numbers, following a simple set of rules. We
show that, across leading LLMs, we obtain stable average performance while
generating benchmark instances dynamically, following a target difficulty
level. Thus, our benchmark alleviates concerns about test-set leakage into
training data, an issue that often undermines popular benchmarks. Additionally,
we conduct a comprehensive evaluation of both open and closed-source
state-of-the-art LLMs on Mathador-LM. Our findings reveal that contemporary
models struggle with Mathador-LM, scoring significantly lower than average 3rd
graders. This stands in stark contrast to their strong performance on popular
mathematical reasoning benchmarks."
Applying Ensemble Methods to Model-Agnostic Machine-Generated Text Detection,https://arxiv.org/abs/2406.12570,2024-06-18,2024-06-21,0.0,0.0,"In this paper, we study the problem of detecting machine-generated text when
the large language model (LLM) it is possibly derived from is unknown. We do so
by apply ensembling methods to the outputs from DetectGPT classifiers (Mitchell
et al. 2023), a zero-shot model for machine-generated text detection which is
highly accurate when the generative (or base) language model is the same as the
discriminative (or scoring) language model. We find that simple summary
statistics of DetectGPT sub-model outputs yield an AUROC of 0.73 (relative to
0.61) while retaining its zero-shot nature, and that supervised learning
methods sharply boost the accuracy to an AUROC of 0.94 but require a training
dataset. This suggests the possibility of further generalisation to create a
highly-accurate, model-agnostic machine-generated text detector."
MOYU - A Theoretical Study on Massive Over-activation Yielded Uplifts in LLMs,https://arxiv.org/abs/2406.12569,2024-06-18,2024-06-21,0.0,0.0,"Massive Over-activation Yielded Uplifts(MOYU) is an inherent property of
large language models, and dynamic activation(DA) based on the MOYU property is
a clever yet under-explored strategy designed to accelerate inference in these
models. Existing methods that utilize MOYU often face a significant 'Impossible
Trinity': struggling to simultaneously maintain model performance, enhance
inference speed, and extend applicability across various architectures. Due to
the theoretical ambiguities surrounding MOYU, this paper elucidates the root
cause of the MOYU property and outlines the mechanisms behind two primary
limitations encountered by current DA methods: 1) history-related activation
uncertainty, and 2) semantic-irrelevant activation inertia. Our analysis not
only underscores the limitations of current dynamic activation strategies
within large-scale LLaMA models but also proposes opportunities for refining
the design of future sparsity schemes."
MolecularGPT - Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction,https://arxiv.org/abs/2406.12950,2024-06-18,2024-06-21,0.0,0.0,"Molecular property prediction (MPP) is a fundamental and crucial task in drug
discovery. However, prior methods are limited by the requirement for a large
number of labeled molecules and their restricted ability to generalize for
unseen and new tasks, both of which are essential for real-world applications.
To address these challenges, we present MolecularGPT for few-shot MPP. From a
perspective on instruction tuning, we fine-tune large language models (LLMs)
based on curated molecular instructions spanning over 1000 property prediction
tasks. This enables building a versatile and specialized LLM that can be
adapted to novel MPP tasks without any fine-tuning through zero- and few-shot
in-context learning (ICL). MolecularGPT exhibits competitive in-context
reasoning capabilities across 10 downstream evaluation datasets, setting new
benchmarks for few-shot molecular prediction tasks. More importantly, with just
two-shot examples, MolecularGPT can outperform standard supervised graph neural
network methods on 4 out of 7 datasets. It also excels state-of-the-art LLM
baselines by up to 16.6% increase on classification accuracy and decrease of
199.17 on regression metrics (e.g., RMSE) under zero-shot. This study
demonstrates the potential of LLMs as effective few-shot molecular property
predictors. The code is available at https://github.com/NYUSHCS/MolecularGPT."
RichRAG - Crafting Rich Responses for Multi-faceted Queries in Retrieval-Augmented Generation,https://arxiv.org/abs/2406.12566,2024-06-18,2024-06-21,0.0,0.0,"Retrieval-augmented generation (RAG) effectively addresses issues of static
knowledge and hallucination in large language models. Existing studies mostly
focus on question scenarios with clear user intents and concise answers.
However, it is prevalent that users issue broad, open-ended queries with
diverse sub-intents, for which they desire rich and long-form answers covering
multiple relevant aspects. To tackle this important yet underexplored problem,
we propose a novel RAG framework, namely RichRAG. It includes a sub-aspect
explorer to identify potential sub-aspects of input questions, a multi-faceted
retriever to build a candidate pool of diverse external documents related to
these sub-aspects, and a generative list-wise ranker, which is a key module to
provide the top-k most valuable documents for the final generator. These ranked
documents sufficiently cover various query aspects and are aware of the
generator's preferences, hence incentivizing it to produce rich and
comprehensive responses for users. The training of our ranker involves a
supervised fine-tuning stage to ensure the basic coverage of documents, and a
reinforcement learning stage to align downstream LLM's preferences to the
ranking of documents. Experimental results on two publicly available datasets
prove that our framework effectively and efficiently provides comprehensive and
satisfying responses to users."
Low-Resource Machine Translation through the Lens of Personalized Federated Learning,https://arxiv.org/abs/2406.12564,2024-06-18,2024-06-21,0.0,0.0,"We present a new approach based on the Personalized Federated Learning
algorithm MeritFed that can be applied to Natural Language Tasks with
heterogeneous data. We evaluate it on the Low-Resource Machine Translation
task, using the dataset from the Large-Scale Multilingual Machine Translation
Shared Task (Small Track #2) and the subset of Sami languages from the
multilingual benchmark for Finno-Ugric languages. In addition to its
effectiveness, MeritFed is also highly interpretable, as it can be applied to
track the impact of each language used for training. Our analysis reveals that
target dataset size affects weight distribution across auxiliary languages,
that unrelated languages do not interfere with the training, and auxiliary
optimizer parameters have minimal impact. Our approach is easy to apply with a
few lines of code, and we provide scripts for reproducing the experiments at
https://github.com/VityaVitalich/MeritFed"
A Super-human Vision-based Reinforcement Learning Agent for Autonomous Racing in Gran Turismo,https://arxiv.org/abs/2406.12563,2024-06-18,2024-06-21,0.0,0.0,"Racing autonomous cars faster than the best human drivers has been a
longstanding grand challenge for the fields of Artificial Intelligence and
robotics. Recently, an end-to-end deep reinforcement learning agent met this
challenge in a high-fidelity racing simulator, Gran Turismo. However, this
agent relied on global features that require instrumentation external to the
car. This paper introduces, to the best of our knowledge, the first super-human
car racing agent whose sensor input is purely local to the car, namely pixels
from an ego-centric camera view and quantities that can be sensed from on-board
the car, such as the car's velocity. By leveraging global features only at
training time, the learned agent is able to outperform the best human drivers
in time trial (one car on the track at a time) races using only local input
features. The resulting agent is evaluated in Gran Turismo 7 on multiple tracks
and cars. Detailed ablation experiments demonstrate the agent's strong reliance
on visual inputs, making it the first vision-based super-human car racing
agent."
Bayesian Data Selection,https://arxiv.org/abs/2406.12560,2024-06-18,2024-06-21,0.0,0.0,"A wide range of machine learning algorithms iteratively add data to the
training sample. Examples include semi-supervised learning, active learning,
multi-armed bandits, and Bayesian optimization. We embed this kind of data
addition into decision theory by framing data selection as a decision problem.
This paves the way for finding Bayes-optimal selections of data. For the
illustrative case of self-training in semi-supervised learning, we derive the
respective Bayes criterion. We further show that deploying this criterion
mitigates the issue of confirmation bias by empirically assessing our method
for generalized linear models, semi-parametric generalized additive models, and
Bayesian neural networks on simulated and real-world data."
Offline Imitation Learning with Model-based Reverse Augmentation,https://arxiv.org/abs/2406.12550,2024-06-18,2024-06-21,0.0,0.0,"In offline Imitation Learning (IL), one of the main challenges is the
\textit{covariate shift} between the expert observations and the actual
distribution encountered by the agent, because it is difficult to determine
what action an agent should take when outside the state distribution of the
expert demonstrations. Recently, the model-free solutions introduce the
supplementary data and identify the latent expert-similar samples to augment
the reliable samples during learning. Model-based solutions build forward
dynamic models with conservatism quantification and then generate additional
trajectories in the neighborhood of expert demonstrations. However, without
reward supervision, these methods are often over-conservative in the
out-of-expert-support regions, because only in states close to expert-observed
states can there be a preferred action enabling policy optimization. To
encourage more exploration on expert-unobserved states, we propose a novel
model-based framework, called offline Imitation Learning with Self-paced
Reverse Augmentation (SRA). Specifically, we build a reverse dynamic model from
the offline demonstrations, which can efficiently generate trajectories leading
to the expert-observed states in a self-paced style. Then, we use the
subsequent reinforcement learning method to learn from the augmented
trajectories and transit from expert-unobserved states to expert-observed
states. This framework not only explores the expert-unobserved states but also
guides maximizing long-term returns on these states, ultimately enabling
generalization beyond the expert data. Empirical results show that our proposal
could effectively mitigate the covariate shift and achieve the state-of-the-art
performance on the offline imitation learning benchmarks. Project website:
\url{https://www.lamda.nju.edu.cn/shaojj/KDD24_SRA/}."
MultiSocial - Multilingual Benchmark of Machine-Generated Text Detection of Social-Media Texts,https://arxiv.org/abs/2406.12549,2024-06-18,2024-06-21,0.0,0.0,"Recent LLMs are able to generate high-quality multilingual texts,
indistinguishable for humans from authentic human-written ones. Research in
machine-generated text detection is however mostly focused on the English
language and longer texts, such as news articles, scientific papers or student
essays. Social-media texts are usually much shorter and often feature informal
language, grammatical errors, or distinct linguistic items (e.g., emoticons,
hashtags). There is a gap in studying the ability of existing methods in
detection of such texts, reflected also in the lack of existing multilingual
benchmark datasets. To fill this gap we propose the first multilingual (22
languages) and multi-platform (5 social media platforms) dataset for
benchmarking machine-generated text detection in the social-media domain,
called MultiSocial. It contains 472,097 texts, of which about 58k are
human-written and approximately the same amount is generated by each of 7
multilingual LLMs. We use this benchmark to compare existing detection methods
in zero-shot as well as fine-tuned form. Our results indicate that the
fine-tuned detectors have no problem to be trained on social-media texts and
that the platform selection for training matters."
P-Tailor - Customizing Personality Traits for Language Models via Mixture of Specialized LoRA Experts,https://arxiv.org/abs/2406.12548,2024-06-18,2024-06-21,0.0,0.0,"Personalized large language models (LLMs) have attracted great attention in
many applications, such as intelligent education and emotional support. Most
work focuses on controlling the character settings based on the profile (e.g.,
age, skill, experience, and so on). Conversely, the psychological theory-based
personality traits with implicit expression and behavior are not well modeled,
limiting their potential application in more specialized fields such as the
psychological counseling agents. In this paper, we propose a mixture of experts
(MoE)-based personalized LLMs, named P-tailor, to model the Big Five
Personality Traits. Particularly, we learn specialized LoRA experts to
represent various traits, such as openness, conscientiousness, extraversion,
agreeableness and neuroticism. Then, we integrate P-Tailor with a personality
specialization loss, promoting experts to specialize in distinct personality
traits, thereby enhancing the efficiency of model parameter utilization. Due to
the lack of datasets, we also curate a high-quality personality crafting
dataset (PCD) to learn and develop the ability to exhibit different personality
traits across various topics. We conduct extensive experiments to verify the
great performance and effectiveness of P-Tailor in manipulation of the
fine-grained personality traits of LLMs."
The Heterophilic Snowflake Hypothesis - Training and Empowering GNNs for Heterophilic Graphs,https://arxiv.org/abs/2406.12539,2024-06-18,2024-06-21,0.0,0.0,"Graph Neural Networks (GNNs) have become pivotal tools for a range of
graph-based learning tasks. Notably, most current GNN architectures operate
under the assumption of homophily, whether explicitly or implicitly. While this
underlying assumption is frequently adopted, it is not universally applicable,
which can result in potential shortcomings in learning effectiveness. In this
paper, \textbf{for the first time}, we transfer the prevailing concept of ``one
node one receptive field"" to the heterophilic graph. By constructing a proxy
label predictor, we enable each node to possess a latent prediction
distribution, which assists connected nodes in determining whether they should
aggregate their associated neighbors. Ultimately, every node can have its own
unique aggregation hop and pattern, much like each snowflake is unique and
possesses its own characteristics. Based on observations, we innovatively
introduce the Heterophily Snowflake Hypothesis and provide an effective
solution to guide and facilitate research on heterophilic graphs and beyond. We
conduct comprehensive experiments including (1) main results on 10 graphs with
varying heterophily ratios across 10 backbones; (2) scalability on various deep
GNN backbones (SGC, JKNet, etc.) across various large number of layers
(2,4,6,8,16,32 layers); (3) comparison with conventional snowflake hypothesis;
(4) efficiency comparison with existing graph pruning algorithms. Our
observations show that our framework acts as a versatile operator for diverse
tasks. It can be integrated into various GNN frameworks, boosting performance
in-depth and offering an explainable approach to choosing the optimal network
depth. The source code is available at
\url{https://github.com/bingreeky/HeteroSnoH}."
Variational Distillation of Diffusion Policies into Mixture of Experts,https://arxiv.org/abs/2406.12538,2024-06-18,2024-06-21,0.0,0.0,"This work introduces Variational Diffusion Distillation (VDD), a novel method
that distills denoising diffusion policies into Mixtures of Experts (MoE)
through variational inference. Diffusion Models are the current
state-of-the-art in generative modeling due to their exceptional ability to
accurately learn and represent complex, multi-modal distributions. This ability
allows Diffusion Models to replicate the inherent diversity in human behavior,
making them the preferred models in behavior learning such as Learning from
Human Demonstrations (LfD). However, diffusion models come with some drawbacks,
including the intractability of likelihoods and long inference times due to
their iterative sampling process. The inference times, in particular, pose a
significant challenge to real-time applications such as robot control. In
contrast, MoEs effectively address the aforementioned issues while retaining
the ability to represent complex distributions but are notoriously difficult to
train. VDD is the first method that distills pre-trained diffusion models into
MoE models, and hence, combines the expressiveness of Diffusion Models with the
benefits of Mixture Models. Specifically, VDD leverages a decompositional upper
bound of the variational objective that allows the training of each expert
separately, resulting in a robust optimization scheme for MoEs. VDD
demonstrates across nine complex behavior learning tasks, that it is able to:
i) accurately distill complex distributions learned by the diffusion model, ii)
outperform existing state-of-the-art distillation methods, and iii) surpass
conventional methods for training MoE."
Unified Active Retrieval for Retrieval Augmented Generation,https://arxiv.org/abs/2406.12534,2024-06-18,2024-06-21,0.0,0.0,"In Retrieval-Augmented Generation (RAG), retrieval is not always helpful and
applying it to every instruction is sub-optimal. Therefore, determining whether
to retrieve is crucial for RAG, which is usually referred to as Active
Retrieval. However, existing active retrieval methods face two challenges: 1.
They usually rely on a single criterion, which struggles with handling various
types of instructions. 2. They depend on specialized and highly differentiated
procedures, and thus combining them makes the RAG system more complicated and
leads to higher response latency. To address these challenges, we propose
Unified Active Retrieval (UAR). UAR contains four orthogonal criteria and casts
them into plug-and-play classification tasks, which achieves multifaceted
retrieval timing judgements with negligible extra inference cost. We further
introduce the Unified Active Retrieval Criteria (UAR-Criteria), designed to
process diverse active retrieval scenarios through a standardized procedure.
Experiments on four representative types of user instructions show that UAR
significantly outperforms existing work on the retrieval timing judgement and
the performance of downstream tasks, which shows the effectiveness of UAR and
its helpfulness to downstream tasks."
New Reservoir Computing Kernel Based on Chaotic Chua Circuit and Investigating Application to Post-Quantum Cryptography,https://arxiv.org/abs/2406.12948,2024-06-18,2024-06-21,0.0,0.0,"The aim of this project was to develop a new Reservoir Computer
implementation, based on a chaotic Chua circuit. In addition to suitable
classification and regression benchmarks, the Reservoir Computer was applied to
Post-Quantum Cryptography, with its suitability for this application
investigated and assessed. The cryptographic algorithm utilised was the
Learning with Errors problem, for both encryption and decryption. To achieve
this, the Chua circuit was characterised, in simulation, and by physical
circuit testing. The Reservoir Computer was designed and implemented using the
results of the characterisation. As part of this development, noise was
considered and mitigated.
  The benchmarks demonstrate that the Reservoir Computer can achieve current
literature benchmarks with low error. However, the results with Learning with
Errors suggest that a Chua-based Reservoir Computer is not sufficiently complex
to tackle the high non-linearity in Post-Quantum Cryptography. Future work
would involve researching the use of different combinations of multiple Chua
Reservoir Computers in larger neural network architectures. Such architectures
may produce the required high-dimensional behaviour to achieve the Learning
with Errors problem.
  This project is believed to be only the second instance of a Chua-based
Reservoir Computer in academia, and it is the first to be applied to
challenging real-world tasks such as Post-Quantum Cryptography. It is also
original by its investigation of hitherto unexplored parameters, and their
impact on performance. It demonstrates a proof-of-concept for a
mass-producible, inexpensive, low-power consumption hardware neural network. It
also enables the next stages in research to occur, paving the road for using
Chua-based Reservoir Computers across various applications."
TREE - Tree Regularization for Efficient Execution,https://arxiv.org/abs/2406.12531,2024-06-18,2024-06-21,0.0,0.0,"The rise of machine learning methods on heavily resource constrained devices
requires not only the choice of a suitable model architecture for the target
platform, but also the optimization of the chosen model with regard to
execution time consumption for inference in order to optimally utilize the
available resources. Random forests and decision trees are shown to be a
suitable model for such a scenario, since they are not only heavily tunable
towards the total model size, but also offer a high potential for optimizing
their executions according to the underlying memory architecture.
  In addition to the straightforward strategy of enforcing shorter paths
through decision trees and hence reducing the execution time for inference,
hardware-aware implementations can optimize the execution time in an orthogonal
manner. One particular hardware-aware optimization is to layout the memory of
decision trees in such a way, that higher probably paths are less likely to be
evicted from system caches. This works particularly well when splits within
tree nodes are uneven and have a high probability to visit one of the child
nodes.
  In this paper, we present a method to reduce path lengths by rewarding uneven
probability distributions during the training of decision trees at the cost of
a minimal accuracy degradation. Specifically, we regularize the impurity
computation of the CART algorithm in order to favor not only low impurity, but
also highly asymmetric distributions for the evaluation of split criteria and
hence offer a high optimization potential for a memory architecture-aware
implementation.
  We show that especially for binary classification data sets and data sets
with many samples, this form of regularization can lead to an reduction of up
to approximately four times in the execution time with a minimal accuracy
degradation."
LLM4MSR - An LLM-Enhanced Paradigm for Multi-Scenario Recommendation,https://arxiv.org/abs/2406.12529,2024-06-18,2024-06-21,0.0,0.0,"As the demand for more personalized recommendation grows and a dramatic boom
in commercial scenarios arises, the study on multi-scenario recommendation
(MSR) has attracted much attention, which uses the data from all scenarios to
simultaneously improve their recommendation performance. However, existing
methods tend to integrate insufficient scenario knowledge and neglect learning
personalized cross-scenario preferences, thus leading to suboptimal performance
and inadequate interpretability. Meanwhile, though large language model (LLM)
has shown great capability of reasoning and capturing semantic information, the
high inference latency and high computation cost of tuning hinder its
implementation in industrial recommender systems. To fill these gaps, we
propose an effective efficient interpretable LLM-enhanced paradigm LLM4MSR in
this work. Specifically, we first leverage LLM to uncover multi-level knowledge
including scenario correlations and users' cross-scenario interests from the
designed scenario- and user-level prompt without fine-tuning the LLM, then
adopt hierarchical meta networks to generate multi-level meta layers to
explicitly improves the scenario-aware and personalized recommendation
capability. Our experiments on KuaiSAR-small, KuaiSAR, and Amazon datasets
validate two significant advantages of LLM4MSR: (i) the effectiveness and
compatibility with different multi-scenario backbone models (achieving 1.5%,
1%, and 40% AUC improvement on three datasets), (ii) high efficiency and
deployability on industrial recommender systems, and (iii) improved
interpretability. The implemented code and data is available to ease
reproduction."
FuseGen - PLM Fusion for Data-generation based Zero-shot Learning,https://arxiv.org/abs/2406.12527,2024-06-18,2024-06-21,0.0,0.0,"Data generation-based zero-shot learning, although effective in training
Small Task-specific Models (STMs) via synthetic datasets generated by
Pre-trained Language Models (PLMs), is often limited by the low quality of such
synthetic datasets. Previous solutions have primarily focused on single PLM
settings, where synthetic datasets are typically restricted to specific
sub-spaces and often deviate from real-world distributions, leading to severe
distribution bias. To mitigate such bias, we propose FuseGen, a novel data
generation-based zero-shot learning framework that introduces a new criteria
for subset selection from synthetic datasets via utilizing multiple PLMs and
trained STMs. The chosen subset provides in-context feedback to each PLM,
enhancing dataset quality through iterative data generation. Trained STMs are
then used for sample re-weighting as well, further improving data quality.
Extensive experiments across diverse tasks demonstrate that FuseGen
substantially outperforms existing methods, highly effective in boosting STM
performance in a PLM-agnostic way. Code is provided in
https://github.com/LindaLydia/FuseGen."
On the Convergence of Ttonnement for Linear Fisher Markets,https://arxiv.org/abs/2406.12526,2024-06-18,2024-06-21,0.0,0.0,"T\^atonnement is a simple, intuitive market process where prices are
iteratively adjusted based on the difference between demand and supply. Many
variants under different market assumptions have been studied and shown to
converge to a market equilibrium, in some cases at a fast rate. However, the
classical case of linear Fisher markets have long eluded the analyses, and it
remains unclear whether t\^atonnement converges in this case. We show that, for
a sufficiently small step size, the prices given by the t\^atonnement process
are guaranteed to converge to equilibrium prices, up to a small approximation
radius that depends on the stepsize. To achieve this, we consider the dual
Eisenberg-Gale convex program in the price space, view t\^atonnement as
subgradient descent on this convex program, and utilize novel last-iterate
convergence results for subgradient descent under error bound conditions. In
doing so, we show that the convex program satisfies a particular error bound
condition, the quadratic growth condition, and that the price sequence
generated by t\^atonnement is bounded above and away from zero. We also show
that a similar convergence result holds for t\^atonnement in quasi-linear
Fisher markets. Numerical experiments are conducted to demonstrate that the
theoretical linear convergence aligns with empirical observations."
Update Selective Parameters - Federated Machine Unlearning Based on Model Explanation,https://arxiv.org/abs/2406.12516,2024-06-18,2024-06-21,0.0,0.0,"Federated learning is a promising privacy-preserving paradigm for distributed
machine learning. In this context, there is sometimes a need for a specialized
process called machine unlearning, which is required when the effect of some
specific training samples needs to be removed from a learning model due to
privacy, security, usability, and/or legislative factors. However, problems
arise when current centralized unlearning methods are applied to existing
federated learning, in which the server aims to remove all information about a
class from the global model. Centralized unlearning usually focuses on simple
models or is premised on the ability to access all training data at a central
node. However, training data cannot be accessed on the server under the
federated learning paradigm, conflicting with the requirements of the
centralized unlearning process. Additionally, there are high computation and
communication costs associated with accessing clients' data, especially in
scenarios involving numerous clients or complex global models. To address these
concerns, we propose a more effective and efficient federated unlearning scheme
based on the concept of model explanation. Model explanation involves
understanding deep networks and individual channel importance, so that this
understanding can be used to determine which model channels are critical for
classes that need to be unlearned. We select the most influential channels
within an already-trained model for the data that need to be unlearned and
fine-tune only influential channels to remove the contribution made by those
data. In this way, we can simultaneously avoid huge consumption costs and
ensure that the unlearned model maintains good performance. Experiments with
different training models on various datasets demonstrate the effectiveness of
the proposed approach."
Improving the Evaluation and Actionability of Explanation Methods for Multivariate Time Series Classification,https://arxiv.org/abs/2406.12507,2024-06-18,2024-06-21,0.0,0.0,"Explanation for Multivariate Time Series Classification (MTSC) is an
important topic that is under explored. There are very few quantitative
evaluation methodologies and even fewer examples of actionable explanation,
where the explanation methods are shown to objectively improve specific
computational tasks on time series data. In this paper we focus on analyzing
InterpretTime, a recent evaluation methodology for attribution methods applied
to MTSC. We showcase some significant weaknesses of the original methodology
and propose ideas to improve both its accuracy and efficiency. Unlike related
work, we go beyond evaluation and also showcase the actionability of the
produced explainer ranking, by using the best attribution methods for the task
of channel selection in MTSC. We find that perturbation-based methods such as
SHAP and Feature Ablation work well across a set of datasets, classifiers and
tasks and outperform gradient-based methods. We apply the best ranked
explainers to channel selection for MTSC and show significant data size
reduction and improved classifier accuracy."
Autonomous navigation of catheters and guidewires in mechanical thrombectomy using inverse reinforcement learning,https://arxiv.org/abs/2406.12499,2024-06-18,2024-06-21,0.0,0.0,"Purpose: Autonomous navigation of catheters and guidewires can enhance
endovascular surgery safety and efficacy, reducing procedure times and operator
radiation exposure. Integrating tele-operated robotics could widen access to
time-sensitive emergency procedures like mechanical thrombectomy (MT).
Reinforcement learning (RL) shows potential in endovascular navigation, yet its
application encounters challenges without a reward signal. This study explores
the viability of autonomous navigation in MT vasculature using inverse RL (IRL)
to leverage expert demonstrations. Methods: This study established a
simulation-based training and evaluation environment for MT navigation. We used
IRL to infer reward functions from expert behaviour when navigating a guidewire
and catheter. We utilized soft actor-critic to train models with various reward
functions and compared their performance in silico. Results: We demonstrated
feasibility of navigation using IRL. When evaluating single versus dual device
(i.e. guidewire versus catheter and guidewire) tracking, both methods achieved
high success rates of 95% and 96%, respectively. Dual-tracking, however,
utilized both devices mimicking an expert. A success rate of 100% and procedure
time of 22.6 s were obtained when training with a reward function obtained
through reward shaping. This outperformed a dense reward function (96%, 24.9 s)
and an IRL-derived reward function (48%, 59.2 s). Conclusions: We have
contributed to the advancement of autonomous endovascular intervention
navigation, particularly MT, by employing IRL. The results underscore the
potential of using reward shaping to train models, offering a promising avenue
for enhancing the accessibility and precision of MT. We envisage that future
research can extend our methodology to diverse anatomical structures to enhance
generalizability."
LightPAL - Lightweight Passage Retrieval for Open Domain Multi-Document Summarization,https://arxiv.org/abs/2406.12494,2024-06-18,2024-06-21,0.0,0.0,"Open-Domain Multi-Document Summarization (ODMDS) is crucial for addressing
diverse information needs, which aims to generate a summary as answer to user's
query, synthesizing relevant content from multiple documents in a large
collection. Existing approaches that first find relevant passages and then
generate a summary using a language model are inadequate for ODMDS. This is
because open-ended queries often require additional context for the retrieved
passages to cover the topic comprehensively, making it challenging to retrieve
all relevant passages initially. While iterative retrieval methods have been
explored for multi-hop question answering (MQA), they are impractical for ODMDS
due to high latency from repeated large language model (LLM) inference for
reasoning. To address this issue, we propose LightPAL, a lightweight passage
retrieval method for ODMDS that constructs a graph representing passage
relationships using an LLM during indexing and employs random walk instead of
iterative reasoning and retrieval at inference time. Experiments on ODMDS
benchmarks show that LightPAL outperforms baseline retrievers in summary
quality while being significantly more efficient than an iterative MQA
approach."
The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions,https://arxiv.org/abs/2406.12480,2024-06-18,2024-06-21,0.0,0.0,"Stance detection holds great potential for enhancing the quality of online
political discussions, as it has shown to be useful for summarizing
discussions, detecting misinformation, and evaluating opinion distributions.
Usually, transformer-based models are used directly for stance detection, which
require large amounts of data. However, the broad range of debate questions in
online political discussion creates a variety of possible scenarios that the
model is faced with and thus makes data acquisition for model training
difficult. In this work, we show how to leverage LLM-generated synthetic data
to train and improve stance detection agents for online political
discussions:(i) We generate synthetic data for specific debate questions by
prompting a Mistral-7B model and show that fine-tuning with the generated
synthetic data can substantially improve the performance of stance detection.
(ii) We examine the impact of combining synthetic data with the most
informative samples from an unlabelled dataset. First, we use the synthetic
data to select the most informative samples, second, we combine both these
samples and the synthetic data for fine-tuning. This approach reduces labelling
effort and consistently surpasses the performance of the baseline model that is
trained with fully labeled data. Overall, we show in comprehensive experiments
that LLM-generated data greatly improves stance detection performance for
online political discussions."
RS-GPT4V - A Unified Multimodal Instruction-Following Dataset for Remote Sensing Image Understanding,https://arxiv.org/abs/2406.12479,2024-06-18,2024-06-21,0.0,0.0,"The remote sensing image intelligence understanding model is undergoing a new
profound paradigm shift which has been promoted by multi-modal large language
model (MLLM), i.e. from the paradigm learning a domain model (LaDM) shifts to
paradigm learning a pre-trained general foundation model followed by an
adaptive domain model (LaGD). Under the new LaGD paradigm, the old datasets,
which have led to advances in RSI intelligence understanding in the last
decade, are no longer suitable for fire-new tasks. We argued that a new dataset
must be designed to lighten tasks with the following features: 1)
Generalization: training model to learn shared knowledge among tasks and to
adapt to different tasks; 2) Understanding complex scenes: training model to
understand the fine-grained attribute of the objects of interest, and to be
able to describe the scene with natural language; 3) Reasoning: training model
to be able to realize high-level visual reasoning. In this paper, we designed a
high-quality, diversified, and unified multimodal instruction-following dataset
for RSI understanding produced by GPT-4V and existing datasets, which we called
RS-GPT4V. To achieve generalization, we used a (Question, Answer) which was
deduced from GPT-4V via instruction-following to unify the tasks such as
captioning and localization; To achieve complex scene, we proposed a
hierarchical instruction description with local strategy in which the
fine-grained attributes of the objects and their spatial relationships are
described and global strategy in which all the local information are integrated
to yield detailed instruction descript; To achieve reasoning, we designed
multiple-turn QA pair to provide the reasoning ability for a model. The
empirical results show that the fine-tuned MLLMs by RS-GPT4V can describe
fine-grained information. The dataset is available at:
https://github.com/GeoX-Lab/RS-GPT4V."
Accelerating Depthwise Separable Convolutions on Ultra-Low-Power Devices,https://arxiv.org/abs/2406.12478,2024-06-18,2024-06-21,0.0,0.0,"Depthwise separable convolutions are a fundamental component in efficient
Deep Neural Networks, as they reduce the number of parameters and operations
compared to traditional convolutions while maintaining comparable accuracy.
However, their low data reuse opportunities make deploying them notoriously
difficult. In this work, we perform an extensive exploration of alternatives to
fuse the depthwise and pointwise kernels that constitute the separable
convolutional block. Our approach aims to minimize time-consuming memory
transfers by combining different data layouts. When targeting a commercial
ultra-low-power device with a three-level memory hierarchy, the GreenWaves GAP8
SoC, we reduce the latency of end-to-end network execution by up to 11.40%.
Furthermore, our kernels reduce activation data movements between L2 and L1
memories by up to 52.97%."
Adversarial Multi-dueling Bandits,https://arxiv.org/abs/2406.12475,2024-06-18,2024-06-21,0.0,0.0,"We introduce the problem of regret minimization in adversarial multi-dueling
bandits. While adversarial preferences have been studied in dueling bandits,
they have not been explored in multi-dueling bandits. In this setting, the
learner is required to select $m \geq 2$ arms at each round and observes as
feedback the identity of the most preferred arm which is based on an arbitrary
preference matrix chosen obliviously. We introduce a novel algorithm, MiDEX
(Multi Dueling EXP3), to learn from such preference feedback that is assumed to
be generated from a pairwise-subset choice model. We prove that the expected
cumulative $T$-round regret of MiDEX compared to a Borda-winner from a set of
$K$ arms is upper bounded by $O((K \log K)^{1/3} T^{2/3})$. Moreover, we prove
a lower bound of $\Omega(K^{1/3} T^{2/3})$ for the expected regret in this
setting which demonstrates that our proposed algorithm is near-optimal."
Exploring Intra and Inter-language Consistency in Embeddings with ICA,https://arxiv.org/abs/2406.12474,2024-06-18,2024-06-21,0.0,0.0,"Word embeddings represent words as multidimensional real vectors,
facilitating data analysis and processing, but are often challenging to
interpret. Independent Component Analysis (ICA) creates clearer semantic axes
by identifying independent key features. Previous research has shown ICA's
potential to reveal universal semantic axes across languages. However, it
lacked verification of the consistency of independent components within and
across languages. We investigated the consistency of semantic axes in two ways:
both within a single language and across multiple languages. We first probed
into intra-language consistency, focusing on the reproducibility of axes by
performing ICA multiple times and clustering the outcomes. Then, we
statistically examined inter-language consistency by verifying those axes'
correspondences using statistical tests. We newly applied statistical methods
to establish a robust framework that ensures the reliability and universality
of semantic axes."
Fighting Randomness with Randomness - Mitigating Optimisation Instability of Fine-Tuning using Delayed Ensemble and Noisy Interpolation,https://arxiv.org/abs/2406.12471,2024-06-18,2024-06-21,0.0,0.0,"While fine-tuning of pre-trained language models generally helps to overcome
the lack of labelled training samples, it also displays model performance
instability. This instability mainly originates from randomness in
initialisation or data shuffling. To address this, researchers either modify
the training process or augment the available samples, which typically results
in increased computational costs. We propose a new mitigation strategy, called
Delayed Ensemble with Noisy Interpolation (DENI), that leverages the strengths
of ensembling, noise regularisation and model interpolation, while retaining
computational efficiency. We compare DENI with 9 representative mitigation
strategies across 3 models, 4 tuning strategies and 7 text classification
datasets. We show that: 1) DENI outperforms the best performing mitigation
strategy (Ensemble), while using only a fraction of its cost; 2) the mitigation
strategies are beneficial for parameter-efficient fine-tuning (PEFT) methods,
outperforming full fine-tuning in specific cases; and 3) combining DENI with
data augmentation often leads to even more effective instability mitigation."
Adaptive Token Biaser - Knowledge Editing via Biasing Key Entities,https://arxiv.org/abs/2406.12468,2024-06-18,2024-06-21,0.0,0.0,"The parametric knowledge memorized by large language models (LLMs) becomes
outdated quickly. In-context editing (ICE) is currently the most effective
method for updating the knowledge of LLMs. Recent advancements involve
enhancing ICE by modifying the decoding strategy, obviating the need for
altering internal model structures or adjusting external prompts. However, this
enhancement operates across the entire sequence generation, encompassing a
plethora of non-critical tokens. In this work, we introduce $\textbf{A}$daptive
$\textbf{T}$oken $\textbf{Bias}$er ($\textbf{ATBias}$), a new decoding
technique designed to enhance ICE. It focuses on the tokens that are mostly
related to knowledge during decoding, biasing their logits by matching key
entities related to new and parametric knowledge. Experimental results show
that ATBias significantly enhances ICE performance, achieving up to a 32.3%
improvement over state-of-the-art ICE methods while incurring only half the
latency. ATBias not only improves the knowledge editing capabilities of ICE but
can also be widely applied to LLMs with negligible cost."
RIGL - A Unified Reciprocal Approach for Tracing the Independent and Group Learning Processes,https://arxiv.org/abs/2406.12465,2024-06-18,2024-06-21,0.0,0.0,"In the realm of education, both independent learning and group learning are
esteemed as the most classic paradigms. The former allows learners to
self-direct their studies, while the latter is typically characterized by
teacher-directed scenarios. Recent studies in the field of intelligent
education have leveraged deep temporal models to trace the learning process,
capturing the dynamics of students' knowledge states, and have achieved
remarkable performance. However, existing approaches have primarily focused on
modeling the independent learning process, with the group learning paradigm
receiving less attention. Moreover, the reciprocal effect between the two
learning processes, especially their combined potential to foster holistic
student development, remains inadequately explored. To this end, in this paper,
we propose RIGL, a unified Reciprocal model to trace knowledge states at both
the individual and group levels, drawing from the Independent and Group
Learning processes. Specifically, we first introduce a time frame-aware
reciprocal embedding module to concurrently model both student and group
response interactions across various time frames. Subsequently, we employ
reciprocal enhanced learning modeling to fully exploit the comprehensive and
complementary information between the two behaviors. Furthermore, we design a
relation-guided temporal attentive network, comprised of dynamic graph modeling
coupled with a temporal self-attention mechanism. It is used to delve into the
dynamic influence of individual and group interactions throughout the learning
processes. Conclusively, we introduce a bias-aware contrastive learning module
to bolster the stability of the model's training. Extensive experiments on four
real-world educational datasets clearly demonstrate the effectiveness of the
proposed RIGL model."
Insect Identification in the Wild - The AMI Dataset,https://arxiv.org/abs/2406.12452,2024-06-18,2024-06-21,0.0,0.0,"Insects represent half of all global biodiversity, yet many of the world's
insects are disappearing, with severe implications for ecosystems and
agriculture. Despite this crisis, data on insect diversity and abundance remain
woefully inadequate, due to the scarcity of human experts and the lack of
scalable tools for monitoring. Ecologists have started to adopt camera traps to
record and study insects, and have proposed computer vision algorithms as an
answer for scalable data processing. However, insect monitoring in the wild
poses unique challenges that have not yet been addressed within computer
vision, including the combination of long-tailed data, extremely similar
classes, and significant distribution shifts. We provide the first large-scale
machine learning benchmarks for fine-grained insect recognition, designed to
match real-world tasks faced by ecologists. Our contributions include a curated
dataset of images from citizen science platforms and museums, and an
expert-annotated dataset drawn from automated camera traps across multiple
continents, designed to test out-of-distribution generalization under field
conditions. We train and evaluate a variety of baseline algorithms and
introduce a combination of data augmentation techniques that enhance
generalization across geographies and hardware setups."
Adaptive Mean Estimation in the Hidden Markov sub-Gaussian Mixture Model,https://arxiv.org/abs/2406.12446,2024-06-18,2024-06-21,0.0,0.0,"We investigate the problem of center estimation in the high dimensional
binary sub-Gaussian Mixture Model with Hidden Markov structure on the labels.
We first study the limitations of existing results in the high dimensional
setting and then propose a minimax optimal procedure for the problem of center
estimation. Among other findings, we show that our procedure reaches the
optimal rate that is of order $\sqrt{\delta d/n} + d/n$ instead of $\sqrt{d/n}
+ d/n$ where $\delta \in(0,1)$ is a dependence parameter between labels. Along
the way, we also develop an adaptive variant of our procedure that is globally
minimax optimal. In order to do so, we rely on a more refined and localized
analysis of the estimation risk. Overall, leveraging the hidden Markovian
dependence between the labels, we show that it is possible to get a strict
improvement of the rates adaptively at almost no cost."
Abstraction-of-Thought Makes Language Models Better Reasoners,https://arxiv.org/abs/2406.12442,2024-06-18,2024-06-21,0.0,0.0,"Abstract reasoning, the ability to reason from the abstract essence of a
problem, serves as a key to generalization in human reasoning. However,
eliciting language models to perform reasoning with abstraction remains
unexplored. This paper seeks to bridge this gap by introducing a novel
structured reasoning format called Abstraction-of-Thought (AoT). The uniqueness
of AoT lies in its explicit requirement for varying levels of abstraction
within the reasoning process. This approach could elicit language models to
first contemplate on the abstract level before incorporating concrete details,
which is overlooked by the prevailing step-by-step Chain-of-Thought (CoT)
method. To align models with the AoT format, we present AoT Collection, a
generic finetuning dataset consisting of 348k high-quality samples with AoT
reasoning processes, collected via an automated and scalable pipeline. We
finetune a wide range of language models with AoT Collection and conduct
extensive evaluations on 23 unseen tasks from the challenging benchmark
Big-Bench Hard. Experimental results indicate that models aligned to AoT
reasoning format substantially outperform those aligned to CoT in many
reasoning tasks."
A data-centric approach for assessing progress of Graph Neural Networks,https://arxiv.org/abs/2406.12439,2024-06-18,2024-06-21,0.0,0.0,"Graph Neural Networks (GNNs) have achieved state-of-the-art results in node
classification tasks. However, most improvements are in multi-class
classification, with less focus on the cases where each node could have
multiple labels. The first challenge in studying multi-label node
classification is the scarcity of publicly available datasets. To address this,
we collected and released three real-world biological datasets and developed a
multi-label graph generator with tunable properties. We also argue that
traditional notions of homophily and heterophily do not apply well to
multi-label scenarios. Therefore, we define homophily and Cross-Class
Neighborhood Similarity for multi-label classification and investigate $9$
collected multi-label datasets. Lastly, we conducted a large-scale comparative
study with $8$ methods across nine datasets to evaluate current progress in
multi-label node classification. We release our code at
\url{https://github.com/Tianqi-py/MLGNC}."
Federated Learning with Limited Node Labels,https://arxiv.org/abs/2406.12435,2024-06-18,2024-06-21,0.0,0.0,"Subgraph federated learning (SFL) is a research methodology that has gained
significant attention for its potential to handle distributed graph-structured
data. In SFL, the local model comprises graph neural networks (GNNs) with a
partial graph structure. However, some SFL models have overlooked the
significance of missing cross-subgraph edges, which can lead to local GNNs
being unable to message-pass global representations to other parties' GNNs.
Moreover, existing SFL models require substantial labeled data, which limits
their practical applications. To overcome these limitations, we present a novel
SFL framework called FedMpa that aims to learn cross-subgraph node
representations. FedMpa first trains a multilayer perceptron (MLP) model using
a small amount of data and then propagates the federated feature to the local
structures. To further improve the embedding representation of nodes with local
subgraphs, we introduce the FedMpae method, which reconstructs the local graph
structure with an innovation view that applies pooling operation to form
super-nodes. Our extensive experiments on six graph datasets demonstrate that
FedMpa is highly effective in node classification. Furthermore, our ablation
experiments verify the effectiveness of FedMpa."
Towards Audio Codec-based Speech Separation,https://arxiv.org/abs/2406.12434,2024-06-18,2024-06-21,0.0,0.0,"Recent improvements in neural audio codec (NAC) models have generated
interest in adopting pre-trained codecs for a variety of speech processing
applications to take advantage of the efficiencies gained from high
compression, but these have yet been applied to the speech separation (SS)
task. SS can benefit from high compression because the compute required for
traditional SS models makes them impractical for many edge computing use cases.
However, SS is a waveform-masking task where compression tends to introduce
distortions that severely impact performance. Here we propose a novel task of
Audio Codec-based SS, where SS is performed within the embedding space of a
NAC, and propose a new model, Codecformer, to address this task. At inference,
Codecformer achieves a 52x reduction in MAC while producing separation
performance comparable to a cloud deployment of Sepformer. This method charts a
new direction for performing efficient SS in practical scenarios."
Exploring Sensing Devices for Heart and Lung Sound Monitoring,https://arxiv.org/abs/2406.12432,2024-06-18,2024-06-21,0.0,0.0,"This paper presents a comprehensive review of cardiorespiratory auscultation
sensing devices which is useful for understanding the theoretical aspects of
sensing devices, as well as practical notes to design novel sensing devices.
One of the methods to design a stethoscope is using electret condenser
microphones (ECM). In this paper, we first introduce the acoustic properties of
the heart and lungs, as well as a brief history of stethoscope evolution. Then,
we discuss the basic concept of ECM sensors and a recent stethoscope based on
this technology. In response to the limitations of ECM-based systems, we
explore the potential of microelectromechanical systems (MEMS), particularly
focusing on piezoelectric transducer (PZT) sensors. This paper comprehensively
reviews sensing technologies, emphasizing innovative MEMS-based designs for
wearable cardiopulmonary auscultation in the past decade. To our knowledge,
this is the first paper to summarize ECM and MEMS applications for heart and
lung sound analysis. Keywords: Micro-electro-mechanical Systems (MEMS);
Electret Condenser Microphone (ECM); Wearable Sensing Devices;
Cardiorespiratory Auscultation; Phonocardiography (PCG); Heart Sound; Lung
Sound"
PlanRAG - A Plan-then-Retrieval Augmented Generation for Generative Large Language Models as Decision Makers,https://arxiv.org/abs/2406.12430,2024-06-18,2024-06-21,0.0,0.0,"In this paper, we conduct a study to utilize LLMs as a solution for decision
making that requires complex data analysis. We define Decision QA as the task
of answering the best decision, $d_{best}$, for a decision-making question $Q$,
business rules $R$ and a database $D$. Since there is no benchmark that can
examine Decision QA, we propose Decision QA benchmark, DQA. It has two
scenarios, Locating and Building, constructed from two video games (Europa
Universalis IV and Victoria 3) that have almost the same goal as Decision QA.
To address Decision QA effectively, we also propose a new RAG technique called
the iterative plan-then-retrieval augmented generation (PlanRAG). Our
PlanRAG-based LM generates the plan for decision making as the first step, and
the retriever generates the queries for data analysis as the second step. The
proposed method outperforms the state-of-the-art iterative RAG method by 15.8%
in the Locating scenario and by 7.4% in the Building scenario, respectively. We
release our code and benchmark at https://github.com/myeon9h/PlanRAG."
Adaptive Selection for Homogeneous Tools - An Instantiation in the RAG Scenario,https://arxiv.org/abs/2406.12429,2024-06-18,2024-06-21,0.0,0.0,"Current research on tool learning primarily focuses on selecting the most
effective tool from a wide array of options, often overlooking
cost-effectiveness, a crucial factor in human problem-solving. In this paper,
we address the selection of homogeneous tools by predicting both their
performance and the associated cost required to accomplish a given task. We
then assign queries to the optimal tools in a cost-effective manner. Our
experimental results demonstrate that our method achieves higher performance at
a lower cost compared to strong baseline approaches."
PSLM - Parallel Generation of Text and Speech with LLMs for Low-Latency Spoken Dialogue Systems,https://arxiv.org/abs/2406.12428,2024-06-18,2024-06-21,0.0,0.0,"Multimodal language models that process both text and speech have a potential
for applications in spoken dialogue systems. However, current models face two
major challenges in response generation latency: (1) generating a spoken
response requires the prior generation of a written response, and (2) speech
sequences are significantly longer than text sequences. This study addresses
these issues by extending the input and output sequences of the language model
to support the parallel generation of text and speech. Our experiments on
spoken question answering tasks demonstrate that our approach improves latency
while maintaining the quality of response content. Additionally, we show that
latency can be further reduced by generating speech in multiple sequences. Demo
samples are available at https://rinnakk.github.io/research/publications/PSLM."
Deep Temporal Deaggregation - Large-Scale Spatio-Temporal Generative Models,https://arxiv.org/abs/2406.12423,2024-06-18,2024-06-21,0.0,0.0,"Many of today's data is time-series data originating from various sources,
such as sensors, transaction systems, or production systems. Major challenges
with such data include privacy and business sensitivity. Generative time-series
models have the potential to overcome these problems, allowing representative
synthetic data, such as people's movement in cities, to be shared openly and be
used to the benefit of society at large. However, contemporary approaches are
limited to prohibitively short sequences and small scales. Aside from major
memory limitations, the models generate less accurate and less representative
samples the longer the sequences are. This issue is further exacerbated by the
lack of a comprehensive and accessible benchmark. Furthermore, a common need in
practical applications is what-if analysis and dynamic adaptation to data
distribution changes, for usage in decision making and to manage a changing
world: What if this road is temporarily blocked or another road is added? The
focus of this paper is on mobility data, such as people's movement in cities,
requiring all these issues to be addressed. To this end, we propose a
transformer-based diffusion model, TDDPM, for time-series which outperforms and
scales substantially better than state-of-the-art. This is evaluated in a new
comprehensive benchmark across several sequence lengths, standard datasets, and
evaluation measures. We also demonstrate how the model can be conditioned on a
prior over spatial occupancy frequency information, allowing the model to
generate mobility data for previously unseen environments and for hypothetical
scenarios where the underlying road network and its usage changes. This is
evaluated by training on mobility data from part of a city. Then, using only
aggregate spatial information as prior, we demonstrate out-of-distribution
generalization to the unobserved remainder of the city."
Open-Source Web Service with Morphological Dictionary-Supplemented Deep Learning for Morphosyntactic Analysis of Czech,https://arxiv.org/abs/2406.12422,2024-06-18,2024-06-21,0.0,0.0,"We present an open-source web service for Czech morphosyntactic analysis. The
system combines a deep learning model with rescoring by a high-precision
morphological dictionary at inference time. We show that our hybrid method
surpasses two competitive baselines: While the deep learning model ensures
generalization for out-of-vocabulary words and better disambiguation, an
improvement over an existing morphological analyser MorphoDiTa, at the same
time, the deep learning model benefits from inference-time guidance of a
manually curated morphological dictionary. We achieve 50% error reduction in
lemmatization and 58% error reduction in POS tagging over MorphoDiTa, while
also offering dependency parsing. The model is trained on one of the currently
largest Czech morphosyntactic corpora, the PDT-C 1.0, with the trained models
available at https://hdl.handle.net/11234/1-5293. We provide the tool as a web
service deployed at https://lindat.mff.cuni.cz/services/udpipe/. The source
code is available at GitHub (https://github.com/ufal/udpipe/tree/udpipe-2),
along with a Python client for a simple use. The documentation for the models
can be found at https://ufal.mff.cuni.cz/udpipe/2/models#czech_pdtc1.0_model."
MMUTF - Multimodal Multimedia Event Argument Extraction with Unified Template Filling,https://arxiv.org/abs/2406.12420,2024-06-18,2024-06-21,0.0,0.0,"With the advancement of multimedia technologies, news documents and
user-generated content are often represented as multiple modalities, making
Multimedia Event Extraction (MEE) an increasingly important challenge. However,
recent MEE methods employ weak alignment strategies and data augmentation with
simple classification models, which ignore the capabilities of natural
language-formulated event templates for the challenging Event Argument
Extraction (EAE) task. In this work, we focus on EAE and address this issue by
introducing a unified template filling model that connects the textual and
visual modalities via textual prompts. This approach enables the exploitation
of cross-ontology transfer and the incorporation of event-specific semantics.
Experiments on the M2E2 benchmark demonstrate the effectiveness of our
approach. Our system surpasses the current SOTA on textual EAE by +7% F1, and
performs generally better than the second-best systems for multimedia EAE."
AI-Assisted Human Evaluation of Machine Translation,https://arxiv.org/abs/2406.12419,2024-06-18,2024-06-21,0.0,0.0,"Annually, research teams spend large amounts of money to evaluate the quality
of machine translation systems (WMT, inter alia). This is expensive because it
requires a lot of expert human labor. The recently adopted annotation protocol,
Error Span Annotation (ESA), has annotators marking erroneous parts of the
translation and then assigning a final score. A lot of the annotator time is
spent on scanning the translation for possible errors. In our work, we help the
annotators by pre-filling the error annotations with recall-oriented automatic
quality estimation. With this AI assistance, we obtain annotations at the same
quality level while cutting down the time per span annotation by half
(71s/error span $\rightarrow$ 31s/error span). The biggest advantage of
ESA$^\mathrm{AI}$ protocol is an accurate priming of annotators (pre-filled
error spans) before they assign the final score. This also alleviates a
potential automation bias, which we confirm to be low. In addition, the
annotation budget can be reduced by almost 25\% with filtering of examples that
the AI deems to be very likely to be correct."
Beyond Under-Alignment - Atomic Preference Enhanced Factuality Tuning for Large Language Models,https://arxiv.org/abs/2406.12416,2024-06-18,2024-06-21,0.0,0.0,"Large language models (LLMs) have achieved remarkable success but still tend
to generate factually erroneous responses, a phenomenon known as hallucination.
A recent trend is to use preference learning to fine-tune models to align with
factuality. However, existing work primarily evaluates fine-tuned models on
in-domain (ID) datasets and the factuality on out-of-domain (OOD) datasets
remains underexplored. In this paper, we conduct a comprehensive evaluation of
the factuality of different models tuned by various preference learning
algorithms and demonstrate that their performance on OOD datasets either
increases minimally or decreases. Subsequently, we reveal that the main cause
of model's failure to uphold factuality under a distribution shift is
\textbf{under-alignment}, rather than \textbf{over-alignment}, by analyzing the
token distribution shift of the models before and after tuning. Finally, we
propose \textbf{APEFT} (\textbf{A}tomic \textbf{P}reference \textbf{E}nhanced
\textbf{F}actuality \textbf{T}uning), a framework that enhances model's
awareness of factuality at the granularity of individual facts. Extensive
experiments demonstrate that APEFT improves model performance by an average of
$\boldsymbol{3.45\%}$ on both ID and OOD datasets, which is highly effective."
Pushing the Frontier on Approximate EFX Allocations,https://arxiv.org/abs/2406.12413,2024-06-18,2024-06-21,0.0,0.0,"We study the problem of allocating a set of indivisible goods to a set of
agents with additive valuation functions, aiming to achieve approximate
envy-freeness up to any good ($\alpha$-EFX). The state-of-the-art results on
the problem include that (exact) EFX allocations exist when (a) there are at
most three agents, or (b) the agents' valuation functions can take at most two
values, or (c) the agents' valuation functions can be represented via a graph.
For $\alpha$-EFX, it is known that a $0.618$-EFX allocation exists for any
number of agents with additive valuation functions. In this paper, we show that
$2/3$-EFX allocations exist when (a) there are at most \emph{seven agents}, (b)
the agents' valuation functions can take at most \emph{three values}, or (c)
the agents' valuation functions can be represented via a \emph{multigraph}. Our
results can be interpreted in two ways. First, by relaxing the notion of EFX to
$2/3$-EFX, we obtain existence results for strict generalizations of the
settings for which exact EFX allocations are known to exist. Secondly, by
imposing restrictions on the setting, we manage to beat the barrier of $0.618$
and achieve an approximation guarantee of $2/3$. Therefore, our results push
the \emph{frontier} of existence and computation of approximate EFX
allocations, and provide insights into the challenges of settling the existence
of exact EFX allocations."
A Novel Algorithm for Community Detection in Networks using Rough Sets and Consensus Clustering,https://arxiv.org/abs/2406.12412,2024-06-18,2024-06-21,0.0,0.0,"Complex networks, such as those in social, biological, and technological
systems, often present challenges to the task of community detection. Our
research introduces a novel rough clustering based consensus community
framework (RC-CCD) for effective structure identification of network
communities. The RC-CCD method employs rough set theory to handle uncertainties
within data and utilizes a consensus clustering approach to aggregate multiple
clustering results, enhancing the reliability and accuracy of community
detection. This integration allows the RC-CCD to effectively manage overlapping
communities, which are often present in complex networks.
  This approach excels at detecting overlapping communities, offering a
detailed and accurate representation of network structures. Comprehensive
testing on benchmark networks generated by the Lancichinetti-Fortunato-Radicchi
method showcased the strength and adaptability of the new proposal to varying
node degrees and community sizes. Cross-comparisons of RC-CCD versus other well
known detection algorithms outcomes highlighted its stability and adaptability."
TADM - Temporally-Aware Diffusion Model for Neurodegenerative Progression on Brain MRI,https://arxiv.org/abs/2406.12411,2024-06-18,2024-06-21,0.0,0.0,"Generating realistic images to accurately predict changes in the structure of
brain MRI is a crucial tool for clinicians. Such applications help assess
patients' outcomes and analyze how diseases progress at the individual level.
However, existing methods for this task present some limitations. Some
approaches attempt to model the distribution of MRI scans directly by
conditioning the model on patients' ages, but they fail to explicitly capture
the relationship between structural changes in the brain and time intervals,
especially on age-unbalanced datasets. Other approaches simply rely on
interpolation between scans, which limits their clinical application as they do
not predict future MRIs. To address these challenges, we propose a
Temporally-Aware Diffusion Model (TADM), which introduces a novel approach to
accurately infer progression in brain MRIs. TADM learns the distribution of
structural changes in terms of intensity differences between scans and combines
the prediction of these changes with the initial baseline scans to generate
future MRIs. Furthermore, during training, we propose to leverage a pre-trained
Brain-Age Estimator (BAE) to refine the model's training process, enhancing its
ability to produce accurate MRIs that match the expected age gap between
baseline and generated scans. Our assessment, conducted on the OASIS-3 dataset,
uses similarity metrics and region sizes computed by comparing predicted and
real follow-up scans on 3 relevant brain regions. TADM achieves large
improvements over existing approaches, with an average decrease of 24% in
region size error and an improvement of 4% in similarity metrics. These
evaluations demonstrate the improvement of our model in mimicking temporal
brain neurodegenerative progression compared to existing methods. Our approach
will benefit applications, such as predicting patient outcomes or improving
treatments for patients."
Translation Equivariant Transformer Neural Processes,https://arxiv.org/abs/2406.12409,2024-06-18,2024-06-21,0.0,0.0,"The effectiveness of neural processes (NPs) in modelling posterior prediction
maps -- the mapping from data to posterior predictive distributions -- has
significantly improved since their inception. This improvement can be
attributed to two principal factors: (1) advancements in the architecture of
permutation invariant set functions, which are intrinsic to all NPs; and (2)
leveraging symmetries present in the true posterior predictive map, which are
problem dependent. Transformers are a notable development in permutation
invariant set functions, and their utility within NPs has been demonstrated
through the family of models we refer to as TNPs. Despite significant interest
in TNPs, little attention has been given to incorporating symmetries. Notably,
the posterior prediction maps for data that are stationary -- a common
assumption in spatio-temporal modelling -- exhibit translation equivariance. In
this paper, we introduce of a new family of translation equivariant TNPs that
incorporate translation equivariance. Through an extensive range of experiments
on synthetic and real-world spatio-temporal data, we demonstrate the
effectiveness of TE-TNPs relative to their non-translation-equivariant
counterparts and other NP baselines."
Fast Rates for Bandit PAC Multiclass Classification,https://arxiv.org/abs/2406.12406,2024-06-18,2024-06-21,0.0,0.0,"We study multiclass PAC learning with bandit feedback, where inputs are
classified into one of $K$ possible labels and feedback is limited to whether
or not the predicted labels are correct. Our main contribution is in designing
a novel learning algorithm for the agnostic $(\varepsilon,\delta)$-PAC version
of the problem, with sample complexity of $O\big( (\operatorname{poly}(K) + 1 /
\varepsilon^2) \log (|H| / \delta) \big)$ for any finite hypothesis class $H$.
In terms of the leading dependence on $\varepsilon$, this improves upon
existing bounds for the problem, that are of the form $O(K/\varepsilon^2)$. We
also provide an extension of this result to general classes and establish
similar sample complexity bounds in which $\log |H|$ is replaced by the
Natarajan dimension. This matches the optimal rate in the full-information
version of the problem and resolves an open question studied by Daniely,
Sabato, Ben-David, and Shalev-Shwartz (2011) who demonstrated that the
multiplicative price of bandit feedback in realizable PAC learning is
$\Theta(K)$. We complement this by revealing a stark contrast with the agnostic
case, where the price of bandit feedback is only $O(1)$ as $\varepsilon \to 0$.
Our algorithm utilizes a stochastic optimization technique to minimize a
log-barrier potential based on Frank-Wolfe updates for computing a low-variance
exploration distribution over the hypotheses, and is made computationally
efficient provided access to an ERM oracle over $H$."
PDSS - A Privacy-Preserving Framework for Step-by-Step Distillation of Large Language Models,https://arxiv.org/abs/2406.12403,2024-06-18,2024-06-21,0.0,0.0,"In the context of real-world applications, leveraging large language models
(LLMs) for domain-specific tasks often faces two major challenges:
domain-specific knowledge privacy and constrained resources. To address these
issues, we propose PDSS, a privacy-preserving framework for step-by-step
distillation of LLMs. PDSS works on a server-client architecture, wherein
client transmits perturbed prompts to the server's LLM for rationale
generation. The generated rationales are then decoded by the client and used to
enrich the training of task-specific small language model(SLM) within a
multi-task learning paradigm. PDSS introduces two privacy protection
strategies: the Exponential Mechanism Strategy and the Encoder-Decoder
Strategy, balancing prompt privacy and rationale usability. Experiments
demonstrate the effectiveness of PDSS in various text generation tasks,
enabling the training of task-specific SLM with enhanced performance while
prioritizing data privacy protection."
Flee the Flaw - Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling,https://arxiv.org/abs/2406.12402,2024-06-18,2024-06-21,0.0,0.0,"Prior research in computational argumentation has mainly focused on scoring
the quality of arguments, with less attention on explicating logical errors. In
this work, we introduce four sets of explainable templates for common informal
logical fallacies designed to explicate a fallacy's implicit logic. Using our
templates, we conduct an annotation study on top of 400 fallacious arguments
taken from LOGIC dataset and achieve a high agreement score (Krippendorf's
alpha of 0.54) and reasonable coverage (0.83). Finally, we conduct an
experiment for detecting the structure of fallacies and discover that
state-of-the-art language models struggle with detecting fallacy templates
(0.47 accuracy). To facilitate research on fallacies, we make our dataset and
guidelines publicly available."
QueerBench - Quantifying Discrimination in Language Models Toward Queer Identities,https://arxiv.org/abs/2406.12399,2024-06-18,2024-06-21,0.0,0.0,"With the increasing role of Natural Language Processing (NLP) in various
applications, challenges concerning bias and stereotype perpetuation are
accentuated, which often leads to hate speech and harm. Despite existing
studies on sexism and misogyny, issues like homophobia and transphobia remain
underexplored and often adopt binary perspectives, putting the safety of
LGBTQIA+ individuals at high risk in online spaces. In this paper, we assess
the potential harm caused by sentence completions generated by English large
language models (LLMs) concerning LGBTQIA+ individuals. This is achieved using
QueerBench, our new assessment framework, which employs a template-based
approach and a Masked Language Modeling (MLM) task. The analysis indicates that
large language models tend to exhibit discriminatory behaviour more frequently
towards individuals within the LGBTQIA+ community, reaching a difference gap of
7.2% in the QueerBench score of harmfulness."
Unveiling the Flaws - Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models,https://arxiv.org/abs/2406.12397,2024-06-18,2024-06-21,0.0,0.0,"Synthetic data has been proposed as a solution to address the issue of
high-quality data scarcity in the training of large language models (LLMs).
Studies have shown that synthetic data can effectively improve the performance
of LLMs on downstream benchmarks. However, despite its potential benefits, our
analysis suggests that there may be inherent flaws in synthetic data. The
uniform format of synthetic data can lead to pattern overfitting and cause
significant shifts in the output distribution, thereby reducing the model's
instruction-following capabilities. Our work delves into these specific flaws
associated with question-answer (Q-A) pairs, a prevalent type of synthetic
data, and presents a method based on unlearning techniques to mitigate these
flaws. The empirical results demonstrate the effectiveness of our approach,
which can reverse the instruction-following issues caused by pattern
overfitting without compromising performance on benchmarks at relatively low
cost. Our work has yielded key insights into the effective use of synthetic
data, aiming to promote more robust and efficient LLM training."
Instruction Data Generation and Unsupervised Adaptation for Speech Language Models,https://arxiv.org/abs/2406.12946,2024-06-18,2024-06-21,0.0,0.0,"In this paper, we propose three methods for generating synthetic samples to
train and evaluate multimodal large language models capable of processing both
text and speech inputs. Addressing the scarcity of samples containing both
modalities, synthetic data generation emerges as a crucial strategy to enhance
the performance of such systems and facilitate the modeling of cross-modal
relationships between the speech and text domains. Our process employs large
language models to generate textual components and text-to-speech systems to
generate speech components. The proposed methods offer a practical and
effective means to expand the training dataset for these models. Experimental
results show progress in achieving an integrated understanding of text and
speech. We also highlight the potential of using unlabeled speech data to
generate synthetic samples comparable in quality to those with available
transcriptions, enabling the expansion of these models to more languages."
EMO-KNOW - A Large Scale Dataset on Emotion and Emotion-cause,https://arxiv.org/abs/2406.12389,2024-06-18,2024-06-21,0.0,0.0,"Emotion-Cause analysis has attracted the attention of researchers in recent
years. However, most existing datasets are limited in size and number of
emotion categories. They often focus on extracting parts of the document that
contain the emotion cause and fail to provide more abstractive, generalizable
root cause. To bridge this gap, we introduce a large-scale dataset of emotion
causes, derived from 9.8 million cleaned tweets over 15 years. We describe our
curation process, which includes a comprehensive pipeline for data gathering,
cleaning, labeling, and validation, ensuring the dataset's reliability and
richness. We extract emotion labels and provide abstractive summarization of
the events causing emotions. The final dataset comprises over 700,000 tweets
with corresponding emotion-cause pairs spanning 48 emotion classes, validated
by human evaluators. The novelty of our dataset stems from its broad spectrum
of emotion classes and the abstractive emotion cause that facilitates the
development of an emotion-cause knowledge graph for nuanced reasoning. Our
dataset will enable the design of emotion-aware systems that account for the
diverse emotional responses of different people for the same event."
From Instance Training to Instruction Learning - Task Adapters Generation from Instructions,https://arxiv.org/abs/2406.12382,2024-06-18,2024-06-21,0.0,0.0,"Large language models (LLMs) have acquired the ability to solve general tasks
by utilizing instruction finetuning (IFT). However, IFT still relies heavily on
instance training of extensive task data, which greatly limits the adaptability
of LLMs to real-world scenarios where labeled task instances are scarce and
broader task generalization becomes paramount. Contrary to LLMs, humans acquire
skills and complete tasks not merely through repeated practice but also by
understanding and following instructional guidelines. This paper is dedicated
to simulating human learning to address the shortcomings of instance training,
focusing on instruction learning to enhance cross-task generalization. Within
this context, we introduce Task Adapters Generation from Instructions (TAGI),
which automatically constructs the task-specific model in a parameter
generation manner based on the given task instructions without retraining for
unseen tasks. Specifically, we utilize knowledge distillation to enhance the
consistency between TAGI developed through Learning with Instruction and
task-specific models developed through Training with Instance, by aligning the
labels, output logits, and adapter parameters between them. TAGI is endowed
with cross-task generalization capabilities through a two-stage training
process that includes hypernetwork pretraining and finetuning. We evaluate TAGI
on the Super-Natural Instructions and P3 datasets. The experimental results
demonstrate that TAGI can match or even outperform traditional meta-trained
models and other hypernetwork models, while significantly reducing
computational requirements."
QOG -Question and Options Generation based on Language Model,https://arxiv.org/abs/2406.12381,2024-06-18,2024-06-21,0.0,0.0,"Question-Options Generation (QOG) is a task that involves generating a set of
question-options pairs given context. This task has various applications,
including fine-tuning large models, information retrieval, and automated
multiple-choice question generation for education. In this paper, we develop
QOG models using three different methods based on fine-tuning
sequence-to-sequence language models (LMs). Experiments demonstrate that the
end-to-end QOG model is computationally efficient and stable during both
training and inference, outperforming other methods. Furthermore, our analysis
indicates that our QOG models are competitive on the QOG task compared to the
large language model Llama 3-8B."
Efficient mapping of phase diagrams with conditional normalizing flows,https://arxiv.org/abs/2406.12378,2024-06-18,2024-06-21,0.0,0.0,"The accurate prediction of phase diagrams is of central importance for both
the fundamental understanding of materials as well as for technological
applications in material sciences. However, the computational prediction of the
relative stability between phases based on their free energy is a daunting
task, as traditional free energy estimators require a large amount of
simulation data to obtain uncorrelated equilibrium samples over a grid of
thermodynamic states. In this work, we develop deep generative machine learning
models based on the Boltzmann Generator approach for entire phase diagrams,
employing normalizing flows conditioned on the thermodynamic states, e.g.,
temperature and pressure, that they map to. By training a single normalizing
flow to transform the equilibrium distribution sampled at only one reference
thermodynamic state to a wide range of target temperatures and pressures, we
can efficiently generate equilibrium samples across the entire phase diagram.
Using a permutation-equivariant architecture allows us, thereby, to treat solid
and liquid phases on the same footing. We demonstrate our approach by
predicting the solid-liquid coexistence line for a Lennard-Jones system in
excellent agreement with state-of-the-art free energy methods while
significantly reducing the number of energy evaluations needed."
GW-MoE - Resolving Uncertainty in MoE Router with Global Workspace Theory,https://arxiv.org/abs/2406.12375,2024-06-18,2024-06-21,0.0,0.0,"Mixture-of-Experts (MoE) has been demonstrated as an efficient method to
scale up models. By dynamically and sparsely selecting activated experts, MoE
can effectively reduce computational costs. Despite the success, we observe
that many tokens in the MoE models have uncertain routing results. These tokens
have nearly equal scores for choosing each expert, and we demonstrate that this
uncertainty can lead to incorrect selections. Inspired by the Global Workspace
Theory (GWT), we propose a new fine-tuning method, GW-MoE, to address this
issue. The core idea is to broadcast the uncertain tokens across experts during
fine-tuning. Therefore, these tokens can acquire the necessary knowledge from
any expert during inference and become less sensitive to the choice. GW-MoE
does not introduce additional inference overhead. We validate that GW can
mitigate the uncertain problem and consistently improve in different tasks
(text classification, question answering, summarization, code generation, and
mathematical problem solving) and model sizes (650M and 8B parameters)."
Problem-Solving in Language Model Networks,https://arxiv.org/abs/2406.12374,2024-06-18,2024-06-21,0.0,0.0,"To improve the reasoning and question-answering capabilities of Large
Language Models (LLMs), several multi-agent approaches have been introduced.
While these methods enhance performance, the application of collective
intelligence-based approaches to complex network structures and the dynamics of
agent interactions remain underexplored. This work extends the concept of
multi-agent debate to more general network topologies, measuring the
question-answering accuracy, influence, consensus, and the effects of bias on
the collective. The results show that random networks perform similarly to
fully connected networks despite using significantly fewer tokens. Furthermore,
a strong consensus among agents correlates with correct answers, whereas
divided responses typically indicate incorrect answers. Analysing the influence
of the agents reveals a balance between self-reflection and interconnectedness;
self-reflection aids when local interactions are incorrect, and local
interactions aid when the agent itself is incorrect. Additionally, bias plays a
strong role in system performance with correctly biased hub nodes boosting
performance. These insights suggest that using random networks or scale-free
networks with knowledgeable agents placed in central positions can enhance the
overall question-answering performance of multi-agent systems."
WebCanvas - Benchmarking Web Agents in Online Environments,https://arxiv.org/abs/2406.12373,2024-06-18,2024-06-21,0.0,0.0,"For web agents to be practically useful, they must adapt to the continuously
evolving web environment characterized by frequent updates to user interfaces
and content. However, most existing benchmarks only capture the static aspects
of the web. To bridge this gap, we introduce WebCanvas, an innovative online
evaluation framework for web agents that effectively addresses the dynamic
nature of web interactions. WebCanvas contains three main components to
facilitate realistic assessments: (1) A novel evaluation metric which reliably
capture critical intermediate actions or states necessary for task completions
while disregarding noise caused by insignificant events or changed
web-elements. (2) A benchmark dataset called Mind2Web-Live, a refined version
of original Mind2Web static dataset containing 542 tasks with 2439 intermediate
evaluation states; (3) Lightweight and generalizable annotation tools and
testing pipelines that enables the community to collect and maintain the
high-quality, up-to-date dataset. Building on WebCanvas, we open-source an
agent framework with extensible modules for reasoning, providing a foundation
for the community to conduct online inference and evaluations. Our
best-performing agent achieves a task success rate of 23.1% and a task
completion rate of 48.8% on the Mind2Web-Live test set. Additionally, we
analyze the performance discrepancies across various websites, domains, and
experimental environments. We encourage the community to contribute further
insights on online agent evaluation, thereby advancing this field of research."
A Comparative Study of Continuous Sign Language Recognition Techniques,https://arxiv.org/abs/2406.12369,2024-06-18,2024-06-21,0.0,0.0,"Continuous Sign Language Recognition (CSLR) focuses on the interpretation of
a sequence of sign language gestures performed continually without pauses. In
this study, we conduct an empirical evaluation of recent deep learning CSLR
techniques and assess their performance across various datasets and sign
languages. The models selected for analysis implement a range of approaches for
extracting meaningful features and employ distinct training strategies. To
determine their efficacy in modeling different sign languages, these models
were evaluated using multiple datasets, specifically RWTH-PHOENIX-Weather-2014,
ArabSign, and GrSL, each representing a unique sign language. The performance
of the models was further tested with unseen signers and sentences. The
conducted experiments establish new benchmarks on the selected datasets and
provide valuable insights into the robustness and generalization of the
evaluated techniques under challenging scenarios."
Competitive Learning for Achieving Content-specific Filters in Video Coding for Machines,https://arxiv.org/abs/2406.12367,2024-06-18,2024-06-21,0.0,0.0,"This paper investigates the efficacy of jointly optimizing content-specific
post-processing filters to adapt a human oriented video/image codec into a
codec suitable for machine vision tasks. By observing that artifacts produced
by video/image codecs are content-dependent, we propose a novel training
strategy based on competitive learning principles. This strategy assigns
training samples to filters dynamically, in a fuzzy manner, which further
optimizes the winning filter on the given sample. Inspired by simulated
annealing optimization techniques, we employ a softmax function with a
temperature variable as the weight allocation function to mitigate the effects
of random initialization. Our evaluation, conducted on a system utilizing
multiple post-processing filters within a Versatile Video Coding (VVC) codec
framework, demonstrates the superiority of content-specific filters trained
with our proposed strategies, specifically, when images are processed in
blocks. Using VVC reference software VTM 12.0 as the anchor, experiments on the
OpenImages dataset show an improvement in the BD-rate reduction from -41.3% and
-44.6% to -42.3% and -44.7% for object detection and instance segmentation
tasks, respectively, compared to independently trained filters. The statistics
of the filter usage align with our hypothesis and underscore the importance of
jointly optimizing filters for both content and reconstruction quality. Our
findings pave the way for further improving the performance of video/image
codecs."
Structured Prediction in Online Learning,https://arxiv.org/abs/2406.12366,2024-06-18,2024-06-21,0.0,0.0,"We study a theoretical and algorithmic framework for structured prediction in
the online learning setting. The problem of structured prediction, i.e.
estimating function where the output space lacks a vectorial structure, is well
studied in the literature of supervised statistical learning. We show that our
algorithm is a generalisation of optimal algorithms from the supervised
learning setting, and achieves the same excess risk upper bound also when data
are not i.i.d. Moreover, we consider a second algorithm designed especially for
non-stationary data distributions, including adversarial data. We bound its
stochastic regret in function of the variation of the data distributions."
UrbanLLM - Autonomous Urban Activity Planning and Management with Large Language Models,https://arxiv.org/abs/2406.12360,2024-06-18,2024-06-21,0.0,0.0,"Location-based services play an critical role in improving the quality of our
daily lives. Despite the proliferation of numerous specialized AI models within
spatio-temporal context of location-based services, these models struggle to
autonomously tackle problems regarding complex urban planing and management. To
bridge this gap, we introduce UrbanLLM, a fine-tuned large language model (LLM)
designed to tackle diverse problems in urban scenarios. UrbanLLM functions as a
problem-solver by decomposing urban-related queries into manageable sub-tasks,
identifying suitable spatio-temporal AI models for each sub-task, and
generating comprehensive responses to the given queries. Our experimental
results indicate that UrbanLLM significantly outperforms other established
LLMs, such as Llama and the GPT series, in handling problems concerning complex
urban activity planning and management. UrbanLLM exhibits considerable
potential in enhancing the effectiveness of solving problems in urban
scenarios, reducing the workload and reliance for human experts."
Memory Sequence Length of Data Sampling Impacts the Adaptation of Meta-Reinforcement Learning Agents,https://arxiv.org/abs/2406.12359,2024-06-18,2024-06-21,0.0,0.0,"Fast adaptation to new tasks is extremely important for embodied agents in
the real world. Meta-reinforcement learning (meta-RL) has emerged as an
effective method to enable fast adaptation in unknown environments. Compared to
on-policy meta-RL algorithms, off-policy algorithms rely heavily on efficient
data sampling strategies to extract and represent the historical trajectories.
However, little is known about how different data sampling methods impact the
ability of meta-RL agents to represent unknown environments. Here, we
investigate the impact of data sampling strategies on the exploration and
adaptability of meta-RL agents. Specifically, we conducted experiments with two
types of off-policy meta-RL algorithms based on Thompson sampling and
Bayes-optimality theories in continuous control tasks within the MuJoCo
environment and sparse reward navigation tasks. Our analysis revealed the
long-memory and short-memory sequence sampling strategies affect the
representation and adaptive capabilities of meta-RL agents. We found that the
algorithm based on Bayes-optimality theory exhibited more robust and better
adaptability than the algorithm based on Thompson sampling, highlighting the
importance of appropriate data sampling strategies for the agent's
representation of an unknown environment, especially in the case of sparse
rewards."
Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models,https://arxiv.org/abs/2406.12354,2024-06-18,2024-06-21,0.0,0.0,"Pretrained language models memorize vast amounts of information, including
private and copyrighted data, raising significant safety concerns. Retraining
these models after excluding sensitive data is prohibitively expensive, making
machine unlearning a viable, cost-effective alternative. Previous research has
focused on machine unlearning for monolingual models, but we find that
unlearning in one language does not necessarily transfer to others. This
vulnerability makes models susceptible to low-resource language attacks, where
sensitive information remains accessible in less dominant languages. This paper
presents a pioneering approach to machine unlearning for multilingual language
models, selectively erasing information across different languages while
maintaining overall performance. Specifically, our method employs an adaptive
unlearning scheme that assigns language-dependent weights to address different
language performances of multilingual language models. Empirical results
demonstrate the effectiveness of our framework compared to existing unlearning
baselines, setting a new standard for secure and adaptable multilingual
language models."
Top-Down Bayesian Posterior Sampling for Sum-Product Networks,https://arxiv.org/abs/2406.12353,2024-06-18,2024-06-21,0.0,0.0,"Sum-product networks (SPNs) are probabilistic models characterized by exact
and fast evaluation of fundamental probabilistic operations. Its superior
computational tractability has led to applications in many fields, such as
machine learning with time constraints or accuracy requirements and real-time
systems. The structural constraints of SPNs supporting fast inference, however,
lead to increased learning-time complexity and can be an obstacle to building
highly expressive SPNs. This study aimed to develop a Bayesian learning
approach that can be efficiently implemented on large-scale SPNs. We derived a
new full conditional probability of Gibbs sampling by marginalizing multiple
random variables to expeditiously obtain the posterior distribution. The
complexity analysis revealed that our sampling algorithm works efficiently even
for the largest possible SPN. Furthermore, we proposed a hyperparameter tuning
method that balances the diversity of the prior distribution and optimization
efficiency in large-scale SPNs. Our method has improved learning-time
complexity and demonstrated computational speed tens to more than one hundred
times faster and superior predictive performance in numerical experiments on
more than 20 datasets."
Effective Generation of Feasible Solutions for Integer Programming via Guided Diffusion,https://arxiv.org/abs/2406.12349,2024-06-18,2024-06-21,0.0,0.0,"Feasible solutions are crucial for Integer Programming (IP) since they can
substantially speed up the solving process. In many applications, similar IP
instances often exhibit similar structures and shared solution distributions,
which can be potentially modeled by deep learning methods. Unfortunately,
existing deep-learning-based algorithms, such as Neural Diving and
Predict-and-search framework, are limited to generating only partial feasible
solutions, and they must rely on solvers like SCIP and Gurobi to complete the
solutions for a given IP problem. In this paper, we propose a novel framework
that generates complete feasible solutions end-to-end. Our framework leverages
contrastive learning to characterize the relationship between IP instances and
solutions, and learns latent embeddings for both IP instances and their
solutions. Further, the framework employs diffusion models to learn the
distribution of solution embeddings conditioned on IP representations, with a
dedicated guided sampling strategy that accounts for both constraints and
objectives. We empirically evaluate our framework on four typical datasets of
IP problems, and show that it effectively generates complete feasible solutions
with a high probability (> 89.7 \%) without the reliance of Solvers and the
quality of solutions is comparable to the best heuristic solutions from Gurobi.
Furthermore, by integrating our method's sampled partial solutions with the
CompleteSol heuristic from SCIP, the resulting feasible solutions outperform
those from state-of-the-art methods across all datasets, exhibiting a 3.7 to
33.7\% improvement in the gap to optimal values, and maintaining a feasible
ratio of over 99.7\% for all datasets."
Under the Hood of Tabular Data Generation Models - the Strong Impact of Hyperparameter Tuning,https://arxiv.org/abs/2406.12945,2024-06-18,2024-06-21,0.0,0.0,"We investigate the impact of dataset-specific hyperparameter, feature
encoding, and architecture tuning on five recent model families for tabular
data generation through an extensive benchmark on 16 datasets. This study
addresses the practical need for a unified evaluation of models that fully
considers hyperparameter optimization. Additionally, we propose a reduced
search space for each model that allows for quick optimization, achieving
nearly equivalent performance at a significantly lower cost.Our benchmark
demonstrates that, for most models, large-scale dataset-specific tuning
substantially improves performance compared to the original configurations.
Furthermore, we confirm that diffusion-based models generally outperform other
models on tabular data. However, this advantage is not significant when the
entire tuning and training process is restricted to the same GPU budget for all
models."
Navigating Knowledge Management Implementation Success in Government Organizations - A type-2 fuzzy approach,https://arxiv.org/abs/2406.12345,2024-06-18,2024-06-21,0.0,0.0,"Optimal information and knowledge management is crucial for organizations to
achieve their objectives efficiently. As a rare and valuable resource,
effective knowledge management provides a strategic advantage and has become a
key determinant of organizational success. The study aims to identify critical
success and failure factors for implementing knowledge management systems in
government organizations. This research employs a descriptive survey
methodology, collecting data through random interviews and questionnaires. The
study highlights the critical success factors for knowledge management systems
in government organizations, including cooperation, an open atmosphere, staff
training, creativity and innovation, removal of organizational constraints,
reward policies, role modeling, and focus. Conversely, failure to consider
formality, staff participation, collaboration technologies, network and
hardware infrastructure, complexity, IT staff, and trust can pose significant
obstacles to successful implementation."
PARAFAC2-based Coupled Matrix and Tensor Factorizations with Constraints,https://arxiv.org/abs/2406.12338,2024-06-18,2024-06-21,0.0,0.0,"Data fusion models based on Coupled Matrix and Tensor Factorizations (CMTF)
have been effective tools for joint analysis of data from multiple sources.
While the vast majority of CMTF models are based on the strictly multilinear
CANDECOMP/PARAFAC (CP) tensor model, recently also the more flexible PARAFAC2
model has been integrated into CMTF models. PARAFAC2 tensor models can handle
irregular/ragged tensors and have shown to be especially useful for modelling
dynamic data with unaligned or irregular time profiles. However, existing
PARAFAC2-based CMTF models have limitations in terms of possible
regularizations on the factors and/or types of coupling between datasets. To
address these limitations, in this paper we introduce a flexible algorithmic
framework that fits PARAFAC2-based CMTF models using Alternating Optimization
(AO) and the Alternating Direction Method of Multipliers (ADMM). The proposed
framework allows to impose various constraints on all modes and linear
couplings to other matrix-, CP- or PARAFAC2-models. Experiments on various
simulated and a real dataset demonstrate the utility and versatility of the
proposed framework as well as its benefits in terms of accuracy and efficiency
in comparison with state-of-the-art methods."
A Compass for Navigating the World of Sentence Embeddings for the Telecom Domain,https://arxiv.org/abs/2406.12336,2024-06-18,2024-06-21,0.0,0.0,"A plethora of sentence embedding models makes it challenging to choose one,
especially for domains such as telecom, rich with specialized vocabulary. We
evaluate multiple embeddings obtained from publicly available models and their
domain-adapted variants, on both point retrieval accuracies as well as their
(95\%) confidence intervals. We establish a systematic method to obtain
thresholds for similarity scores for different embeddings. We observe that
fine-tuning improves mean bootstrapped accuracies as well as tightens
confidence intervals. The pre-training combined with fine-tuning makes
confidence intervals even tighter. To understand these variations, we analyse
and report significant correlations between the distributional overlap between
top-$K$, correct and random sentence similarities with retrieval accuracies and
similarity thresholds. Following current literature, we analyze if retrieval
accuracy variations can be attributed to isotropy of embeddings. Our
conclusions are that isotropy of embeddings (as measured by two independent
state-of-the-art isotropy metric definitions) cannot be attributed to better
retrieval performance. However, domain adaptation which improves retrieval
accuracies also improves isotropy. We establish that domain adaptation moves
domain specific embeddings further away from general domain embeddings."
Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction - Value Also Matters,https://arxiv.org/abs/2406.12335,2024-06-18,2024-06-21,0.0,0.0,"Scaling the context size of large language models (LLMs) enables them to
perform various new tasks, e.g., book summarization. However, the memory cost
of the Key and Value (KV) cache in attention significantly limits the practical
applications of LLMs. Recent works have explored token pruning for KV cache
reduction in LLMs, relying solely on attention scores as a token importance
indicator. However, our investigation into value vector norms revealed a
notably non-uniform pattern questioning their reliance only on attention
scores. Inspired by this, we propose a new method: Value-Aware Token Pruning
(VATP) which uses both attention scores and the $ \ell_{1} $ norm of value
vectors to evaluate token importance. Extensive experiments on LLaMA2-7B-chat
and Vicuna-v1.5-7B across 16 LongBench tasks demonstrate that VATP outperforms
attention-score-only baselines in over 12 tasks, confirming the effectiveness
of incorporating value vector norms into token importance evaluation of LLMs."
What Did I Do Wrong? Quantifying LLMs' Sensitivity and Consistency to Prompt Engineering,https://arxiv.org/abs/2406.12334,2024-06-18,2024-06-21,0.0,0.0,"Large Language Models (LLMs) changed the way we design and interact with
software systems. Their ability to process and extract information from text
has drastically improved productivity in a number of routine tasks. Developers
that want to include these models in their software stack, however, face a
dreadful challenge: debugging LLMs' inconsistent behavior across minor
variations of the prompt. We therefore introduce two metrics for classification
tasks, namely sensitivity and consistency, which are complementary to task
performance. First, sensitivity measures changes of predictions across
rephrasings of the prompt, and does not require access to ground truth labels.
Instead, consistency measures how predictions vary across rephrasings for
elements of the same class. We perform an empirical comparison of these metrics
on text classification tasks, using them as guideline for understanding failure
modes of the LLM. Our hope is that sensitivity and consistency will be helpful
to guide prompt engineering and obtain LLMs that balance robustness with
performance."
Retrieval Meets Reasoning - Dynamic In-Context Editing for Long-Text Understanding,https://arxiv.org/abs/2406.12331,2024-06-18,2024-06-21,0.0,0.0,"Current Large Language Models (LLMs) face inherent limitations due to their
pre-defined context lengths, which impede their capacity for multi-hop
reasoning within extensive textual contexts. While existing techniques like
Retrieval-Augmented Generation (RAG) have attempted to bridge this gap by
sourcing external information, they fall short when direct answers are not
readily available. We introduce a novel approach that re-imagines information
retrieval through dynamic in-context editing, inspired by recent breakthroughs
in knowledge editing. By treating lengthy contexts as malleable external
knowledge, our method interactively gathers and integrates relevant
information, thereby enabling LLMs to perform sophisticated reasoning steps.
Experimental results demonstrate that our method effectively empowers
context-limited LLMs, such as Llama2, to engage in multi-hop reasoning with
improved performance, which outperforms state-of-the-art context window
extrapolation methods and even compares favorably to more advanced commercial
long-context models. Our interactive method not only enhances reasoning
capabilities but also mitigates the associated training and computational
costs, making it a pragmatic solution for enhancing LLMs' reasoning within
expansive contexts."
Security and Privacy of 6G Federated Learning-enabled Dynamic Spectrum Sharing,https://arxiv.org/abs/2406.12330,2024-06-18,2024-06-21,0.0,0.0,"Spectrum sharing is increasingly vital in 6G wireless communication,
facilitating dynamic access to unused spectrum holes. Recently, there has been
a significant shift towards employing machine learning (ML) techniques for
sensing spectrum holes. In this context, federated learning (FL)-enabled
spectrum sensing technology has garnered wide attention, allowing for the
construction of an aggregated ML model without disclosing the private spectrum
sensing information of wireless user devices. However, the integrity of
collaborative training and the privacy of spectrum information from local users
have remained largely unexplored. This article first examines the latest
developments in FL-enabled spectrum sharing for prospective 6G scenarios. It
then identifies practical attack vectors in 6G to illustrate potential
AI-powered security and privacy threats in these contexts. Finally, the study
outlines future directions, including practical defense challenges and
guidelines."
SNAP - Unlearning Selective Knowledge in Large Language Models with Negative Instructions,https://arxiv.org/abs/2406.12329,2024-06-18,2024-06-21,0.0,0.0,"Instruction-following large language models (LLMs), such as ChatGPT, have
become increasingly popular with the general audience, many of whom are
incorporating them into their daily routines. However, these LLMs inadvertently
disclose personal or copyrighted information, which calls for a machine
unlearning method to remove selective knowledge. Previous attempts sought to
forget the link between the target information and its associated entities, but
it rather led to generating undesirable responses about the target,
compromising the end-user experience. In this work, we propose SNAP, an
innovative framework designed to selectively unlearn information by 1) training
an LLM with negative instructions to generate obliterated responses, 2)
augmenting hard positives to retain the original LLM performance, and 3)
applying the novel Wasserstein regularization to ensure adequate deviation from
the initial weights of the LLM. We evaluate our framework on various NLP
benchmarks and demonstrate that our approach retains the original LLM
capabilities, while successfully unlearning the specified information."
Toward Exploring the Code Understanding Capabilities of Pre-trained Code Generation Models,https://arxiv.org/abs/2406.12326,2024-06-18,2024-06-21,0.0,0.0,"Recently, large code generation models trained in a self-supervised manner on
extensive unlabeled programming language data have achieved remarkable success.
While these models acquire vast amounts of code knowledge, they perform poorly
on code understanding tasks, such as code search and clone detection, as they
are specifically trained for generation. Pre-training a larger encoder-only
architecture model from scratch on massive code data can improve understanding
performance. However, this approach is costly and time-consuming, making it
suboptimal. In this paper, we pioneer the transfer of knowledge from
pre-trained code generation models to code understanding tasks, significantly
reducing training costs. We examine effective strategies for enabling
decoder-only models to acquire robust code representations. Furthermore, we
introduce CL4D, a contrastive learning method designed to enhance the
representation capabilities of decoder-only models. Comprehensive experiments
demonstrate that our approach achieves state-of-the-art performance in
understanding tasks such as code search and clone detection. Our analysis shows
that our method effectively reduces the distance between semantically identical
samples in the representation space. These findings suggest the potential for
unifying code understanding and generation tasks using a decoder-only
structured model."
PRePair - Pointwise Reasoning Enhance Pairwise Evaluating for Robust Instruction-Following Assessments,https://arxiv.org/abs/2406.12319,2024-06-18,2024-06-21,0.0,0.0,"Pairwise evaluation using large language models (LLMs) is widely used for
evaluating natural language generation (NLG) tasks. However, the reliability of
LLMs is often compromised by biases, such as favoring verbosity and
authoritative tone. In the study, we focus on the comparison of two LLM-based
evaluation approaches, pointwise and pairwise. Our findings demonstrate that
pointwise evaluators exhibit more robustness against undesirable preferences.
Further analysis reveals that pairwise evaluators can accurately identify the
shortcomings of low-quality outputs even when their judgment is incorrect.
These results indicate that LLMs are more severely influenced by their bias in
a pairwise evaluation setup. To mitigate this, we propose a hybrid method that
integrates pointwise reasoning into pairwise evaluation. Experimental results
show that our method enhances the robustness of pairwise evaluators against
adversarial samples while preserving accuracy on normal samples."
Finding Task-specific Subnetworks in Multi-task Spoken Language Understanding Model,https://arxiv.org/abs/2406.12317,2024-06-18,2024-06-21,0.0,0.0,"Recently, multi-task spoken language understanding (SLU) models have emerged,
designed to address various speech processing tasks. However, these models
often rely on a large number of parameters. Also, they often encounter
difficulties in adapting to new data for a specific task without experiencing
catastrophic forgetting of previously trained tasks. In this study, we propose
finding task-specific subnetworks within a multi-task SLU model via neural
network pruning. In addition to model compression, we expect that the
forgetting of previously trained tasks can be mitigated by updating only a
task-specific subnetwork. We conduct experiments on top of the state-of-the-art
multi-task SLU model ``UniverSLU'', trained for several tasks such as emotion
recognition (ER), intent classification (IC), and automatic speech recognition
(ASR). We show that pruned models were successful in adapting to additional ASR
or IC data with minimal performance degradation on previously trained tasks."
Enhancing Visible-Infrared Person Re-identification with Modality- and Instance-aware Visual Prompt Learning,https://arxiv.org/abs/2406.12316,2024-06-18,2024-06-21,0.0,0.0,"The Visible-Infrared Person Re-identification (VI ReID) aims to match visible
and infrared images of the same pedestrians across non-overlapped camera views.
These two input modalities contain both invariant information, such as shape,
and modality-specific details, such as color. An ideal model should utilize
valuable information from both modalities during training for enhanced
representational capability. However, the gap caused by modality-specific
information poses substantial challenges for the VI ReID model to handle
distinct modality inputs simultaneously. To address this, we introduce the
Modality-aware and Instance-aware Visual Prompts (MIP) network in our work,
designed to effectively utilize both invariant and specific information for
identification. Specifically, our MIP model is built on the transformer
architecture. In this model, we have designed a series of modality-specific
prompts, which could enable our model to adapt to and make use of the specific
information inherent in different modality inputs, thereby reducing the
interference caused by the modality gap and achieving better identification.
Besides, we also employ each pedestrian feature to construct a group of
instance-specific prompts. These customized prompts are responsible for guiding
our model to adapt to each pedestrian instance dynamically, thereby capturing
identity-level discriminative clues for identification. Through extensive
experiments on SYSU-MM01 and RegDB datasets, the effectiveness of both our
designed modules is evaluated. Additionally, our proposed MIP performs better
than most state-of-the-art methods."
PruningBench - A Comprehensive Benchmark of Structural Pruning,https://arxiv.org/abs/2406.12315,2024-06-18,2024-06-21,0.0,0.0,"Structural pruning has emerged as a promising approach for producing more
efficient models. Nevertheless, the community suffers from a lack of
standardized benchmarks and metrics, leaving the progress in this area not
fully comprehended. To fill this gap, we present the first comprehensive
benchmark, termed \textit{PruningBench}, for structural pruning. PruningBench
showcases the following three characteristics: 1) PruningBench employs a
unified and consistent framework for evaluating the effectiveness of diverse
structural pruning techniques; 2) PruningBench systematically evaluates 16
existing pruning methods, encompassing a wide array of models (e.g., CNNs and
ViTs) and tasks (e.g., classification and detection); 3) PruningBench provides
easily implementable interfaces to facilitate the implementation of future
pruning methods, and enables the subsequent researchers to incorporate their
work into our leaderboards. We provide an online pruning platform
http://pruning.vipazoo.cn for customizing pruning tasks and reproducing all
results in this paper. Codes will be made publicly on
https://github.com/HollyLee2000/PruningBench."
Mixture of Scales - Memory-Efficient Token-Adaptive Binarization for Large Language Models,https://arxiv.org/abs/2406.12311,2024-06-18,2024-06-21,0.0,0.0,"Binarization, which converts weight parameters to binary values, has emerged
as an effective strategy to reduce the size of large language models (LLMs).
However, typical binarization techniques significantly diminish linguistic
effectiveness of LLMs. To address this issue, we introduce a novel binarization
technique called Mixture of Scales (BinaryMoS). Unlike conventional methods,
BinaryMoS employs multiple scaling experts for binary weights, dynamically
merging these experts for each token to adaptively generate scaling factors.
This token-adaptive approach boosts the representational power of binarized
LLMs by enabling contextual adjustments to the values of binary weights.
Moreover, because this adaptive process only involves the scaling factors
rather than the entire weight matrix, BinaryMoS maintains compression
efficiency similar to traditional static binarization methods. Our experimental
results reveal that BinaryMoS surpasses conventional binarization techniques in
various natural language processing tasks and even outperforms 2-bit
quantization methods, all while maintaining similar model size to static
binarization techniques."
Can Tool-augmented Large Language Models be Aware of Incomplete Conditions?,https://arxiv.org/abs/2406.12307,2024-06-18,2024-06-21,0.0,0.0,"Recent advancements in integrating large language models (LLMs) with tools
have allowed the models to interact with real-world environments. However,
these \textit{tool-augmented LLMs} often encounter incomplete scenarios when
users provide partial information or the necessary tools are unavailable.
Recognizing and managing such scenarios is crucial for LLMs to ensure their
reliability, but this exploration remains understudied. This study examines
whether LLMs can identify incomplete conditions and appropriately determine
when to refrain from using tools. To this end, we address a dataset by
manipulating instances from two datasets by removing necessary tools or
essential information for tool invocation. We confirm that most LLMs are
challenged to identify the additional information required to utilize specific
tools and the absence of appropriate tools. We further analyze model behaviors
in different environments and compare their performance against humans. Our
research can contribute to advancing reliable LLMs by addressing scenarios that
commonly arise during interactions between humans and LLMs."
COT - A Generative Approach for Hate Speech Counter-Narratives via Contrastive Optimal Transport,https://arxiv.org/abs/2406.12304,2024-06-18,2024-06-21,0.0,0.0,"Counter-narratives, which are direct responses consisting of non-aggressive
fact-based arguments, have emerged as a highly effective approach to combat the
proliferation of hate speech. Previous methodologies have primarily focused on
fine-tuning and post-editing techniques to ensure the fluency of generated
contents, while overlooking the critical aspects of individualization and
relevance concerning the specific hatred targets, such as LGBT groups,
immigrants, etc. This research paper introduces a novel framework based on
contrastive optimal transport, which effectively addresses the challenges of
maintaining target interaction and promoting diversification in generating
counter-narratives. Firstly, an Optimal Transport Kernel (OTK) module is
leveraged to incorporate hatred target information in the token
representations, in which the comparison pairs are extracted between original
and transported features. Secondly, a self-contrastive learning module is
employed to address the issue of model degeneration. This module achieves this
by generating an anisotropic distribution of token representations. Finally, a
target-oriented search method is integrated as an improved decoding strategy to
explicitly promote domain relevance and diversification in the inference
process. This strategy modifies the model's confidence score by considering
both token similarity and target relevance. Quantitative and qualitative
experiments have been evaluated on two benchmark datasets, which demonstrate
that our proposed model significantly outperforms current methods evaluated by
metrics from multiple aspects."
A Step Towards a Universal Method for Modeling and Implementing Cross-Organizational Business Processes,https://arxiv.org/abs/2406.12302,2024-06-18,2024-06-21,0.0,0.0,"The widely adopted Business Process Model and Notation (BPMN) is a
cornerstone of industry standards for business process modeling. However, its
ambiguous execution semantics often result in inconsistent interpretations,
depending on the software used for implementation. In response, the Process
Specification Language (PASS) provides formally defined semantics to overcome
these interpretational challenges. Despite its clear advantages, PASS has not
reached the same level of industry penetration as BPMN.
  This feasibility study proposes using PASS as an intermediary framework to
translate and execute BPMN models. It describes the development of a prototype
translator that converts specific BPMN elements into a format compatible with
PASS. These models are then transformed into source code and executed in a
bespoke workflow environment, marking a departure from traditional BPMN
implementations.
  Our findings suggest that integrating PASS enhances compatibility across
different modeling and execution tools and offers a more robust methodology for
implementing business processes across organizations. This study lays the
groundwork for more accurate and unified business process model executions,
potentially transforming industry standards for process modeling and execution."
Research on Dangerous Flight Weather Prediction based on Machine Learning,https://arxiv.org/abs/2406.12298,2024-06-18,2024-06-21,0.0,0.0,"With the continuous expansion of the scale of air transport, the demand for
aviation meteorological support also continues to grow. The impact of hazardous
weather on flight safety is critical. How to effectively use meteorological
data to improve the early warning capability of flight dangerous weather and
ensure the safe flight of aircraft is the primary task of aviation
meteorological services. In this work, support vector machine (SVM) models are
used to predict hazardous flight weather, especially for meteorological
conditions with high uncertainty such as storms and turbulence. SVM is a
supervised learning method that distinguishes between different classes of data
by finding optimal decision boundaries in a high-dimensional space. In order to
meet the needs of this study, we chose the radial basis function (RBF) as the
kernel function, which helps to deal with nonlinear problems and enables the
model to better capture complex meteorological data structures. During the
model training phase, we used historical meteorological observations from
multiple weather stations, including temperature, humidity, wind speed, wind
direction, and other meteorological indicators closely related to flight
safety. From this data, the SVM model learns how to distinguish between normal
and dangerous flight weather conditions."
Faithful Density-Peaks Clustering via Matrix Computations on MPI Parallelization System,https://arxiv.org/abs/2406.12297,2024-06-18,2024-06-21,0.0,0.0,"Density peaks clustering (DP) has the ability of detecting clusters of
arbitrary shape and clustering non-Euclidean space data, but its quadratic
complexity in both computing and storage makes it difficult to scale for big
data. Various approaches have been proposed in this regard, including MapReduce
based distribution computing, multi-core parallelism, presentation
transformation (e.g., kd-tree, Z-value), granular computing, and so forth.
However, most of these existing methods face two limitations. One is their
target datasets are mostly constrained to be in Euclidian space, the other is
they emphasize only on local neighbors while ignoring global data distribution
due to restriction to cut-off kernel when computing density. To address the two
issues, we present a faithful and parallel DP method that makes use of two
types of vector-like distance matrices and an inverse leading-node-finding
policy. The method is implemented on a message passing interface (MPI) system.
Extensive experiments showed that our method is capable of clustering
non-Euclidean data such as in community detection, while outperforming the
state-of-the-art counterpart methods in accuracy when clustering large
Euclidean data. Our code is publicly available at
https://github.com/alanxuji/FaithPDP."
Fast and Slow Generating - An Empirical Study on Large and Small Language Models Collaborative Decoding,https://arxiv.org/abs/2406.12295,2024-06-18,2024-06-21,0.0,0.0,"Large Language Models (LLMs) demonstrate impressive performance in diverse
applications, yet they face significant drawbacks, including high inference
latency, expensive training cost, and generation of hallucination.
Collaborative decoding between large and small language models (SLMs) offers a
novel approach to address these challenges. Inspired by dual-process cognitive
theory, we integrate these methods into a unified framework termed Fast and
Slow Generating (FS-GEN). This paper explores several techniques within the
FS-GEN framework, including speculative decoding, contrastive decoding, and
emulator or proxy fine-tuning. We provide a comprehensive analysis of these
methodologies, offering insights into their similarities and differences under
this framework. Our study delves into the differential knowledge capabilities
of LLMs versus SLMs through the FS-GEN lens, revealing that fewer than 20% of
collaborative interactions are required across various methods. These
interactions adhere to a scaling law relative to the parameter ratios, thereby
facilitating predictable collaboration. Furthermore, we investigate the
specific positions where collaboration is most effective from an uncertainty
perspective, yielding novel insights that could refine FS-GEN methods. Our
findings reveal that the essential difference between models of different sizes
lies in the uncertainty of the next token prediction, where interventions by
larger models are most needed to assist the smaller ones. Code for
Reproduction: https://github.com/TsinghuaC3I/FS-GEN"
JEN-1 DreamStyler - Customized Musical Concept Learning via Pivotal Parameters Tuning,https://arxiv.org/abs/2406.12292,2024-06-18,2024-06-21,0.0,0.0,"Large models for text-to-music generation have achieved significant progress,
facilitating the creation of high-quality and varied musical compositions from
provided text prompts. However, input text prompts may not precisely capture
user requirements, particularly when the objective is to generate music that
embodies a specific concept derived from a designated reference collection. In
this paper, we propose a novel method for customized text-to-music generation,
which can capture the concept from a two-minute reference music and generate a
new piece of music conforming to the concept. We achieve this by fine-tuning a
pretrained text-to-music model using the reference music. However, directly
fine-tuning all parameters leads to overfitting issues. To address this
problem, we propose a Pivotal Parameters Tuning method that enables the model
to assimilate the new concept while preserving its original generative
capabilities. Additionally, we identify a potential concept conflict when
introducing multiple concepts into the pretrained model. We present a concept
enhancement strategy to distinguish multiple concepts, enabling the fine-tuned
model to generate music incorporating either individual or multiple concepts
simultaneously. Since we are the first to work on the customized music
generation task, we also introduce a new dataset and evaluation protocol for
the new task. Our proposed Jen1-DreamStyler outperforms several baselines in
both qualitative and quantitative evaluations. Demos will be available at
https://www.jenmusic.ai/research#DreamStyler."
Stability of Data-Dependent Ridge-Regularization for Inverse Problems,https://arxiv.org/abs/2406.12289,2024-06-18,2024-06-21,0.0,0.0,"Theoretical guarantees for the robust solution of inverse problems have
important implications for applications. To achieve both guarantees and high
reconstruction quality, we propose to learn a pixel-based ridge regularizer
with a data-dependent and spatially-varying regularization strength. For this
architecture, we establish the existence of solutions to the associated
variational problem and the stability of its solution operator. Further, we
prove that the reconstruction forms a maximum-a-posteriori approach.
Simulations for biomedical imaging and material sciences demonstrate that the
approach yields high-quality reconstructions even if only a small
instance-specific training set is available."
An Investigation of Neuron Activation as a Unified Lens to Explain Chain-of-Thought Eliciting Arithmetic Reasoning of LLMs,https://arxiv.org/abs/2406.12288,2024-06-18,2024-06-21,0.0,0.0,"Large language models (LLMs) have shown strong arithmetic reasoning
capabilities when prompted with Chain-of-Thought (CoT) prompts. However, we
have only a limited understanding of how they are processed by LLMs. To
demystify it, prior work has primarily focused on ablating different components
in the CoT prompt and empirically observing their resulting LLM performance
change. Yet, the reason why these components are important to LLM reasoning is
not explored. To fill this gap, in this work, we investigate ``neuron
activation'' as a lens to provide a unified explanation to observations made by
prior work. Specifically, we look into neurons within the feed-forward layers
of LLMs that may have activated their arithmetic reasoning capabilities, using
Llama2 as an example. To facilitate this investigation, we also propose an
approach based on GPT-4 to automatically identify neurons that imply arithmetic
reasoning. Our analyses revealed that the activation of reasoning neurons in
the feed-forward layers of an LLM can explain the importance of various
components in a CoT prompt, and future research can extend it for a more
complete understanding."
VIRL - Volume-Informed Representation Learning towards Few-shot Manufacturability Estimation,https://arxiv.org/abs/2406.12286,2024-06-18,2024-06-21,0.0,0.0,"Designing for manufacturing poses significant challenges in part due to the
computation bottleneck of Computer-Aided Manufacturing (CAM) simulations.
Although deep learning as an alternative offers fast inference, its performance
is dependently bounded by the need for abundant training data. Representation
learning, particularly through pre-training, offers promise for few-shot
learning, aiding in manufacturability tasks where data can be limited. This
work introduces VIRL, a Volume-Informed Representation Learning approach to
pre-train a 3D geometric encoder. The pretrained model is evaluated across four
manufacturability indicators obtained from CAM simulations: subtractive
machining (SM) time, additive manufacturing (AM) time, residual von Mises
stress, and blade collisions during Laser Power Bed Fusion process. Across all
case studies, the model pre-trained by VIRL shows substantial enhancements on
demonstrating improved generalizability with limited data and superior
performance with larger datasets. Regarding deployment strategy, case-specific
phenomenon exists where finetuning VIRL-pretrained models adversely affects AM
tasks with limited data but benefits SM time prediction. Moreover, the efficacy
of Low-rank adaptation (LoRA), which balances between probing and finetuning,
is explored. LoRA shows stable performance akin to probing with limited data,
while achieving a higher upper bound than probing as data size increases,
without the computational costs of finetuning. Furthermore, static
normalization of manufacturing indicators consistently performs well across
tasks, while dynamic normalization enhances performance when a reliable task
dependent input is available."
DASSF - Dynamic-Attention Scale-Sequence Fusion for Aerial Object Detection,https://arxiv.org/abs/2406.12285,2024-06-18,2024-06-21,0.0,0.0,"The detection of small objects in aerial images is a fundamental task in the
field of computer vision. Moving objects in aerial photography have problems
such as different shapes and sizes, dense overlap, occlusion by the background,
and object blur, however, the original YOLO algorithm has low overall detection
accuracy due to its weak ability to perceive targets of different scales. In
order to improve the detection accuracy of densely overlapping small targets
and fuzzy targets, this paper proposes a dynamic-attention scale-sequence
fusion algorithm (DASSF) for small target detection in aerial images. First, we
propose a dynamic scale sequence feature fusion (DSSFF) module that improves
the up-sampling mechanism and reduces computational load. Secondly, a x-small
object detection head is specially added to enhance the detection capability of
small targets. Finally, in order to improve the expressive ability of targets
of different types and sizes, we use the dynamic head (DyHead). The model we
proposed solves the problem of small target detection in aerial images and can
be applied to multiple different versions of the YOLO algorithm, which is
universal. Experimental results show that when the DASSF method is applied to
YOLOv8, compared to YOLOv8n, on the VisDrone-2019 and DIOR datasets, the model
shows an increase of 9.2% and 2.4% in the mean average precision (mAP),
respectively, and outperforms the current mainstream methods."
Demystifying the Recency Heuristic in Temporal-Difference Learning,https://arxiv.org/abs/2406.12284,2024-06-18,2024-06-21,0.0,0.0,"The recency heuristic in reinforcement learning is the assumption that
stimuli that occurred closer in time to an acquired reward should be more
heavily reinforced. The recency heuristic is one of the key assumptions made by
TD($\lambda$), which reinforces recent experiences according to an
exponentially decaying weighting. In fact, all other widely used return
estimators for TD learning, such as $n$-step returns, satisfy a weaker (i.e.,
non-monotonic) recency heuristic. Why is the recency heuristic effective for
temporal credit assignment? What happens when credit is assigned in a way that
violates this heuristic? In this paper, we analyze the specific mathematical
implications of adopting the recency heuristic in TD learning. We prove that
any return estimator satisfying this heuristic: 1) is guaranteed to converge to
the correct value function, 2) has a relatively fast contraction rate, and 3)
has a long window of effective credit assignment, yet bounded worst-case
variance. We also give a counterexample where on-policy, tabular TD methods
violating the recency heuristic diverge. Our results offer some of the first
theoretical evidence that credit assignment based on the recency heuristic
facilitates learning."
SAGDFN - A Scalable Adaptive Graph Diffusion Forecasting Network for Multivariate Time Series Forecasting,https://arxiv.org/abs/2406.12282,2024-06-18,2024-06-21,0.0,0.0,"Time series forecasting is essential for our daily activities and precise
modeling of the complex correlations and shared patterns among multiple time
series is essential for improving forecasting performance. Spatial-Temporal
Graph Neural Networks (STGNNs) are widely used in multivariate time series
forecasting tasks and have achieved promising performance on multiple
real-world datasets for their ability to model the underlying complex spatial
and temporal dependencies. However, existing studies have mainly focused on
datasets comprising only a few hundred sensors due to the heavy computational
cost and memory cost of spatial-temporal GNNs. When applied to larger datasets,
these methods fail to capture the underlying complex spatial dependencies and
exhibit limited scalability and performance. To this end, we present a Scalable
Adaptive Graph Diffusion Forecasting Network (SAGDFN) to capture complex
spatial-temporal correlation for large-scale multivariate time series and
thereby, leading to exceptional performance in multivariate time series
forecasting tasks. The proposed SAGDFN is scalable to datasets of thousands of
nodes without the need of prior knowledge of spatial correlation. Extensive
experiments demonstrate that SAGDFN achieves comparable performance with
state-of-the-art baselines on one real-world dataset of 207 nodes and
outperforms all state-of-the-art baselines by a significant margin on three
real-world datasets of 2000 nodes."
What Matters in Learning Facts in Language Models? Multifaceted Knowledge Probing with Diverse Multi-Prompt Datasets,https://arxiv.org/abs/2406.12277,2024-06-18,2024-06-21,0.0,0.0,"Large language models (LLMs) face issues in handling factual knowledge,
making it vital to evaluate their true ability to understand facts. In this
study, we introduce knowledge probing frameworks, BELIEF(-ICL), to evaluate the
knowledge understanding ability of not only encoder-based PLMs but also
decoder-based PLMs from diverse perspectives. BELIEFs utilize a multi-prompt
dataset to evaluate PLM's accuracy, consistency, and reliability in factual
knowledge understanding. To provide a more reliable evaluation with BELIEFs, we
semi-automatically create MyriadLAMA, which has more diverse prompts than
existing datasets. We validate the effectiveness of BELIEFs in correctly and
comprehensively evaluating PLM's factual understanding ability through
extensive evaluations. We further investigate key factors in learning facts in
LLMs, and reveal the limitation of the prompt-based knowledge probing. The
dataset is anonymously publicized."
CodeNav - Beyond tool-use to using real-world codebases with LLM agents,https://arxiv.org/abs/2406.12276,2024-06-18,2024-06-21,0.0,0.0,"We present CodeNav, an LLM agent that navigates and leverages previously
unseen code repositories to solve user queries. In contrast to tool-use LLM
agents that require ``registration'' of all relevant tools via manual
descriptions within the LLM context, CodeNav automatically indexes and searches
over code blocks in the target codebase, finds relevant code snippets, imports
them, and uses them to iteratively generate a solution with execution feedback.
To highlight the core-capabilities of CodeNav, we first showcase three case
studies where we use CodeNav for solving complex user queries using three
diverse codebases. Next, on three benchmarks, we quantitatively compare the
effectiveness of code-use (which only has access to the target codebase) to
tool-use (which has privileged access to all tool names and descriptions).
Finally, we study the effect of varying kinds of tool and library descriptions
on code-use performance, as well as investigate the advantage of the agent
seeing source code as opposed to natural descriptions of code. All code will be
made open source under a permissive license."
SafeInfer - Context Adaptive Decoding Time Safety Alignment for Large Language Models,https://arxiv.org/abs/2406.12274,2024-06-18,2024-06-21,0.0,0.0,"Safety-aligned language models often exhibit fragile and imbalanced safety
mechanisms, increasing the likelihood of generating unsafe content. In
addition, incorporating new knowledge through editing techniques to language
models can further compromise safety. To address these issues, we propose
SafeInfer, a context-adaptive, decoding-time safety alignment strategy for
generating safe responses to user queries. SafeInfer comprises two phases: the
safety amplification phase, which employs safe demonstration examples to adjust
the model's hidden states and increase the likelihood of safer outputs, and the
safety-guided decoding phase, which influences token selection based on
safety-optimized distributions, ensuring the generated content complies with
ethical guidelines. Further, we present HarmEval, a novel benchmark for
extensive safety evaluations, designed to address potential misuse scenarios in
accordance with the policies of leading AI tech giants."
Slot State Space Models,https://arxiv.org/abs/2406.12272,2024-06-18,2024-06-21,0.0,0.0,"Recent State Space Models (SSMs) such as S4, S5, and Mamba have shown
remarkable computational benefits in long-range temporal dependency modeling.
However, in many sequence modeling problems, the underlying process is
inherently modular and it is of interest to have inductive biases that mimic
this modular structure. In this paper, we introduce SlotSSMs, a novel framework
for incorporating independent mechanisms into SSMs to preserve or encourage
separation of information. Unlike conventional SSMs that maintain a monolithic
state vector, SlotSSMs maintains the state as a collection of multiple vectors
called slots. Crucially, the state transitions are performed independently per
slot with sparse interactions across slots implemented via the bottleneck of
self-attention. In experiments, we evaluate our model in object-centric video
understanding, 3D visual reasoning, and video prediction tasks, which involve
modeling multiple objects and their long-range temporal dependencies. We find
that our proposed design offers substantial performance gains over existing
sequence modeling methods. Project page is available at
https://slotssms.github.io/"
Unveiling Implicit Table Knowledge with Question-Then-Pinpoint Reasoner for Insightful Table Summarization,https://arxiv.org/abs/2406.12269,2024-06-18,2024-06-21,0.0,0.0,"Implicit knowledge hidden within the explicit table cells, such as data
insights, is the key to generating a high-quality table summary. However,
unveiling such implicit knowledge is a non-trivial task. Due to the complex
nature of structured tables, it is challenging even for large language models
(LLMs) to mine the implicit knowledge in an insightful and faithful manner. To
address this challenge, we propose a novel table reasoning framework
Question-then-Pinpoint. Our work focuses on building a plug-and-play table
reasoner that can self-question the insightful knowledge and answer it by
faithfully pinpointing evidence on the table to provide explainable guidance
for the summarizer. To train a reliable reasoner, we collect table knowledge by
guiding a teacher LLM to follow the coarse-to-fine reasoning paths and refine
it through two quality enhancement strategies to selectively distill the
high-quality knowledge to the reasoner. Extensive experiments on two table
summarization datasets, including our newly proposed InsTaSumm, validate the
general effectiveness of our framework."
Projection Methods for Operator Learning and Universal Approximation,https://arxiv.org/abs/2406.12264,2024-06-18,2024-06-21,0.0,0.0,"We obtain a new universal approximation theorem for continuous operators on
arbitrary Banach spaces using the Leray-Schauder mapping. Moreover, we
introduce and study a method for operator learning in Banach spaces $L^p$ of
functions with multiple variables, based on orthogonal projections on
polynomial bases. We derive a universal approximation result for operators
where we learn a linear projection and a finite dimensional mapping under some
additional assumptions. For the case of $p=2$, we give some sufficient
conditions for the approximation results to hold. This article serves as the
theoretical framework for a deep learning methodology whose implementation will
be provided in subsequent work."
Defending Against Social Engineering Attacks in the Age of LLMs,https://arxiv.org/abs/2406.12263,2024-06-18,2024-06-21,0.0,0.0,"The proliferation of Large Language Models (LLMs) poses challenges in
detecting and mitigating digital deception, as these models can emulate human
conversational patterns and facilitate chat-based social engineering (CSE)
attacks. This study investigates the dual capabilities of LLMs as both
facilitators and defenders against CSE threats. We develop a novel dataset,
SEConvo, simulating CSE scenarios in academic and recruitment contexts, and
designed to examine how LLMs can be exploited in these situations. Our findings
reveal that, while off-the-shelf LLMs generate high-quality CSE content, their
detection capabilities are suboptimal, leading to increased operational costs
for defense. In response, we propose ConvoSentinel, a modular defense pipeline
that improves detection at both the message and the conversation levels,
offering enhanced adaptability and cost-effectiveness. The retrieval-augmented
module in ConvoSentinel identifies malicious intent by comparing messages to a
database of similar conversations, enhancing CSE detection at all stages. Our
study highlights the need for advanced strategies to leverage LLMs in
cybersecurity."
Investigating Data Usage for Inductive Conformal Predictors,https://arxiv.org/abs/2406.12262,2024-06-18,2024-06-21,0.0,0.0,"Inductive conformal predictors (ICPs) are algorithms that are able to
generate prediction sets, instead of point predictions, which are valid at a
user-defined confidence level, only assuming exchangeability. These algorithms
are useful for reliable machine learning and are increasing in popularity. The
ICP development process involves dividing development data into three parts:
training, calibration and test. With access to limited or expensive development
data, it is an open question regarding the most efficient way to divide the
data. This study provides several experiments to explore this question and
consider the case for allowing overlap of examples between training and
calibration sets. Conclusions are drawn that will be of value to academics and
practitioners planning to use ICPs."
Self-Supervised Time-Series Anomaly Detection Using Learnable Data Augmentation,https://arxiv.org/abs/2406.12260,2024-06-18,2024-06-21,0.0,0.0,"Continuous efforts are being made to advance anomaly detection in various
manufacturing processes to increase the productivity and safety of industrial
sites. Deep learning replaced rule-based methods and recently emerged as a
promising method for anomaly detection in diverse industries. However, in the
real world, the scarcity of abnormal data and difficulties in obtaining labeled
data create limitations in the training of detection models. In this study, we
addressed these shortcomings by proposing a learnable data augmentation-based
time-series anomaly detection (LATAD) technique that is trained in a
self-supervised manner. LATAD extracts discriminative features from time-series
data through contrastive learning. At the same time, learnable data
augmentation produces challenging negative samples to enhance learning
efficiency. We measured anomaly scores of the proposed technique based on
latent feature similarities. As per the results, LATAD exhibited comparable or
improved performance to the state-of-the-art anomaly detection assessments on
several benchmark datasets and provided a gradient-based diagnosis technique to
help identify root causes."
CleanGen - Mitigating Backdoor Attacks for Generation Tasks in Large Language Models,https://arxiv.org/abs/2406.12257,2024-06-18,2024-06-21,0.0,0.0,"The remarkable performance of large language models (LLMs) in generation
tasks has enabled practitioners to leverage publicly available models to power
custom applications, such as chatbots and virtual assistants. However, the data
used to train or fine-tune these LLMs is often undisclosed, allowing an
attacker to compromise the data and inject backdoors into the models. In this
paper, we develop a novel inference time defense, named CleanGen, to mitigate
backdoor attacks for generation tasks in LLMs. CleanGenis a lightweight and
effective decoding strategy that is compatible with the state-of-the-art (SOTA)
LLMs. Our insight behind CleanGen is that compared to other LLMs, backdoored
LLMs assign significantly higher probabilities to tokens representing the
attacker-desired contents. These discrepancies in token probabilities enable
CleanGen to identify suspicious tokens favored by the attacker and replace them
with tokens generated by another LLM that is not compromised by the same
attacker, thereby avoiding generation of attacker-desired content. We evaluate
CleanGen against five SOTA backdoor attacks. Our results show that CleanGen
achieves lower attack success rates (ASR) compared to five SOTA baseline
defenses for all five backdoor attacks. Moreover, LLMs deploying CleanGen
maintain helpfulness in their responses when serving benign user queries with
minimal added computational overhead."
A Hopfieldian View-based Interpretation for Chain-of-Thought Reasoning,https://arxiv.org/abs/2406.12255,2024-06-18,2024-06-21,0.0,0.0,"Chain-of-Thought (CoT) holds a significant place in augmenting the reasoning
performance for large language models (LLMs). While some studies focus on
improving CoT accuracy through methods like retrieval enhancement, yet a
rigorous explanation for why CoT achieves such success remains unclear. In this
paper, we analyze CoT methods under two different settings by asking the
following questions: (1) For zero-shot CoT, why does prompting the model with
""let's think step by step"" significantly impact its outputs? (2) For few-shot
CoT, why does providing examples before questioning the model could
substantially improve its reasoning ability? To answer these questions, we
conduct a top-down explainable analysis from the Hopfieldian view and propose a
Read-and-Control approach for controlling the accuracy of CoT. Through
extensive experiments on seven datasets for three different tasks, we
demonstrate that our framework can decipher the inner workings of CoT, provide
reasoning error localization, and control to come up with the correct reasoning
path."
Mitigate Negative Transfer with Similarity Heuristic Lifelong Prompt Tuning,https://arxiv.org/abs/2406.12251,2024-06-18,2024-06-21,0.0,0.0,"Lifelong prompt tuning has significantly advanced parameter-efficient
lifelong learning with its efficiency and minimal storage demands on various
tasks. Our empirical studies, however, highlights certain transferability
constraints in the current methodologies: a universal algorithm that guarantees
consistent positive transfer across all tasks is currently unattainable,
especially when dealing dissimilar tasks that may engender negative transfer.
Identifying the misalignment between algorithm selection and task specificity
as the primary cause of negative transfer, we present the Similarity Heuristic
Lifelong Prompt Tuning (SHLPT) framework. This innovative strategy partitions
tasks into two distinct subsets by harnessing a learnable similarity metric,
thereby facilitating fruitful transfer from tasks regardless of their
similarity or dissimilarity. Additionally, SHLPT incorporates a parameter pool
to combat catastrophic forgetting effectively. Our experiments shows that SHLPT
outperforms state-of-the-art techniques in lifelong learning benchmarks and
demonstrates robustness against negative transfer in diverse task sequences."
TroL - Traversal of Layers for Large Language and Vision Models,https://arxiv.org/abs/2406.12246,2024-06-18,2024-06-21,0.0,0.0,"Large language and vision models (LLVMs) have been driven by the
generalization power of large language models (LLMs) and the advent of visual
instruction tuning. Along with scaling them up directly, these models enable
LLVMs to showcase powerful vision language (VL) performances by covering
diverse tasks via natural language instructions. However, existing open-source
LLVMs that perform comparably to closed-source LLVMs such as GPT-4V are often
considered too large (e.g., 26B, 34B, and 110B parameters), having a larger
number of layers. These large models demand costly, high-end resources for both
training and inference. To address this issue, we present a new efficient LLVM
family with 1.8B, 3.8B, and 7B LLM model sizes, Traversal of Layers (TroL),
which enables the reuse of layers in a token-wise manner. This layer traversing
technique simulates the effect of looking back and retracing the answering
stream while increasing the number of forward propagation layers without
physically adding more layers. We demonstrate that TroL employs a simple layer
traversing approach yet efficiently outperforms the open-source LLVMs with
larger model sizes and rivals the performances of the closed-source LLVMs with
substantial sizes."
CherryRec - Enhancing News Recommendation Quality via LLM-driven Framework,https://arxiv.org/abs/2406.12243,2024-06-18,2024-06-21,0.0,0.0,"Large Language Models (LLMs) have achieved remarkable progress in language
understanding and generation. Custom LLMs leveraging textual features have been
applied to recommendation systems, demonstrating improvements across various
recommendation scenarios. However, most existing methods perform untrained
recommendation based on pre-trained knowledge (e.g., movie recommendation), and
the auto-regressive generation of LLMs leads to slow inference speeds, making
them less effective in real-time recommendations.To address this, we propose a
framework for news recommendation using LLMs, named \textit{CherryRec}, which
ensures the quality of recommendations while accelerating the recommendation
process. Specifically, we employ a Knowledge-aware News Rapid Selector to
retrieve candidate options based on the user's interaction history. The history
and retrieved items are then input as text into a fine-tuned LLM, the
Content-aware News Llm Evaluator, designed to enhance news recommendation
capabilities. Finally, the Value-aware News Scorer integrates the scores to
compute the CherryRec Score, which serves as the basis for the final
recommendation.We validate the effectiveness of the proposed framework by
comparing it with state-of-the-art baseline methods on benchmark datasets. Our
experimental results consistently show that CherryRec outperforms the baselines
in both recommendation performance and efficiency.The project resource can be
accessed at: \url{https://github.com/xxxxxx}"
GMP-AR - Granularity Message Passing and Adaptive Reconciliation for Temporal Hierarchy Forecasting,https://arxiv.org/abs/2406.12242,2024-06-18,2024-06-21,0.0,0.0,"Time series forecasts of different temporal granularity are widely used in
real-world applications, e.g., sales prediction in days and weeks for making
different inventory plans. However, these tasks are usually solved separately
without ensuring coherence, which is crucial for aligning downstream decisions.
Previous works mainly focus on ensuring coherence with some straightforward
methods, e.g., aggregation from the forecasts of fine granularity to the coarse
ones, and allocation from the coarse granularity to the fine ones. These
methods merely take the temporal hierarchical structure to maintain coherence
without improving the forecasting accuracy. In this paper, we propose a novel
granularity message-passing mechanism (GMP) that leverages temporal hierarchy
information to improve forecasting performance and also utilizes an adaptive
reconciliation (AR) strategy to maintain coherence without performance loss.
Furthermore, we introduce an optimization module to achieve task-based targets
while adhering to more real-world constraints. Experiments on real-world
datasets demonstrate that our framework (GMP-AR) achieves superior performances
on temporal hierarchical forecasting tasks compared to state-of-the-art
methods. In addition, our framework has been successfully applied to a
real-world task of payment traffic management in Alipay by integrating with the
task-based optimization module."
More Efficient Randomized Exploration for Reinforcement Learning via Approximate Sampling,https://arxiv.org/abs/2406.12241,2024-06-18,2024-06-21,0.0,0.0,"Thompson sampling (TS) is one of the most popular exploration techniques in
reinforcement learning (RL). However, most TS algorithms with theoretical
guarantees are difficult to implement and not generalizable to Deep RL. While
the emerging approximate sampling-based exploration schemes are promising, most
existing algorithms are specific to linear Markov Decision Processes (MDP) with
suboptimal regret bounds, or only use the most basic samplers such as Langevin
Monte Carlo. In this work, we propose an algorithmic framework that
incorporates different approximate sampling methods with the recently proposed
Feel-Good Thompson Sampling (FGTS) approach (Zhang, 2022; Dann et al., 2021),
which was previously known to be computationally intractable in general. When
applied to linear MDPs, our regret analysis yields the best known dependency of
regret on dimensionality, surpassing existing randomized algorithms.
Additionally, we provide explicit sampling complexity for each employed
sampler. Empirically, we show that in tasks where deep exploration is
necessary, our proposed algorithms that combine FGTS and approximate sampling
perform significantly better compared to other strong baselines. On several
challenging games from the Atari 57 suite, our algorithms achieve performance
that is either better than or on par with other strong baselines from the deep
RL literature."
PFID - Privacy First Inference Delegation Framework for LLMs,https://arxiv.org/abs/2406.12238,2024-06-18,2024-06-21,0.0,0.0,"This paper introduces a novel privacy-preservation framework named PFID for
LLMs that addresses critical privacy concerns by localizing user data through
model sharding and singular value decomposition. When users are interacting
with LLM systems, their prompts could be subject to being exposed to
eavesdroppers within or outside LLM system providers who are interested in
collecting users' input. In this work, we proposed a framework to camouflage
user input, so as to alleviate privacy issues. Our framework proposes to place
model shards on the client and the public server, we sent compressed hidden
states instead of prompts to and from servers. Clients have held back
information that can re-privatized the hidden states so that overall system
performance is comparable to traditional LLMs services. Our framework was
designed to be communication efficient, computation can be delegated to the
local client so that the server's computation burden can be lightened. We
conduct extensive experiments on machine translation tasks to verify our
framework's performance."
SyncVSR - Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization,https://arxiv.org/abs/2406.12233,2024-06-18,2024-06-21,0.0,0.0,"Visual Speech Recognition (VSR) stands at the intersection of computer vision
and speech recognition, aiming to interpret spoken content from visual cues. A
prominent challenge in VSR is the presence of homophenes-visually similar lip
gestures that represent different phonemes. Prior approaches have sought to
distinguish fine-grained visemes by aligning visual and auditory semantics, but
often fell short of full synchronization. To address this, we present SyncVSR,
an end-to-end learning framework that leverages quantized audio for frame-level
crossmodal supervision. By integrating a projection layer that synchronizes
visual representation with acoustic data, our encoder learns to generate
discrete audio tokens from a video sequence in a non-autoregressive manner.
SyncVSR shows versatility across tasks, languages, and modalities at the cost
of a forward pass. Our empirical evaluations show that it not only achieves
state-of-the-art results but also reduces data usage by up to ninefold."
MCSD - An Efficient Language Model with Diverse Fusion,https://arxiv.org/abs/2406.12230,2024-06-18,2024-06-21,0.0,0.0,"Transformers excel in Natural Language Processing (NLP) due to their prowess
in capturing long-term dependencies but suffer from exponential resource
consumption with increasing sequence lengths. To address these challenges, we
propose MCSD model, an efficient language model with linear scaling and fast
inference speed. MCSD model leverages diverse feature fusion, primarily through
the multi-channel slope and decay (MCSD) block, to robustly represent features.
This block comprises slope and decay sections that extract features across
diverse temporal receptive fields, facilitating capture of both local and
global information. In addition, MCSD block conducts element-wise fusion of
diverse features to further enhance the delicate feature extraction capability.
For inference, we formulate the inference process into a recurrent
representation, slashing space complexity to $O(1)$ and time complexity to
$O(N)$ respectively. Our experiments show that MCSD attains higher throughput
and lower GPU memory consumption compared to Transformers, while maintaining
comparable performance to larger-scale language learning models on benchmark
tests. These attributes position MCSD as a promising base for edge deployment
and embodied intelligence."
Spatially Resolved Gene Expression Prediction from Histology via Multi-view Graph Contrastive Learning with HSIC-bottleneck Regularization,https://arxiv.org/abs/2406.12229,2024-06-18,2024-06-21,0.0,0.0,"The rapid development of spatial transcriptomics(ST) enables the measurement
of gene expression at spatial resolution, making it possible to simultaneously
profile the gene expression, spatial locations of spots, and the matched
histopathological images. However, the cost for collecting ST data is much
higher than acquiring histopathological images, and thus several studies
attempt to predict the gene expression on ST by leveraging their corresponding
histopathological images. Most of the existing image-based gene prediction
models treat the prediction task on each spot of ST data independently, which
ignores the spatial dependency among spots. In addition, while the histology
images share phenotypic characteristics with the ST data, it is still challenge
to extract such common information to help align paired image and expression
representations. To address the above issues, we propose a Multi-view Graph
Contrastive Learning framework with HSIC-bottleneck Regularization(ST-GCHB)
aiming at learning shared representation to help impute the gene expression of
the queried imagingspots by considering their spatial dependency."
Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector,https://arxiv.org/abs/2406.12227,2024-06-18,2024-06-21,0.0,0.0,"Fine-tuning large language models (LLMs) can cause them to lose their general
capabilities. However, the intrinsic mechanisms behind such forgetting remain
unexplored. In this paper, we begin by examining this phenomenon by focusing on
knowledge understanding and instruction following, with the latter identified
as the main contributor to forgetting during fine-tuning. Consequently, we
propose the Instruction Vector (IV) framework to capture model representations
highly related to specific instruction-following capabilities, thereby making
it possible to understand model-intrinsic forgetting. Through the analysis of
IV dynamics pre and post-training, we suggest that fine-tuning mostly adds
specialized reasoning patterns instead of erasing previous skills, which may
appear as forgetting. Building on this insight, we develop IV-guided training,
which aims to preserve original computation graph, thereby mitigating
catastrophic forgetting. Empirical tests on three benchmarks confirm the
efficacy of this new approach, supporting the relationship between IVs and
forgetting. Our code will be made available soon."
ToxiCloakCN - Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations,https://arxiv.org/abs/2406.12223,2024-06-18,2024-06-21,0.0,0.0,"Detecting hate speech and offensive language is essential for maintaining a
safe and respectful digital environment. This study examines the limitations of
state-of-the-art large language models (LLMs) in identifying offensive content
within systematically perturbed data, with a focus on Chinese, a language
particularly susceptible to such perturbations. We introduce
\textsf{ToxiCloakCN}, an enhanced dataset derived from ToxiCN, augmented with
homophonic substitutions and emoji transformations, to test the robustness of
LLMs against these cloaking perturbations. Our findings reveal that existing
models significantly underperform in detecting offensive content when these
perturbations are applied. We provide an in-depth analysis of how different
types of offensive content are affected by these perturbations and explore the
alignment between human and model explanations of offensiveness. Our work
highlights the urgent need for more advanced techniques in offensive language
detection to combat the evolving tactics used to evade detection mechanisms."
BadSampler - Harnessing the Power of Catastrophic Forgetting to Poison Byzantine-robust Federated Learning,https://arxiv.org/abs/2406.12222,2024-06-18,2024-06-21,0.0,0.0,"Federated Learning (FL) is susceptible to poisoning attacks, wherein
compromised clients manipulate the global model by modifying local datasets or
sending manipulated model updates. Experienced defenders can readily detect and
mitigate the poisoning effects of malicious behaviors using Byzantine-robust
aggregation rules. However, the exploration of poisoning attacks in scenarios
where such behaviors are absent remains largely unexplored for Byzantine-robust
FL. This paper addresses the challenging problem of poisoning Byzantine-robust
FL by introducing catastrophic forgetting. To fill this gap, we first formally
define generalization error and establish its connection to catastrophic
forgetting, paving the way for the development of a clean-label data poisoning
attack named BadSampler. This attack leverages only clean-label data (i.e.,
without poisoned data) to poison Byzantine-robust FL and requires the adversary
to selectively sample training data with high loss to feed model training and
maximize the model's generalization error. We formulate the attack as an
optimization problem and present two elegant adversarial sampling strategies,
Top-$\kappa$ sampling, and meta-sampling, to approximately solve it.
Additionally, our formal error upper bound and time complexity analysis
demonstrate that our design can preserve attack utility with high efficiency.
Extensive evaluations on two real-world datasets illustrate the effectiveness
and performance of our proposed attacks."
On-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation,https://arxiv.org/abs/2406.12221,2024-06-18,2024-06-21,0.0,0.0,"Hallucination occurs when large language models (LLMs) exhibit behavior that
deviates from the boundaries of their knowledge during the response generation
process. Previous learning-based methods focus on detecting knowledge
boundaries and finetuning models with instance-level feedback, but they suffer
from inaccurate signals due to off-policy data sampling and coarse-grained
feedback. In this paper, we introduce \textit{\b{R}einforcement \b{L}earning
\b{f}or \b{H}allucination} (RLFH), a fine-grained feedback-based online
reinforcement learning method for hallucination mitigation. Unlike previous
learning-based methods, RLFH enables LLMs to explore the boundaries of their
internal knowledge and provide on-policy, fine-grained feedback on these
explorations. To construct fine-grained feedback for learning reliable
generation behavior, RLFH decomposes the outcomes of large models into atomic
facts, provides statement-level evaluation signals, and traces back the signals
to the tokens of the original responses. Finally, RLFH adopts the online
reinforcement algorithm with these token-level rewards to adjust model behavior
for hallucination mitigation. For effective on-policy optimization, RLFH also
introduces an LLM-based fact assessment framework to verify the truthfulness
and helpfulness of atomic facts without human intervention. Experiments on
HotpotQA, SQuADv2, and Biography benchmarks demonstrate that RLFH can balance
their usage of internal knowledge during the generation process to eliminate
the hallucination behavior of LLMs."
"Hierarchical Associative Memory, Parallelized MLP-Mixer, and Symmetry Breaking",https://arxiv.org/abs/2406.12220,2024-06-18,2024-06-21,0.0,0.0,"Transformers have established themselves as the leading neural network model
in natural language processing and are increasingly foundational in various
domains. In vision, the MLP-Mixer model has demonstrated competitive
performance, suggesting that attention mechanisms might not be indispensable.
Inspired by this, recent research has explored replacing attention modules with
other mechanisms, including those described by MetaFormers. However, the
theoretical framework for these models remains underdeveloped. This paper
proposes a novel perspective by integrating Krotov's hierarchical associative
memory with MetaFormers, enabling a comprehensive representation of the entire
Transformer block, encompassing token-/channel-mixing modules, layer
normalization, and skip connections, as a single Hopfield network. This
approach yields a parallelized MLP-Mixer derived from a three-layer Hopfield
network, which naturally incorporates symmetric token-/channel-mixing modules
and layer normalization. Empirical studies reveal that symmetric interaction
matrices in the model hinder performance in image recognition tasks.
Introducing symmetry-breaking effects transitions the performance of the
symmetric parallelized MLP-Mixer to that of the vanilla MLP-Mixer. This
indicates that during standard training, weight matrices of the vanilla
MLP-Mixer spontaneously acquire a symmetry-breaking configuration, enhancing
their effectiveness. These findings offer insights into the intrinsic
properties of Transformers and MLP-Mixers and their theoretical underpinnings,
providing a robust framework for future model design and optimization."
Is persona enough for personality? Using ChatGPT to reconstruct an agent's latent personality from simple descriptions,https://arxiv.org/abs/2406.12216,2024-06-18,2024-06-21,0.0,0.0,"Personality, a fundamental aspect of human cognition, contains a range of
traits that influence behaviors, thoughts, and emotions. This paper explores
the capabilities of large language models (LLMs) in reconstructing these
complex cognitive attributes based only on simple descriptions containing
socio-demographic and personality type information. Utilizing the HEXACO
personality framework, our study examines the consistency of LLMs in recovering
and predicting underlying (latent) personality dimensions from simple
descriptions. Our experiments reveal a significant degree of consistency in
personality reconstruction, although some inconsistencies and biases, such as a
tendency to default to positive traits in the absence of explicit information,
are also observed. Additionally, socio-demographic factors like age and number
of children were found to influence the reconstructed personality dimensions.
These findings have implications for building sophisticated agent-based
simulacra using LLMs and highlight the need for further research on robust
personality generation in LLMs."
LLM-Oracle Machines,https://arxiv.org/abs/2406.12213,2024-06-18,2024-06-21,0.0,0.0,"Contemporary AI applications leverage large language models (LLMs) to harness
their knowledge and reasoning abilities for natural language processing tasks.
This approach shares similarities with the concept of oracle Turing machines
(OTMs). To capture the broader potential of these computations, including those
not yet realized, we propose an extension to OTMs: the LLM-oracle machine
(LLM-OM), by employing a cluster of LLMs as the oracle. Each LLM acts as a
black box, capable of answering queries within its expertise, albeit with a
delay. We introduce four variants of the LLM-OM: basic, augmented,
fault-avoidance, and $\epsilon$-fault. The first two are commonly observed in
existing AI applications. The latter two are specifically designed to address
the challenges of LLM hallucinations, biases, and inconsistencies, aiming to
ensure reliable outcomes."
Interface Design for Self-Supervised Speech Models,https://arxiv.org/abs/2406.12209,2024-06-18,2024-06-21,0.0,0.0,"Self-supervised speech (SSL) models have recently become widely adopted for
many downstream speech processing tasks. The general usage pattern is to employ
SSL models as feature extractors, and then train a downstream prediction head
to solve a specific task. However, different layers of SSL models have been
shown to capture different types of information, and the methods of combining
them are not well studied. To this end, we extend the general framework for SSL
model utilization by proposing the interface that connects the upstream and
downstream. Under this view, the dominant technique of combining features via a
layerwise weighted sum can be regarded as a specific interface. We propose
several alternative interface designs and demonstrate that the weighted sum
interface is suboptimal for many tasks. In particular, we show that a
convolutional interface whose depth scales logarithmically with the depth of
the upstream model consistently outperforms many other interface designs."
Knowledge Fusion By Evolving Weights of Language Models,https://arxiv.org/abs/2406.12208,2024-06-18,2024-06-21,0.0,0.0,"Fine-tuning pre-trained language models, particularly large language models,
demands extensive computing resources and can result in varying performance
outcomes across different domains and datasets. This paper examines the
approach of integrating multiple models from diverse training scenarios into a
unified model. This unified model excels across various data domains and
exhibits the ability to generalize well on out-of-domain data. We propose a
knowledge fusion method named Evolver, inspired by evolutionary algorithms,
which does not need further training or additional training data. Specifically,
our method involves aggregating the weights of different language models into a
population and subsequently generating offspring models through mutation and
crossover operations. These offspring models are then evaluated against their
parents, allowing for the preservation of those models that show enhanced
performance on development datasets. Importantly, our model evolving strategy
can be seamlessly integrated with existing model merging frameworks, offering a
versatile tool for model enhancement. Experimental results on mainstream
language models (i.e., encoder-only, decoder-only, encoder-decoder) reveal that
Evolver outperforms previous state-of-the-art models by large margins. The code
is publicly available at {https://github.com/duguodong7/model-evolution}."
Order-Optimal Instance-Dependent Bounds for Offline Reinforcement Learning with Preference Feedback,https://arxiv.org/abs/2406.12205,2024-06-18,2024-06-21,0.0,0.0,"We consider offline reinforcement learning (RL) with preference feedback in
which the implicit reward is a linear function of an unknown parameter. Given
an offline dataset, our objective consists in ascertaining the optimal action
for each state, with the ultimate goal of minimizing the {\em simple regret}.
We propose an algorithm, \underline{RL} with \underline{L}ocally
\underline{O}ptimal \underline{W}eights or {\sc RL-LOW}, which yields a simple
regret of $\exp ( - \Omega(n/H) )$ where $n$ is the number of data samples and
$H$ denotes an instance-dependent hardness quantity that depends explicitly on
the suboptimality gap of each action. Furthermore, we derive a
first-of-its-kind instance-dependent lower bound in offline RL with preference
feedback. Interestingly, we observe that the lower and upper bounds on the
simple regret match order-wise in the exponent, demonstrating order-wise
optimality of {\sc RL-LOW}. In view of privacy considerations in practical
applications, we also extend {\sc RL-LOW} to the setting of
$(\varepsilon,\delta)$-differential privacy and show, somewhat surprisingly,
that the hardness parameter $H$ is unchanged in the asymptotic regime as $n$
tends to infinity; this underscores the inherent efficiency of {\sc RL-LOW} in
terms of preserving the privacy of the observed rewards. Given our focus on
establishing instance-dependent bounds, our work stands in stark contrast to
previous works that focus on establishing worst-case regrets for offline RL
with preference feedback."
An Optimal Transport Approach for Network Regression,https://arxiv.org/abs/2406.12204,2024-06-18,2024-06-21,0.0,0.0,"We study the problem of network regression, where one is interested in how
the topology of a network changes as a function of Euclidean covariates. We
build upon recent developments in generalized regression models on metric
spaces based on Fr\'echet means and propose a network regression method using
the Wasserstein metric. We show that when representing graphs as multivariate
Gaussian distributions, the network regression problem requires the computation
of a Riemannian center of mass (i.e., Fr\'echet means). Fr\'echet means with
non-negative weights translates into a barycenter problem and can be
efficiently computed using fixed point iterations. Although the convergence
guarantees of fixed-point iterations for the computation of Wasserstein affine
averages remain an open problem, we provide evidence of convergence in a large
number of synthetic and real-data scenarios. Extensive numerical results show
that the proposed approach improves existing procedures by accurately
accounting for graph size, topology, and sparsity in synthetic experiments.
Additionally, real-world experiments using the proposed approach result in
higher Coefficient of Determination ($R^{2}$) values and lower mean squared
prediction error (MSPE), cementing improved prediction capabilities in
practice."
InterIntent - Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context,https://arxiv.org/abs/2406.12203,2024-06-18,2024-06-21,0.0,0.0,"Large language models (LLMs) have demonstrated the potential to mimic human
social intelligence. However, most studies focus on simplistic and static
self-report or performance-based tests, which limits the depth and validity of
the analysis. In this paper, we developed a novel framework, InterIntent, to
assess LLMs' social intelligence by mapping their ability to understand and
manage intentions in a game setting. We focus on four dimensions of social
intelligence: situational awareness, self-regulation, self-awareness, and
theory of mind. Each dimension is linked to a specific game task: intention
selection, intention following, intention summarization, and intention
guessing. Our findings indicate that while LLMs exhibit high proficiency in
selecting intentions, achieving an accuracy of 88\%, their ability to infer the
intentions of others is significantly weaker, trailing human performance by
20\%. Additionally, game performance correlates with intention understanding,
highlighting the importance of the four components towards success in this
game. These findings underline the crucial role of intention understanding in
evaluating LLMs' social intelligence and highlight the potential of using
social deduction games as a complex testbed to enhance LLM evaluation.
InterIntent contributes a structured approach to bridging the evaluation gap in
social intelligence within multiplayer games."
SFedCA - Credit Assignment-Based Active Client Selection Strategy for Spiking Federated Learning,https://arxiv.org/abs/2406.12200,2024-06-18,2024-06-21,0.0,0.0,"Spiking federated learning is an emerging distributed learning paradigm that
allows resource-constrained devices to train collaboratively at low power
consumption without exchanging local data. It takes advantage of both the
privacy computation property in federated learning (FL) and the energy
efficiency in spiking neural networks (SNN). Thus, it is highly promising to
revolutionize the efficient processing of multimedia data. However, existing
spiking federated learning methods employ a random selection approach for
client aggregation, assuming unbiased client participation. This neglect of
statistical heterogeneity affects the convergence and accuracy of the global
model significantly. In our work, we propose a credit assignment-based active
client selection strategy, the SFedCA, to judiciously aggregate clients that
contribute to the global sample distribution balance. Specifically, the client
credits are assigned by the firing intensity state before and after local model
training, which reflects the local data distribution difference from the global
model. Comprehensive experiments are conducted on various non-identical and
independent distribution (non-IID) scenarios. The experimental results
demonstrate that the SFedCA outperforms the existing state-of-the-art spiking
federated learning methods, and requires fewer communication rounds."
Debate as Optimization - Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction,https://arxiv.org/abs/2406.12197,2024-06-18,2024-06-21,0.0,0.0,"We propose a multi-agent debate as optimization (DAO) system for event
extraction, where the primary objective is to iteratively refine the large
language models (LLMs) outputs through debating without parameter tuning. In
DAO, we introduce two novel modules: the Diverse-RAG (DRAG) module and the
Adaptive Conformal Prediction (AdaCP) module. DRAG systematically retrieves
supporting information that best fits the debate discussion, while AdaCP
enhances the accuracy and reliability of event extraction by effectively
rejecting less promising answers. Experimental results demonstrate a
significant reduction in the performance gap between supervised approaches and
tuning-free LLM-based methods by 18.1% and 17.8% on ACE05 and 17.9% and 15.2%
on CASIE for event detection and argument extraction respectively."
Quantum Compiling with Reinforcement Learning on a Superconducting Processor,https://arxiv.org/abs/2406.12195,2024-06-18,2024-06-21,0.0,0.0,"To effectively implement quantum algorithms on noisy intermediate-scale
quantum (NISQ) processors is a central task in modern quantum technology. NISQ
processors feature tens to a few hundreds of noisy qubits with limited
coherence times and gate operations with errors, so NISQ algorithms naturally
require employing circuits of short lengths via quantum compilation. Here, we
develop a reinforcement learning (RL)-based quantum compiler for a
superconducting processor and demonstrate its capability of discovering novel
and hardware-amenable circuits with short lengths. We show that for the
three-qubit quantum Fourier transformation, a compiled circuit using only seven
CZ gates with unity circuit fidelity can be achieved. The compiler is also able
to find optimal circuits under device topological constraints, with lengths
considerably shorter than those by the conventional method. Our study
exemplifies the codesign of the software with hardware for efficient quantum
compilation, offering valuable insights for the advancement of RL-based
compilers."
Adaptive Collaborative Correlation Learning-based Semi-Supervised Multi-Label Feature Selection,https://arxiv.org/abs/2406.12193,2024-06-18,2024-06-21,0.0,0.0,"Semi-supervised multi-label feature selection has recently been developed to
solve the curse of dimensionality problem in high-dimensional multi-label data
with certain samples missing labels. Although many efforts have been made, most
existing methods use a predefined graph approach to capture the sample
similarity or the label correlation. In this manner, the presence of noise and
outliers within the original feature space can undermine the reliability of the
resulting sample similarity graph. It also fails to precisely depict the label
correlation due to the existence of unknown labels. Besides, these methods only
consider the discriminative power of selected features, while neglecting their
redundancy. In this paper, we propose an Adaptive Collaborative Correlation
lEarning-based Semi-Supervised Multi-label Feature Selection (Access-MFS)
method to address these issues. Specifically, a generalized regression model
equipped with an extended uncorrelated constraint is introduced to select
discriminative yet irrelevant features and maintain consistency between
predicted and ground-truth labels in labeled data, simultaneously. Then, the
instance correlation and label correlation are integrated into the proposed
regression model to adaptively learn both the sample similarity graph and the
label similarity graph, which mutually enhance feature selection performance.
Extensive experimental results demonstrate the superiority of the proposed
Access-MFS over other state-of-the-art methods."
Navigating the Labyrinth - Evaluating and Enhancing LLMs' Ability to Reason About Search Problems,https://arxiv.org/abs/2406.12172,2024-06-18,2024-06-21,0.0,0.0,"Recently, Large Language Models (LLMs) attained impressive performance in
math and reasoning benchmarks. However, they still often struggle with logic
problems and puzzles that are relatively easy for humans. To further
investigate this, we introduce a new benchmark, SearchBench, containing 11
unique search problem types, each equipped with automated pipelines to generate
an arbitrary number of instances and analyze the feasibility, correctness, and
optimality of LLM-generated solutions. We show that even the most advanced LLMs
fail to solve these problems end-to-end in text, e.g. GPT4 solves only 1.4%.
SearchBench problems require considering multiple pathways to the solution as
well as backtracking, posing a significant challenge to auto-regressive models.
Instructing LLMs to generate code that solves the problem helps, but only
slightly, e.g., GPT4's performance rises to 11.7%. In this work, we show that
in-context learning with A* algorithm implementations enhances performance. The
full potential of this promoting approach emerges when combined with our
proposed Multi-Stage-Multi-Try method, which breaks down the algorithm
implementation into two stages and verifies the first stage against unit tests,
raising GPT-4's performance above 57%."
BPO - Supercharging Online Preference Learning by Adhering to the Proximity of Behavior LLM,https://arxiv.org/abs/2406.12168,2024-06-18,2024-06-21,0.0,0.0,"Direct alignment from preferences (DAP) has emerged as a promising paradigm
for aligning large language models (LLMs) to human desiderata from
pre-collected, offline preference datasets. While recent studies indicate that
existing offline DAP methods can directly benefit from online training samples,
we highlight the need to develop specific online DAP algorithms to fully
harness the power of online training. Specifically, we identify that the
learned LLM should adhere to the proximity of the behavior LLM, which collects
the training samples. To this end, we propose online Preference Optimization in
proximity to the Behavior LLM (BPO), emphasizing the importance of constructing
a proper trust region for LLM alignment.
  We conduct extensive experiments to validate the effectiveness and
applicability of our approach by integrating it with various DAP methods,
resulting in significant performance improvements across a wide range of tasks
when training with the same amount of preference data. Even when only
introducing one additional data collection phase, our online BPO improves its
offline DAP baseline from 72.0% to 80.2% on TL;DR and from 82.2% to 89.1% on
Anthropic Helpfulness in terms of win rate against human reference text."
A Mel Spectrogram Enhancement Paradigm Based on CWT in Speech Synthesis,https://arxiv.org/abs/2406.12164,2024-06-18,2024-06-21,0.0,0.0,"Acoustic features play an important role in improving the quality of the
synthesised speech. Currently, the Mel spectrogram is a widely employed
acoustic feature in most acoustic models. However, due to the fine-grained loss
caused by its Fourier transform process, the clarity of speech synthesised by
Mel spectrogram is compromised in mutant signals. In order to obtain a more
detailed Mel spectrogram, we propose a Mel spectrogram enhancement paradigm
based on the continuous wavelet transform (CWT). This paradigm introduces an
additional task: a more detailed wavelet spectrogram, which like the
post-processing network takes as input the Mel spectrogram output by the
decoder. We choose Tacotron2 and Fastspeech2 for experimental validation in
order to test autoregressive (AR) and non-autoregressive (NAR) speech systems,
respectively. The experimental results demonstrate that the speech synthesised
using the model with the Mel spectrogram enhancement paradigm exhibits higher
MOS, with an improvement of 0.14 and 0.09 compared to the baseline model,
respectively. These findings provide some validation for the universality of
the enhancement paradigm, as they demonstrate the success of the paradigm in
different architectures."
Discussion Graph Semantics of First-Order Logic with Equality for Reasoning about Discussion and Argumentation,https://arxiv.org/abs/2406.12163,2024-06-18,2024-06-21,0.0,0.0,"We formulate discussion graph semantics of first-order logic with equality
for reasoning about discussion and argumentation as naturally as we would
reason about sentences. While there are a few existing proposals to use a
formal logic for reasoning about argumentation, they are constructed bottom-up
and specialised to the argumentation model by Dung. There is indeed a
conspicuous lack of a formal reasoning framework for handling general
discussion and argumentation models. We achieve the generality through a
top-down formulation of the semantics of first-order logic (with equality)
formulas, addressing the current shortage."
Exploring the Impact of a Transformer's Latent Space Geometry on Downstream Task Performance,https://arxiv.org/abs/2406.12159,2024-06-18,2024-06-21,0.0,0.0,"It is generally thought that transformer-based large language models benefit
from pre-training by learning generic linguistic knowledge that can be focused
on a specific task during fine-tuning. However, we propose that much of the
benefit from pre-training may be captured by geometric characteristics of the
latent space representations, divorced from any specific linguistic knowledge.
In this work we explore the relationship between GLUE benchmarking task
performance and a variety of measures applied to the latent space resulting
from BERT-type contextual language models. We find that there is a strong
linear relationship between a measure of quantized cell density and average
GLUE performance and that these measures may be predictive of otherwise
surprising GLUE performance for several non-standard BERT-type models from the
literature. These results may be suggestive of a strategy for decreasing
pre-training requirements, wherein model initialization can be informed by the
geometric characteristics of the model's latent space."
LLMs Are Prone to Fallacies in Causal Inference,https://arxiv.org/abs/2406.12158,2024-06-18,2024-06-21,0.0,0.0,"Recent work shows that causal facts can be effectively extracted from LLMs
through prompting, facilitating the creation of causal graphs for causal
inference tasks. However, it is unclear if this success is limited to
explicitly-mentioned causal facts in the pretraining data which the model can
memorize. Thus, this work investigates: Can LLMs infer causal relations from
other relational data in text? To disentangle the role of memorized causal
facts vs inferred causal relations, we finetune LLMs on synthetic data
containing temporal, spatial and counterfactual relations, and measure whether
the LLM can then infer causal relations. We find that: (a) LLMs are susceptible
to inferring causal relations from the order of two entity mentions in text
(e.g. X mentioned before Y implies X causes Y); (b) if the order is randomized,
LLMs still suffer from the post hoc fallacy, i.e. X occurs before Y (temporal
relation) implies X causes Y. We also find that while LLMs can correctly deduce
the absence of causal relations from temporal and spatial relations, they have
difficulty inferring causal relations from counterfactuals, questioning their
understanding of causality."
StableNormal - Reducing Diffusion Variance for Stable and Sharp Normal,https://arxiv.org/abs/2406.16864,2024-06-24,2024-06-25,0.0,0.0,"This work addresses the challenge of high-quality surface normal estimation
from monocular colored inputs (i.e., images and videos), a field which has
recently been revolutionized by repurposing diffusion priors. However, previous
attempts still struggle with stochastic inference, conflicting with the
deterministic nature of the Image2Normal task, and costly ensembling step,
which slows down the estimation process. Our method, StableNormal, mitigates
the stochasticity of the diffusion process by reducing inference variance, thus
producing ""Stable-and-Sharp"" normal estimates without any additional ensembling
process. StableNormal works robustly under challenging imaging conditions, such
as extreme lighting, blurring, and low quality. It is also robust against
transparent and reflective surfaces, as well as cluttered scenes with numerous
objects. Specifically, StableNormal employs a coarse-to-fine strategy, which
starts with a one-step normal estimator (YOSO) to derive an initial normal
guess, that is relatively coarse but reliable, then followed by a
semantic-guided refinement process (SG-DRN) that refines the normals to recover
geometric details. The effectiveness of StableNormal is demonstrated through
competitive performance in standard datasets such as DIODE-indoor, iBims,
ScannetV2 and NYUv2, and also in various downstream tasks, such as surface
reconstruction and normal enhancement. These results evidence that StableNormal
retains both the ""stability"" and ""sharpness"" for accurate normal estimation.
StableNormal represents a baby attempt to repurpose diffusion priors for
deterministic estimation. To democratize this, code and models have been
publicly available in hf.co/Stable-X"
EAGLE-2 - Faster Inference of Language Models with Dynamic Draft Trees,https://arxiv.org/abs/2406.16858,2024-06-24,2024-06-25,0.0,0.0,"Inference with modern Large Language Models (LLMs) is expensive and
time-consuming, and speculative sampling has proven to be an effective
solution. Most speculative sampling methods such as EAGLE use a static draft
tree, implicitly assuming that the acceptance rate of draft tokens depends only
on their position. Interestingly, we found that the acceptance rate of draft
tokens is also context-dependent. In this paper, building upon EAGLE, we
propose EAGLE-2, which introduces a new technique of context-aware dynamic
draft tree into drafting modeling. This improvement leverages the fact that the
draft model of EAGLE is well-calibrated: the confidence scores from the draft
model approximate acceptance rates with small errors. We conducted extensive
evaluations on three series of LLMs and six tasks, with EAGLE-2 achieving
speedup ratios 3.05x-4.26x, which is 20%-40% faster than EAGLE-1. EAGLE-2 also
ensures that the distribution of the generated text remains unchanged, making
it a lossless acceleration algorithm."
Losing Visual Needles in Image Haystacks - Vision Language Models are Easily Distracted in Short and Long Contexts,https://arxiv.org/abs/2406.16851,2024-06-24,2024-06-25,0.0,0.0,"We present LoCoVQA, a dynamic benchmark generator for evaluating long-context
extractive reasoning in vision language models (VLMs). LoCoVQA augments test
examples for mathematical reasoning, VQA, and character recognition tasks with
increasingly long visual contexts composed of both in-distribution and
out-of-distribution distractor images.
  Across these tasks, a diverse set of VLMs rapidly lose performance as the
visual context length grows, often exhibiting a striking logarithmic decay
trend. This test assesses how well VLMs can ignore irrelevant information when
answering queries -- a task that is quite easy for language models (LMs) in the
text domain -- demonstrating that current state-of-the-art VLMs lack this
essential capability for many long-context applications."
Data Debiasing with Datamodels (D3M) - Improving Subgroup Robustness via Data Selection,https://arxiv.org/abs/2406.16846,2024-06-24,2024-06-25,0.0,0.0,"Machine learning models can fail on subgroups that are underrepresented
during training. While techniques such as dataset balancing can improve
performance on underperforming groups, they require access to training group
annotations and can end up removing large portions of the dataset. In this
paper, we introduce Data Debiasing with Datamodels (D3M), a debiasing approach
which isolates and removes specific training examples that drive the model's
failures on minority groups. Our approach enables us to efficiently train
debiased classifiers while removing only a small number of examples, and does
not require training group annotations or additional hyperparameter tuning."
Exploring Factual Entailment with NLI - A News Media Study,https://arxiv.org/abs/2406.16842,2024-06-24,2024-06-25,0.0,0.0,"We explore the relationship between factuality and Natural Language Inference
(NLI) by introducing FactRel -- a novel annotation scheme that models
\textit{factual} rather than \textit{textual} entailment, and use it to
annotate a dataset of naturally occurring sentences from news articles. Our
analysis shows that 84\% of factually supporting pairs and 63\% of factually
undermining pairs do not amount to NLI entailment or contradiction,
respectively, suggesting that factual relationships are more apt for analyzing
media discourse. We experiment with models for pairwise classification on the
new dataset, and find that in some cases, generating synthetic data with GPT-4
on the basis of the annotated dataset can improve performance. Surprisingly,
few-shot learning with GPT-4 yields strong results on par with medium LMs
(DeBERTa) trained on the labelled dataset. We hypothesize that these results
indicate the fundamental dependence of this task on both world knowledge and
advanced reasoning abilities."
From Decoding to Meta-Generation - Inference-time Algorithms for Large Language Models,https://arxiv.org/abs/2406.16838,2024-06-24,2024-06-25,0.0,0.0,"One of the most striking findings in modern research on large language models
(LLMs) is that scaling up compute during training leads to better results.
However, less attention has been given to the benefits of scaling compute
during inference. This survey focuses on these inference-time approaches. We
explore three areas under a unified mathematical formalism: token-level
generation algorithms, meta-generation algorithms, and efficient generation.
Token-level generation algorithms, often called decoding algorithms, operate by
sampling a single token at a time or constructing a token-level search space
and then selecting an output. These methods typically assume access to a
language model's logits, next-token distributions, or probability scores.
Meta-generation algorithms work on partial or full sequences, incorporating
domain knowledge, enabling backtracking, and integrating external information.
Efficient generation methods aim to reduce token costs and improve the speed of
generation. Our survey unifies perspectives from three research communities:
traditional natural language processing, modern LLMs, and machine learning
systems."
"Concentration Inequalities for $(f,)$-GANs",https://arxiv.org/abs/2406.16834,2024-06-24,2024-06-25,0.0,0.0,"Generative adversarial networks (GANs) are unsupervised learning methods for
training a generator distribution to produce samples that approximate those
drawn from a target distribution. Many such methods can be formulated as
minimization of a metric or divergence. Recent works have proven the
statistical consistency of GANs that are based on integral probability metrics
(IPMs), e.g., WGAN which is based on the 1-Wasserstein metric. IPMs are defined
by optimizing a linear functional (difference of expectations) over a space of
discriminators. A much larger class of GANs, which allow for the use of
nonlinear objective functionals, can be constructed using
$(f,\Gamma)$-divergences; these generalize and interpolate between IPMs and
$f$-divergences (e.g., KL or $\alpha$-divergences). Instances of
$(f,\Gamma)$-GANs have been shown to exhibit improved performance in a number
of applications. In this work we study the statistical consistency of
$(f,\Gamma)$-GANs for general $f$ and $\Gamma$. Specifically, we derive
finite-sample concentration inequalities. These derivations require novel
arguments due to nonlinearity of the objective functional. We demonstrate that
our new results reduce to the known results for IPM-GANs in the appropriate
limit while also significantly extending the domain of applicability of this
theory."
USDC - A Dataset of $\underline{U}$ser $\underline{S}$tance and $\underline{D}$ogmatism in Long $\underline{C}$onversations,https://arxiv.org/abs/2406.16833,2024-06-24,2024-06-25,0.0,0.0,"Identifying user's opinions and stances in long conversation threads on
various topics can be extremely critical for enhanced personalization, market
research, political campaigns, customer service, conflict resolution, targeted
advertising, and content moderation. Hence, training language models to
automate this task is critical. However, to train such models, gathering manual
annotations has multiple challenges: 1) It is time-consuming and costly; 2)
Conversation threads could be very long, increasing chances of noisy
annotations; and 3) Interpreting instances where a user changes their opinion
within a conversation is difficult because often such transitions are subtle
and not expressed explicitly. Inspired by the recent success of large language
models (LLMs) for complex natural language processing (NLP) tasks, we leverage
Mistral Large and GPT-4 to automate the human annotation process on the
following two tasks while also providing reasoning: i) User Stance
classification, which involves labeling a user's stance of a post in a
conversation on a five-point scale; ii) User Dogmatism classification, which
deals with labeling a user's overall opinion in the conversation on a
four-point scale. The majority voting on zero-shot, one-shot, and few-shot
annotations from these two LLMs on 764 multi-user Reddit conversations helps us
curate the USDC dataset. USDC is then used to finetune and instruction-tune
multiple deployable small language models for the 5-class stance and 4-class
dogmatism classification tasks. We make the code and dataset publicly available
[https://anonymous.4open.science/r/USDC-0F7F]."
Understanding and Mitigating Tokenization Bias in Language Models,https://arxiv.org/abs/2406.16829,2024-06-24,2024-06-25,1.0,1.0,"State-of-the-art language models are autoregressive and operate on subword
units known as tokens. Specifically, one must encode the conditioning string
into a list of tokens before passing to the language models for next-token
prediction. We show that popular encoding schemes, such as maximum prefix
encoding (MPE) and byte-pair-encoding (BPE), induce a sampling bias that cannot
be mitigated with more training or data. To counter this universal problem, for
each encoding scheme above, we propose a novel algorithm to obtain unbiased
estimates from any language model trained on tokenized data. Our methods do not
require finetuning the model, and the complexity, defined as the number of
model runs, scales linearly with the sequence length in the case of MPE. As a
result, we show that one can simulate token-free behavior from a tokenized
language model. We empirically verify the correctness of our method through a
Markov-chain setup, where it accurately recovers the transition probabilities,
as opposed to the conventional method of directly prompting tokens into the
language model."
Ragnark - A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track,https://arxiv.org/abs/2406.16828,2024-06-24,2024-06-25,0.0,0.0,"Did you try out the new Bing Search? Or maybe you fiddled around with Google
AI~Overviews? These might sound familiar because the modern-day search stack
has recently evolved to include retrieval-augmented generation (RAG) systems.
They allow searching and incorporating real-time data into large language
models (LLMs) to provide a well-informed, attributed, concise summary in
contrast to the traditional search paradigm that relies on displaying a ranked
list of documents. Therefore, given these recent advancements, it is crucial to
have an arena to build, test, visualize, and systematically evaluate RAG-based
search systems. With this in mind, we propose the TREC 2024 RAG Track to foster
innovation in evaluating RAG systems. In our work, we lay out the steps we've
made towards making this track a reality -- we describe the details of our
reusable framework, Ragnar\""ok, explain the curation of the new MS MARCO V2.1
collection choice, release the development topics for the track, and
standardize the I/O definitions which assist the end user. Next, using
Ragnar\""ok, we identify and provide key industrial baselines such as OpenAI's
GPT-4o or Cohere's Command R+. Further, we introduce a web-based user interface
for an interactive arena allowing benchmarking pairwise RAG systems by
crowdsourcing. We open-source our Ragnar\""ok framework and baselines to achieve
a unified standard for future RAG systems."
General Binding Affinity Guidance for Diffusion Models in Structure-Based Drug Design,https://arxiv.org/abs/2406.16821,2024-06-24,2024-06-25,0.0,0.0,"Structure-Based Drug Design (SBDD) focuses on generating valid ligands that
strongly and specifically bind to a designated protein pocket. Several methods
use machine learning for SBDD to generate these ligands in 3D space,
conditioned on the structure of a desired protein pocket. Recently, diffusion
models have shown success here by modeling the underlying distributions of
atomic positions and types. While these methods are effective in considering
the structural details of the protein pocket, they often fail to explicitly
consider the binding affinity. Binding affinity characterizes how tightly the
ligand binds to the protein pocket, and is measured by the change in free
energy associated with the binding process. It is one of the most crucial
metrics for benchmarking the effectiveness of the interaction between a ligand
and protein pocket. To address this, we propose BADGER: Binding Affinity
Diffusion Guidance with Enhanced Refinement. BADGER is a general guidance
method to steer the diffusion sampling process towards improved protein-ligand
binding, allowing us to adjust the distribution of the binding affinity between
ligands and proteins. Our method is enabled by using a neural network (NN) to
model the energy function, which is commonly approximated by AutoDock Vina
(ADV). ADV's energy function is non-differentiable, and estimates the affinity
based on the interactions between a ligand and target protein receptor. By
using a NN as a differentiable energy function proxy, we utilize the gradient
of our learned energy function as a guidance method on top of any trained
diffusion model. We show that our method improves the binding affinity of
generated ligands to their protein receptors by up to 60\%, significantly
surpassing previous machine learning methods. We also show that our guidance
method is flexible and can be easily applied to other diffusion-based SBDD
frameworks."
PISTOL - Dataset Compilation Pipeline for Structural Unlearning of LLMs,https://arxiv.org/abs/2406.16810,2024-06-24,2024-06-25,0.0,0.0,"Recently, machine unlearning, which seeks to erase specific data stored in
the pre-trained or fine-tuned models, has emerged as a crucial protective
measure for LLMs. However, unlearning approaches for LLMs that have been
considered thus far have focused on the removal of independent data points and
have not taken into account that the stored facts are logically connected to
one another and form an implicit knowledge graph. To facilitate the development
of structural unlearning methods, which are essential for the practical
application of unlearning, we propose PISTOL, a pipeline for compiling
multi-scenario datasets for benchmarking structural LLM unlearning.
Additionally, leveraging sample datasets synthesized using PISTOL, we conducted
benchmarks with four distinct unlearning methods on both Llama2-7B and
Mistral-7B models. This analysis helps to illustrate the prevailing challenges
in effectively and robustly removing highly inter-connected data, batched data,
or data skewed towards a specific domain. It also highlights the choice of
pre-trained model can impact unlearning performance. This work not only
advances our understandings on the limitation of current LLMs unlearning
methods and proposes future research directions, but also provides a replicable
framework for ongoing exploration and validation in the field."
Beyond Thumbs Up/Down - Untangling Challenges of Fine-Grained Feedback for Text-to-Image Generation,https://arxiv.org/abs/2406.16807,2024-06-24,2024-06-25,0.0,0.0,"Human feedback plays a critical role in learning and refining reward models
for text-to-image generation, but the optimal form the feedback should take for
learning an accurate reward function has not been conclusively established.
This paper investigates the effectiveness of fine-grained feedback which
captures nuanced distinctions in image quality and prompt-alignment, compared
to traditional coarse-grained feedback (for example, thumbs up/down or ranking
between a set of options). While fine-grained feedback holds promise,
particularly for systems catering to diverse societal preferences, we show that
demonstrating its superiority to coarse-grained feedback is not automatic.
Through experiments on real and synthetic preference data, we surface the
complexities of building effective models due to the interplay of model choice,
feedback type, and the alignment between human judgment and computational
interpretation. We identify key challenges in eliciting and utilizing
fine-grained feedback, prompting a reassessment of its assumed benefits and
practicality. Our findings -- e.g., that fine-grained feedback can lead to
worse models for a fixed budget, in some settings; however, in controlled
settings with known attributes, fine grained rewards can indeed be more helpful
-- call for careful consideration of feedback attributes and potentially beckon
novel modeling approaches to appropriately unlock the potential value of
fine-grained feedback in-the-wild."
Improved Regret Bounds for Bandits with Expert Advice,https://arxiv.org/abs/2406.16802,2024-06-24,2024-06-25,0.0,0.0,"In this research note, we revisit the bandits with expert advice problem.
Under a restricted feedback model, we prove a lower bound of order $\sqrt{K T
\ln(N/K)}$ for the worst-case regret, where $K$ is the number of actions, $N>K$
the number of experts, and $T$ the time horizon. This matches a previously
known upper bound of the same order and improves upon the best available lower
bound of $\sqrt{K T (\ln N) / (\ln K)}$. For the standard feedback model, we
prove a new instance-based upper bound that depends on the agreement between
the experts and provides a logarithmic improvement compared to prior results."
RES-Q - Evaluating Code-Editing Large Language Model Systems at the Repository Scale,https://arxiv.org/abs/2406.16801,2024-06-24,2024-06-25,0.0,0.0,"The instruction-following ability of Large Language Models (LLMs) has
cultivated a class of LLM-based systems capable of approaching complex tasks
such as making edits to large code repositories. Due to the high sensitivity
and unpredictability of LLM behavior in response to changes in prompting,
robust evaluation tools are needed to drive future iteration of these systems.
We propose RES-Q, a natural language instruction-based benchmark for evaluating
$\textbf{R}$epository $\textbf{E}$diting $\textbf{S}$ystems, which consists of
100 handcrafted repository editing tasks derived from real GitHub commits.
Given an edit instruction and a code repository, RES-Q evaluates an LLM
system's ability to interpret the instruction, navigate the repository to
gather relevant information, and construct an appropriate edit that satisfies
the specified criteria. We argue that evaluating LLMs in this way addresses
issues with traditional benchmarks and provides a more holistic assessment of a
model's abilities. We evaluate various state-of-the-art LLMs as language agents
in a repository-editing system built on Qurrent OS, our language agent
development software. Despite their 1% pass@1 performance difference on
HumanEval, we find Claude Sonnet 3.5 outperforms GPT-4o by 12% pass@1 on RES-Q,
indicating RES-Q's capacity to differentiate model capability as traditional
benchmarks approach saturation. We further investigate token efficiency,
performance relationships with existing benchmarks, and interesting disparities
between closed and open-source LLMs. Code and dataset are available at
https://github.com/Qurrent-AI/RES-Q."
Lottery Ticket Adaptation - Mitigating Destructive Interference in LLMs,https://arxiv.org/abs/2406.16797,2024-06-24,2024-06-25,1.0,0.0,"Existing methods for adapting large language models (LLMs) to new tasks are
not suited to multi-task adaptation because they modify all the model weights
-- causing destructive interference between tasks. The resulting effects, such
as catastrophic forgetting of earlier tasks, make it challenging to obtain good
performance on multiple tasks at the same time. To mitigate this, we propose
Lottery Ticket Adaptation (LoTA), a sparse adaptation method that identifies
and optimizes only a sparse subnetwork of the model. We evaluate LoTA on a wide
range of challenging tasks such as instruction following, reasoning, math, and
summarization. LoTA obtains better performance than full fine-tuning and
low-rank adaptation (LoRA), and maintains good performance even after training
on other tasks -- thus, avoiding catastrophic forgetting. By extracting and
fine-tuning over lottery tickets (or sparse task vectors), LoTA also enables
model merging over highly dissimilar tasks. Our code is made publicly available
at https://github.com/kiddyboots216/lottery-ticket-adaptation."
Adam-mini - Use Fewer Learning Rates To Gain More,https://arxiv.org/abs/2406.16793,2024-06-24,2024-06-25,1.0,0.0,"We propose Adam-mini, an optimizer that achieves on-par or better performance
than AdamW with 45% to 50% less memory footprint. Adam-mini reduces memory by
cutting down the learning rate resources in Adam (i.e., $1/\sqrt{v}$). We find
that $\geq$ 90% of these learning rates in $v$ could be harmlessly removed if
we (1) carefully partition the parameters into blocks following our proposed
principle on Hessian structure; (2) assign a single but good learning rate to
each parameter block. We further find that, for each of these parameter blocks,
there exists a single high-quality learning rate that can outperform Adam,
provided that sufficient resources are available to search it out. We then
provide one cost-effective way to find good learning rates and propose
Adam-mini. Empirically, we verify that Adam-mini performs on par or better than
AdamW on various language models sized from 125M to 7B for pre-training,
supervised fine-tuning, and RLHF. The reduced memory footprint of Adam-mini
also alleviates communication overheads among GPUs and CPUs, thereby increasing
throughput. For instance, Adam-mini achieves 49.6% higher throughput than AdamW
when pre-training Llama2-7B on $2\times$ A800-80GB GPUs, which saves 33%
wall-clock time for pre-training."
"Enabling more efficient and cost-effective AI/ML systems with Collective Mind, virtualized MLOps, MLPerf, Collective Knowledge Playground and reproducible optimization tournaments",https://arxiv.org/abs/2406.16791,2024-06-24,2024-06-25,0.0,0.0,"In this white paper, I present my community effort to automatically co-design
cheaper, faster and more energy-efficient software and hardware for AI, ML and
other popular workloads with the help of the Collective Mind framework (CM),
virtualized MLOps, MLPerf benchmarks and reproducible optimization tournaments.
I developed CM to modularize, automate and virtualize the tedious process of
building, running, profiling and optimizing complex applications across rapidly
evolving open-source and proprietary AI/ML models, datasets, software and
hardware. I achieved that with the help of portable, reusable and
technology-agnostic automation recipes (ResearchOps) for MLOps and DevOps
(CM4MLOps) discovered in close collaboration with academia and industry when
reproducing more than 150 research papers and organizing the 1st mass-scale
community benchmarking of ML and AI systems using CM and MLPerf.
  I donated CM and CM4MLOps to MLCommons to help connect academia and industry
to learn how to build and run AI and other emerging workloads in the most
efficient and cost-effective way using a common and technology-agnostic
automation, virtualization and reproducibility framework while unifying
knowledge exchange, protecting everyone's intellectual property, enabling
portable skills, and accelerating transfer of the state-of-the-art research to
production. My long-term vision is to make AI accessible to everyone by making
it a commodity automatically produced from the most suitable open-source and
proprietary components from different vendors based on user demand,
requirements and constraints such as cost, latency, throughput, accuracy,
energy, size and other important characteristics."
The Progression of Transformers from Language to Vision to MOT - A Literature Review on Multi-Object Tracking with Transformers,https://arxiv.org/abs/2406.16784,2024-06-24,2024-06-25,0.0,0.0,"The transformer neural network architecture allows for autoregressive
sequence-to-sequence modeling through the use of attention layers. It was
originally created with the application of machine translation but has
revolutionized natural language processing. Recently, transformers have also
been applied across a wide variety of pattern recognition tasks, particularly
in computer vision. In this literature review, we describe major advances in
computer vision utilizing transformers. We then focus specifically on
Multi-Object Tracking (MOT) and discuss how transformers are increasingly
becoming competitive in state-of-the-art MOT works, yet still lag behind
traditional deep learning methods."
"M2Lingual - Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models",https://arxiv.org/abs/2406.16783,2024-06-24,2024-06-25,0.0,0.0,"Instruction finetuning (IFT) is critical for aligning Large Language Models
(LLMs) to follow instructions. While many effective IFT datasets have been
introduced recently, they predominantly focus on high-resource languages like
English. To better align LLMs across a broad spectrum of languages and tasks,
we propose a fully synthetic, novel taxonomy (Evol) guided Multilingual,
Multi-turn instruction finetuning dataset, called M2Lingual. It is constructed
by first selecting a diverse set of seed examples and then utilizing the
proposed Evol taxonomy to convert these seeds into complex and challenging
multi-turn instructions. We demonstrate the effectiveness of M2Lingual by
training LLMs of varying sizes and showcasing the enhanced performance across a
diverse set of languages. We contribute the 2 step Evol taxonomy with the
guided generation code: https://github.com/ServiceNow/M2Lingual, as well as the
first fully synthetic, general and task-oriented, multi-turn, multilingual
dataset built with Evol - M2Lingual:
https://huggingface.co/datasets/ServiceNow-AI/ M2Lingual - containing 182K
total IFT pairs, covering 70 languages and 17+ NLP tasks."
Confidence Aware Inverse Constrained Reinforcement Learning,https://arxiv.org/abs/2406.16782,2024-06-24,2024-06-25,0.0,0.0,"In coming up with solutions to real-world problems, humans implicitly adhere
to constraints that are too numerous and complex to be specified completely.
However, reinforcement learning (RL) agents need these constraints to learn the
correct optimal policy in these settings. The field of Inverse Constraint
Reinforcement Learning (ICRL) deals with this problem and provides algorithms
that aim to estimate the constraints from expert demonstrations collected
offline. Practitioners prefer to know a measure of confidence in the estimated
constraints, before deciding to use these constraints, which allows them to
only use the constraints that satisfy a desired level of confidence. However,
prior works do not allow users to provide the desired level of confidence for
the inferred constraints. This work provides a principled ICRL method that can
take a confidence level with a set of expert demonstrations and outputs a
constraint that is at least as constraining as the true underlying constraint
with the desired level of confidence. Further, unlike previous methods, this
method allows a user to know if the number of expert trajectories is
insufficient to learn a constraint with a desired level of confidence, and
therefore collect more expert trajectories as required to simultaneously learn
constraints with the desired level of confidence and a policy that achieves the
desired level of performance."
"It Is Not About What You Say, It Is About How You Say It - A Surprisingly Simple Approach for Improving Reading Comprehension",https://arxiv.org/abs/2406.16779,2024-06-24,2024-06-25,0.0,0.0,"Natural language processing has seen rapid progress over the past decade. Due
to the speed of developments, some practices get established without proper
evaluation. Considering one such case and focusing on reading comprehension, we
ask our first research question: 1) How does the order of inputs -- i.e.,
question and context -- affect model performance? Additionally, given recent
advancements in input emphasis, we ask a second research question: 2) Does
emphasizing either the question, the context, or both enhance performance?
Experimenting with 9 large language models across 3 datasets, we find that
presenting the context before the question improves model performance, with an
accuracy increase of up to $31\%$. Furthermore, emphasizing the context yields
superior results compared to question emphasis, and in general, emphasizing
parts of the input is particularly effective for addressing questions that
models lack the parametric knowledge to answer. Experimenting with both
prompt-based and attention-based emphasis methods, we additionally find that
the best method is surprisingly simple: it only requires concatenating a few
tokens to the input and results in an accuracy improvement of up to $36\%$,
allowing smaller models to outperform their significantly larger counterparts."
Finding Transformer Circuits with Edge Pruning,https://arxiv.org/abs/2406.16778,2024-06-24,2024-06-25,1.0,1.0,"The path to interpreting a language model often proceeds via analysis of
circuits -- sparse computational subgraphs of the model that capture specific
aspects of its behavior. Recent work has automated the task of discovering
circuits. Yet, these methods have practical limitations, as they rely either on
inefficient search algorithms or inaccurate approximations. In this paper, we
frame automated circuit discovery as an optimization problem and propose *Edge
Pruning* as an effective and scalable solution. Edge Pruning leverages
gradient-based pruning techniques, but instead of removing neurons or
components, it prunes the \emph{edges} between components. Our method finds
circuits in GPT-2 that use less than half the number of edges compared to
circuits found by previous methods while being equally faithful to the full
model predictions on standard circuit-finding tasks. Edge Pruning is efficient
even with as many as 100K examples, outperforming previous methods in speed and
producing substantially better circuits. It also perfectly recovers the
ground-truth circuits in two models compiled with Tracr. Thanks to its
efficiency, we scale Edge Pruning to CodeLlama-13B, a model over 100x the scale
that prior methods operate on. We use this setting for a case study comparing
the mechanisms behind instruction prompting and in-context learning. We find
two circuits with more than 99.96% sparsity that match the performance of the
full model and reveal that the mechanisms in the two settings overlap
substantially. Our case study shows that Edge Pruning is a practical and
scalable tool for interpretability and sheds light on behaviors that only
emerge in large models."
Blending LLMs into Cascaded Speech Translation - KIT's Offline Speech Translation System for IWSLT 2024,https://arxiv.org/abs/2406.16777,2024-06-24,2024-06-25,0.0,0.0,"Large Language Models (LLMs) are currently under exploration for various
tasks, including Automatic Speech Recognition (ASR), Machine Translation (MT),
and even End-to-End Speech Translation (ST). In this paper, we present KIT's
offline submission in the constrained + LLM track by incorporating recently
proposed techniques that can be added to any cascaded speech translation.
Specifically, we integrate
Mistral-7B\footnote{mistralai/Mistral-7B-Instruct-v0.1} into our system to
enhance it in two ways. Firstly, we refine the ASR outputs by utilizing the
N-best lists generated by our system and fine-tuning the LLM to predict the
transcript accurately. Secondly, we refine the MT outputs at the document level
by fine-tuning the LLM, leveraging both ASR and MT predictions to improve
translation quality. We find that integrating the LLM into the ASR and MT
systems results in an absolute improvement of $0.3\%$ in Word Error Rate and
$0.65\%$ in COMET for tst2019 test set. In challenging test sets with
overlapping speakers and background noise, we find that integrating LLM is not
beneficial due to poor ASR performance. Here, we use ASR with chunked long-form
decoding to improve context usage that may be unavailable when transcribing
with Voice Activity Detection segmentation alone."
OlympicArena Medal Ranks - Who Is the Most Intelligent AI So Far?,https://arxiv.org/abs/2406.16772,2024-06-24,2024-06-25,0.0,0.0,"In this report, we pose the following question: Who is the most intelligent
AI model to date, as measured by the OlympicArena (an Olympic-level,
multi-discipline, multi-modal benchmark for superintelligent AI)? We
specifically focus on the most recently released models: Claude-3.5-Sonnet,
Gemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic
medal Table approach to rank AI models based on their comprehensive performance
across various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet
shows highly competitive overall performance over GPT-4o, even surpassing
GPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)
Gemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and
Claude-3.5-Sonnet, but with a clear performance gap between them. (3) The
performance of AI models from the open-source community significantly lags
behind these proprietary models. (4) The performance of these models on this
benchmark has been less than satisfactory, indicating that we still have a long
way to go before achieving superintelligence. We remain committed to
continuously tracking and evaluating the performance of the latest powerful
models on this benchmark (available at
https://github.com/GAIR-NLP/OlympicArena)."
WARP - On the Benefits of Weight Averaged Rewarded Policies,https://arxiv.org/abs/2406.16768,2024-06-24,2024-06-25,0.0,0.0,"Reinforcement learning from human feedback (RLHF) aligns large language
models (LLMs) by encouraging their generations to have high rewards, using a
reward model trained on human preferences. To prevent the forgetting of
pre-trained knowledge, RLHF usually incorporates a KL regularization; this
forces the policy to remain close to its supervised fine-tuned initialization,
though it hinders the reward optimization. To tackle the trade-off between KL
and reward, in this paper we introduce a novel alignment strategy named Weight
Averaged Rewarded Policies (WARP). WARP merges policies in the weight space at
three distinct stages. First, it uses the exponential moving average of the
policy as a dynamic anchor in the KL regularization. Second, it applies
spherical interpolation to merge independently fine-tuned policies into a new
enhanced one. Third, it linearly interpolates between this merged model and the
initialization, to recover features from pre-training. This procedure is then
applied iteratively, with each iteration's final model used as an advanced
initialization for the next, progressively refining the KL-reward Pareto front,
achieving superior rewards at fixed KL. Experiments with GEMMA policies
validate that WARP improves their quality and alignment, outperforming other
open-source LLMs."
Conformal time series decomposition with component-wise exchangeability,https://arxiv.org/abs/2406.16766,2024-06-24,2024-06-25,0.0,0.0,"Conformal prediction offers a practical framework for distribution-free
uncertainty quantification, providing finite-sample coverage guarantees under
relatively mild assumptions on data exchangeability. However, these assumptions
cease to hold for time series due to their temporally correlated nature. In
this work, we present a novel use of conformal prediction for time series
forecasting that incorporates time series decomposition. This approach allows
us to model different temporal components individually. By applying specific
conformal algorithms to each component and then merging the obtained prediction
intervals, we customize our methods to account for the different
exchangeability regimes underlying each component. Our decomposition-based
approach is thoroughly discussed and empirically evaluated on synthetic and
real-world data. We find that the method provides promising results on
well-structured time series, but can be limited by factors such as the
decomposition step for more complex data."
Towards Fast Multilingual LLM Inference - Speculative Decoding and Specialized Drafters,https://arxiv.org/abs/2406.16758,2024-06-24,2024-06-25,0.0,0.0,"Large language models (LLMs) have revolutionized natural language processing
and broadened their applicability across diverse commercial applications.
However, the deployment of these models is constrained by high inference time
in multilingual settings. To mitigate this challenge, this paper explores a
training recipe of an assistant model in speculative decoding, which are
leveraged to draft and-then its future tokens are verified by the target LLM.
We show that language-specific draft models, optimized through a targeted
pretrain-and-finetune strategy, substantially brings a speedup of inference
time compared to the previous methods. We validate these models across various
languages in inference time, out-of-domain speedup, and GPT-4o evaluation."
Addressing Polarization and Unfairness in Performative Prediction,https://arxiv.org/abs/2406.16756,2024-06-24,2024-06-25,0.0,0.0,"When machine learning (ML) models are used in applications that involve
humans (e.g., online recommendation, school admission, hiring, lending), the
model itself may trigger changes in the distribution of targeted data it aims
to predict. Performative prediction (PP) is a framework that explicitly
considers such model-dependent distribution shifts when learning ML models.
While significant efforts have been devoted to finding performative stable (PS)
solutions in PP for system robustness, their societal implications are less
explored and it is unclear whether PS solutions are aligned with social norms
such as fairness. In this paper, we set out to examine the fairness property of
PS solutions in performative prediction. We first show that PS solutions can
incur severe polarization effects and group-wise loss disparity. Although
existing fairness mechanisms commonly used in literature can help mitigate
unfairness, they may fail and disrupt the stability under model-dependent
distribution shifts. We thus propose novel fairness intervention mechanisms
that can simultaneously achieve both stability and fairness in PP settings.
Both theoretical analysis and experiments are provided to validate the proposed
method."
The MRI Scanner as a Diagnostic - Image-less Active Sampling,https://arxiv.org/abs/2406.16754,2024-06-24,2024-06-25,0.0,0.0,"Despite the high diagnostic accuracy of Magnetic Resonance Imaging (MRI),
using MRI as a Point-of-Care (POC) disease identification tool poses
significant accessibility challenges due to the use of high magnetic field
strength and lengthy acquisition times. We ask a simple question: Can we
dynamically optimise acquired samples, at the patient level, according to an
(automated) downstream decision task, while discounting image reconstruction?
We propose an ML-based framework that learns an active sampling strategy, via
reinforcement learning, at a patient-level to directly infer disease from
undersampled k-space. We validate our approach by inferring Meniscus Tear in
undersampled knee MRI data, where we achieve diagnostic performance comparable
with ML-based diagnosis, using fully sampled k-space data. We analyse
task-specific sampling policies, showcasing the adaptability of our active
sampling approach. The introduced frugal sampling strategies have the potential
to reduce high field strength requirements that in turn strengthen the
viability of MRI-based POC disease identification and associated preliminary
screening tools."
Towards Zero-Shot Text-To-Speech for Arabic Dialects,https://arxiv.org/abs/2406.16751,2024-06-24,2024-06-25,0.0,0.0,"Zero-shot multi-speaker text-to-speech (ZS-TTS) systems have advanced for
English, however, it still lags behind due to insufficient resources. We
address this gap for Arabic, a language of more than 450 million native
speakers, by first adapting a sizeable existing dataset to suit the needs of
speech synthesis. Additionally, we employ a set of Arabic dialect
identification models to explore the impact of pre-defined dialect labels on
improving the ZS-TTS model in a multi-dialect setting. Subsequently, we
fine-tune the
XTTS\footnote{https://docs.coqui.ai/en/latest/models/xtts.html}\footnote{https://medium.com/machine-learns/xtts-v2-new-version-of-the-open-source-text-to-speech-model-af73914db81f}\footnote{https://medium.com/@erogol/xtts-v1-techincal-notes-eb83ff05bdc}
model, an open-source architecture. We then evaluate our models on a dataset
comprising 31 unseen speakers and an in-house dialectal dataset. Our automated
and human evaluation results show convincing performance while capable of
generating dialectal speech. Our study highlights significant potential for
improvements in this emerging area of research in Arabic."
Inferring stochastic low-rank recurrent neural networks from neural data,https://arxiv.org/abs/2406.16749,2024-06-24,2024-06-25,0.0,0.0,"A central aim in computational neuroscience is to relate the activity of
large populations of neurons to an underlying dynamical system. Models of these
neural dynamics should ideally be both interpretable and fit the observed data
well. Low-rank recurrent neural networks (RNNs) exhibit such interpretability
by having tractable dynamics. However, it is unclear how to best fit low-rank
RNNs to data consisting of noisy observations of an underlying stochastic
system. Here, we propose to fit stochastic low-rank RNNs with variational
sequential Monte Carlo methods. We validate our method on several datasets
consisting of both continuous and spiking neural data, where we obtain lower
dimensional latent dynamics than current state of the art methods.
Additionally, for low-rank models with piecewise linear nonlinearities, we show
how to efficiently identify all fixed points in polynomial rather than
exponential cost in the number of units, making analysis of the inferred
dynamics tractable for large RNNs. Our method both elucidates the dynamical
systems underlying experimental recordings and provides a generative model
whose trajectories match observed trial-to-trial variability."
OCALM - Object-Centric Assessment with Language Models,https://arxiv.org/abs/2406.16748,2024-06-24,2024-06-25,0.0,0.0,"Properly defining a reward signal to efficiently train a reinforcement
learning (RL) agent is a challenging task. Designing balanced objective
functions from which a desired behavior can emerge requires expert knowledge,
especially for complex environments. Learning rewards from human feedback or
using large language models (LLMs) to directly provide rewards are promising
alternatives, allowing non-experts to specify goals for the agent. However,
black-box reward models make it difficult to debug the reward. In this work, we
propose Object-Centric Assessment with Language Models (OCALM) to derive
inherently interpretable reward functions for RL agents from natural language
task descriptions. OCALM uses the extensive world-knowledge of LLMs while
leveraging the object-centric nature common to many environments to derive
reward functions focused on relational concepts, providing RL agents with the
ability to derive policies from task descriptions."
Sparser is Faster and Less is More - Efficient Sparse Attention for Long-Range Transformers,https://arxiv.org/abs/2406.16747,2024-06-24,2024-06-25,0.0,0.0,"Accommodating long sequences efficiently in autoregressive Transformers,
especially within an extended context window, poses significant challenges due
to the quadratic computational complexity and substantial KV memory
requirements inherent in self-attention mechanisms. In this work, we introduce
SPARSEK Attention, a novel sparse attention mechanism designed to overcome
these computational and memory obstacles while maintaining performance. Our
approach integrates a scoring network and a differentiable top-k mask operator,
SPARSEK, to select a constant number of KV pairs for each query, thereby
enabling gradient-based optimization. As a result, SPARSEK Attention offers
linear time complexity and constant memory footprint during generation.
Experimental results reveal that SPARSEK Attention outperforms previous sparse
attention methods and provides significant speed improvements during both
training and inference, particularly in language modeling and downstream tasks.
Furthermore, our method can be seamlessly integrated into pre-trained Large
Language Models (LLMs) with minimal fine-tuning, offering a practical solution
for effectively managing long-range dependencies in diverse applications."
The Responsible Foundation Model Development Cheatsheet - A Review of Tools & Resources,https://arxiv.org/abs/2406.16746,2024-06-24,2024-06-25,1.0,1.0,"Foundation model development attracts a rapidly expanding body of
contributors, scientists, and applications. To help shape responsible
development practices, we introduce the Foundation Model Development
Cheatsheet: a growing collection of 250+ tools and resources spanning text,
vision, and speech modalities. We draw on a large body of prior work to survey
resources (e.g. software, documentation, frameworks, guides, and practical
tools) that support informed data selection, processing, and understanding,
precise and limitation-aware artifact documentation, efficient model training,
advance awareness of the environmental impact from training, careful model
evaluation of capabilities, risks, and claims, as well as responsible model
release, licensing and deployment practices. We hope this curated collection of
resources helps guide more responsible development. The process of curating
this list, enabled us to review the AI development ecosystem, revealing what
tools are critically missing, misused, or over-used in existing practices. We
find that (i) tools for data sourcing, model evaluation, and monitoring are
critically under-serving ethical and real-world needs, (ii) evaluations for
model safety, capabilities, and environmental impact all lack reproducibility
and transparency, (iii) text and particularly English-centric analyses continue
to dominate over multilingual and multi-modal analyses, and (iv) evaluation of
systems, rather than just models, is needed so that capabilities and impact are
assessed in context."
Bandits with Preference Feedback - A Stackelberg Game Perspective,https://arxiv.org/abs/2406.16745,2024-06-24,2024-06-25,0.0,0.0,"Bandits with preference feedback present a powerful tool for optimizing
unknown target functions when only pairwise comparisons are allowed instead of
direct value queries. This model allows for incorporating human feedback into
online inference and optimization and has been employed in systems for
fine-tuning large language models. The problem is well understood in simplified
settings with linear target functions or over finite small domains that limit
practical interest. Taking the next step, we consider infinite domains and
nonlinear (kernelized) rewards. In this setting, selecting a pair of actions is
quite challenging and requires balancing exploration and exploitation at two
levels: within the pair, and along the iterations of the algorithm. We propose
MAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, and
chooses action pairs that are informative and yield favorable rewards.
MAXMINLCB consistently outperforms existing algorithms and satisfies an
anytime-valid rate-optimal regret guarantee. This is due to our novel
preference-based confidence sequences for kernelized logistic estimators."
Adversarial Contrastive Decoding - Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization,https://arxiv.org/abs/2406.16743,2024-06-24,2024-06-25,0.0,0.0,"With the widespread application of Large Language Models (LLMs), it has
become a significant concern to ensure their safety and prevent harmful
responses. While current safe-alignment methods based on instruction
fine-tuning and Reinforcement Learning from Human Feedback (RLHF) can
effectively reduce harmful responses from LLMs, they often require high-quality
datasets and heavy computational overhead during model training. Another way to
align language models is to modify the logit of tokens in model outputs without
heavy training. Recent studies have shown that contrastive decoding can enhance
the performance of language models by reducing the likelihood of confused
tokens. However, these methods require the manual selection of contrastive
models or instruction templates. To this end, we propose Adversarial
Contrastive Decoding (ACD), an optimization-based framework to generate two
opposite system prompts for prompt-based contrastive decoding. ACD only needs
to apply a lightweight prompt tuning on a rather small anchor dataset (< 3 min
for each model) without training the target model. Experiments conducted on
extensive models and benchmarks demonstrate that the proposed method achieves
much better safety performance than previous model training-free decoding
methods without sacrificing its original generation ability."
Extracting thin film structures of energy materials using transformers,https://arxiv.org/abs/2406.16741,2024-06-24,2024-06-25,0.0,0.0,"Neutron-Transformer Reflectometry and Advanced Computation Engine (N-TRACE ),
a neural network model using transformer architecture, is introduced for
neutron reflectometry data analysis. It offers fast, accurate initial parameter
estimations and efficient refinements, improving efficiency and precision for
real-time data analysis of lithium-mediated nitrogen reduction for
electrochemical ammonia synthesis, with relevance to other chemical
transformations and batteries. Despite limitations in generalizing across
systems, it shows promises for the use of transformers as the basis for models
that could replace trial-and-error approaches to modeling reflectometry data."
Learning the boundary-to-domain mapping using Lifting Product Fourier Neural Operators for partial differential equations,https://arxiv.org/abs/2406.16740,2024-06-24,2024-06-25,0.0,0.0,"Neural operators such as the Fourier Neural Operator (FNO) have been shown to
provide resolution-independent deep learning models that can learn mappings
between function spaces. For example, an initial condition can be mapped to the
solution of a partial differential equation (PDE) at a future time-step using a
neural operator. Despite the popularity of neural operators, their use to
predict solution functions over a domain given only data over the boundary
(such as a spatially varying Dirichlet boundary condition) remains unexplored.
In this paper, we refer to such problems as boundary-to-domain problems; they
have a wide range of applications in areas such as fluid mechanics, solid
mechanics, heat transfer etc. We present a novel FNO-based architecture, named
Lifting Product FNO (or LP-FNO) which can map arbitrary boundary functions
defined on the lower-dimensional boundary to a solution in the entire domain.
Specifically, two FNOs defined on the lower-dimensional boundary are lifted
into the higher dimensional domain using our proposed lifting product layer. We
demonstrate the efficacy and resolution independence of the proposed LP-FNO for
the 2D Poisson equation."
Inducing Group Fairness in LLM-Based Decisions,https://arxiv.org/abs/2406.16738,2024-06-24,2024-06-25,0.0,0.0,"Prompting Large Language Models (LLMs) has created new and interesting means
for classifying textual data. While evaluating and remediating group fairness
is a well-studied problem in classifier fairness literature, some classical
approaches (e.g., regularization) do not carry over, and some new opportunities
arise (e.g., prompt-based remediation). We measure fairness of LLM-based
classifiers on a toxicity classification task, and empirically show that
prompt-based classifiers may lead to unfair decisions. We introduce several
remediation techniques and benchmark their fairness and performance trade-offs.
We hope our work encourages more research on group fairness in LLM-based
classifiers."
CLIMATELI - Evaluating Entity Linking on Climate Change Data,https://arxiv.org/abs/2406.16732,2024-06-24,2024-06-25,0.0,0.0,"Climate Change (CC) is a pressing topic of global importance, attracting
increasing attention across research fields, from social sciences to Natural
Language Processing (NLP). CC is also discussed in various settings and
communication platforms, from academic publications to social media forums.
Understanding who and what is mentioned in such data is a first critical step
to gaining new insights into CC. We present CLIMATELI (CLIMATe Entity LInking),
the first manually annotated CC dataset that links 3,087 entity spans to
Wikipedia. Using CLIMATELI (CLIMATe Entity LInking), we evaluate existing
entity linking (EL) systems on the CC topic across various genres and propose
automated filtering methods for CC entities. We find that the performance of EL
models notably lags behind humans at both token and entity levels. Testing
within the scope of retaining or excluding non-nominal and/or non-CC entities
particularly impacts the models' performances."
Convolutional neural network for Lyman break galaxies classification and redshift regression in DESI (Dark Energy Spectroscopic Instrument),https://arxiv.org/abs/2406.16730,2024-06-24,2024-06-25,0.0,0.0,"DESI is a groundbreaking international project to observe more than 40
million quasars and galaxies over a 5-year period to create a 3D map of the
sky. This map will enable us to probe multiple aspects of cosmology, from dark
energy to neutrino mass. We are focusing here on one type of object observed by
DESI, the Lyman Break Galaxies (LBGs). The aim is to use their spectra to
determine whether they are indeed LBGs, and if so, to determine their distance
from the Earth using a phenomenon called redshift. This will enable us to place
these galaxies on the DESI 3D map.
  The aim is therefore to develop a convolutional neural network (CNN) inspired
by QuasarNET (See arXiv:1808.09955), performing simultaneously a classification
(LBG type or not) and a regression task (determine the redshift of the LBGs).
Initially, data augmentation techniques such as shifting the spectra in
wavelengths, adding noise to the spectra, or adding synthetic spectra were used
to increase the model training dataset from 3,019 data to over 66,000. In a
second phase, modifications to the QuasarNET architecture, notably through
transfer learning and hyperparameter tuning with Bayesian optimization, boosted
model performance.
  Gains of up to 26% were achieved on the Purity/Efficiency curve, which is
used to evaluate model performance, particularly in areas with interesting
redshifts, at low (around 2) and high (around 4) redshifts. The best model
obtained an average score of 94%, compared with 75% for the initial model."
CausalMMM - Learning Causal Structure for Marketing Mix Modeling,https://arxiv.org/abs/2406.16728,2024-06-24,2024-06-25,0.0,0.0,"In online advertising, marketing mix modeling (MMM) is employed to predict
the gross merchandise volume (GMV) of brand shops and help decision-makers to
adjust the budget allocation of various advertising channels. Traditional MMM
methods leveraging regression techniques can fail in handling the complexity of
marketing. Although some efforts try to encode the causal structures for better
prediction, they have the strict restriction that causal structures are
prior-known and unchangeable. In this paper, we define a new causal MMM problem
that automatically discovers the interpretable causal structures from data and
yields better GMV predictions. To achieve causal MMM, two essential challenges
should be addressed: (1) Causal Heterogeneity. The causal structures of
different kinds of shops vary a lot. (2) Marketing Response Patterns. Various
marketing response patterns i.e., carryover effect and shape effect, have been
validated in practice. We argue that causal MMM needs dynamically discover
specific causal structures for different shops and the predictions should
comply with the prior known marketing response patterns. Thus, we propose
CausalMMM that integrates Granger causality in a variational inference
framework to measure the causal relationships between different channels and
predict the GMV with the regularization of both temporal and saturation
marketing response patterns. Extensive experiments show that CausalMMM can not
only achieve superior performance of causal structure learning on synthetic
datasets with improvements of 5.7%\sim 7.1%, but also enhance the GMV
prediction results on a representative E-commerce platform."
Venturing into Uncharted Waters - The Navigation Compass from Transformer to Mamba,https://arxiv.org/abs/2406.16722,2024-06-24,2024-06-25,0.0,0.0,"Transformer, a deep neural network architecture, has long dominated the field
of natural language processing and beyond. Nevertheless, the recent
introduction of Mamba challenges its supremacy, sparks considerable interest
among researchers, and gives rise to a series of Mamba-based models that have
exhibited notable potential. This survey paper orchestrates a comprehensive
discussion, diving into essential research dimensions, covering: (i) the
functioning of the Mamba mechanism and its foundation on the principles of
structured state space models; (ii) the proposed improvements and the
integration of Mamba with various networks, exploring its potential as a
substitute for Transformers; (iii) the combination of Transformers and Mamba to
compensate for each other's shortcomings. We have also made efforts to
interpret Mamba and Transformer in the framework of kernel functions, allowing
for a comparison of their mathematical nature within a unified context. Our
paper encompasses the vast majority of improvements related to Mamba to date."
GC-Bench - A Benchmark Framework for Graph Condensation with New Insights,https://arxiv.org/abs/2406.16715,2024-06-24,2024-06-25,0.0,0.0,"Graph condensation (GC) is an emerging technique designed to learn a
significantly smaller graph that retains the essential information of the
original graph. This condensed graph has shown promise in accelerating graph
neural networks while preserving performance comparable to those achieved with
the original, larger graphs. Additionally, this technique facilitates
downstream applications such as neural architecture search and enhances our
understanding of redundancy in large graphs. Despite the rapid development of
GC methods, a systematic evaluation framework remains absent, which is
necessary to clarify the critical designs for particular evaluative aspects.
Furthermore, several meaningful questions have not been investigated, such as
whether GC inherently preserves certain graph properties and offers robustness
even without targeted design efforts. In this paper, we introduce GC-Bench, a
comprehensive framework to evaluate recent GC methods across multiple
dimensions and to generate new insights. Our experimental findings provide a
deeper insights into the GC process and the characteristics of condensed
graphs, guiding future efforts in enhancing performance and exploring new
applications. Our code is available at
\url{https://github.com/Emory-Melody/GraphSlim/tree/main/benchmark}."
AutoDetect - Towards a Unified Framework for Automated Weakness Detection in Large Language Models,https://arxiv.org/abs/2406.16714,2024-06-24,2024-06-25,0.0,0.0,"Although Large Language Models (LLMs) are becoming increasingly powerful,
they still exhibit significant but subtle weaknesses, such as mistakes in
instruction-following or coding tasks. As these unexpected errors could lead to
severe consequences in practical deployments, it is crucial to investigate the
limitations within LLMs systematically. Traditional benchmarking approaches
cannot thoroughly pinpoint specific model deficiencies, while manual
inspections are costly and not scalable. In this paper, we introduce a unified
framework, AutoDetect, to automatically expose weaknesses in LLMs across
various tasks. Inspired by the educational assessment process that measures
students' learning outcomes, AutoDetect consists of three LLM-powered agents:
Examiner, Questioner, and Assessor. The collaboration among these three agents
is designed to realize comprehensive and in-depth weakness identification. Our
framework demonstrates significant success in uncovering flaws, with an
identification success rate exceeding 30% in prominent models such as ChatGPT
and Claude. More importantly, these identified weaknesses can guide specific
model improvements, proving more effective than untargeted data augmentation
methods like Self-Instruct. Our approach has led to substantial enhancements in
popular LLMs, including the Llama series and Mistral-7b, boosting their
performance by over 10% across several benchmarks. Code and data are publicly
available at https://github.com/thu-coai/AutoDetect."
CausalFormer - An Interpretable Transformer for Temporal Causal Discovery,https://arxiv.org/abs/2406.16708,2024-06-24,2024-06-25,0.0,0.0,"Temporal causal discovery is a crucial task aimed at uncovering the causal
relations within time series data. The latest temporal causal discovery methods
usually train deep learning models on prediction tasks to uncover the causality
between time series. They capture causal relations by analyzing the parameters
of some components of the trained models, e.g., attention weights and
convolution weights. However, this is an incomplete mapping process from the
model parameters to the causality and fails to investigate the other
components, e.g., fully connected layers and activation functions, that are
also significant for causal discovery. To facilitate the utilization of the
whole deep learning models in temporal causal discovery, we proposed an
interpretable transformer-based causal discovery model termed CausalFormer,
which consists of the causality-aware transformer and the decomposition-based
causality detector. The causality-aware transformer learns the causal
representation of time series data using a prediction task with the designed
multi-kernel causal convolution which aggregates each input time series along
the temporal dimension under the temporal priority constraint. Then, the
decomposition-based causality detector interprets the global structure of the
trained causality-aware transformer with the proposed regression relevance
propagation to identify potential causal relations and finally construct the
causal graph. Experiments on synthetic, simulated, and real datasets
demonstrate the state-of-the-art performance of CausalFormer on discovering
temporal causality. Our code is available at
https://github.com/lingbai-kong/CausalFormer."
Probabilistic Subgoal Representations for Hierarchical Reinforcement learning,https://arxiv.org/abs/2406.16707,2024-06-24,2024-06-25,0.0,0.0,"In goal-conditioned hierarchical reinforcement learning (HRL), a high-level
policy specifies a subgoal for the low-level policy to reach. Effective HRL
hinges on a suitable subgoal represen tation function, abstracting state space
into latent subgoal space and inducing varied low-level behaviors. Existing
methods adopt a subgoal representation that provides a deterministic mapping
from state space to latent subgoal space. Instead, this paper utilizes Gaussian
Processes (GPs) for the first probabilistic subgoal representation. Our method
employs a GP prior on the latent subgoal space to learn a posterior
distribution over the subgoal representation functions while exploiting the
long-range correlation in the state space through learnable kernels. This
enables an adaptive memory that integrates long-range subgoal information from
prior planning steps allowing to cope with stochastic uncertainties.
Furthermore, we propose a novel learning objective to facilitate the
simultaneous learning of probabilistic subgoal representations and policies
within a unified framework. In experiments, our approach outperforms
state-of-the-art baselines in standard benchmarks but also in environments with
stochastic elements and under diverse reward conditions. Additionally, our
model shows promising capabilities in transferring low-level policies across
different tasks."
Learning Interpretable Fair Representations,https://arxiv.org/abs/2406.16698,2024-06-24,2024-06-25,0.0,0.0,"Numerous approaches have been recently proposed for learning fair
representations that mitigate unfair outcomes in prediction tasks. A key
motivation for these methods is that the representations can be used by third
parties with unknown objectives. However, because current fair representations
are generally not interpretable, the third party cannot use these fair
representations for exploration, or to obtain any additional insights, besides
the pre-contracted prediction tasks. Thus, to increase data utility beyond
prediction tasks, we argue that the representations need to be fair, yet
interpretable. We propose a general framework for learning interpretable fair
representations by introducing an interpretable ""prior knowledge"" during the
representation learning process. We implement this idea and conduct experiments
with ColorMNIST and Dsprite datasets. The results indicate that in addition to
being interpretable, our representations attain slightly higher accuracy and
fairer outcomes in a downstream classification task compared to
state-of-the-art fair representations."
Expected Runtime Comparisons Between Breadth-First Search and Constant-Depth Restarting Random Walks,https://arxiv.org/abs/2406.16697,2024-06-24,2024-06-25,0.0,0.0,"When greedy search algorithms encounter a local minima or plateau, the search
typically devolves into a breadth-first search (BrFS), or a local search
technique is used in an attempt to find a way out. In this work, we formally
analyze the performance of BrFS and constant-depth restarting random walks
(RRW) -- two methods often used for finding exits to a plateau/local minima --
to better understand when each is best suited. In particular, we formally
derive the expected runtime for BrFS in the case of a uniformly distributed set
of goals at a given goal depth. We then prove RRW will be faster than BrFS on
trees if there are enough goals at that goal depth. We refer to this threshold
as the crossover point. Our bound shows that the crossover point grows linearly
with the branching factor of the tree, the goal depth, and the error in the
random walk depth, while the size of the tree grows exponentially in branching
factor and goal depth. Finally, we discuss the practical implications and
applicability of this bound."
Public Constitutional AI,https://arxiv.org/abs/2406.16696,2024-06-24,2024-06-25,0.0,0.0,"We are increasingly subjected to the power of AI authorities. As AI decisions
become inescapable, entering domains such as healthcare, education, and law, we
must confront a vital question: how can we ensure AI systems have the
legitimacy necessary for effective governance? This essay argues that to secure
AI legitimacy, we need methods that engage the public in designing and
constraining AI systems, ensuring these technologies reflect the community's
shared values. Constitutional AI, proposed by Anthropic, represents a step
towards this goal, offering a model for democratic control of AI. However,
while Constitutional AI's commitment to hardcoding explicit principles into AI
models enhances transparency and accountability, it falls short in two crucial
aspects: addressing the opacity of individual AI decisions and fostering
genuine democratic legitimacy. To overcome these limitations, this essay
proposes ""Public Constitutional AI."" This approach envisions a participatory
process where diverse stakeholders, including ordinary citizens, deliberate on
the principles guiding AI development. The resulting ""AI Constitution"" would
carry the legitimacy of popular authorship, grounding AI governance in the
public will. Furthermore, the essay proposes ""AI Courts"" to develop ""AI case
law,"" providing concrete examples for operationalizing constitutional
principles in AI training. This evolving combination of constitutional
principles and case law aims to make AI governance more responsive to public
values. By grounding AI governance in deliberative democratic processes, Public
Constitutional AI offers a path to imbue automated authorities with genuine
democratic legitimacy, addressing the unique challenges posed by increasingly
powerful AI systems while ensuring their alignment with the public interest."
Task Oriented In-Domain Data Augmentation,https://arxiv.org/abs/2406.16694,2024-06-24,2024-06-25,0.0,0.0,"Large Language Models (LLMs) have shown superior performance in various
applications and fields. To achieve better performance on specialized domains
such as law and advertisement, LLMs are often continue pre-trained on in-domain
data. However, existing approaches suffer from two major issues. First,
in-domain data are scarce compared with general domain-agnostic data. Second,
data used for continual pre-training are not task-aware, such that they may not
be helpful to downstream applications. We propose TRAIT, a task-oriented
in-domain data augmentation framework. Our framework is divided into two parts:
in-domain data selection and task-oriented synthetic passage generation. The
data selection strategy identifies and selects a large amount of in-domain data
from general corpora, and thus significantly enriches domain knowledge in the
continual pre-training data. The synthetic passages contain guidance on how to
use domain knowledge to answer questions about downstream tasks. By training on
such passages, the model aligns with the need of downstream applications. We
adapt LLMs to two domains: advertisement and math. On average, TRAIT improves
LLM performance by 8% in the advertisement domain and 7.5% in the math domain."
Scaling Laws for Linear Complexity Language Models,https://arxiv.org/abs/2406.16690,2024-06-24,2024-06-25,1.0,0.0,"The interest in linear complexity models for large language models is on the
rise, although their scaling capacity remains uncertain. In this study, we
present the scaling laws for linear complexity language models to establish a
foundation for their scalability. Specifically, we examine the scaling
behaviors of three efficient linear architectures. These include TNL, a linear
attention model with data-independent decay; HGRN2, a linear RNN with
data-dependent decay; and cosFormer2, a linear attention model without decay.
We also include LLaMA as a baseline architecture for softmax attention for
comparison. These models were trained with six variants, ranging from 70M to 7B
parameters on a 300B-token corpus, and evaluated with a total of 1,376
intermediate checkpoints on various downstream tasks. These tasks include
validation loss, commonsense reasoning, and information retrieval and
generation. The study reveals that existing linear complexity language models
exhibit similar scaling capabilities as conventional transformer-based models
while also demonstrating superior linguistic proficiency and knowledge
retention."
Coding schemes in neural networks learning classification tasks,https://arxiv.org/abs/2406.16689,2024-06-24,2024-06-25,0.0,0.0,"Neural networks posses the crucial ability to generate meaningful
representations of task-dependent features. Indeed, with appropriate scaling,
supervised learning in neural networks can result in strong, task-dependent
feature learning. However, the nature of the emergent representations, which we
call the `coding scheme', is still unclear. To understand the emergent coding
scheme, we investigate fully-connected, wide neural networks learning
classification tasks using the Bayesian framework where learning shapes the
posterior distribution of the network weights. Consistent with previous
findings, our analysis of the feature learning regime (also known as
`non-lazy', `rich', or `mean-field' regime) shows that the networks acquire
strong, data-dependent features. Surprisingly, the nature of the internal
representations depends crucially on the neuronal nonlinearity. In linear
networks, an analog coding scheme of the task emerges. Despite the strong
representations, the mean predictor is identical to the lazy case. In nonlinear
networks, spontaneous symmetry breaking leads to either redundant or sparse
coding schemes. Our findings highlight how network properties such as scaling
of weights and neuronal nonlinearity can profoundly influence the emergent
representations."
Link Prediction with Untrained Message Passing Layers,https://arxiv.org/abs/2406.16687,2024-06-24,2024-06-25,0.0,0.0,"Message passing neural networks (MPNNs) operate on graphs by exchanging
information between neigbouring nodes. MPNNs have been successfully applied to
various node-, edge-, and graph-level tasks in areas like molecular science,
computer vision, natural language processing, and combinatorial optimization.
However, most MPNNs require training on large amounts of labeled data, which
can be costly and time-consuming. In this work, we explore the use of various
untrained message passing layers in graph neural networks, i.e. variants of
popular message passing architecture where we remove all trainable parameters
that are used to transform node features in the message passing step. Focusing
on link prediction, we find that untrained message passing layers can lead to
competitive and even superior performance compared to fully trained MPNNs,
especially in the presence of high-dimensional features. We provide a
theoretical analysis of untrained message passing by relating the inner
products of features implicitly produced by untrained message passing layers to
path-based topological node similarity measures. As such, untrained message
passing architectures can be viewed as a highly efficient and interpretable
approach to link prediction."
Repulsive Score Distillation for Diverse Sampling of Diffusion Models,https://arxiv.org/abs/2406.16683,2024-06-24,2024-06-25,0.0,0.0,"Score distillation sampling has been pivotal for integrating diffusion models
into generation of complex visuals. Despite impressive results it suffers from
mode collapse and lack of diversity. To cope with this challenge, we leverage
the gradient flow interpretation of score distillation to propose Repulsive
Score Distillation (RSD). In particular, we propose a variational framework
based on repulsion of an ensemble of particles that promotes diversity. Using a
variational approximation that incorporates a coupling among particles, the
repulsion appears as a simple regularization that allows interaction of
particles based on their relative pairwise similarity, measured e.g., via
radial basis kernels. We design RSD for both unconstrained and constrained
sampling scenarios. For constrained sampling we focus on inverse problems in
the latent space that leads to an augmented variational formulation, that
strikes a good balance between compute, quality and diversity. Our extensive
experiments for text-to-image generation, and inverse problems demonstrate that
RSD achieves a superior trade-off between diversity and quality compared with
state-of-the-art alternatives."
A Comprehensive Review of Emerging Approaches in Machine Learning for De Novo PROTAC Design,https://arxiv.org/abs/2406.16681,2024-06-24,2024-06-25,0.0,0.0,"Targeted protein degradation (TPD) is a rapidly growing field in modern drug
discovery that aims to regulate the intracellular levels of proteins by
harnessing the cell's innate degradation pathways to selectively target and
degrade disease-related proteins. This strategy creates new opportunities for
therapeutic intervention in cases where occupancy-based inhibitors have not
been successful. Proteolysis-targeting chimeras (PROTACs) are at the heart of
TPD strategies, which leverage the ubiquitin-proteasome system for the
selective targeting and proteasomal degradation of pathogenic proteins. As the
field evolves, it becomes increasingly apparent that the traditional
methodologies for designing such complex molecules have limitations. This has
led to the use of machine learning (ML) and generative modeling to improve and
accelerate the development process. In this review, we explore the impact of ML
on de novo PROTAC design $-$ an aspect of molecular design that has not been
comprehensively reviewed despite its significance. We delve into the distinct
characteristics of PROTAC linker design, underscoring the complexities required
to create effective bifunctional molecules capable of TPD. We then examine how
ML in the context of fragment-based drug design (FBDD), honed in the realm of
small-molecule drug discovery, is paving the way for PROTAC linker design. Our
review provides a critical evaluation of the limitations inherent in applying
this method to the complex field of PROTAC development. Moreover, we review
existing ML works applied to PROTAC design, highlighting pioneering efforts
and, importantly, the limitations these studies face. By offering insights into
the current state of PROTAC development and the integral role of ML in PROTAC
design, we aim to provide valuable perspectives for researchers in their
pursuit of better design strategies for this new modality."
"Segment Any Text - A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation",https://arxiv.org/abs/2406.16678,2024-06-24,2024-06-25,0.0,0.0,"Segmenting text into sentences plays an early and crucial role in many NLP
systems. This is commonly achieved by using rule-based or statistical methods
relying on lexical features such as punctuation. Although some recent works no
longer exclusively rely on punctuation, we find that no prior method achieves
all of (i) robustness to missing punctuation, (ii) effective adaptability to
new domains, and (iii) high efficiency. We introduce a new model - Segment any
Text (SaT) - to solve this problem. To enhance robustness, we propose a new
pretraining scheme that ensures less reliance on punctuation. To address
adaptability, we introduce an extra stage of parameter-efficient fine-tuning,
establishing state-of-the-art performance in distinct domains such as verses
from lyrics and legal documents. Along the way, we introduce architectural
modifications that result in a threefold gain in speed over the previous state
of the art and solve spurious reliance on context far in the future. Finally,
we introduce a variant of our model with fine-tuning on a diverse, multilingual
mixture of sentence-segmented data, acting as a drop-in replacement and
enhancement for existing segmentation tools. Overall, our contributions provide
a universal approach for segmenting any text. Our method outperforms all
baselines - including strong LLMs - across 8 corpora spanning diverse domains
and languages, especially in practically relevant situations where text is
poorly formatted. Our models and code, including documentation, are available
at https://huggingface.co/segment-any-text under the MIT license."
Computational Approaches to the Detection of Lesser-Known Rhetorical Figures - A Systematic Survey and Research Challenges,https://arxiv.org/abs/2406.16674,2024-06-24,2024-06-25,0.0,0.0,"Rhetorical figures play a major role in our everyday communication as they
make text more interesting, more memorable, or more persuasive. Therefore, it
is important to computationally detect rhetorical figures to fully understand
the meaning of a text. We provide a comprehensive overview of computational
approaches to lesser-known rhetorical figures. We explore the linguistic and
computational perspectives on rhetorical figures, emphasizing their
significance for the domain of Natural Language Processing. We present
different figures in detail, delving into datasets, definitions, rhetorical
functions, and detection approaches. We identified challenges such as dataset
scarcity, language limitations, and reliance on rule-based methods."
CAVE - Controllable Authorship Verification Explanations,https://arxiv.org/abs/2406.16672,2024-06-24,2024-06-25,0.0,0.0,"Authorship Verification (AV) (do two documents have the same author?) is
essential in many sensitive real-life applications. AV is often used in
proprietary domains that require a private, offline model, making SOTA online
models like ChatGPT undesirable. Current offline models however have lower
downstream utility due to low accuracy/scalability (eg: traditional stylometry
AV systems) and lack of accessible post-hoc explanations. In this work, we take
the first step to address the above challenges with our trained, offline
Llama-3-8B model CAVE (Controllable Authorship Verification Explanations): CAVE
generates free-text AV explanations that are controlled to be (1) structured
(can be decomposed into sub-explanations in terms of relevant linguistic
features), and (2) easily verified for explanation-label consistency (via
intermediate labels in sub-explanations). We first engineer a prompt that can
generate silver training data from a SOTA teacher model in the desired CAVE
output format. We then filter and distill this data into a pretrained
Llama-3-8B, our carefully selected student model. Results on three difficult AV
datasets IMDb62, Blog-Auth, and Fanfiction show that CAVE generates high
quality explanations (as measured by automatic and human evaluation) as well as
competitive task accuracies."
Cubic regularized subspace Newton for non-convex optimization,https://arxiv.org/abs/2406.16666,2024-06-24,2024-06-25,0.0,0.0,"This paper addresses the optimization problem of minimizing non-convex
continuous functions, which is relevant in the context of high-dimensional
machine learning applications characterized by over-parametrization. We analyze
a randomized coordinate second-order method named SSCN which can be interpreted
as applying cubic regularization in random subspaces. This approach effectively
reduces the computational complexity associated with utilizing second-order
information, rendering it applicable in higher-dimensional scenarios.
Theoretically, we establish convergence guarantees for non-convex functions,
with interpolating rates for arbitrary subspace sizes and allowing inexact
curvature estimation. When increasing subspace size, our complexity matches
$\mathcal{O}(\epsilon^{-3/2})$ of the cubic regularization (CR) rate.
Additionally, we propose an adaptive sampling scheme ensuring exact convergence
rate of $\mathcal{O}(\epsilon^{-3/2}, \epsilon^{-3})$ to a second-order
stationary point, even without sampling all coordinates. Experimental results
demonstrate substantial speed-ups achieved by SSCN compared to conventional
first-order methods."
"Data-driven Modeling in Metrology -- A Short Introduction, Current Developments and Future Perspectives",https://arxiv.org/abs/2406.16659,2024-06-24,2024-06-25,0.0,0.0,"Mathematical models are vital to the field of metrology, playing a key role
in the derivation of measurement results and the calculation of uncertainties
from measurement data, informed by an understanding of the measurement process.
These models generally represent the correlation between the quantity being
measured and all other pertinent quantities. Such relationships are used to
construct measurement systems that can interpret measurement data to generate
conclusions and predictions about the measurement system itself. Classic models
are typically analytical, built on fundamental physical principles. However,
the rise of digital technology, expansive sensor networks, and high-performance
computing hardware have led to a growing shift towards data-driven
methodologies. This trend is especially prominent when dealing with large,
intricate networked sensor systems in situations where there is limited expert
understanding of the frequently changing real-world contexts. Here, we
demonstrate the variety of opportunities that data-driven modeling presents,
and how they have been already implemented in various real-world applications."
Large Language Models Are Cross-Lingual Knowledge-Free Reasoners,https://arxiv.org/abs/2406.16655,2024-06-24,2024-06-25,0.0,0.0,"Large Language Models have demonstrated impressive reasoning capabilities
across multiple languages. However, the relationship between capabilities in
different languages is less explored. In this work, we decompose the process of
reasoning tasks into two separated parts: knowledge retrieval and
knowledge-free reasoning, and analyze the cross-lingual transferability of
them. With adapted and constructed knowledge-free reasoning datasets, we show
that the knowledge-free reasoning capability can be nearly perfectly
transferred across various source-target language directions despite the
secondary impact of resource in some specific target languages, while
cross-lingual knowledge retrieval significantly hinders the transfer. Moreover,
by analyzing the hidden states and feed-forward network neuron activation
during the reasoning tasks, we show that higher similarity of hidden
representations and larger overlap of activated neurons could explain the
better cross-lingual transferability of knowledge-free reasoning than knowledge
retrieval. Thus, we hypothesize that knowledge-free reasoning embeds in some
language-shared mechanism, while knowledge is stored separately in different
languages."
Vision-Language Consistency Guided Multi-modal Prompt Learning for Blind AI Generated Image Quality Assessment,https://arxiv.org/abs/2406.16641,2024-06-24,2024-06-25,0.0,0.0,"Recently, textual prompt tuning has shown inspirational performance in
adapting Contrastive Language-Image Pre-training (CLIP) models to natural image
quality assessment. However, such uni-modal prompt learning method only tunes
the language branch of CLIP models. This is not enough for adapting CLIP models
to AI generated image quality assessment (AGIQA) since AGIs visually differ
from natural images. In addition, the consistency between AGIs and user input
text prompts, which correlates with the perceptual quality of AGIs, is not
investigated to guide AGIQA. In this letter, we propose vision-language
consistency guided multi-modal prompt learning for blind AGIQA, dubbed
CLIP-AGIQA. Specifically, we introduce learnable textual and visual prompts in
language and vision branches of CLIP models, respectively. Moreover, we design
a text-to-image alignment quality prediction task, whose learned
vision-language consistency knowledge is used to guide the optimization of the
above multi-modal prompts. Experimental results on two public AGIQA datasets
demonstrate that the proposed method outperforms state-of-the-art quality
assessment models. The source code is available at
https://github.com/JunFu1995/CLIP-AGIQA."
Feature Fusion for Human Activity Recognition using Parameter-Optimized Multi-Stage Graph Convolutional Network and Transformer Models,https://arxiv.org/abs/2406.16638,2024-06-24,2024-06-25,0.0,0.0,"Human activity recognition (HAR) is a crucial area of research that involves
understanding human movements using computer and machine vision technology.
Deep learning has emerged as a powerful tool for this task, with models such as
Convolutional Neural Networks (CNNs) and Transformers being employed to capture
various aspects of human motion. One of the key contributions of this work is
the demonstration of the effectiveness of feature fusion in improving HAR
accuracy by capturing spatial and temporal features, which has important
implications for the development of more accurate and robust activity
recognition systems. The study uses sensory data from HuGaDB, PKU-MMD, LARa,
and TUG datasets. Two model, the PO-MS-GCN and a Transformer were trained and
evaluated, with PO-MS-GCN outperforming state-of-the-art models. HuGaDB and TUG
achieved high accuracies and f1-scores, while LARa and PKU-MMD had lower
scores. Feature fusion improved results across datasets."
ShadowLLM - Predictor-based Contextual Sparsity for Large Language Models,https://arxiv.org/abs/2406.16635,2024-06-24,2024-06-25,0.0,0.0,"The high power consumption and latency-sensitive deployments of large
language models (LLMs) have motivated techniques like quantization and
sparsity. Contextual sparsity, where the sparsity pattern is input-dependent,
is crucial in LLMs because the permanent removal of attention heads or neurons
from LLMs can significantly degrade accuracy. Prior work has attempted to model
contextual sparsity using neural networks trained to predict activation
magnitudes, which can be used to dynamically prune structures with low
predicted activation magnitude. In this paper, we look beyond magnitude-based
pruning criteria to assess attention head and neuron importance in LLMs. We
developed a novel predictor called ShadowLLM, which can shadow the LLM behavior
and enforce better sparsity patterns, resulting in over 15% improvement in
end-to-end accuracy without increasing latency compared to previous methods.
ShadowLLM achieves up to a 20\% speed-up over the state-of-the-art DejaVu
framework. These enhancements are validated on models with up to 30 billion
parameters. Our code is available at
\href{https://github.com/abdelfattah-lab/shadow_llm/}{ShadowLLM}."
Hacking a surrogate model approach to XAI,https://arxiv.org/abs/2406.16626,2024-06-24,2024-06-25,0.0,0.0,"In recent years, the number of new applications for highly complex AI systems
has risen significantly. Algorithmic decision-making systems (ADMs) are one of
such applications, where an AI system replaces the decision-making process of a
human expert. As one approach to ensure fairness and transparency of such
systems, explainable AI (XAI) has become more important. One variant to achieve
explainability are surrogate models, i.e., the idea to train a new simpler
machine learning model based on the input-output-relationship of a black box
model. The simpler machine learning model could, for example, be a decision
tree, which is thought to be intuitively understandable by humans. However,
there is not much insight into how well the surrogate model approximates the
black box.
  Our main assumption is that a good surrogate model approach should be able to
bring such a discriminating behavior to the attention of humans; prior to our
research we assumed that a surrogate decision tree would identify such a
pattern on one of its first levels. However, in this article we show that even
if the discriminated subgroup - while otherwise being the same in all
categories - does not get a single positive decision from the black box ADM
system, the corresponding question of group membership can be pushed down onto
a level as low as wanted by the operator of the system.
  We then generalize this finding to pinpoint the exact level of the tree on
which the discriminating question is asked and show that in a more realistic
scenario, where discrimination only occurs to some fraction of the
disadvantaged group, it is even more feasible to hide such discrimination.
  Our approach can be generalized easily to other surrogate models."
Towards Physically Talented Aerial Robots with Tactically Smart Swarm Behavior thereof - An Efficient Co-design Approach,https://arxiv.org/abs/2406.16612,2024-06-24,2024-06-25,0.0,0.0,"The collective performance or capacity of collaborative autonomous systems
such as a swarm of robots is jointly influenced by the morphology and the
behavior of individual systems in that collective. In that context, this paper
explores how morphology impacts the learned tactical behavior of unmanned
aerial/ground robots performing reconnaissance and search & rescue. This is
achieved by presenting a computationally efficient framework to solve this
otherwise challenging problem of jointly optimizing the morphology and tactical
behavior of swarm robots. Key novel developments to this end include the use of
physical talent metrics and modification of graph reinforcement learning
architectures to allow joint learning of the swarm tactical policy and the
talent metrics (search speed, flight range, and cruising speed) that constrain
mobility and object/victim search capabilities of the aerial robots executing
these tactics. Implementation of this co-design approach is supported by
advancements to an open-source Pybullet-based swarm simulator that allows the
use of variable aerial asset capabilities. The results of the co-design are
observed to outperform those of tactics learning with a fixed Pareto design,
when compared in terms of mission performance metrics. Significant differences
in morphology and learned behavior are also observed by comparing the baseline
design and the co-design outcomes."
Evaluating the Robustness of Deep-Learning Algorithm-Selection Models by Evolving Adversarial Instances,https://arxiv.org/abs/2406.16609,2024-06-24,2024-06-25,0.0,0.0,"Deep neural networks (DNN) are increasingly being used to perform
algorithm-selection in combinatorial optimisation domains, particularly as they
accommodate input representations which avoid designing and calculating
features. Mounting evidence from domains that use images as input shows that
deep convolutional networks are vulnerable to adversarial samples, in which a
small perturbation of an instance can cause the DNN to misclassify. However, it
remains unknown as to whether deep recurrent networks (DRN) which have recently
been shown promise as algorithm-selectors in the bin-packing domain are equally
vulnerable. We use an evolutionary algorithm (EA) to find perturbations of
instances from two existing benchmarks for online bin packing that cause
trained DRNs to misclassify: adversarial samples are successfully generated
from up to 56% of the original instances depending on the dataset. Analysis of
the new misclassified instances sheds light on the `fragility' of some training
instances, i.e. instances where it is trivial to find a small perturbation that
results in a misclassification and the factors that influence this. Finally,
the method generates a large number of new instances misclassified with a wide
variation in confidence, providing a rich new source of training data to create
more robust models."
When Invariant Representation Learning Meets Label Shift - Insufficiency and Theoretical Insights,https://arxiv.org/abs/2406.16608,2024-06-24,2024-06-25,0.0,0.0,"As a crucial step toward real-world learning scenarios with changing
environments, dataset shift theory and invariant representation learning
algorithm have been extensively studied to relax the identical distribution
assumption in classical learning setting. Among the different assumptions on
the essential of shifting distributions, generalized label shift (GLS) is the
latest developed one which shows great potential to deal with the complex
factors within the shift. In this paper, we aim to explore the limitations of
current dataset shift theory and algorithm, and further provide new insights by
presenting a comprehensive understanding of GLS. From theoretical aspect, two
informative generalization bounds are derived, and the GLS learner is proved to
be sufficiently close to optimal target model from the Bayesian perspective.
The main results show the insufficiency of invariant representation learning,
and prove the sufficiency and necessity of GLS correction for generalization,
which provide theoretical supports and innovations for exploring generalizable
model under dataset shift. From methodological aspect, we provide a unified
view of existing shift correction frameworks, and propose a kernel
embedding-based correction algorithm (KECA) to minimize the generalization
error and achieve successful knowledge transfer. Both theoretical results and
extensive experiment evaluations demonstrate the sufficiency and necessity of
GLS correction for addressing dataset shift and the superiority of proposed
algorithm."
Cherry on the Cake - Fairness is NOT an Optimization Problem,https://arxiv.org/abs/2406.16606,2024-06-24,2024-06-25,0.0,0.0,"Fair cake-cutting is a mathematical subfield that studies the problem of
fairly dividing a resource among a number of participants. The so-called
``cake,'' as an object, represents any resource that can be distributed among
players. This concept is connected to supervised multi-label classification:
any dataset can be thought of as a cake that needs to be distributed, where
each label is a player that receives its share of the dataset. In particular,
any efficient cake-cutting solution for the dataset is equivalent to an optimal
decision function. Although we are not the first to demonstrate this
connection, the important ramifications of this parallel seem to have been
partially forgotten. We revisit these classical results and demonstrate how
this connection can be prolifically used for fairness in machine learning
problems. Understanding the set of achievable fair decisions is a fundamental
step in finding optimal fair solutions and satisfying fairness requirements. By
employing the tools of cake-cutting theory, we have been able to describe the
behavior of optimal fair decisions, which, counterintuitively, often exhibit
quite unfair properties. Specifically, in order to satisfy fairness
constraints, it is sometimes preferable, in the name of optimality, to
purposefully make mistakes and deny giving the positive label to deserving
individuals in a community in favor of less worthy individuals within the same
community. This practice is known in the literature as cherry-picking and has
been described as ``blatantly unfair.''"
CLEAR - Can Language Models Really Understand Causal Graphs?,https://arxiv.org/abs/2406.16605,2024-06-24,2024-06-25,0.0,0.0,"Causal reasoning is a cornerstone of how humans interpret the world. To model
and reason about causality, causal graphs offer a concise yet effective
solution. Given the impressive advancements in language models, a crucial
question arises: can they really understand causal graphs? To this end, we
pioneer an investigation into language models' understanding of causal graphs.
Specifically, we develop a framework to define causal graph understanding, by
assessing language models' behaviors through four practical criteria derived
from diverse disciplines (e.g., philosophy and psychology). We then develop
CLEAR, a novel benchmark that defines three complexity levels and encompasses
20 causal graph-based tasks across these levels. Finally, based on our
framework and benchmark, we conduct extensive experiments on six leading
language models and summarize five empirical findings. Our results indicate
that while language models demonstrate a preliminary understanding of causal
graphs, significant potential for improvement remains. Our project website is
at https://github.com/OpenCausaLab/CLEAR."
Measuring the Recyclability of Electronic Components to Assist Automatic Disassembly and Sorting Waste Printed Circuit Boards,https://arxiv.org/abs/2406.16593,2024-06-24,2024-06-25,0.0,0.0,"The waste of electrical and electronic equipment has been increased due to
the fast evolution of technology products and competition of many IT sectors.
Every year millions of tons of electronic waste are thrown into the environment
which causes high consequences for human health. Therefore, it is crucial to
control this waste flow using technology, especially using Artificial
Intelligence but also reclamation of critical raw materials for new production
processes. In this paper, we focused on the measurement of recyclability of
waste electronic components (WECs) from waste printed circuit boards (WPCBs)
using mathematical innovation model. This innovative approach evaluates both
the recyclability and recycling difficulties of WECs, integrating an AI model
for improved disassembly and sorting. Assessing the recyclability of individual
electronic components present on WPCBs provides insight into the recovery
potential of valuable materials and indicates the level of complexity involved
in recycling in terms of economic worth and production utility. This novel
measurement approach helps AI models in accurately determining the number of
classes to be identified and sorted during the automated disassembly of
discarded PCBs. It also facilitates the model in iterative training and
validation of individual electronic components."
Forecasting with Deep Learning - Beyond Average of Average of Average Performance,https://arxiv.org/abs/2406.16590,2024-06-24,2024-06-25,1.0,0.0,"Accurate evaluation of forecasting models is essential for ensuring reliable
predictions. Current practices for evaluating and comparing forecasting models
focus on summarising performance into a single score, using metrics such as
SMAPE. We hypothesize that averaging performance over all samples dilutes
relevant information about the relative performance of models. Particularly,
conditions in which this relative performance is different than the overall
accuracy. We address this limitation by proposing a novel framework for
evaluating univariate time series forecasting models from multiple
perspectives, such as one-step ahead forecasting versus multi-step ahead
forecasting. We show the advantages of this framework by comparing a
state-of-the-art deep learning approach with classical forecasting techniques.
While classical methods (e.g. ARIMA) are long-standing approaches to
forecasting, deep neural networks (e.g. NHITS) have recently shown
state-of-the-art forecasting performance in benchmark datasets. We conducted
extensive experiments that show NHITS generally performs best, but its
superiority varies with forecasting conditions. For instance, concerning the
forecasting horizon, NHITS only outperforms classical approaches for multi-step
ahead forecasting. Another relevant insight is that, when dealing with
anomalies, NHITS is outperformed by methods such as Theta. These findings
highlight the importance of aspect-based model evaluation."
Personalized federated learning based on feature fusion,https://arxiv.org/abs/2406.16583,2024-06-24,2024-06-25,0.0,0.0,"Federated learning enables distributed clients to collaborate on training
while storing their data locally to protect client privacy. However, due to the
heterogeneity of data, models, and devices, the final global model may need to
perform better for tasks on each client. Communication bottlenecks, data
heterogeneity, and model heterogeneity have been common challenges in federated
learning. In this work, we considered a label distribution skew problem, a type
of data heterogeneity easily overlooked. In the context of classification, we
propose a personalized federated learning approach called pFedPM. In our
process, we replace traditional gradient uploading with feature uploading,
which helps reduce communication costs and allows for heterogeneous client
models. These feature representations play a role in preserving privacy to some
extent.
  We use a hyperparameter $a$ to mix local and global features, which enables
us to control the degree of personalization. We also introduced a relation
network as an additional decision layer, which provides a non-linear learnable
classifier to predict labels. Experimental results show that, with an
appropriate setting of $a$, our scheme outperforms several recent FL methods on
MNIST, FEMNIST, and CRIFAR10 datasets and achieves fewer communications."
Differentiable Distributionally Robust Optimization Layers,https://arxiv.org/abs/2406.16571,2024-06-24,2024-06-25,0.0,0.0,"In recent years, there has been a growing research interest in
decision-focused learning, which embeds optimization problems as a layer in
learning pipelines and demonstrates a superior performance than the
prediction-focused approach. However, for distributionally robust optimization
(DRO), a popular paradigm for decision-making under uncertainty, it is still
unknown how to embed it as a layer, i.e., how to differentiate decisions with
respect to an ambiguity set. In this paper, we develop such differentiable DRO
layers for generic mixed-integer DRO problems with parameterized second-order
conic ambiguity sets and discuss its extension to Wasserstein ambiguity sets.
To differentiate the mixed-integer decisions, we propose a novel dual-view
methodology by handling continuous and discrete parts of decisions via
different principles. Specifically, we construct a differentiable energy-based
surrogate to implement the dual-view methodology and use importance sampling to
estimate its gradient. We further prove that such a surrogate enjoys the
asymptotic convergency under regularization. As an application of the proposed
differentiable DRO layers, we develop a novel decision-focused learning
pipeline for contextual distributionally robust decision-making tasks and
compare it with the prediction-focused approach in experiments."
Data Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting,https://arxiv.org/abs/2406.16567,2024-06-24,2024-06-25,0.0,0.0,"Existing dialogue data augmentation (DA) techniques predominantly focus on
augmenting utterance-level dialogues, which makes it difficult to take dialogue
contextual information into account. The advent of large language models (LLMs)
has simplified the implementation of multi-turn dialogues. Due to absence of
professional understanding and knowledge, it remains challenging to deliver
satisfactory performance in low-resource domain, like psychological dialogue
dialogue. DA involves creating new training or prompting data based on the
existing data, which help the model better understand and generate
psychology-related responses. In this paper, we aim to address the issue of
multi-turn dialogue data augmentation for boosted performance in the psychology
domain. We propose a knowledge-driven progressive thought prompting method to
guide LLM to generate multi-turn psychology-related dialogue. This method
integrates a progressive thought generator, a psychology knowledge generator,
and a multi-turn dialogue generator. The thought generated by the progressive
thought generator serves as a prompt to prevent the generated dialogue from
having significant semantic deviations, while the psychology knowledge
generator produces psychological knowledge to serve as the dialogue history for
the LLM, guiding the dialogue generator to create multi-turn psychological
dialogue. To ensure the precision of multi-turn psychological dialogue
generation by LLM, a meticulous professional evaluation is required. Extensive
experiments conducted on three datasets related to psychological dialogue
verify the effectiveness of the proposed method."
Noisy Neighbors - Efficient membership inference attacks against LLMs,https://arxiv.org/abs/2406.16565,2024-06-24,2024-06-25,0.0,0.0,"The potential of transformer-based LLMs risks being hindered by privacy
concerns due to their reliance on extensive datasets, possibly including
sensitive information. Regulatory measures like GDPR and CCPA call for using
robust auditing tools to address potential privacy issues, with Membership
Inference Attacks (MIA) being the primary method for assessing LLMs' privacy
risks. Differently from traditional MIA approaches, often requiring
computationally intensive training of additional models, this paper introduces
an efficient methodology that generates \textit{noisy neighbors} for a target
sample by adding stochastic noise in the embedding space, requiring operating
the target model in inference mode only. Our findings demonstrate that this
approach closely matches the effectiveness of employing shadow models, showing
its usability in practical privacy auditing scenarios."
Are there identifiable structural parts in the sentence embedding whole?,https://arxiv.org/abs/2406.16563,2024-06-24,2024-06-25,0.0,0.0,"Sentence embeddings from transformer models encode in a fixed length vector
much linguistic information. We explore the hypothesis that these embeddings
consist of overlapping layers of information that can be separated, and on
which specific types of information -- such as information about chunks and
their structural and semantic properties -- can be detected. We show that this
is the case using a dataset consisting of sentences with known chunk structure,
and two linguistic intelligence datasets, solving which relies on detecting
chunks and their grammatical number, and respectively, their semantic roles,
and through analyses of the performance on the tasks and of the internal
representations built during learning."
EvalAlign - Evaluating Text-to-Image Models through Precision Alignment of Multimodal Large Models with Supervised Fine-Tuning to Human Annotations,https://arxiv.org/abs/2406.16562,2024-06-24,2024-06-25,0.0,0.0,"The recent advancements in text-to-image generative models have been
remarkable. Yet, the field suffers from a lack of evaluation metrics that
accurately reflect the performance of these models, particularly lacking
fine-grained metrics that can guide the optimization of the models. In this
paper, we propose EvalAlign, a metric characterized by its accuracy, stability,
and fine granularity. Our approach leverages the capabilities of Multimodal
Large Language Models (MLLMs) pre-trained on extensive datasets. We develop
evaluation protocols that focus on two key dimensions: image faithfulness and
text-image alignment. Each protocol comprises a set of detailed, fine-grained
instructions linked to specific scoring options, enabling precise manual
scoring of the generated images. We Supervised Fine-Tune (SFT) the MLLM to
align closely with human evaluative judgments, resulting in a robust evaluation
model. Our comprehensive tests across 24 text-to-image generation models
demonstrate that EvalAlign not only provides superior metric stability but also
aligns more closely with human preferences than existing metrics, confirming
its effectiveness and utility in model assessment."
Efficient k-means with Individual Fairness via Exponential Tilting,https://arxiv.org/abs/2406.16557,2024-06-24,2024-06-25,0.0,0.0,"In location-based resource allocation scenarios, the distances between each
individual and the facility are desired to be approximately equal, thereby
ensuring fairness. Individually fair clustering is often employed to achieve
the principle of treating all points equally, which can be applied in these
scenarios. This paper proposes a novel algorithm, tilted k-means (TKM), aiming
to achieve individual fairness in clustering. We integrate the exponential
tilting into the sum of squared errors (SSE) to formulate a novel objective
function called tilted SSE. We demonstrate that the tilted SSE can generalize
to SSE and employ the coordinate descent and first-order gradient method for
optimization. We propose a novel fairness metric, the variance of the distances
within each cluster, which can alleviate the Matthew Effect typically caused by
existing fairness metrics. Our theoretical analysis demonstrates that the
well-known k-means++ incurs a multiplicative error of O(k log k), and we
establish the convergence of TKM under mild conditions. In terms of fairness,
we prove that the variance generated by TKM decreases with a scaled
hyperparameter. In terms of efficiency, we demonstrate the time complexity is
linear with the dataset size. Our experiments demonstrate that TKM outperforms
state-of-the-art methods in effectiveness, fairness, and efficiency."
Homomorphisms and Embeddings of STRIPS Planning Models,https://arxiv.org/abs/2406.16555,2024-06-24,2024-06-25,0.0,0.0,"Determining whether two STRIPS planning instances are isomorphic is the
simplest form of comparison between planning instances. It is also a particular
case of the problem concerned with finding an isomorphism between a planning
instance $P$ and a sub-instance of another instance $P_0$ . One application of
such a mapping is to efficiently produce a compiled form containing all
solutions to P from a compiled form containing all solutions to $P_0$. We also
introduce the notion of embedding from an instance $P$ to another instance
$P_0$, which allows us to deduce that $P_0$ has no solution-plan if $P$ is
unsolvable. In this paper, we study the complexity of these problems. We show
that the first is GI-complete, and can thus be solved, in theory, in
quasi-polynomial time. While we prove the remaining problems to be NP-complete,
we propose an algorithm to build an isomorphism, when possible. We report
extensive experimental trials on benchmark problems which demonstrate
conclusively that applying constraint propagation in preprocessing can greatly
improve the efficiency of a SAT solver."
LLaMA-MoE - Building Mixture-of-Experts from LLaMA with Continual Pre-training,https://arxiv.org/abs/2406.16554,2024-06-24,2024-06-25,1.0,0.0,"Mixture-of-Experts (MoE) has gained increasing popularity as a promising
framework for scaling up large language models (LLMs). However, training MoE
from scratch in a large-scale setting still suffers from data-hungry and
instability problems. Motivated by this limit, we investigate building MoE
models from existing dense large language models. Specifically, based on the
well-known LLaMA-2 7B model, we obtain an MoE model by: (1) Expert
Construction, which partitions the parameters of original Feed-Forward Networks
(FFNs) into multiple experts; (2) Continual Pre-training, which further trains
the transformed MoE model and additional gate networks. In this paper, we
comprehensively explore different methods for expert construction and various
data sampling strategies for continual pre-training. After these stages, our
LLaMA-MoE models could maintain language abilities and route the input tokens
to specific experts with part of the parameters activated. Empirically, by
training 200B tokens, LLaMA-MoE-3.5B models significantly outperform dense
models that contain similar activation parameters. The source codes and models
are available at https://github.com/pjlab-sys4nlp/llama-moe ."
Inference of Sequential Patterns for Neural Message Passing in Temporal Graphs,https://arxiv.org/abs/2406.16552,2024-06-24,2024-06-25,0.0,0.0,"The modelling of temporal patterns in dynamic graphs is an important current
research issue in the development of time-aware GNNs. Whether or not a specific
sequence of events in a temporal graph constitutes a temporal pattern not only
depends on the frequency of its occurrence. We consider whether it deviates
from what is expected in a temporal graph where timestamps are randomly
shuffled. While accounting for such a random baseline is important to model
temporal patterns, it has mostly been ignored by current temporal graph neural
networks. To address this issue we propose HYPA-DBGNN, a novel two-step
approach that combines (i) the inference of anomalous sequential patterns in
time series data on graphs based on a statistically principled null model, with
(ii) a neural message passing approach that utilizes a higher-order De Bruijn
graph whose edges capture overrepresented sequential patterns. Our method
leverages hypergeometric graph ensembles to identify anomalous edges within
both first- and higher-order De Bruijn graphs, which encode the temporal
ordering of events. The model introduces an inductive bias that enhances model
interpretability. We evaluate our approach for static node classification using
benchmark datasets and a synthetic dataset that showcases its ability to
incorporate the observed inductive bias regarding over- and under-represented
temporal edges. We demonstrate the framework's effectiveness in detecting
similar patterns within empirical datasets, resulting in superior performance
compared to baseline methods in node classification tasks. To the best of our
knowledge, our work is the first to introduce statistically informed GNNs that
leverage temporal and causal sequence anomalies. HYPA-DBGNN represents a path
for bridging the gap between statistical graph inference and neural graph
representation learning, with potential applications to static GNNs."
Improving robustness to corruptions with multiplicative weight perturbations,https://arxiv.org/abs/2406.16540,2024-06-24,2024-06-25,0.0,0.0,"Deep neural networks (DNNs) excel on clean images but struggle with corrupted
ones. Incorporating specific corruptions into the data augmentation pipeline
can improve robustness to those corruptions but may harm performance on clean
images and other types of distortion. In this paper, we introduce an
alternative approach that improves the robustness of DNNs to a wide range of
corruptions without compromising accuracy on clean images. We first demonstrate
that input perturbations can be mimicked by multiplicative perturbations in the
weight space. Leveraging this, we propose Data Augmentation via Multiplicative
Perturbation (DAMP), a training method that optimizes DNNs under random
multiplicative weight perturbations. We also examine the recently proposed
Adaptive Sharpness-Aware Minimization (ASAM) and show that it optimizes DNNs
under adversarial multiplicative weight perturbations. Experiments on image
classification datasets (CIFAR-10/100, TinyImageNet and ImageNet) and neural
network architectures (ResNet50, ViT-S/16) show that DAMP enhances model
generalization performance in the presence of corruptions across different
settings. Notably, DAMP is able to train a ViT-S/16 on ImageNet from scratch,
reaching the top-1 error of 23.7% which is comparable to ResNet50 without
extensive data augmentations."
Character-Adapter - Prompt-Guided Region Control for High-Fidelity Character Customization,https://arxiv.org/abs/2406.16537,2024-06-24,2024-06-25,0.0,0.0,"Customized image generation, which seeks to synthesize images with consistent
characters, holds significant relevance for applications such as storytelling,
portrait generation, and character design. However, previous approaches have
encountered challenges in preserving characters with high-fidelity consistency
due to inadequate feature extraction and concept confusion of reference
characters. Therefore, we propose Character-Adapter, a plug-and-play framework
designed to generate images that preserve the details of reference characters,
ensuring high-fidelity consistency. Character-Adapter employs prompt-guided
segmentation to ensure fine-grained regional features of reference characters
and dynamic region-level adapters to mitigate concept confusion. Extensive
experiments are conducted to validate the effectiveness of Character-Adapter.
Both quantitative and qualitative results demonstrate that Character-Adapter
achieves the state-of-the-art performance of consistent character generation,
with an improvement of 24.8% compared with other methods. Our code will be
released at https://github.com/Character-Adapter/Character-Adapter."
C-LLM - Learn to Check Chinese Spelling Errors Character by Character,https://arxiv.org/abs/2406.16536,2024-06-24,2024-06-25,0.0,0.0,"Chinese Spell Checking (CSC) aims to detect and correct spelling errors in
sentences. Despite Large Language Models (LLMs) exhibit robust capabilities and
are widely applied in various tasks, their performance on CSC is often
unsatisfactory. We find that LLMs fail to meet the Chinese character-level
constraints of the CSC task, namely equal length and phonetic similarity,
leading to a performance bottleneck. Further analysis reveal that this issue
stems from the granularity of tokenization, as current mixed character-word
tokenization struggles to satisfy these character-level constraints. To address
this issue, we propose C-LLM, a Large Language Model-based Chinese Spell
Checking method that learns to check errors Character by Character.
Character-level tokenization enables the model to learn character-level
alignment, effectively mitigating issues related to character-level
constraints. Furthermore, CSC is simplified to replication-dominated and
substitution-supplemented tasks. Experiments on two CSC benchmarks demonstrate
that C-LLM achieves an average improvement of 10% over existing methods.
Specifically, it shows a 2.1% improvement in general scenarios and a
significant 12% improvement in vertical domain scenarios, establishing
state-of-the-art performance. The source code can be accessed at
https://github.com/ktlKTL/C-LLM."
Token-based Decision Criteria Are Suboptimal in In-context Learning,https://arxiv.org/abs/2406.16535,2024-06-24,2024-06-25,0.0,0.0,"In-Context Learning (ICL) typically utilizes classification criteria from
probabilities of manually selected label tokens. However, we argue that such
token-based classification criteria lead to suboptimal decision boundaries,
despite delicate calibrations through translation and constrained rotation. To
address this problem, we propose Hidden Calibration, which renounces token
probabilities and uses the nearest centroid classifier on the LM's last hidden
states. In detail, we use the nearest centroid classification on the hidden
states, assigning the category of the nearest centroid previously observed from
a few-shot calibration set to the test sample as the predicted label. Our
experiments on 3 models and 10 classification datasets indicate that Hidden
Calibration consistently outperforms current token-based calibrations by about
20%. Our further analysis demonstrates that Hidden Calibration finds better
classification criteria with less inter-categories overlap, and LMs provide
linearly separable intra-category clusters with the help of demonstrations,
which supports Hidden Calibration and gives new insights into the conventional
ICL."
Conditional Bayesian Quadrature,https://arxiv.org/abs/2406.16530,2024-06-24,2024-06-25,0.0,0.0,"We propose a novel approach for estimating conditional or parametric
expectations in the setting where obtaining samples or evaluating integrands is
costly. Through the framework of probabilistic numerical methods (such as
Bayesian quadrature), our novel approach allows to incorporates prior
information about the integrands especially the prior smoothness knowledge
about the integrands and the conditional expectation. As a result, our approach
provides a way of quantifying uncertainty and leads to a fast convergence rate,
which is confirmed both theoretically and empirically on challenging tasks in
Bayesian sensitivity analysis, computational finance and decision making under
uncertainty."
Towards Better Graph-based Cross-document Relation Extraction via Non-bridge Entity Enhancement and Prediction Debiasing,https://arxiv.org/abs/2406.16529,2024-06-24,2024-06-25,0.0,0.0,"Cross-document Relation Extraction aims to predict the relation between
target entities located in different documents. In this regard, the dominant
models commonly retain useful information for relation prediction via bridge
entities, which allows the model to elaborately capture the intrinsic
interdependence between target entities. However, these studies ignore the
non-bridge entities, each of which co-occurs with only one target entity and
offers the semantic association between target entities for relation
prediction. Besides, the commonly-used dataset--CodRED contains substantial NA
instances, leading to the prediction bias during inference. To address these
issues, in this paper, we propose a novel graph-based cross-document RE model
with non-bridge entity enhancement and prediction debiasing. Specifically, we
use a unified entity graph to integrate numerous non-bridge entities with
target entities and bridge entities, modeling various associations between
them, and then use a graph recurrent network to encode this graph. Finally, we
introduce a novel debiasing strategy to calibrate the original prediction
distribution. Experimental results on the closed and open settings show that
our model significantly outperforms all baselines, including the GPT-3.5-turbo
and InstructUIE, achieving state-of-the-art performance. Particularly, our
model obtains 66.23% and 55.87% AUC points in the official
leaderboard\footnote{\url{https://codalab.lisn.upsaclay.fr/competitions/3770#results}}
under the two settings, respectively, ranking the first place in all
submissions since December 2023. Our code is available at
https://github.com/DeepLearnXMU/CoRE-NEPD."
Evaluating the Ability of Large Language Models to Reason about Cardinal Directions,https://arxiv.org/abs/2406.16528,2024-06-24,2024-06-25,0.0,0.0,"We investigate the abilities of a representative set of Large language Models
(LLMs) to reason about cardinal directions (CDs). To do so, we create two
datasets: the first, co-created with ChatGPT, focuses largely on recall of
world knowledge about CDs; the second is generated from a set of templates,
comprehensively testing an LLM's ability to determine the correct CD given a
particular scenario. The templates allow for a number of degrees of variation
such as means of locomotion of the agent involved, and whether set in the first
, second or third person. Even with a temperature setting of zero, Our
experiments show that although LLMs are able to perform well in the simpler
dataset, in the second more complex dataset no LLM is able to reliably
determine the correct CD, even with a temperature setting of zero."
SyROCCo - Enhancing Systematic Reviews using Machine Learning,https://arxiv.org/abs/2406.16527,2024-06-24,2024-06-25,0.0,0.0,"The sheer number of research outputs published every year makes systematic
reviewing increasingly time- and resource-intensive. This paper explores the
use of machine learning techniques to help navigate the systematic review
process. ML has previously been used to reliably 'screen' articles for review -
that is, identify relevant articles based on reviewers' inclusion criteria. The
application of ML techniques to subsequent stages of a review, however, such as
data extraction and evidence mapping, is in its infancy. We therefore set out
to develop a series of tools that would assist in the profiling and analysis of
1,952 publications on the theme of 'outcomes-based contracting'. Tools were
developed for the following tasks: assign publications into 'policy area'
categories; identify and extract key information for evidence mapping, such as
organisations, laws, and geographical information; connect the evidence base to
an existing dataset on the same topic; and identify subgroups of articles that
may share thematic content. An interactive tool using these techniques and a
public dataset with their outputs have been released. Our results demonstrate
the utility of ML techniques to enhance evidence accessibility and analysis
within the systematic review processes. These efforts show promise in
potentially yielding substantial efficiencies for future systematic reviewing
and for broadening their analytical scope. Our work suggests that there may be
implications for the ease with which policymakers and practitioners can access
evidence. While ML techniques seem poised to play a significant role in
bridging the gap between research and policy by offering innovative ways of
gathering, accessing, and analysing data from systematic reviews, we also
highlight their current limitations and the need to exercise caution in their
application, particularly given the potential for errors and biases."
NARRepair - Non-Autoregressive Code Generation Model for Automatic Program Repair,https://arxiv.org/abs/2406.16526,2024-06-24,2024-06-25,0.0,0.0,"With the advancement of deep learning techniques, the performance of
Automatic Program Repair(APR) techniques has reached a new level. Previous deep
learning-based APR techniques essentially modified program sentences in the
Autoregressive(AR) manner, which predicts future values based on past values.
Due to the manner of word-by-word generation, the AR-based APR technique has a
huge time delay. This negative consequence overshadows the widespread adoption
of APR techniques in real-life software development.
  To address the issue, we aim to apply the Non-Autoregressive(NAR) method to
the APR task, which can output target code in a parallel manner to avoid huge
inference delays. To effectively adapt the NAR manner for the APR task, we in
this paper propose NARRepair, the first customized NAR code generation model
for the APR task. The NARRepair features three major novelties, including 1)
using repair actions to alleviate the over-correction issue, 2) extracting
dependency information from AST to alleviate the issue of lacking inter-word
dependency information, 3) employing two-stage decoding to alleviate the issue
of lacking contextual information. We evaluated NARRepair on three widely used
datasets in the APR community, and the results show that our technique can
significantly improve the inference speed while maintaining high repair
accuracy."
OAML - Outlier Aware Metric Learning for OOD Detection Enhancement,https://arxiv.org/abs/2406.16525,2024-06-24,2024-06-25,0.0,0.0,"Out-of-distribution (OOD) detection methods have been developed to identify
objects that a model has not seen during training. The Outlier Exposure (OE)
methods use auxiliary datasets to train OOD detectors directly. However, the
collection and learning of representative OOD samples may pose challenges. To
tackle these issues, we propose the Outlier Aware Metric Learning (OAML)
framework. The main idea of our method is to use the k-NN algorithm and Stable
Diffusion model to generate outliers for training at the feature level without
making any distributional assumptions. To increase feature discrepancies in the
semantic space, we develop a mutual information-based contrastive learning
approach for learning from OOD data effectively. Both theoretical and empirical
results confirm the effectiveness of this contrastive learning technique.
Furthermore, we incorporate knowledge distillation into our learning framework
to prevent degradation of in-distribution classification accuracy. The
combination of contrastive learning and knowledge distillation algorithms
significantly enhances the performance of OOD detection. Experimental results
across various datasets show that our method significantly outperforms previous
OE methods."
The Privileged Students - On the Value of Initialization in Multilingual Knowledge Distillation,https://arxiv.org/abs/2406.16524,2024-06-24,2024-06-25,0.0,0.0,"Knowledge distillation (KD) has proven to be a successful strategy to improve
the performance of a smaller model in many NLP tasks. However, most of the work
in KD only explores monolingual scenarios. In this paper, we investigate the
value of KD in multilingual settings. We find the significance of KD and model
initialization by analyzing how well the student model acquires multilingual
knowledge from the teacher model. Our proposed method emphasizes copying the
teacher model's weights directly to the student model to enhance
initialization. Our finding shows that model initialization using copy-weight
from the fine-tuned teacher contributes the most compared to the distillation
process itself across various multilingual settings. Furthermore, we
demonstrate that efficient weight initialization preserves multilingual
capabilities even in low-resource scenarios."
Carrot and Stick - Inducing Self-Motivation with Positive & Negative Feedback,https://arxiv.org/abs/2406.16521,2024-06-24,2024-06-25,0.0,0.0,"Positive thinking is thought to be an important component of self-motivation
in various practical fields such as education and the workplace. Previous work,
including sentiment transfer and positive reframing, has focused on the
positive side of language. However, self-motivation that drives people to reach
their goals has not yet been studied from a computational perspective.
Moreover, negative feedback has not yet been explored, even though positive and
negative feedback are both necessary to grow self-motivation. To facilitate
self-motivation, we propose CArrot and STICk (CASTIC) dataset, consisting of
12,590 sentences with 5 different strategies for enhancing self-motivation. Our
data and code are publicly available at here."
Large Vocabulary Size Improves Large Language Models,https://arxiv.org/abs/2406.16508,2024-06-24,2024-06-25,1.0,0.0,"This paper empirically investigates the relationship between subword
vocabulary size and the performance of large language models (LLMs) to provide
insights on how to define the vocabulary size. Experimental results show that
larger vocabulary sizes lead to better performance in LLMs. Moreover, we
consider a continual training scenario where a pre-trained language model is
trained on a different target language. We introduce a simple method to use a
new vocabulary instead of the pre-defined one. We show that using the new
vocabulary outperforms the model with the vocabulary used in pre-training."
Statistical ranking with dynamic covariates,https://arxiv.org/abs/2406.16507,2024-06-24,2024-06-25,0.0,0.0,"We consider a covariate-assisted ranking model grounded in the Plackett--Luce
framework. Unlike existing works focusing on pure covariates or individual
effects with fixed covariates, our approach integrates individual effects with
dynamic covariates. This added flexibility enhances realistic ranking yet poses
significant challenges for analyzing the associated estimation procedures. This
paper makes an initial attempt to address these challenges. We begin by
discussing the sufficient and necessary condition for the model's
identifiability. We then introduce an efficient alternating maximization
algorithm to compute the maximum likelihood estimator (MLE). Under suitable
assumptions on the topology of comparison graphs and dynamic covariates, we
establish a quantitative uniform consistency result for the MLE with
convergence rates characterized by the asymptotic graph connectivity. The
proposed graph topology assumption holds for several popular random graph
models under optimal leading-order sparsity conditions. A comprehensive
numerical study is conducted to corroborate our theoretical findings and
demonstrate the application of the proposed model to real-world datasets,
including horse racing and tennis competitions."
$\text{Alpha}^2$ - Discovering Logical Formulaic Alphas using Deep Reinforcement Learning,https://arxiv.org/abs/2406.16505,2024-06-24,2024-06-25,0.0,0.0,"Alphas are pivotal in providing signals for quantitative trading. The
industry highly values the discovery of formulaic alphas for their
interpretability and ease of analysis, compared with the expressive yet
overfitting-prone black-box alphas. In this work, we focus on discovering
formulaic alphas. Prior studies on automatically generating a collection of
formulaic alphas were mostly based on genetic programming (GP), which is known
to suffer from the problems of being sensitive to the initial population,
converting to local optima, and slow computation speed. Recent efforts
employing deep reinforcement learning (DRL) for alpha discovery have not fully
addressed key practical considerations such as alpha correlations and validity,
which are crucial for their effectiveness. In this work, we propose a novel
framework for alpha discovery using DRL by formulating the alpha discovery
process as program construction. Our agent, $\text{Alpha}^2$, assembles an
alpha program optimized for an evaluation metric. A search algorithm guided by
DRL navigates through the search space based on value estimates for potential
alpha outcomes. The evaluation metric encourages both the performance and the
diversity of alphas for a better final trading strategy. Our formulation of
searching alphas also brings the advantage of pre-calculation dimensional
analysis, ensuring the logical soundness of alphas, and pruning the vast search
space to a large extent. Empirical experiments on real-world stock markets
demonstrates $\text{Alpha}^2$'s capability to identify a diverse set of logical
and effective alphas, which significantly improves the performance of the final
trading strategy. The code of our method is available at
https://github.com/x35f/alpha2."
"UNICAD - A Unified Approach for Attack Detection, Noise Reduction and Novel Class Identification",https://arxiv.org/abs/2406.16501,2024-06-24,2024-06-25,0.0,0.0,"As the use of Deep Neural Networks (DNNs) becomes pervasive, their
vulnerability to adversarial attacks and limitations in handling unseen classes
poses significant challenges. The state-of-the-art offers discrete solutions
aimed to tackle individual issues covering specific adversarial attack
scenarios, classification or evolving learning. However, real-world systems
need to be able to detect and recover from a wide range of adversarial attacks
without sacrificing classification accuracy and to flexibly act in {\bf unseen}
scenarios. In this paper, UNICAD, is proposed as a novel framework that
integrates a variety of techniques to provide an adaptive solution.
  For the targeted image classification, UNICAD achieves accurate image
classification, detects unseen classes, and recovers from adversarial attacks
using Prototype and Similarity-based DNNs with denoising autoencoders. Our
experiments performed on the CIFAR-10 dataset highlight UNICAD's effectiveness
in adversarial mitigation and unseen class classification, outperforming
traditional models."
OTCE - Hybrid SSM and Attention with Cross Domain Mixture of Experts to construct Observer-Thinker-Conceiver-Expresser,https://arxiv.org/abs/2406.16495,2024-06-24,2024-06-25,1.0,1.0,"Recent research has shown that combining Mamba with Transformer architecture,
which has selective state space and quadratic self-attention mechanism,
outperforms using Mamba or Transformer architecture alone in language modeling
tasks. The quadratic self-attention mechanism effectively alleviates the
shortcomings of selective state space in handling long-term dependencies of any
element in the sequence. We propose a position information injection method
that connects the selective state space model with the quadratic attention, and
integrates these two architectures with hybrid experts with cross-sharing
domains, so that we can enjoy the advantages of both. We design a new
architecture with a more biomimetic idea: Observer-Thinker-Conceiver-Expresser
(OTCE), which can compete with well-known medium-scale open-source language
models on a small scale in language modeling tasks."
Cross-domain Transfer of Valence Preferences via a Meta-optimization Approach,https://arxiv.org/abs/2406.16494,2024-06-24,2024-06-25,0.0,0.0,"Cross-domain recommendation offers a potential avenue for alleviating data
sparsity and cold-start problems. Embedding and mapping, as a classic
cross-domain research genre, aims to identify a common mapping function to
perform representation transformation between two domains. Nevertheless,
previous coarse-grained preference representations, non-personalized mapping
functions, and excessive reliance on overlapping users limit their performance,
especially in scenarios where overlapping users are sparse. To address
aforementioned challenges, we propose a novel cross-domain approach, namely
CVPM. CVPM formalizes cross-domain interest transfer as a hybrid architecture
of parametric meta-learning and self-supervised learning, which not only
transfers user preferences at a finer level, but also enables signal
enhancement with the knowledge of non-overlapping users. Specifically, with
deep insights into user preferences and valence preference theory, we believe
that there exists significant difference between users' positive preferences
and negative behaviors, and thus employ differentiated encoders to learn their
distributions. In particular, we further utilize the pre-trained model and item
popularity to sample pseudo-interaction items to ensure the integrity of both
distributions. To guarantee the personalization of preference transfer, we
treat each user's mapping as two parts, the common transformation and the
personalized bias, where the network used to generate the personalized bias is
output by a meta-learner. Furthermore, in addition to the supervised loss for
overlapping users, we design contrastive tasks for non-overlapping users from
both group and individual-levels to avoid model skew and enhance the semantics
of representations. Exhaustive data analysis and extensive experimental results
demonstrate the effectiveness and advancement of our proposed framework."
eagerlearners at SemEval2024 Task 5 - The Legal Argument Reasoning Task in Civil Procedure,https://arxiv.org/abs/2406.16490,2024-06-24,2024-06-25,0.0,0.0,"This study investigates the performance of the zero-shot method in
classifying data using three large language models, alongside two models with
large input token sizes and the two pre-trained models on legal data. Our main
dataset comes from the domain of U.S. civil procedure. It includes summaries of
legal cases, specific questions, potential answers, and detailed explanations
for why each solution is relevant, all sourced from a book aimed at law
students. By comparing different methods, we aimed to understand how
effectively they handle the complexities found in legal datasets. Our findings
show how well the zero-shot method of large language models can understand
complicated data. We achieved our highest F1 score of 64% in these experiments."
Deepfake tweets automatic detection,https://arxiv.org/abs/2406.16489,2024-06-24,2024-06-25,0.0,0.0,"This study addresses the critical challenge of detecting DeepFake tweets by
leveraging advanced natural language processing (NLP) techniques to distinguish
between genuine and AI-generated texts. Given the increasing prevalence of
misinformation, our research utilizes the TweepFake dataset to train and
evaluate various machine learning models. The objective is to identify
effective strategies for recognizing DeepFake content, thereby enhancing the
integrity of digital communications. By developing reliable methods for
detecting AI-generated misinformation, this work contributes to a more
trustworthy online information environment."
Towards Comprehensive Preference Data Collection for Reward Modeling,https://arxiv.org/abs/2406.16486,2024-06-24,2024-06-25,0.0,0.0,"Reinforcement Learning from Human Feedback (RLHF) facilitates the alignment
of large language models (LLMs) with human preferences, thereby enhancing the
quality of responses generated. A critical component of RLHF is the reward
model, which is trained on preference data and outputs a scalar reward during
the inference stage. However, the collection of preference data still lacks
thorough investigation. Recent studies indicate that preference data is
collected either by AI or humans, where chosen and rejected instances are
identified among pairwise responses. We question whether this process
effectively filters out noise and ensures sufficient diversity in collected
data. To address these concerns, for the first time, we propose a comprehensive
framework for preference data collection, decomposing the process into four
incremental steps: Prompt Generation, Response Generation, Response Filtering,
and Human Labeling. This structured approach ensures the collection of
high-quality preferences while reducing reliance on human labor. We conducted
comprehensive experiments based on the data collected at different stages,
demonstrating the effectiveness of the proposed data collection method."
Robust prediction under missingness shifts,https://arxiv.org/abs/2406.16484,2024-06-24,2024-06-25,0.0,0.0,"Prediction becomes more challenging with missing covariates. What method is
chosen to handle missingness can greatly affect how models perform. In many
real-world problems, the best prediction performance is achieved by models that
can leverage the informative nature of a value being missing. Yet, the reasons
why a covariate goes missing can change once a model is deployed in practice.
If such a missingness shift occurs, the conditional probability of a value
being missing differs in the target data. Prediction performance in the source
data may no longer be a good selection criterion, and approaches that do not
rely on informative missingness may be preferable. However, we show that the
Bayes predictor remains unchanged by ignorable shifts for which the probability
of missingness only depends on observed data. Any consistent estimator of the
Bayes predictor may therefore result in robust prediction under those
conditions, although we show empirically that different methods appear robust
to different types of shifts. If the missingness shift is non-ignorable, the
Bayes predictor may change due to the shift. While neither approach recovers
the Bayes predictor in this case, we found empirically that disregarding
missingness was most beneficial when it was highly informative."
Improving Quaternion Neural Networks with Quaternionic Activation Functions,https://arxiv.org/abs/2406.16481,2024-06-24,2024-06-25,0.0,0.0,"In this paper, we propose novel quaternion activation functions where we
modify either the quaternion magnitude or the phase, as an alternative to the
commonly used split activation functions. We define criteria that are relevant
for quaternion activation functions, and subsequently we propose our novel
activation functions based on this analysis. Instead of applying a known
activation function like the ReLU or Tanh on the quaternion elements
separately, these activation functions consider the quaternion properties and
respect the quaternion space $\mathbb{H}$. In particular, all quaternion
components are utilized to calculate all output components, carrying out the
benefit of the Hamilton product in e.g. the quaternion convolution to the
activation functions. The proposed activation functions can be incorporated in
arbitrary quaternion valued neural networks trained with gradient descent
techniques. We further discuss the derivatives of the proposed activation
functions where we observe beneficial properties for the activation functions
affecting the phase. Specifically, they prove to be sensitive on basically the
whole input range, thus improved gradient flow can be expected. We provide an
elaborate experimental evaluation of our proposed quaternion activation
functions including comparison with the split ReLU and split Tanh on two image
classification tasks using the CIFAR-10 and SVHN dataset. There, especially the
quaternion activation functions affecting the phase consistently prove to
provide better performance."
Emerging NeoHebbian Dynamics in Forward-Forward Learning - Implications for Neuromorphic Computing,https://arxiv.org/abs/2406.16479,2024-06-24,2024-06-25,0.0,0.0,"Advances in neural computation have predominantly relied on the gradient
backpropagation algorithm (BP). However, the recent shift towards
non-stationary data modeling has highlighted the limitations of this heuristic,
exposing that its adaptation capabilities are far from those seen in biological
brains. Unlike BP, where weight updates are computed through a reverse error
propagation path, Hebbian learning dynamics provide synaptic updates using only
information within the layer itself. This has spurred interest in biologically
plausible learning algorithms, hypothesized to overcome BP's shortcomings. In
this context, Hinton recently introduced the Forward-Forward Algorithm (FFA),
which employs local learning rules for each layer and has empirically proven
its efficacy in multiple data modeling tasks. In this work we argue that when
employing a squared Euclidean norm as a goodness function driving the local
learning, the resulting FFA is equivalent to a neo-Hebbian Learning Rule. To
verify this result, we compare the training behavior of FFA in analog networks
with its Hebbian adaptation in spiking neural networks. Our experiments
demonstrate that both versions of FFA produce similar accuracy and latent
distributions. The findings herein reported provide empirical evidence linking
biological learning rules with currently used training algorithms, thus paving
the way towards extrapolating the positive outcomes from FFA to Hebbian
learning rules. Simultaneously, our results imply that analog networks trained
under FFA could be directly applied to neuromorphic computing, leading to
reduced energy usage and increased computational speed."
EMMI -- Empathic Multimodal Motivational Interviews Dataset - Analyses and Annotations,https://arxiv.org/abs/2406.16478,2024-06-24,2024-06-25,0.0,0.0,"The study of multimodal interaction in therapy can yield a comprehensive
understanding of therapist and patient behavior that can be used to develop a
multimodal virtual agent supporting therapy. This investigation aims to uncover
how therapists skillfully blend therapy's task goal (employing classical steps
of Motivational Interviewing) with the social goal (building a trusting
relationship and expressing empathy). Furthermore, we seek to categorize
patients into various ``types'' requiring tailored therapeutic approaches. To
this intent, we present multimodal annotations of a corpus consisting of
simulated motivational interviewing conversations, wherein actors portray the
roles of patients and therapists. We introduce EMMI, composed of two publicly
available MI corpora, AnnoMI and the Motivational Interviewing Dataset, for
which we add multimodal annotations. We analyze these annotations to
characterize functional behavior for developing a virtual agent performing
motivational interviews emphasizing social and empathic behaviors. Our analysis
found three clusters of patients expressing significant differences in behavior
and adaptation of the therapist's behavior to those types. This shows the
importance of a therapist being able to adapt their behavior depending on the
current situation within the dialog and the type of user."
Seeking Certainty In Uncertainty - Dual-Stage Unified Framework Solving Uncertainty in Dynamic Facial Expression Recognition,https://arxiv.org/abs/2406.16473,2024-06-24,2024-06-25,0.0,0.0,"The contemporary state-of-the-art of Dynamic Facial Expression Recognition
(DFER) technology facilitates remarkable progress by deriving emotional
mappings of facial expressions from video content, underpinned by training on
voluminous datasets. Yet, the DFER datasets encompass a substantial volume of
noise data. Noise arises from low-quality captures that defy logical labeling,
and instances that suffer from mislabeling due to annotation bias, engendering
two principal types of uncertainty: the uncertainty regarding data usability
and the uncertainty concerning label reliability. Addressing the two types of
uncertainty, we have meticulously crafted a two-stage framework aiming at
\textbf{S}eeking \textbf{C}ertain data \textbf{I}n extensive \textbf{U}ncertain
data (SCIU). This initiative aims to purge the DFER datasets of these
uncertainties, thereby ensuring that only clean, verified data is employed in
training processes. To mitigate the issue of low-quality samples, we introduce
the Coarse-Grained Pruning (CGP) stage, which assesses sample weights and
prunes those deemed unusable due to their low weight. For samples with
incorrect annotations, the Fine-Grained Correction (FGC) stage evaluates
prediction stability to rectify mislabeled data. Moreover, SCIU is conceived as
a universally compatible, plug-and-play framework, tailored to integrate
seamlessly with prevailing DFER methodologies. Rigorous experiments across
prevalent DFER datasets and against numerous benchmark methods substantiates
SCIU's capacity to markedly elevate performance metrics."
Evaluating Visual and Cultural Interpretation - The K-Viscuit Benchmark with Human-VLM Collaboration,https://arxiv.org/abs/2406.16469,2024-06-24,2024-06-25,0.0,0.0,"To create culturally inclusive vision-language models (VLMs), the foremost
requirement is developing a test benchmark that can diagnose the models'
ability to respond to questions reflecting cultural elements. This paper
addresses the necessity for such benchmarks, noting that existing research has
relied on human annotators' manual efforts, which impedes diversity and
efficiency. We propose a semi-automated pipeline for constructing cultural VLM
benchmarks to enhance diversity and efficiency. This pipeline leverages
human-VLM collaboration, where VLMs generate questions based on guidelines,
human-annotated examples, and image-wise relevant knowledge, which are then
reviewed by native speakers for quality and cultural relevance. The
effectiveness of our adaptable pipeline is demonstrated through a specific
application: creating a dataset tailored to Korean culture, dubbed K-Viscuit.
The resulting benchmark features two types of questions: Type 1 questions
measure visual recognition abilities, while Type 2 assess fine-grained visual
reasoning skills. This ensures a thorough diagnosis of VLM models across
various aspects. Our evaluation using K-Viscuit revealed that open-source
models notably lag behind proprietary models in understanding Korean culture,
highlighting areas for improvement. We provided diverse analyses of VLM
performance across different cultural aspects. Besides, we explored the
potential of incorporating external knowledge retrieval to enhance the
generation process, suggesting future directions for improving cultural
interpretation ability of VLMs. Our dataset and code will be made publicly
available."
The Hidden Pitfalls of the Cosine Similarity Loss,https://arxiv.org/abs/2406.16468,2024-06-24,2024-06-25,1.0,1.0,"We show that the gradient of the cosine similarity between two points goes to
zero in two under-explored settings: (1) if a point has large magnitude or (2)
if the points are on opposite ends of the latent space. Counterintuitively, we
prove that optimizing the cosine similarity between points forces them to grow
in magnitude. Thus, (1) is unavoidable in practice. We then observe that these
derivations are extremely general -- they hold across deep learning
architectures and for many of the standard self-supervised learning (SSL) loss
functions. This leads us to propose cut-initialization: a simple change to
network initialization that helps all studied SSL methods converge faster."
SLOctolyzer - Fully automatic analysis toolkit for segmentation and feature extracting in scanning laser ophthalmoscopy images,https://arxiv.org/abs/2406.16466,2024-06-24,2024-06-25,0.0,0.0,"Purpose: To describe SLOctolyzer: an open-source analysis toolkit for en face
retinal vessels appearing in infrared reflectance scanning laser ophthalmoscopy
(SLO) images.
  Methods: SLOctolyzer includes two main modules: segmentation and measurement.
The segmentation module use deep learning methods to delineate retinal anatomy,
while the measurement module quantifies key retinal vascular features such as
vessel complexity, density, tortuosity, and calibre. We evaluate the
segmentation module using unseen data and measure its reproducibility.
  Results: SLOctolyzer's segmentation module performed well against unseen
internal test data (Dice for all-vessels, 0.9097; arteries, 0.8376; veins,
0.8525; optic disc, 0.9430; fovea, 0.8837). External validation against severe
retinal pathology showed decreased performance (Dice for arteries, 0.7180;
veins, 0.7470; optic disc, 0.9032). SLOctolyzer had good reproducibility (mean
difference for fractal dimension, -0.0007; vessel density, -0.0003; vessel
calibre, -0.3154 $\mu$m; tortuosity density, 0.0013). SLOctolyzer can process a
macula-centred SLO image in under 20 seconds and a disc-centred SLO image in
under 30 seconds using a standard laptop CPU.
  Conclusions: To our knowledge, SLOctolyzer is the first open-source tool to
convert raw SLO images into reproducible and clinically meaningful retinal
vascular parameters. SLO images are captured simultaneous to optical coherence
tomography (OCT), and we believe our software will be useful for extracting
retinal vascular measurements from large OCT image sets and linking them to
ocular or systemic diseases. It requires no specialist knowledge or proprietary
software, and allows manual correction of segmentations and re-computing of
vascular metrics. SLOctolyzer is freely available at
https://github.com/jaburke166/SLOctolyzer."
InterCLIP-MEP - Interactive CLIP and Memory-Enhanced Predictor for Multi-modal Sarcasm Detection,https://arxiv.org/abs/2406.16464,2024-06-24,2024-06-25,0.0,0.0,"The prevalence of sarcasm in social media, conveyed through text-image
combinations, presents significant challenges for sentiment analysis and
intention mining. Existing multi-modal sarcasm detection methods have been
proven to overestimate performance, as they struggle to effectively capture the
intricate sarcastic cues that arise from the interaction between an image and
text. To address these issues, we propose InterCLIP-MEP, a novel framework for
multi-modal sarcasm detection. Specifically, we introduce an Interactive CLIP
(InterCLIP) as the backbone to extract text-image representations, enhancing
them by embedding cross-modality information directly within each encoder,
thereby improving the representations to capture text-image interactions
better. Furthermore, an efficient training strategy is designed to adapt
InterCLIP for our proposed Memory-Enhanced Predictor (MEP). MEP uses a dynamic,
fixed-length dual-channel memory to store historical knowledge of valuable test
samples during inference. It then leverages this memory as a non-parametric
classifier to derive the final prediction, offering a more robust recognition
of multi-modal sarcasm. Experiments demonstrate that InterCLIP-MEP achieves
state-of-the-art performance on the MMSD2.0 benchmark, with an accuracy
improvement of 1.08% and an F1 score improvement of 1.51% over the previous
best method."
Automated Privacy-Preserving Techniques via Meta-Learning,https://arxiv.org/abs/2406.16456,2024-06-24,2024-06-25,0.0,0.0,"Sharing private data for learning tasks is pivotal for transparent and secure
machine learning applications. Many privacy-preserving techniques have been
proposed for this task aiming to transform the data while ensuring the privacy
of individuals. Some of these techniques have been incorporated into tools,
whereas others are accessed through various online platforms. However, such
tools require manual configuration, which can be complex and time-consuming.
Moreover, they require substantial expertise, potentially restricting their use
to those with advanced technical knowledge. In this paper, we propose AUTOPRIV,
the first automated privacy-preservation method, that eliminates the need for
any manual configuration. AUTOPRIV employs meta-learning to automate the
de-identification process, facilitating the secure release of data for machine
learning tasks. The main goal is to anticipate the predictive performance and
privacy risk of a large set of privacy configurations. We provide a ranked list
of the most promising solutions, which are likely to achieve an optimal
approximation within a new domain. AUTOPRIV is highly effective as it reduces
computational complexity and energy consumption considerably."
Learning in Wilson-Cowan model for metapopulation,https://arxiv.org/abs/2406.16453,2024-06-24,2024-06-25,0.0,0.0,"The Wilson-Cowan model for metapopulation, a Neural Mass Network Model,
treats different subcortical regions of the brain as connected nodes, with
connections representing various types of structural, functional, or effective
neuronal connectivity between these regions. Each region comprises interacting
populations of excitatory and inhibitory cells, consistent with the standard
Wilson-Cowan model. By incorporating stable attractors into such a
metapopulation model's dynamics, we transform it into a learning algorithm
capable of achieving high image and text classification accuracy. We test it on
MNIST and Fashion MNIST, in combination with convolutional neural networks, on
CIFAR-10 and TF-FLOWERS, and, in combination with a transformer architecture
(BERT), on IMDB, always showing high classification accuracy. These numerical
evaluations illustrate that minimal modifications to the Wilson-Cowan model for
metapopulation can reveal unique and previously unobserved dynamics."
Building on Efficient Foundations - Effectively Training LLMs with Structured Feedforward Layers,https://arxiv.org/abs/2406.16450,2024-06-24,2024-06-25,1.0,0.0,"State-of-the-art results in large language models (LLMs) often rely on scale,
which becomes computationally expensive. This has sparked a research agenda to
reduce these models' parameter count and computational costs without
significantly impacting their performance. Our study focuses on
transformer-based LLMs, specifically targeting the computationally intensive
feedforward networks (FFN), which are less studied than attention blocks. We
consider three candidate linear layer approximations in the FFN by combining
efficient low-rank and block-diagonal matrices. In contrast to many previous
works that examined these approximations, our study i) explores these
structures from the training-from-scratch perspective, ii) scales up to 1.3B
parameters, and iii) is conducted within recent Transformer-based LLMs rather
than convolutional architectures. We first demonstrate they can lead to actual
computational gains in various scenarios, including online decoding when using
a pre-merge technique. Additionally, we propose a novel training regime, called
\textit{self-guided training}, aimed at improving the poor training dynamics
that these approximations exhibit when used from initialization. Experiments on
the large RefinedWeb dataset show that our methods are both efficient and
effective for training and inference. Interestingly, these structured FFNs
exhibit steeper scaling curves than the original models. Further applying
self-guided training to the structured matrices with 32\% FFN parameters and
2.5$\times$ speed-up enables only a 0.4 perplexity increase under the same
training FLOPs. Finally, we develop the wide and structured networks surpassing
the current medium-sized and large-sized Transformer in perplexity and
throughput performance. Our code is available at
\url{https://github.com/CLAIRE-Labo/StructuredFFN/tree/main}."
UniCoder - Scaling Code Large Language Model via Universal Code,https://arxiv.org/abs/2406.16441,2024-06-24,2024-06-25,0.0,0.0,"Intermediate reasoning or acting steps have successfully improved large
language models (LLMs) for handling various downstream natural language
processing (NLP) tasks. When applying LLMs for code generation, recent works
mainly focus on directing the models to articulate intermediate
natural-language reasoning steps, as in chain-of-thought (CoT) prompting, and
then output code with the natural language or other structured intermediate
steps. However, such output is not suitable for code translation or generation
tasks since the standard CoT has different logical structures and forms of
expression with the code. In this work, we introduce the universal code
(UniCode) as the intermediate representation. It is a description of algorithm
steps using a mix of conventions of programming languages, such as assignment
operator, conditional operator, and loop. Hence, we collect an instruction
dataset UniCoder-Instruct to train our model UniCoder on multi-task learning
objectives. UniCoder-Instruct comprises natural-language questions, code
solutions, and the corresponding universal code. The alignment between the
intermediate universal code representation and the final code solution
significantly improves the quality of the generated code. The experimental
results demonstrate that UniCoder with the universal code significantly
outperforms the previous prompting methods by a large margin, showcasing the
effectiveness of the structural clues in pseudo-code."
Theory on Mixture-of-Experts in Continual Learning,https://arxiv.org/abs/2406.16437,2024-06-24,2024-06-25,1.0,0.0,"Continual learning (CL) has garnered significant attention because of its
ability to adapt to new tasks that arrive over time. Catastrophic forgetting
(of old tasks) has been identified as a major issue in CL, as the model adapts
to new tasks. The Mixture-of-Experts (MoE) model has recently been shown to
effectively mitigate catastrophic forgetting in CL, by employing a gating
network to sparsify and distribute diverse tasks among multiple experts.
However, there is a lack of theoretical analysis of MoE and its impact on the
learning performance in CL. This paper provides the first theoretical results
to characterize the impact of MoE in CL via the lens of overparameterized
linear regression tasks. We establish the benefit of MoE over a single expert
by proving that the MoE model can diversify its experts to specialize in
different tasks, while its router learns to select the right expert for each
task and balance the loads across all experts. Our study further suggests an
intriguing fact that the MoE in CL needs to terminate the update of the gating
network after sufficient training rounds to attain system convergence, which is
not needed in the existing MoE studies that do not consider the continual task
arrival. Furthermore, we provide explicit expressions for the expected
forgetting and overall generalization error to characterize the benefit of MoE
in the learning performance in CL. Interestingly, adding more experts requires
additional rounds before convergence, which may not enhance the learning
performance. Finally, we conduct experiments on both synthetic and real
datasets to extend these insights from linear models to deep neural networks
(DNNs), which also shed light on the practical algorithm design for MoE in CL."
Dynamic Pseudo Label Optimization in Point-Supervised Nuclei Segmentation,https://arxiv.org/abs/2406.16427,2024-06-24,2024-06-25,0.0,0.0,"Deep learning has achieved impressive results in nuclei segmentation, but the
massive requirement for pixel-wise labels remains a significant challenge. To
alleviate the annotation burden, existing methods generate pseudo masks for
model training using point labels. However, the generated masks are inevitably
different from the ground truth, and these dissimilarities are not handled
reasonably during the network training, resulting in the subpar performance of
the segmentation model. To tackle this issue, we propose a framework named
DoNuSeg, enabling \textbf{D}ynamic pseudo label \textbf{O}ptimization in
point-supervised \textbf{Nu}clei \textbf{Seg}mentation. Specifically, DoNuSeg
takes advantage of class activation maps (CAMs) to adaptively capture regions
with semantics similar to annotated points. To leverage semantic diversity in
the hierarchical feature levels, we design a dynamic selection module to choose
the optimal one among CAMs from different encoder blocks as pseudo masks.
Meanwhile, a CAM-guided contrastive module is proposed to further enhance the
accuracy of pseudo masks. In addition to exploiting the semantic information
provided by CAMs, we consider location priors inherent to point labels,
developing a task-decoupled structure for effectively differentiating nuclei.
Extensive experiments demonstrate that DoNuSeg outperforms state-of-the-art
point-supervised methods. The code is available at
https://github.com/shinning0821/MICCAI24-DoNuSeg."
Fault Detection for agents on power grid topology optimization - A Comprehensive analysis,https://arxiv.org/abs/2406.16426,2024-06-24,2024-06-25,0.0,0.0,"Optimizing the topology of transmission networks using Deep Reinforcement
Learning (DRL) has increasingly come into focus. Various DRL agents have been
proposed, which are mostly benchmarked on the Grid2Op environment from the
Learning to Run a Power Network (L2RPN) challenges. The environments have many
advantages with their realistic grid scenarios and underlying power flow
backends. However, the interpretation of agent survival or failure is not
always clear, as there are a variety of potential causes. In this work, we
focus on the failures of the power grid simulation to identify patterns and
detect them in advance. We collect the failed scenarios of three different
agents on the WCCI 2022 L2RPN environment, totaling about 40k data points. By
clustering, we are able to detect five distinct clusters, identifying common
failure types. Further, we propose a multi-class prediction approach to detect
failures beforehand and evaluate five different prediction models. Here, the
Light Gradient-Boosting Machine (LightGBM) shows the best failure prediction
performance, with an accuracy of 82%. It also accurately classifies whether a
the grid survives or fails in 87% of cases. Finally, we provide a detailed
feature importance analysis that identifies critical features and regions in
the grid."
Exploring Cross-Domain Few-Shot Classification via Frequency-Aware Prompting,https://arxiv.org/abs/2406.16422,2024-06-24,2024-06-25,0.0,0.0,"Cross-Domain Few-Shot Learning has witnessed great stride with the
development of meta-learning. However, most existing methods pay more attention
to learning domain-adaptive inductive bias (meta-knowledge) through
feature-wise manipulation or task diversity improvement while neglecting the
phenomenon that deep networks tend to rely more on high-frequency cues to make
the classification decision, which thus degenerates the robustness of learned
inductive bias since high-frequency information is vulnerable and easy to be
disturbed by noisy information. Hence in this paper, we make one of the first
attempts to propose a Frequency-Aware Prompting method with mutual attention
for Cross-Domain Few-Shot classification, which can let networks simulate the
human visual perception of selecting different frequency cues when facing new
recognition tasks. Specifically, a frequency-aware prompting mechanism is first
proposed, in which high-frequency components of the decomposed source image are
switched either with normal distribution sampling or zeroing to get
frequency-aware augment samples. Then, a mutual attention module is designed to
learn generalizable inductive bias under CD-FSL settings. More importantly, the
proposed method is a plug-and-play module that can be directly applied to most
off-the-shelf CD-FLS methods. Experimental results on CD-FSL benchmarks
demonstrate the effectiveness of our proposed method as well as robustly
improve the performance of existing CD-FLS methods. Resources at
https://github.com/tinkez/FAP_CDFSC."
Multilingual Knowledge Editing with Language-Agnostic Factual Neurons,https://arxiv.org/abs/2406.16416,2024-06-24,2024-06-25,0.0,0.0,"Multilingual knowledge editing (MKE) aims to simultaneously revise factual
knowledge across multilingual languages within large language models (LLMs).
However, most existing MKE methods just adapt existing monolingual editing
methods to multilingual scenarios, overlooking the deep semantic connections of
the same factual knowledge between different languages, thereby limiting edit
performance. To address this issue, we first investigate how LLMs represent
multilingual factual knowledge and discover that the same factual knowledge in
different languages generally activates a shared set of neurons, which we call
language-agnostic factual neurons. These neurons represent the semantic
connections between multilingual knowledge and are mainly located in certain
layers. Inspired by this finding, we propose a new MKE method by locating and
modifying Language-Agnostic Factual Neurons (LAFN) to simultaneously edit
multilingual knowledge. Specifically, we first generate a set of paraphrases
for each multilingual knowledge to be edited to precisely locate the
corresponding language-agnostic factual neurons. Then we optimize the update
values for modifying these located neurons to achieve simultaneous modification
of the same factual knowledge in multiple languages. Experimental results on
Bi-ZsRE and MzsRE benchmarks demonstrate that our method outperforms existing
MKE methods and achieves remarkable edit performance, indicating the importance
of considering the semantic connections among multilingual knowledge."
A Symmetry Property of Christoffel Words,https://arxiv.org/abs/2406.16408,2024-06-24,2024-06-25,0.0,0.0,"Motivated by the theory of trapezoidal words, whose sequences of cardinality
of factors by length are symmetric, we introduce a bivariate variant of this
symmetry. We show that this symmetry characterizes Christoffel words, and
establish other related results."
PenSLR - Persian end-to-end Sign Language Recognition Using Ensembling,https://arxiv.org/abs/2406.16388,2024-06-24,2024-06-25,0.0,0.0,"Sign Language Recognition (SLR) is a fast-growing field that aims to fill the
communication gaps between the hearing-impaired and people without hearing
loss. Existing solutions for Persian Sign Language (PSL) are limited to
word-level interpretations, underscoring the need for more advanced and
comprehensive solutions. Moreover, previous work on other languages mainly
focuses on manipulating the neural network architectures or hardware
configurations instead of benefiting from the aggregated results of multiple
models. In this paper, we introduce PenSLR, a glove-based sign language system
consisting of an Inertial Measurement Unit (IMU) and five flexible sensors
powered by a deep learning framework capable of predicting variable-length
sequences. We achieve this in an end-to-end manner by leveraging the
Connectionist Temporal Classification (CTC) loss function, eliminating the need
for segmentation of input signals. To further enhance its capabilities, we
propose a novel ensembling technique by leveraging a multiple sequence
alignment algorithm known as Star Alignment. Furthermore, we introduce a new
PSL dataset, including 16 PSL signs with more than 3000 time-series samples in
total. We utilize this dataset to evaluate the performance of our system based
on four word-level and sentence-level metrics. Our evaluations show that PenSLR
achieves a remarkable word accuracy of 94.58% and 96.70% in subject-independent
and subject-dependent setups, respectively. These achievements are attributable
to our ensembling algorithm, which not only boosts the word-level performance
by 0.51% and 1.32% in the respective scenarios but also yields significant
enhancements of 1.46% and 4.00%, respectively, in sentence-level accuracy."
Automatically Generating UI Code from Screenshot - A Divide-and-Conquer-Based Approach,https://arxiv.org/abs/2406.16386,2024-06-24,2024-06-25,0.0,0.0,"Websites are critical in today's digital world, with over 1.11 billion
currently active and approximately 252,000 new sites launched daily. Converting
website layout design into functional UI code is a time-consuming yet
indispensable step of website development. Manual methods of converting visual
designs into functional code present significant challenges, especially for
non-experts. To explore automatic design-to-code solutions, we first conduct a
motivating study on GPT-4o and identify three types of issues in generating UI
code: element omission, element distortion, and element misarrangement. We
further reveal that a focus on smaller visual segments can help multimodal
large language models (MLLMs) mitigate these failures in the generation
process. In this paper, we propose DCGen, a divide-and-conquer-based approach
to automate the translation of webpage design to UI code. DCGen starts by
dividing screenshots into manageable segments, generating descriptions for each
segment, and then reassembling them into complete UI code for the entire
screenshot. We conduct extensive testing with a dataset comprised of real-world
websites and various MLLMs and demonstrate that DCGen achieves up to a 14%
improvement in visual similarity over competing methods. To the best of our
knowledge, DCGen is the first segment-aware prompt-based approach for
generating UI code directly from screenshots."
UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models,https://arxiv.org/abs/2406.16382,2024-06-24,2024-06-25,0.0,0.0,"Sequential decision-making refers to algorithms that take into account the
dynamics of the environment, where early decisions affect subsequent decisions.
With large language models (LLMs) demonstrating powerful capabilities between
tasks, we can't help but ask: Can Current LLMs Effectively Make Sequential
Decisions? In order to answer this question, we propose the UNO Arena based on
the card game UNO to evaluate the sequential decision-making capability of LLMs
and explain in detail why we choose UNO. In UNO Arena, We evaluate the
sequential decision-making capability of LLMs dynamically with novel metrics
based Monte Carlo methods. We set up random players, DQN-based reinforcement
learning players, and LLM players (e.g. GPT-4, Gemini-pro) for comparison
testing. Furthermore, in order to improve the sequential decision-making
capability of LLMs, we propose the TUTRI player, which can involves having LLMs
reflect their own actions wtih the summary of game history and the game
strategy. Numerous experiments demonstrate that the TUTRI player achieves a
notable breakthrough in the performance of sequential decision-making compared
to the vanilla LLM player."
"On the Transformations across Reward Model, Parameter Update, and In-Context Prompt",https://arxiv.org/abs/2406.16377,2024-06-24,2024-06-25,0.0,0.0,"Despite the general capabilities of pre-trained large language models (LLMs),
they still need further adaptation to better serve practical applications. In
this paper, we demonstrate the interchangeability of three popular and distinct
adaptation tools: parameter updating, reward modeling, and in-context
prompting. This interchangeability establishes a triangular framework with six
transformation directions, each of which facilitates a variety of applications.
Our work offers a holistic view that unifies numerous existing studies and
suggests potential research directions. We envision our work as a useful
roadmap for future research on LLMs."
KEHRL - Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning,https://arxiv.org/abs/2406.16374,2024-06-24,2024-06-25,0.0,0.0,"Knowledge-enhanced pre-trained language models (KEPLMs) leverage relation
triples from knowledge graphs (KGs) and integrate these external data sources
into language models via self-supervised learning. Previous works treat
knowledge enhancement as two independent operations, i.e., knowledge injection
and knowledge integration. In this paper, we propose to learn
Knowledge-Enhanced language representations with Hierarchical Reinforcement
Learning (KEHRL), which jointly addresses the problems of detecting positions
for knowledge injection and integrating external knowledge into the model in
order to avoid injecting inaccurate or irrelevant knowledge. Specifically, a
high-level reinforcement learning (RL) agent utilizes both internal and prior
knowledge to iteratively detect essential positions in texts for knowledge
injection, which filters out less meaningful entities to avoid diverting the
knowledge learning direction. Once the entity positions are selected, a
relevant triple filtration module is triggered to perform low-level RL to
dynamically refine the triples associated with polysemic entities through
binary-valued actions. Experiments validate KEHRL's effectiveness in probing
factual knowledge and enhancing the model's performance on various natural
language understanding tasks."
UniPSDA - Unsupervised Pseudo Semantic Data Augmentation for Zero-Shot Cross-Lingual Natural Language Understanding,https://arxiv.org/abs/2406.16372,2024-06-24,2024-06-25,0.0,0.0,"Cross-lingual representation learning transfers knowledge from resource-rich
data to resource-scarce ones to improve the semantic understanding abilities of
different languages. However, previous works rely on shallow unsupervised data
generated by token surface matching, regardless of the global context-aware
semantics of the surrounding text tokens. In this paper, we propose an
Unsupervised Pseudo Semantic Data Augmentation (UniPSDA) mechanism for
cross-lingual natural language understanding to enrich the training data
without human interventions. Specifically, to retrieve the tokens with similar
meanings for the semantic data augmentation across different languages, we
propose a sequential clustering process in 3 stages: within a single language,
across multiple languages of a language family, and across languages from
multiple language families. Meanwhile, considering the multi-lingual knowledge
infusion with context-aware semantics while alleviating computation burden, we
directly replace the key constituents of the sentences with the above-learned
multi-lingual family knowledge, viewed as pseudo-semantic. The infusion process
is further optimized via three de-biasing techniques without introducing any
neural parameters. Extensive experiments demonstrate that our model
consistently improves the performance on general zero-shot cross-lingual
natural language understanding tasks, including sequence classification,
information extraction, and question answering."
Towards Lightweight Graph Neural Network Search with Curriculum Graph Sparsification,https://arxiv.org/abs/2406.16357,2024-06-24,2024-06-25,0.0,0.0,"Graph Neural Architecture Search (GNAS) has achieved superior performance on
various graph-structured tasks. However, existing GNAS studies overlook the
applications of GNAS in resource-constraint scenarios. This paper proposes to
design a joint graph data and architecture mechanism, which identifies
important sub-architectures via the valuable graph data. To search for optimal
lightweight Graph Neural Networks (GNNs), we propose a Lightweight Graph Neural
Architecture Search with Graph SparsIfication and Network Pruning (GASSIP)
method. In particular, GASSIP comprises an operation-pruned architecture search
module to enable efficient lightweight GNN search. Meanwhile, we design a novel
curriculum graph data sparsification module with an architecture-aware
edge-removing difficulty measurement to help select optimal sub-architectures.
With the aid of two differentiable masks, we iteratively optimize these two
modules to efficiently search for the optimal lightweight architecture.
Extensive experiments on five benchmarks demonstrate the effectiveness of
GASSIP. Particularly, our method achieves on-par or even higher node
classification performance with half or fewer model parameters of searched GNNs
and a sparser graph."
Evaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation,https://arxiv.org/abs/2406.16356,2024-06-24,2024-06-25,0.0,0.0,"Instruction-tuned Large Language Models (LLMs) have achieved remarkable
performance across various benchmark tasks. While providing instructions to
LLMs for guiding their generations is user-friendly, assessing their
instruction-following capabilities is still unclarified due to a lack of
evaluation metrics. In this paper, we focus on evaluating the
instruction-following ability of LLMs in the context of story-ending
generation, which requires diverse and context-specific instructions. We
propose an automatic evaluation pipeline that utilizes a machine reading
comprehension (MRC) model to determine whether the generated story-ending
reflects instruction. Our findings demonstrate that our proposed metric aligns
with human evaluation. Furthermore, our experiments confirm that recent
open-source LLMs can achieve instruction-following performance close to
GPT-3.5, as assessed through automatic evaluation."
Compact Model Parameter Extraction via Derivative-Free Optimization,https://arxiv.org/abs/2406.16355,2024-06-24,2024-06-25,0.0,0.0,"In this paper, we address the problem of compact model parameter extraction
to simultaneously extract tens of parameters via derivative-free optimization.
Traditionally, parameter extraction is performed manually by dividing the
complete set of parameters into smaller subsets, each targeting different
operational regions of the device, a process that can take several days or even
weeks. Our approach streamlines this process by employing derivative-free
optimization to identify a good parameter set that best fits the compact model
without performing an exhaustive number of simulations. We further enhance the
optimization process to address critical issues in device modeling by carefully
choosing a loss function that evaluates model performance consistently across
varying magnitudes by focusing on relative errors (as opposed to absolute
errors), prioritizing accuracy in key operational regions of the device above a
certain threshold, and reducing sensitivity to outliers. Furthermore, we
utilize the concept of train-test split to assess the model fit and avoid
overfitting. This is done by fitting 80% of the data and testing the model
efficacy with the remaining 20%. We demonstrate the effectiveness of our
methodology by successfully modeling two semiconductor devices: a diamond
Schottky diode and a GaN-on-SiC HEMT, with the latter involving the ASM-HEMT DC
model, which requires simultaneously extracting 35 model parameters to fit the
model to the measured data. These examples demonstrate the effectiveness of our
approach and showcase the practical benefits of derivative-free optimization in
device modeling."
METRIK - Measurement-Efficient Randomized Controlled Trials using Transformers with Input Masking,https://arxiv.org/abs/2406.16351,2024-06-24,2024-06-25,0.0,0.0,"Clinical randomized controlled trials (RCTs) collect hundreds of measurements
spanning various metric types (e.g., laboratory tests, cognitive/motor
assessments, etc.) across 100s-1000s of subjects to evaluate the effect of a
treatment, but do so at the cost of significant trial expense. To reduce the
number of measurements, trial protocols can be revised to remove metrics
extraneous to the study's objective, but doing so requires additional human
labor and limits the set of hypotheses that can be studied with the collected
data. In contrast, a planned missing design (PMD) can reduce the amount of data
collected without removing any metric by imputing the unsampled data. Standard
PMDs randomly sample data to leverage statistical properties of imputation
algorithms, but are ad hoc, hence suboptimal. Methods that learn PMDs produce
more sample-efficient PMDs, but are not suitable for RCTs because they require
ample prior data (150+ subjects) to model the data distribution. Therefore, we
introduce a framework called Measurement EfficienT Randomized Controlled Trials
using Transformers with Input MasKing (METRIK), which, for the first time,
calculates a PMD specific to the RCT from a modest amount of prior data (e.g.,
60 subjects). Specifically, METRIK models the PMD as a learnable input masking
layer that is optimized with a state-of-the-art imputer based on the
Transformer architecture. METRIK implements a novel sampling and selection
algorithm to generate a PMD that satisfies the trial designer's objective,
i.e., whether to maximize sampling efficiency or imputation performance for a
given sampling budget. Evaluated across five real-world clinical RCT datasets,
METRIK increases the sampling efficiency of and imputation performance under
the generated PMD by leveraging correlations over time and across metrics,
thereby removing the need to manually remove metrics from the RCT."
AnnotatedTables - A Large Tabular Dataset with Language Model Annotations,https://arxiv.org/abs/2406.16349,2024-06-24,2024-06-25,0.0,0.0,"Tabular data is ubiquitous in real-world applications and abundant on the
web, yet its annotation has traditionally required human labor, posing a
significant scalability bottleneck for tabular machine learning. Our
methodology can successfully annotate a large amount of tabular data and can be
flexibly steered to generate various types of annotations based on specific
research objectives, as we demonstrate with SQL annotation and input-target
column annotation as examples. As a result, we release AnnotatedTables, a
collection of 32,119 databases with LLM-generated annotations. The dataset
includes 405,616 valid SQL programs, making it the largest SQL dataset with
associated tabular data that supports query execution. To further demonstrate
the value of our methodology and dataset, we perform two follow-up research
studies. 1) We investigate whether LLMs can translate SQL programs to Rel
programs, a database language previously unknown to LLMs, while obtaining the
same execution results. Using our Incremental Prompt Engineering methods based
on execution feedback, we show that LLMs can produce adequate translations with
few-shot learning. 2) We evaluate the performance of TabPFN, a recent neural
tabular classifier trained on Bayesian priors, on 2,720 tables with
input-target columns identified and annotated by LLMs. On average, TabPFN
performs on par with the baseline AutoML method, though the relative
performance can vary significantly from one data table to another, making both
models viable for practical applications depending on the situation. Our
findings underscore the potential of LLMs in automating the annotation of large
volumes of diverse tabular data."
Directed Domain Fine-Tuning - Tailoring Separate Modalities for Specific Training Tasks,https://arxiv.org/abs/2406.16346,2024-06-24,2024-06-25,0.0,0.0,"Large language models (LLMs) and large visual language models (LVLMs) have
been at the forefront of the artificial intelligence field, particularly for
tasks like text generation, video captioning, and question-answering.
Typically, it is more applicable to train these models on broader knowledge
bases or datasets to increase generalizability, learn relationships between
topics, and recognize patterns. Instead, we propose to provide instructional
datasets specific to the task of each modality within a distinct domain and
then fine-tune the parameters of the model using LORA. With our approach, we
can eliminate all noise irrelevant to the given task while also ensuring that
the model generates with enhanced precision. For this work, we use Video-LLaVA
to generate recipes given cooking videos without transcripts. Video-LLaVA's
multimodal architecture allows us to provide cooking images to its image
encoder, cooking videos to its video encoder, and general cooking questions to
its text encoder. Thus, we aim to remove all noise unrelated to cooking while
improving our model's capabilities to generate specific ingredient lists and
detailed instructions. As a result, our approach to fine-tuning Video-LLaVA
leads to gains over the baseline Video-LLaVA by 2% on the YouCook2 dataset.
While this may seem like a marginal increase, our model trains on an image
instruction dataset 2.5% the size of Video-LLaVA's and a video instruction
dataset 23.76% of Video-LLaVA's."
ADVSCORE - A Metric for the Evaluation and Creation of Adversarial Benchmarks,https://arxiv.org/abs/2406.16342,2024-06-24,2024-06-25,0.0,0.0,"Adversarial benchmarks validate model abilities by providing samples that
fool models but not humans. However, despite the proliferation of datasets that
claim to be adversarial, there does not exist an established metric to evaluate
how adversarial these datasets are. To address this lacuna, we introduce
ADVSCORE, a metric which quantifies how adversarial and discriminative an
adversarial dataset is and exposes the features that make data adversarial. We
then use ADVSCORE to underpin a dataset creation pipeline that incentivizes
writing a high-quality adversarial dataset. As a proof of concept, we use
ADVSCORE to collect an adversarial question answering (QA) dataset, ADVQA, from
our pipeline. The high-quality questions in ADVQA surpasses three adversarial
benchmarks across domains at fooling several models but not humans. We validate
our result based on difficulty estimates from 9,347 human responses on four
datasets and predictions from three models. Moreover, ADVSCORE uncovers which
adversarial tactics used by human writers fool models (e.g., GPT-4) but not
humans. Through ADVSCORE and its analyses, we offer guidance on revealing
language model vulnerabilities and producing reliable adversarial examples."
"Prompt-Consistency Image Generation (PCIG) - A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models",https://arxiv.org/abs/2406.16333,2024-06-24,2024-06-25,0.0,0.0,"The rapid advancement of Text-to-Image(T2I) generative models has enabled the
synthesis of high-quality images guided by textual descriptions. Despite this
significant progress, these models are often susceptible in generating contents
that contradict the input text, which poses a challenge to their reliability
and practical deployment. To address this problem, we introduce a novel
diffusion-based framework to significantly enhance the alignment of generated
images with their corresponding descriptions, addressing the inconsistency
between visual output and textual input. Our framework is built upon a
comprehensive analysis of inconsistency phenomena, categorizing them based on
their manifestation in the image. Leveraging a state-of-the-art large language
module, we first extract objects and construct a knowledge graph to predict the
locations of these objects in potentially generated images. We then integrate a
state-of-the-art controllable image generation model with a visual text
generation module to generate an image that is consistent with the original
prompt, guided by the predicted object locations. Through extensive experiments
on an advanced multimodal hallucination benchmark, we demonstrate the efficacy
of our approach in accurately generating the images without the inconsistency
with the original prompt. The code can be accessed via
https://github.com/TruthAI-Lab/PCIG."
DemoRank - Selecting Effective Demonstrations for Large Language Models in Ranking Task,https://arxiv.org/abs/2406.16332,2024-06-24,2024-06-25,0.0,0.0,"Recently, there has been increasing interest in applying large language
models (LLMs) as zero-shot passage rankers. However, few studies have explored
how to select appropriate in-context demonstrations for the passage ranking
task, which is the focus of this paper. Previous studies mainly use LLM's
feedback to train a retriever for demonstration selection. These studies apply
the LLM to score each demonstration independently, which ignores the
dependencies between demonstrations (especially important in ranking task),
leading to inferior performance of top-$k$ retrieved demonstrations. To
mitigate this issue, we introduce a demonstration reranker to rerank the
retrieved demonstrations so that top-$k$ ranked ones are more suitable for ICL.
However, generating training data for such reranker is quite challenging. On
the one hand, different from demonstration retriever, the training samples of
reranker need to incorporate demonstration dependencies. On the other hand,
obtaining the gold ranking from the retrieved demonstrations is an NP-hard
problem, which is hard to implement. To overcome these challenges, we propose a
method to approximate the optimal demonstration list iteratively and utilize
LLM to score demonstration lists of varying lengths. By doing so, the search
space is greatly reduced and demonstration dependencies are considered. Based
on these scored demonstration lists, we further design a list-pairwise training
approach which compares a pair of lists that only differ in the last
demonstration, to teach the reranker how to select the next demonstration given
a previous sequence. In this paper, we propose a demonstration selection
framework DemoRank for ranking task and conduct extensive experiments to prove
its strong ability."
Pruning via Merging - Compressing LLMs via Manifold Alignment Based Layer Merging,https://arxiv.org/abs/2406.16330,2024-06-24,2024-06-25,1.0,0.0,"While large language models (LLMs) excel in many domains, their complexity
and scale challenge deployment in resource-limited environments. Current
compression techniques, such as parameter pruning, often fail to effectively
utilize the knowledge from pruned parameters. To address these challenges, we
propose Manifold-Based Knowledge Alignment and Layer Merging Compression (MKA),
a novel approach that uses manifold learning and the Normalized Pairwise
Information Bottleneck (NPIB) measure to merge similar layers, reducing model
size while preserving essential performance. We evaluate MKA on multiple
benchmark datasets and various LLMs. Our findings show that MKA not only
preserves model performance but also achieves substantial compression ratios,
outperforming traditional pruning methods. Moreover, when coupled with
quantization, MKA delivers even greater compression. Specifically, on the MMLU
dataset using the Llama3-8B model, MKA achieves a compression ratio of 43.75%
with a minimal performance decrease of only 2.82\%. The proposed MKA method
offers a resource-efficient and performance-preserving model compression
technique for LLMs."
Multimodal Graph Benchmark,https://arxiv.org/abs/2406.16321,2024-06-24,2024-06-25,0.0,0.0,"Associating unstructured data with structured information is crucial for
real-world tasks that require relevance search. However, existing graph
learning benchmarks often overlook the rich semantic information associate with
each node. To bridge such gap, we introduce the Multimodal Graph Benchmark
(MM-GRAPH), the first comprehensive multi-modal graph benchmark that
incorporates both textual and visual information. MM-GRAPH surpasses previous
efforts, which have primarily focused on text-attributed graphs with various
connectivity patterns. MM-GRAPH consists of five graph learning datasets of
various scales that are appropriate for different learning tasks. Their
multimodal node features, enabling a more comprehensive evaluation of graph
learning algorithms in real-world scenarios. To facilitate research on
multimodal graph learning, we further provide an extensive study on the
performance of various graph neural networks in the presence of features from
various modalities. MM-GRAPH aims to foster research on multimodal graph
learning and drive the development of more advanced and robust graph learning
algorithms. By providing a diverse set of datasets and benchmarks, MM-GRAPH
enables researchers to evaluate and compare their models in realistic settings,
ultimately leading to improved performance on real-world applications that rely
on multimodal graph data."
What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for Noise-free Text-Image Corruption and Evaluation,https://arxiv.org/abs/2406.16320,2024-06-24,2024-06-25,1.0,0.0,"Vision-Language Models (VLMs) have gained community-spanning prominence due
to their ability to integrate visual and textual inputs to perform complex
tasks. Despite their success, the internal decision-making processes of these
models remain opaque, posing challenges in high-stakes applications. To address
this, we introduce NOTICE, the first Noise-free Text-Image Corruption and
Evaluation pipeline for mechanistic interpretability in VLMs. NOTICE
incorporates a Semantic Minimal Pairs (SMP) framework for image corruption and
Symmetric Token Replacement (STR) for text. This approach enables semantically
meaningful causal mediation analysis for both modalities, providing a robust
method for analyzing multimodal integration within models like BLIP. Our
experiments on the SVO-Probes, MIT-States, and Facial Expression Recognition
datasets reveal crucial insights into VLM decision-making, identifying the
significant role of middle-layer cross-attention heads. Further, we uncover a
set of ``universal cross-attention heads'' that consistently contribute across
tasks and modalities, each performing distinct functions such as implicit image
segmentation, object inhibition, and outlier inhibition. This work paves the
way for more transparent and interpretable multimodal systems."
Modelled Multivariate Overlap - A method for measuring vowel merger,https://arxiv.org/abs/2406.16319,2024-06-24,2024-06-25,0.0,0.0,"This paper introduces a novel method for quantifying vowel overlap. There is
a tension in previous work between using multivariate measures, such as those
derived from empirical distributions, and the ability to control for unbalanced
data and extraneous factors, as is possible when using fitted model parameters.
The method presented here resolves this tension by jointly modelling all
acoustic dimensions of interest and by simulating distributions from the model
to compute a measure of vowel overlap. An additional benefit of this method is
that computation of uncertainty becomes straightforward. We evaluate this
method on corpus speech data targeting the PIN-PEN merger in four dialects of
English and find that using modelled distributions to calculate Bhattacharyya
affinity substantially improves results compared to empirical distributions,
while the difference between multivariate and univariate modelling is subtle."
Does Cross-Cultural Alignment Change the Commonsense Morality of Language Models?,https://arxiv.org/abs/2406.16316,2024-06-24,2024-06-25,1.0,0.0,"Alignment of the language model with human preferences is a common approach
to making a language model useful to end users. However, most alignment work is
done in English, and human preference datasets are dominated by English,
reflecting only the preferences of English-speaking annotators. Nevertheless,
it is common practice to use the English preference data, either directly or by
translating it into the target language, when aligning a multilingual language
model. The question is whether such an alignment strategy marginalizes the
preference of non-English speaking users. To this end, we investigate the
effect of aligning Japanese language models with (mostly) English resources. In
particular, we focus on evaluating whether the commonsense morality of the
resulting fine-tuned models is aligned with Japanese culture using the
JCommonsenseMorality (JCM) and ETHICS datasets. The experimental results show
that the fine-tuned model outperforms the SFT model. However, it does not
demonstrate the same level of improvement as a model fine-tuned using the JCM,
suggesting that while some aspects of commonsense morality are transferable,
others may not be."
Song Data Cleansing for End-to-End Neural Singer Diarization Using Neural Analysis and Synthesis Framework,https://arxiv.org/abs/2406.16315,2024-06-24,2024-06-25,0.0,0.0,"We propose a data cleansing method that utilizes a neural analysis and
synthesis (NANSY++) framework to train an end-to-end neural diarization model
(EEND) for singer diarization. Our proposed model converts song data with
choral singing which is commonly contained in popular music and unsuitable for
generating a simulated dataset to the solo singing data. This cleansing is
based on NANSY++, which is a framework trained to reconstruct an input
non-overlapped audio signal. We exploit the pre-trained NANSY++ to convert
choral singing into clean, non-overlapped audio. This cleansing process
mitigates the mislabeling of choral singing to solo singing and helps the
effective training of EEND models even when the majority of available song data
contains choral singing sections. We experimentally evaluated the EEND model
trained with a dataset using our proposed method using annotated popular duet
songs. As a result, our proposed method improved 14.8 points in diarization
error rate."
Anomaly Detection of Tabular Data Using LLMs,https://arxiv.org/abs/2406.16308,2024-06-24,2024-06-25,0.0,0.0,"Large language models (LLMs) have shown their potential in long-context
understanding and mathematical reasoning. In this paper, we study the problem
of using LLMs to detect tabular anomalies and show that pre-trained LLMs are
zero-shot batch-level anomaly detectors. That is, without extra
distribution-specific model fitting, they can discover hidden outliers in a
batch of data, demonstrating their ability to identify low-density data
regions. For LLMs that are not well aligned with anomaly detection and
frequently output factual errors, we apply simple yet effective data-generating
processes to simulate synthetic batch-level anomaly detection datasets and
propose an end-to-end fine-tuning strategy to bring out the potential of LLMs
in detecting real anomalies. Experiments on a large anomaly detection benchmark
(ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art
transductive learning-based anomaly detection methods and ii) the efficacy of
our synthetic dataset and fine-tuning strategy in aligning LLMs to this task."
Cascade Reward Sampling for Efficient Decoding-Time Alignment,https://arxiv.org/abs/2406.16306,2024-06-24,2024-06-25,0.0,0.0,"Aligning large language models (LLMs) with human preferences is critical for
their deployment. Recently, decoding-time alignment has emerged as an effective
plug-and-play technique that requires no fine-tuning of model parameters.
However, generating text that achieves both high reward and high likelihood
remains a significant challenge. Existing methods often fail to generate
high-reward text or incur substantial computational costs. In this paper, we
propose Cascade Reward Sampling (CARDS) to address both issues, guaranteeing
the generation of high-reward and high-likelihood text with significantly low
costs. Based on our analysis of reward models (RMs) on incomplete text and our
observation that high-reward prefixes induce high-reward complete text, we use
rejection sampling to iteratively generate small semantic segments to form such
prefixes. The segment length is dynamically determined by the predictive
uncertainty of LLMs. This strategy guarantees desirable prefixes for subsequent
generations and significantly reduces wasteful token re-generations and the
number of reward model scoring. Our experiments demonstrate substantial gains
in both generation efficiency and alignment ratings compared to the baselines,
achieving five times faster text generation and 99\% win-ties in GPT-4/Claude-3
helpfulness evaluation."
UBiSS - A Unified Framework for Bimodal Semantic Summarization of Videos,https://arxiv.org/abs/2406.16301,2024-06-24,2024-06-25,0.0,0.0,"With the surge in the amount of video data, video summarization techniques,
including visual-modal(VM) and textual-modal(TM) summarization, are attracting
more and more attention. However, unimodal summarization inevitably loses the
rich semantics of the video. In this paper, we focus on a more comprehensive
video summarization task named Bimodal Semantic Summarization of Videos
(BiSSV). Specifically, we first construct a large-scale dataset, BIDS, in
(video, VM-Summary, TM-Summary) triplet format. Unlike traditional processing
methods, our construction procedure contains a VM-Summary extraction algorithm
aiming to preserve the most salient content within long videos. Based on BIDS,
we propose a Unified framework UBiSS for the BiSSV task, which models the
saliency information in the video and generates a TM-summary and VM-summary
simultaneously. We further optimize our model with a list-wise ranking-based
objective to improve its capacity to capture highlights. Lastly, we propose a
metric, $NDCG_{MS}$, to provide a joint evaluation of the bimodal summary.
Experiments show that our unified framework achieves better performance than
multi-stage summarization pipelines. Code and data are available at
https://github.com/MeiYutingg/UBiSS."
Landscaping Linear Mode Connectivity,https://arxiv.org/abs/2406.16300,2024-06-24,2024-06-25,0.0,0.0,"The presence of linear paths in parameter space between two different network
solutions in certain cases, i.e., linear mode connectivity (LMC), has garnered
interest from both theoretical and practical fronts. There has been significant
research that either practically designs algorithms catered for connecting
networks by adjusting for the permutation symmetries as well as some others
that more theoretically construct paths through which networks can be
connected. Yet, the core reasons for the occurrence of LMC, when in fact it
does occur, in the highly non-convex loss landscapes of neural networks are far
from clear. In this work, we take a step towards understanding it by providing
a model of how the loss landscape needs to behave topographically for LMC (or
the lack thereof) to manifest. Concretely, we present a `mountainside and
ridge' perspective that helps to neatly tie together different geometric
features that can be spotted in the loss landscape along the training runs. We
also complement this perspective by providing a theoretical analysis of the
barrier height, for which we provide empirical support, and which additionally
extends as a faithful predictor of layer-wise LMC. We close with a toy example
that provides further intuition on how barriers arise in the first place, all
in all, showcasing the larger aim of the work -- to provide a working model of
the landscape and its topography for the occurrence of LMC."
Compensate Quantization Errors - Make Weights Hierarchical to Compensate Each Other,https://arxiv.org/abs/2406.16299,2024-06-24,2024-06-25,0.0,0.0,"Emergent Large Language Models (LLMs) use their extraordinary performance and
powerful deduction capacity to discern from traditional language models.
However, the expenses of computational resources and storage for these LLMs are
stunning, quantization then arises as a trending conversation. To address
accuracy decay caused by quantization, two streams of works in post-training
quantization methods stand out. One uses other weights to compensate existing
quantization error, while the other transfers the quantization difficulty to
other parts in the model. Combining both merits, we introduce Learnable
Singular value Increment (LSI) as an advanced solution. LSI uses Singular Value
Decomposition to extract singular values of the weights and make them learnable
to help weights compensate each other conditioned on activation. Incorporating
LSI with existing techniques, we achieve state-of-the-art performance in
diverse quantization settings, no matter in weight-only, weight-activation or
extremely low bit scenarios. By unleashing the potential of LSI, efficient
finetuning on quantized model is no longer a prohibitive problem."
"LangSuitE - Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments",https://arxiv.org/abs/2406.16294,2024-06-24,2024-06-25,0.0,0.0,"Recent advances in Large Language Models (LLMs) have shown inspiring
achievements in constructing autonomous agents that rely on language
descriptions as inputs. However, it remains unclear how well LLMs can function
as few-shot or zero-shot embodied agents in dynamic interactive environments.
To address this gap, we introduce LangSuitE, a versatile and simulation-free
testbed featuring 6 representative embodied tasks in textual embodied worlds.
Compared with previous LLM-based testbeds, LangSuitE (i) offers adaptability to
diverse environments without multiple simulation engines, (ii) evaluates
agents' capacity to develop ``internalized world knowledge'' with embodied
observations, and (iii) allows easy customization of communication and action
strategies. To address the embodiment challenge, we devise a novel
chain-of-thought (CoT) schema, EmMem, which summarizes embodied states w.r.t.
history information. Comprehensive benchmark results illustrate challenges and
insights of embodied planning. LangSuitE represents a significant step toward
building embodied generalists in the context of language models."
Combining Supervised Learning and Reinforcement Learning for Multi-Label Classification Tasks with Partial Labels,https://arxiv.org/abs/2406.16293,2024-06-24,2024-06-25,0.0,0.0,"Traditional supervised learning heavily relies on human-annotated datasets,
especially in data-hungry neural approaches. However, various tasks, especially
multi-label tasks like document-level relation extraction, pose challenges in
fully manual annotation due to the specific domain knowledge and large class
sets. Therefore, we address the multi-label positive-unlabelled learning
(MLPUL) problem, where only a subset of positive classes is annotated. We
propose Mixture Learner for Partially Annotated Classification (MLPAC), an
RL-based framework combining the exploration ability of reinforcement learning
and the exploitation ability of supervised learning. Experimental results
across various tasks, including document-level relation extraction, multi-label
image classification, and binary PU learning, demonstrate the generalization
and effectiveness of our framework."
PlagBench - Exploring the Duality of Large Language Models in Plagiarism Generation and Detection,https://arxiv.org/abs/2406.16288,2024-06-24,2024-06-25,0.0,0.0,"Recent literature has highlighted potential risks to academic integrity
associated with large language models (LLMs), as they can memorize parts of
training instances and reproduce them in the generated texts without proper
attribution. In addition, given their capabilities in generating high-quality
texts, plagiarists can exploit LLMs to generate realistic paraphrases or
summaries indistinguishable from original work. In response to possible
malicious use of LLMs in plagiarism, we introduce PlagBench, a comprehensive
dataset consisting of 46.5K synthetic plagiarism cases generated using three
instruction-tuned LLMs across three writing domains. The quality of PlagBench
is ensured through fine-grained automatic evaluation for each type of
plagiarism, complemented by human annotation. We then leverage our proposed
dataset to evaluate the plagiarism detection performance of five modern LLMs
and three specialized plagiarism checkers. Our findings reveal that GPT-3.5
tends to generates paraphrases and summaries of higher quality compared to
Llama2 and GPT-4. Despite LLMs' weak performance in summary plagiarism
identification, they can surpass current commercial plagiarism detectors.
Overall, our results highlight the potential of LLMs to serve as robust
plagiarism detection tools."
Reducing Fine-Tuning Memory Overhead by Approximate and Memory-Sharing Backpropagation,https://arxiv.org/abs/2406.16282,2024-06-24,2024-06-25,0.0,0.0,"Fine-tuning pretrained large models to downstream tasks is an important
problem, which however suffers from huge memory overhead due to large-scale
parameters. This work strives to reduce memory overhead in fine-tuning from
perspectives of activation function and layer normalization. To this end, we
propose the Approximate Backpropagation (Approx-BP) theory, which provides the
theoretical feasibility of decoupling the forward and backward passes. We apply
our Approx-BP theory to backpropagation training and derive memory-efficient
alternatives of GELU and SiLU activation functions, which use derivative
functions of ReLUs in the backward pass while keeping their forward pass
unchanged. In addition, we introduce a Memory-Sharing Backpropagation strategy,
which enables the activation memory to be shared by two adjacent layers,
thereby removing activation memory usage redundancy. Our method neither induces
extra computation nor reduces training efficiency. We conduct extensive
experiments with pretrained vision and language models, and the results
demonstrate that our proposal can reduce up to $\sim$$30\%$ of the peak memory
usage. Our code is released at https://github.com/yyyyychen/LowMemoryBP."
Investigating the Influence of Prompt-Specific Shortcuts in AI Generated Text Detection,https://arxiv.org/abs/2406.16275,2024-06-24,2024-06-25,0.0,0.0,"AI Generated Text (AIGT) detectors are developed with texts from humans and
LLMs of common tasks. Despite the diversity of plausible prompt choices, these
datasets are generally constructed with a limited number of prompts. The lack
of prompt variation can introduce prompt-specific shortcut features that exist
in data collected with the chosen prompt, but do not generalize to others. In
this paper, we analyze the impact of such shortcuts in AIGT detection. We
propose Feedback-based Adversarial Instruction List Optimization (FAILOpt), an
attack that searches for instructions deceptive to AIGT detectors exploiting
prompt-specific shortcuts. FAILOpt effectively drops the detection performance
of the target detector, comparable to other attacks based on adversarial
in-context examples. We also utilize our method to enhance the robustness of
the detector by mitigating the shortcuts. Based on the findings, we further
train the classifier with the dataset augmented by FAILOpt prompt. The
augmented classifier exhibits improvements across generation models, tasks, and
attacks. Our code will be available at https://github.com/zxcvvxcz/FAILOpt."
Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via Attention-Guided Feature Enhancement,https://arxiv.org/abs/2406.16272,2024-06-24,2024-06-25,0.0,0.0,"Text-to-Image Diffusion Models (T2I DMs) have garnered significant attention
for their ability to generate high-quality images from textual descriptions.
However, these models often produce images that do not fully align with the
input prompts, resulting in semantic inconsistencies. The most prominent issue
among these semantic inconsistencies is catastrophic-neglect, where the images
generated by T2I DMs miss key objects mentioned in the prompt. We first conduct
an empirical study on this issue, exploring the prevalence of
catastrophic-neglect, potential mitigation strategies with feature enhancement,
and the insights gained. Guided by the empirical findings, we propose an
automated repair approach named Patcher to address catastrophic-neglect in T2I
DMs. Specifically, Patcher first determines whether there are any neglected
objects in the prompt, and then applies attention-guided feature enhancement to
these neglected objects, resulting in a repaired prompt. Experimental results
on three versions of Stable Diffusion demonstrate that Patcher effectively
repairs the issue of catastrophic-neglect, achieving 10.1%-16.3% higher Correct
Rate in image generation compared to baselines."
Learning-Based Heavy Hitters and Flow Frequency Estimation in Streams,https://arxiv.org/abs/2406.16270,2024-06-24,2024-06-25,0.0,0.0,"Identifying heavy hitters and estimating the frequencies of flows are
fundamental tasks in various network domains. Existing approaches to this
challenge can broadly be categorized into two groups, hashing-based and
competing-counter-based. The Count-Min sketch is a standard example of a
hashing-based algorithm, and the Space Saving algorithm is an example of a
competing-counter algorithm. Recent works have explored the use of machine
learning to enhance algorithms for frequency estimation problems, under the
algorithms with prediction framework. However, these works have focused solely
on the hashing-based approach, which may not be best for identifying heavy
hitters. In this paper, we present the first learned competing-counter-based
algorithm, called LSS, for identifying heavy hitters, top k, and flow frequency
estimation that utilizes the well-known Space Saving algorithm. We provide
theoretical insights into how and to what extent our approach can improve upon
Space Saving, backed by experimental results on both synthetic and real-world
datasets. Our evaluation demonstrates that LSS can enhance the accuracy and
efficiency of Space Saving in identifying heavy hitters, top k, and estimating
flow frequencies."
"One Thousand and One Pairs - A ""novel"" challenge for long-context language models",https://arxiv.org/abs/2406.16264,2024-06-24,2024-06-25,1.0,0.0,"Synthetic long-context LLM benchmarks (e.g., ""needle-in-the-haystack"") test
only surface-level retrieval capabilities, but how well can long-context LLMs
retrieve, synthesize, and reason over information across book-length inputs? We
address this question by creating NoCha, a dataset of 1,001 minimally different
pairs of true and false claims about 67 recently-published English fictional
books, written by human readers of those books. In contrast to existing
long-context benchmarks, our annotators confirm that the largest share of pairs
in NoCha require global reasoning over the entire book to verify. Our
experiments show that while human readers easily perform this task, it is
enormously challenging for all ten long-context LLMs that we evaluate: no
open-weight model performs above random chance (despite their strong
performance on synthetic benchmarks), while GPT-4o achieves the highest
accuracy at 55.8%. Further analysis reveals that (1) on average, models perform
much better on pairs that require only sentence-level retrieval vs. global
reasoning; (2) model-generated explanations for their decisions are often
inaccurate even for correctly-labeled claims; and (3) models perform
substantially worse on speculative fiction books that contain extensive
world-building. The methodology proposed in NoCha allows for the evolution of
the benchmark dataset and the easy analysis of future models."
Video-Infinity - Distributed Long Video Generation,https://arxiv.org/abs/2406.16260,2024-06-24,2024-06-25,1.0,0.0,"Diffusion models have recently achieved remarkable results for video
generation. Despite the encouraging performances, the generated videos are
typically constrained to a small number of frames, resulting in clips lasting
merely a few seconds. The primary challenges in producing longer videos include
the substantial memory requirements and the extended processing time required
on a single GPU. A straightforward solution would be to split the workload
across multiple GPUs, which, however, leads to two issues: (1) ensuring all
GPUs communicate effectively to share timing and context information, and (2)
modifying existing video diffusion models, which are usually trained on short
sequences, to create longer videos without additional training. To tackle
these, in this paper we introduce Video-Infinity, a distributed inference
pipeline that enables parallel processing across multiple GPUs for long-form
video generation. Specifically, we propose two coherent mechanisms: Clip
parallelism and Dual-scope attention. Clip parallelism optimizes the gathering
and sharing of context information across GPUs which minimizes communication
overhead, while Dual-scope attention modulates the temporal self-attention to
balance local and global contexts efficiently across the devices. Together, the
two mechanisms join forces to distribute the workload and enable the fast
generation of long videos. Under an 8 x Nvidia 6000 Ada GPU (48G) setup, our
method generates videos up to 2,300 frames in approximately 5 minutes, enabling
long video generation at a speed 100 times faster than the prior methods."
User Story Tutor (UST) to Support Agile Software Developers,https://arxiv.org/abs/2406.16259,2024-06-24,2024-06-25,0.0,0.0,"User Stories record what must be built in projects that use agile practices.
User Stories serve both to estimate effort, generally measured in Story Points,
and to plan what should be done in a Sprint. Therefore, it is essential to
train software engineers on how to create simple, easily readable, and
comprehensive User Stories. For that reason, we designed, implemented, applied,
and evaluated a web application called User Story Tutor (UST). UST checks the
description of a given User Story for readability, and if needed, recommends
appropriate practices for improvement. UST also estimates a User Story effort
in Story Points using Machine Learning techniques. As such UST may support the
continuing education of agile development teams when writing and reviewing User
Stories. UST's ease of use was evaluated by 40 agile practitioners according to
the Technology Acceptance Model (TAM) and AttrakDiff. The TAM evaluation
averages were good in almost all considered variables. Application of the
AttrakDiff evaluation framework produced similar good results. Apparently, UST
can be used with good reliability. Applying UST to assist in the construction
of User Stories is a viable technique that, at the very least, can be used by
agile developments to complement and enhance current User Story creation."
MEReQ - Max-Ent Residual-Q Inverse RL for Sample-Efficient Alignment from Intervention,https://arxiv.org/abs/2406.16258,2024-06-24,2024-06-25,0.0,0.0,"Aligning robot behavior with human preferences is crucial for deploying
embodied AI agents in human-centered environments. A promising solution is
interactive imitation learning from human intervention, where a human expert
observes the policy's execution and provides interventions as feedback.
However, existing methods often fail to utilize the prior policy efficiently to
facilitate learning, thus hindering sample efficiency. In this work, we
introduce MEReQ (Maximum-Entropy Residual-Q Inverse Reinforcement Learning),
designed for sample-efficient alignment from human intervention. Instead of
inferring the complete human behavior characteristics, MEReQ infers a residual
reward function that captures the discrepancy between the human expert's and
the prior policy's underlying reward functions. It then employs Residual
Q-Learning (RQL) to align the policy with human preferences using this residual
reward function. Extensive evaluations on simulated and real-world tasks
demonstrate that MEReQ achieves sample-efficient policy alignment from human
intervention."
Towards Scalable Exact Machine Unlearning Using Parameter-Efficient Fine-Tuning,https://arxiv.org/abs/2406.16257,2024-06-24,2024-06-25,0.0,0.0,"Machine unlearning is the process of efficiently removing the influence of a
training data instance from a trained machine learning model without retraining
it from scratch. A popular subclass of unlearning approaches is exact machine
unlearning, which focuses on techniques that explicitly guarantee the removal
of the influence of a data instance from a model. Exact unlearning approaches
use a machine learning model in which individual components are trained on
disjoint subsets of the data. During deletion, exact unlearning approaches only
retrain the affected components rather than the entire model. While existing
approaches reduce retraining costs, it can still be expensive for an
organization to retrain a model component as it requires halting a system in
production, which leads to service failure and adversely impacts customers. To
address these challenges, we introduce an exact unlearning framework --
Sequence-aware Sharded Sliced Training (S3T), designed to enhance the deletion
capabilities of an exact unlearning system while minimizing the impact on
model's performance. At the core of S3T, we utilize a lightweight
parameter-efficient fine-tuning approach that enables parameter isolation by
sequentially training layers with disjoint data slices. This enables efficient
unlearning by simply deactivating the layers affected by data deletion.
Furthermore, to reduce the retraining cost and improve model performance, we
train the model on multiple data sequences, which allows S3T to handle an
increased number of deletion requests. Both theoretically and empirically, we
demonstrate that S3T attains superior deletion capabilities and enhanced
performance compared to baselines across a wide range of settings."
Uncertainty-Aware Reward-Free Exploration with General Function Approximation,https://arxiv.org/abs/2406.16255,2024-06-24,2024-06-25,0.0,0.0,"Mastering multiple tasks through exploration and learning in an environment
poses a significant challenge in reinforcement learning (RL). Unsupervised RL
has been introduced to address this challenge by training policies with
intrinsic rewards rather than extrinsic rewards. However, current intrinsic
reward designs and unsupervised RL algorithms often overlook the heterogeneous
nature of collected samples, thereby diminishing their sample efficiency. To
overcome this limitation, in this paper, we propose a reward-free RL algorithm
called \alg. The key idea behind our algorithm is an uncertainty-aware
intrinsic reward for exploring the environment and an uncertainty-weighted
learning process to handle heterogeneous uncertainty in different samples.
Theoretically, we show that in order to find an $\epsilon$-optimal policy,
GFA-RFE needs to collect $\tilde{O} (H^2 \log N_{\mathcal F} (\epsilon)
\mathrm{dim} (\mathcal F) / \epsilon^2 )$ number of episodes, where $\mathcal
F$ is the value function class with covering number $N_{\mathcal F} (\epsilon)$
and generalized eluder dimension $\mathrm{dim} (\mathcal F)$. Such a result
outperforms all existing reward-free RL algorithms. We further implement and
evaluate GFA-RFE across various domains and tasks in the DeepMind Control
Suite. Experiment results show that GFA-RFE outperforms or is comparable to the
performance of state-of-the-art unsupervised RL algorithms."
Graph-Augmented LLMs for Personalized Health Insights - A Case Study in Sleep Analysis,https://arxiv.org/abs/2406.16252,2024-06-24,2024-06-25,0.0,0.0,"Health monitoring systems have revolutionized modern healthcare by enabling
the continuous capture of physiological and behavioral data, essential for
preventive measures and early health intervention. While integrating this data
with Large Language Models (LLMs) has shown promise in delivering interactive
health advice, traditional methods like Retrieval-Augmented Generation (RAG)
and fine-tuning often fail to fully utilize the complex, multi-dimensional, and
temporally relevant data from wearable devices. These conventional approaches
typically provide limited actionable and personalized health insights due to
their inadequate capacity to dynamically integrate and interpret diverse health
data streams. In response, this paper introduces a graph-augmented LLM
framework designed to significantly enhance the personalization and clarity of
health insights. Utilizing a hierarchical graph structure, the framework
captures inter and intra-patient relationships, enriching LLM prompts with
dynamic feature importance scores derived from a Random Forest Model. The
effectiveness of this approach is demonstrated through a sleep analysis case
study involving 20 college students during the COVID-19 lockdown, highlighting
the potential of our model to generate actionable and personalized health
insights efficiently. We leverage another LLM to evaluate the insights for
relevance, comprehensiveness, actionability, and personalization, addressing
the critical need for models that process and interpret complex health data
effectively. Our findings show that augmenting prompts with our framework
yields significant improvements in all 4 criteria. Through our framework, we
can elicit well-crafted, more thoughtful responses tailored to a specific
patient."
An Optimal Tightness Bound for the Simulation Lemma,https://arxiv.org/abs/2406.16249,2024-06-24,2024-06-25,0.0,0.0,"We present a bound for value-prediction error with respect to model
misspecification that is tight, including constant factors. This is a direct
improvement of the ""simulation lemma,"" a foundational result in reinforcement
learning. We demonstrate that existing bounds are quite loose, becoming vacuous
for large discount factors, due to the suboptimal treatment of compounding
probability errors. By carefully considering this quantity on its own, instead
of as a subcomponent of value error, we derive a bound that is sub-linear with
respect to transition function misspecification. We then demonstrate broader
applicability of this technique, improving a similar bound in the related
subfield of hierarchical abstraction."
Position - Benchmarking is Limited in Reinforcement Learning Research,https://arxiv.org/abs/2406.16241,2024-06-23,2024-06-25,0.0,0.0,"Novel reinforcement learning algorithms, or improvements on existing ones,
are commonly justified by evaluating their performance on benchmark
environments and are compared to an ever-changing set of standard algorithms.
However, despite numerous calls for improvements, experimental practices
continue to produce misleading or unsupported claims. One reason for the
ongoing substandard practices is that conducting rigorous benchmarking
experiments requires substantial computational time. This work investigates the
sources of increased computation costs in rigorous experiment designs. We show
that conducting rigorous performance benchmarks will likely have computational
costs that are often prohibitive. As a result, we argue for using an additional
experimentation paradigm to overcome the limitations of benchmarking."
Preference Tuning For Toxicity Mitigation Generalizes Across Languages,https://arxiv.org/abs/2406.16235,2024-06-23,2024-06-25,0.0,0.0,"Detoxifying multilingual Large Language Models (LLMs) has become crucial due
to their increasing global use. In this work, we explore zero-shot
cross-lingual generalization of preference tuning in detoxifying LLMs. Unlike
previous studies that show limited cross-lingual generalization for other
safety tasks, we demonstrate that Direct Preference Optimization (DPO) training
with only English data can significantly reduce toxicity in multilingual
open-ended generations. For example, the probability of mGPT-1.3B generating
toxic continuations drops from 46.8% to 3.9% across 17 different languages
after training. Our results also extend to other multilingual LLMs, such as
BLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal
intervention and activation analysis, we identified the dual multilinguality
property of MLP layers in LLMs, which explains the cross-lingual generalization
of DPO. Finally, we show that bilingual sentence retrieval can predict the
cross-lingual transferability of DPO preference tuning."
Jacobian Descent for Multi-Objective Optimization,https://arxiv.org/abs/2406.16232,2024-06-23,2024-06-25,0.0,0.0,"Many optimization problems are inherently multi-objective. To address them,
we formalize Jacobian descent (JD), a direct generalization of gradient descent
for vector-valued functions. Each step of this algorithm relies on a Jacobian
matrix consisting of one gradient per objective. The aggregator, responsible
for reducing this matrix into an update vector, characterizes JD. While the
multi-task learning literature already contains a variety of aggregators, they
often lack some natural properties. In particular, the update should not
conflict with any objective and should scale proportionally to the norm of each
gradient. We propose a new aggregator specifically designed to satisfy this.
Emphasizing conflict between objectives, we then highlight direct applications
for our methods. Most notably, we introduce instance-wise risk minimization
(IWRM), a learning paradigm in which the loss of each training example is
considered a separate objective. On simple image classification tasks, IWRM
exhibits promising results compared to the direct minimization of the average
loss. The performance of our aggregator in those experiments also corroborates
our theoretical findings. Lastly, as speed is the main limitation of JD, we
provide a path towards a more efficient implementation."
Gradual Divergence for Seamless Adaptation - A Novel Domain Incremental Learning Method,https://arxiv.org/abs/2406.16231,2024-06-23,2024-06-25,0.0,0.0,"Domain incremental learning (DIL) poses a significant challenge in real-world
scenarios, as models need to be sequentially trained on diverse domains over
time, all the while avoiding catastrophic forgetting. Mitigating representation
drift, which refers to the phenomenon of learned representations undergoing
changes as the model adapts to new tasks, can help alleviate catastrophic
forgetting. In this study, we propose a novel DIL method named DARE, featuring
a three-stage training process: Divergence, Adaptation, and REfinement. This
process gradually adapts the representations associated with new tasks into the
feature space spanned by samples from previous tasks, simultaneously
integrating task-specific decision boundaries. Additionally, we introduce a
novel strategy for buffer sampling and demonstrate the effectiveness of our
proposed method, combined with this sampling strategy, in reducing
representation drift within the feature encoder. This contribution effectively
alleviates catastrophic forgetting across multiple DIL benchmarks. Furthermore,
our approach prevents sudden representation drift at task boundaries, resulting
in a well-calibrated DIL model that maintains the performance on previous
tasks."
Multi-Objective Linguistic Control of Large Language Models,https://arxiv.org/abs/2406.16229,2024-06-23,2024-06-25,0.0,0.0,"Large language models (LLMs), despite their breakthroughs on many challenging
benchmark tasks, lean to generate verbose responses and lack the
controllability of output complexity, which is usually preferred by human users
in practice. In this paper, we study how to precisely control multiple
linguistic complexities of LLM output by finetuning using off-the-shelf data.
To this end, we propose multi-control tuning (MCTune), which includes multiple
linguistic complexity values of ground-truth responses as controls in the input
for instruction tuning. We finetune LLaMA2-7B on Alpaca-GPT4 and WizardLM
datasets. Evaluations on widely used benchmarks demonstrate that our method
does not only improve LLMs' multi-complexity controllability substantially but
also retains or even enhances the quality of the responses as a side benefit."
From Text to Test - AI-Generated Control Software for Materials Science Instruments,https://arxiv.org/abs/2406.16224,2024-06-23,2024-06-25,0.0,0.0,"Large language models (LLMs) are transforming the landscape of chemistry and
materials science. Recent examples of LLM-accelerated experimental research
include virtual assistants for parsing synthesis recipes from the literature,
or using the extracted knowledge to guide synthesis and characterization.
Despite these advancements, their application is constrained to labs with
automated instruments and control software, leaving much of materials science
reliant on manual processes. Here, we demonstrate the rapid deployment of a
Python-based control module for a Keithley 2400 electrical source measure unit
using ChatGPT-4. Through iterative refinement, we achieved effective instrument
management with minimal human intervention. Additionally, a user-friendly
graphical user interface (GUI) was created, effectively linking all instrument
controls to interactive screen elements. Finally, we integrated this AI-crafted
instrument control software with a high-performance stochastic optimization
algorithm to facilitate rapid and automated extraction of electronic device
parameters related to semiconductor charge transport mechanisms from
current-voltage (IV) measurement data. This integration resulted in a
comprehensive open-source toolkit for semiconductor device characterization and
analysis using IV curve measurements. We demonstrate the application of these
tools by acquiring, analyzing, and parameterizing IV data from a
Pt/Cr$_2$O$_3$:Mg/$\beta$-Ga$_2$O$_3$ heterojunction diode, a novel stack for
high-power and high-temperature electronic devices. This approach underscores
the powerful synergy between LLMs and the development of instruments for
scientific inquiry, showcasing a path for further acceleration in materials
science."
Continuous Output Personality Detection Models via Mixed Strategy Training,https://arxiv.org/abs/2406.16223,2024-06-23,2024-06-25,0.0,0.0,"The traditional personality models only yield binary results. This paper
presents a novel approach for training personality detection models that
produce continuous output values, using mixed strategies. By leveraging the
PANDORA dataset, which includes extensive personality labeling of Reddit
comments, we developed models that predict the Big Five personality traits with
high accuracy. Our approach involves fine-tuning a RoBERTa-base model with
various strategies such as Multi-Layer Perceptron (MLP) integration, and
hyperparameter tuning. The results demonstrate that our models significantly
outperform traditional binary classification methods, offering precise
continuous outputs for personality traits, thus enhancing applications in AI,
psychology, human resources, marketing and health care fields."
F-FOMAML - GNN-Enhanced Meta-Learning for Peak Period Demand Forecasting with Proxy Data,https://arxiv.org/abs/2406.16221,2024-06-23,2024-06-25,0.0,0.0,"Demand prediction is a crucial task for e-commerce and physical retail
businesses, especially during high-stake sales events. However, the limited
availability of historical data from these peak periods poses a significant
challenge for traditional forecasting methods. In this paper, we propose a
novel approach that leverages strategically chosen proxy data reflective of
potential sales patterns from similar entities during non-peak periods,
enriched by features learned from a graph neural networks (GNNs)-based
forecasting model, to predict demand during peak events. We formulate the
demand prediction as a meta-learning problem and develop the Feature-based
First-Order Model-Agnostic Meta-Learning (F-FOMAML) algorithm that leverages
proxy data from non-peak periods and GNN-generated relational metadata to learn
feature-specific layer parameters, thereby adapting to demand forecasts for
peak events. Theoretically, we show that by considering domain similarities
through task-specific metadata, our model achieves improved generalization,
where the excess risk decreases as the number of training tasks increases.
Empirical evaluations on large-scale industrial datasets demonstrate the
superiority of our approach. Compared to existing state-of-the-art models, our
method demonstrates a notable improvement in demand prediction accuracy,
reducing the Mean Absolute Error by 26.24% on an internal vending machine
dataset and by 1.04% on the publicly accessible JD.com dataset."
Learning Run-time Safety Monitors for Machine Learning Components,https://arxiv.org/abs/2406.16220,2024-06-23,2024-06-25,0.0,0.0,"For machine learning components used as part of autonomous systems (AS) in
carrying out critical tasks it is crucial that assurance of the models can be
maintained in the face of post-deployment changes (such as changes in the
operating environment of the system). A critical part of this is to be able to
monitor when the performance of the model at runtime (as a result of changes)
poses a safety risk to the system. This is a particularly difficult challenge
when ground truth is unavailable at runtime. In this paper we introduce a
process for creating safety monitors for ML components through the use of
degraded datasets and machine learning. The safety monitor that is created is
deployed to the AS in parallel to the ML component to provide a prediction of
the safety risk associated with the model output. We demonstrate the viability
of our approach through some initial experiments using publicly available speed
sign datasets."
Trace is the New AutoDiff -- Unlocking Efficient Optimization of Computational Workflows,https://arxiv.org/abs/2406.16218,2024-06-23,2024-06-25,0.0,0.0,"We study a class of optimization problems motivated by automating the design
and update of AI systems like coding assistants, robots, and copilots. We
propose an end-to-end optimization framework, Trace, which treats the
computational workflow of an AI system as a graph akin to neural networks,
based on a generalization of back-propagation. Optimization of computational
workflows often involves rich feedback (e.g. console output or user's
responses), heterogeneous parameters (e.g. prompts, hyper-parameters, codes),
and intricate objectives (beyond maximizing a score). Moreover, its computation
graph can change dynamically with the inputs and parameters. We frame a new
mathematical setup of iterative optimization, Optimization with Trace Oracle
(OPTO), to capture and abstract these properties so as to design optimizers
that work across many domains. In OPTO, an optimizer receives an execution
trace along with feedback on the computed output and updates parameters
iteratively. Trace is the tool to implement OPTO in practice. Trace has a
Python interface that efficiently converts a computational workflow into an
OPTO instance using a PyTorch-like interface. Using Trace, we develop a
general-purpose LLM-based optimizer called OptoPrime that can effectively solve
OPTO problems. In empirical studies, we find that OptoPrime is capable of
first-order numerical optimization, prompt optimization, hyper-parameter
tuning, robot controller design, code debugging, etc., and is often competitive
with specialized optimizers for each domain. We believe that Trace, OptoPrime
and the OPTO framework will enable the next generation of interactive agents
that automatically adapt using various kinds of feedback. Website:
https://microsoft.github.io/Trace"
Provable Statistical Rates for Consistency Diffusion Models,https://arxiv.org/abs/2406.16213,2024-06-23,2024-06-25,0.0,0.0,"Diffusion models have revolutionized various application domains, including
computer vision and audio generation. Despite the state-of-the-art performance,
diffusion models are known for their slow sample generation due to the
extensive number of steps involved. In response, consistency models have been
developed to merge multiple steps in the sampling process, thereby
significantly boosting the speed of sample generation without compromising
quality. This paper contributes towards the first statistical theory for
consistency models, formulating their training as a distribution discrepancy
minimization problem. Our analysis yields statistical estimation rates based on
the Wasserstein distance for consistency models, matching those of vanilla
diffusion models. Additionally, our results encompass the training of
consistency models through both distillation and isolation methods,
demystifying their underlying advantage."
Zero-Inflated Tweedie Boosted Trees with CatBoost for Insurance Loss Analytics,https://arxiv.org/abs/2406.16206,2024-06-23,2024-06-25,0.0,0.0,"In this paper, we explore advanced modifications to the Tweedie regression
model in order to address its limitations in modeling aggregate claims for
various types of insurance such as automobile, health, and liability.
Traditional Tweedie models, while effective in capturing the probability and
magnitude of claims, usually fall short in accurately representing the large
incidence of zero claims. Our recommended approach involves a refined modeling
of the zero-claim process, together with the integration of boosting methods in
order to help leverage an iterative process to enhance predictive accuracy.
Despite the inherent slowdown in learning algorithms due to this iteration,
several efficient implementation techniques that also help precise tuning of
parameter like XGBoost, LightGBM, and CatBoost have emerged. Nonetheless, we
chose to utilize CatBoost, a efficient boosting approach that effectively
handles categorical and other special types of data. The core contribution of
our paper is the assembly of separate modeling for zero claims and the
application of tree-based boosting ensemble methods within a CatBoost
framework, assuming that the inflated probability of zero is a function of the
mean parameter. The efficacy of our enhanced Tweedie model is demonstrated
through the application of an insurance telematics dataset, which presents the
additional complexity of compositional feature variables. Our modeling results
reveal a marked improvement in model performance, showcasing its potential to
deliver more accurate predictions suitable for insurance claim analytics."
LLMs' Classification Performance is Overclaimed,https://arxiv.org/abs/2406.16203,2024-06-23,2024-06-25,0.0,0.0,"In many classification tasks designed for AI or human to solve, gold labels
are typically included within the label space by default, often posed as ""which
of the following is correct?"" This standard setup has traditionally highlighted
the strong performance of advanced AI, particularly top-performing Large
Language Models (LLMs), in routine classification tasks. However, when the gold
label is intentionally excluded from the label space, it becomes evident that
LLMs still attempt to select from the available label candidates, even when
none are correct. This raises a pivotal question: Do LLMs truly demonstrate
their intelligence in understanding the essence of classification tasks?
  In this study, we evaluate both closed-source and open-source LLMs across
representative classification tasks, arguing that the perceived performance of
LLMs is overstated due to their inability to exhibit the expected comprehension
of the task. This paper makes a threefold contribution: i) To our knowledge,
this is the first work to identify the limitations of LLMs in classification
tasks when gold labels are absent. We define this task as Classify-w/o-Gold and
propose it as a new testbed for LLMs. ii) We introduce a benchmark, Know-No,
comprising two existing classification tasks and one new task, to evaluate
Classify-w/o-Gold. iii) This work defines and advocates for a new evaluation
metric, OmniAccuracy, which assesses LLMs' performance in classification tasks
both when gold labels are present and absent."
Blind Baselines Beat Membership Inference Attacks for Foundation Models,https://arxiv.org/abs/2406.16201,2024-06-23,2024-06-25,0.0,0.0,"Membership inference (MI) attacks try to determine if a data sample was used
to train a machine learning model. For foundation models trained on unknown Web
data, MI attacks can be used to detect copyrighted training materials, measure
test set contamination, or audit machine unlearning. Unfortunately, we find
that evaluations of MI attacks for foundation models are flawed, because they
sample members and non-members from different distributions. For 8 published MI
evaluation datasets, we show that blind attacks -- that distinguish the member
and non-member distributions without looking at any trained model -- outperform
state-of-the-art MI attacks. Existing evaluations thus tell us nothing about
membership leakage of a foundation model's training data."
Towards unlocking the mystery of adversarial fragility of neural networks,https://arxiv.org/abs/2406.16200,2024-06-23,2024-06-25,0.0,0.0,"In this paper, we study the adversarial robustness of deep neural networks
for classification tasks. We look at the smallest magnitude of possible
additive perturbations that can change the output of a classification
algorithm. We provide a matrix-theoretic explanation of the adversarial
fragility of deep neural network for classification. In particular, our
theoretical results show that neural network's adversarial robustness can
degrade as the input dimension $d$ increases. Analytically we show that neural
networks' adversarial robustness can be only $1/\sqrt{d}$ of the best possible
adversarial robustness. Our matrix-theoretic explanation is consistent with an
earlier information-theoretic feature-compression-based explanation for the
adversarial fragility of neural networks."
Reinterpreting Economic Complexity - A co-clustering approach,https://arxiv.org/abs/2406.16199,2024-06-23,2024-06-25,0.0,0.0,"Economic growth results from countries' accumulation of organizational and
technological capabilities. The Economic and Product Complexity Indices,
introduced as an attempt to measure these capabilities from a country's basket
of exported products, have become popular to study economic development, the
geography of innovation, and industrial policies. Despite this reception, the
interpretation of these indicators proved difficult. Although the original
Method of Reflections suggested a direct interconnection between country and
product metrics, it has been proved that the Economic and Product Complexity
Indices result from a spectral clustering algorithm that separately groups
similar countries or similar products, respectively. This recent approach to
economic and product complexity conflicts with the original one and treats
separately countries and products. However, building on previous
interpretations of the indices and the recent evolution in spectral clustering,
we show that these indices simultaneously identify two co-clusters of similar
countries and products. This viewpoint reconciles the spectral clustering
interpretation of the indices with the original Method of Reflections
interpretation. By proving the often neglected intimate relationship between
country and product complexity, this approach emphasizes the role of a selected
set of products in determining economic development while extending the range
of applications of these indicators in economics."
Hardware-Aware Neural Dropout Search for Reliable Uncertainty Prediction on FPGA,https://arxiv.org/abs/2406.16198,2024-06-23,2024-06-25,0.0,0.0,"The increasing deployment of artificial intelligence (AI) for critical
decision-making amplifies the necessity for trustworthy AI, where uncertainty
estimation plays a pivotal role in ensuring trustworthiness. Dropout-based
Bayesian Neural Networks (BayesNNs) are prominent in this field, offering
reliable uncertainty estimates. Despite their effectiveness, existing
dropout-based BayesNNs typically employ a uniform dropout design across
different layers, leading to suboptimal performance. Moreover, as diverse
applications require tailored dropout strategies for optimal performance,
manually optimizing dropout configurations for various applications is both
error-prone and labor-intensive. To address these challenges, this paper
proposes a novel neural dropout search framework that automatically optimizes
both the dropout-based BayesNNs and their hardware implementations on FPGA. We
leverage one-shot supernet training with an evolutionary algorithm for
efficient dropout optimization. A layer-wise dropout search space is introduced
to enable the automatic design of dropout-based BayesNNs with heterogeneous
dropout configurations. Extensive experiments demonstrate that our proposed
framework can effectively find design configurations on the Pareto frontier.
Compared to manually-designed dropout-based BayesNNs on GPU, our search
approach produces FPGA designs that can achieve up to 33X higher energy
efficiency. Compared to state-of-the-art FPGA designs of BayesNN, the solutions
from our approach can achieve higher algorithmic performance and energy
efficiency."
Semi-Variance Reduction for Fair Federated Learning,https://arxiv.org/abs/2406.16193,2024-06-23,2024-06-25,0.0,0.0,"Ensuring fairness in a Federated Learning (FL) system, i.e., a satisfactory
performance for all of the participating diverse clients, is an important and
challenging problem. There are multiple fair FL algorithms in the literature,
which have been relatively successful in providing fairness. However, these
algorithms mostly emphasize on the loss functions of worst-off clients to
improve their performance, which often results in the suppression of
well-performing ones. As a consequence, they usually sacrifice the system's
overall average performance for achieving fairness. Motivated by this and
inspired by two well-known risk modeling methods in Finance, Mean-Variance and
Mean-Semi-Variance, we propose and study two new fair FL algorithms, Variance
Reduction (VRed) and Semi-Variance Reduction (SemiVRed). VRed encourages
equality between clients' loss functions by penalizing their variance. In
contrast, SemiVRed penalizes the discrepancy of only the worst-off clients'
loss functions from the average loss. Through extensive experiments on multiple
vision and language datasets, we show that, SemiVRed achieves SoTA performance
in scenarios with heterogeneous data distributions and improves both fairness
and system overall average performance."
Accelerating Matrix Diagonalization through Decision Transformers with Epsilon-Greedy Optimization,https://arxiv.org/abs/2406.16191,2024-06-23,2024-06-25,0.0,0.0,"This paper introduces a novel framework for matrix diagonalization, recasting
it as a sequential decision-making problem and applying the power of Decision
Transformers (DTs). Our approach determines optimal pivot selection during
diagonalization with the Jacobi algorithm, leading to significant speedups
compared to the traditional max-element Jacobi method. To bolster robustness,
we integrate an epsilon-greedy strategy, enabling success in scenarios where
deterministic approaches fail. This work demonstrates the effectiveness of DTs
in complex computational tasks and highlights the potential of reimagining
mathematical operations through a machine learning lens. Furthermore, we
establish the generalizability of our method by using transfer learning to
diagonalize matrices of smaller sizes than those trained."
Evaluation and Comparison of Emotionally Evocative Image Augmentation Methods,https://arxiv.org/abs/2406.16187,2024-06-23,2024-06-25,0.0,0.0,"Experiments in affective computing are based on stimulus datasets that, in
the process of standardization, receive metadata describing which emotions each
stimulus evokes. In this paper, we explore an approach to creating stimulus
datasets for affective computing using generative adversarial networks (GANs).
Traditional dataset preparation methods are costly and time consuming,
prompting our investigation of alternatives. We conducted experiments with
various GAN architectures, including Deep Convolutional GAN, Conditional GAN,
Auxiliary Classifier GAN, Progressive Augmentation GAN, and Wasserstein GAN,
alongside data augmentation and transfer learning techniques. Our findings
highlight promising advances in the generation of emotionally evocative
synthetic images, suggesting significant potential for future research and
improvements in this domain."
GraphEval2000 - Benchmarking and Improving Large Language Models on Graph Datasets,https://arxiv.org/abs/2406.16176,2024-06-23,2024-06-25,0.0,0.0,"Large language models (LLMs) have achieved remarkable success in natural
language processing (NLP), demonstrating significant capabilities in processing
and understanding text data. However, recent studies have identified
limitations in LLMs' ability to reason about graph-structured data. To address
this gap, we introduce GraphEval2000, the first comprehensive graph dataset,
comprising 40 graph data structure problems along with 2000 test cases.
Additionally, we introduce an evaluation framework based on GraphEval2000,
designed to assess the graph reasoning abilities of LLMs through coding
challenges. Our dataset categorizes test cases into four primary and four
sub-categories, ensuring a comprehensive evaluation. We evaluate eight popular
LLMs on GraphEval2000, revealing that LLMs exhibit a better understanding of
directed graphs compared to undirected ones. While private LLMs consistently
outperform open-source models, the performance gap is narrowing. Furthermore,
to improve the usability of our evaluation framework, we propose Structured
Symbolic Decomposition (SSD), an instruction-based method designed to enhance
LLM performance on GraphEval2000. Results show that SSD improves the
performance of GPT-3.5, GPT-4, and GPT-4o on complex graph problems, with an
increase of 11.11\%, 33.37\%, and 33.37\%, respectively."
SimCE - Simplifying Cross-Entropy Loss for Collaborative Filtering,https://arxiv.org/abs/2406.16170,2024-06-23,2024-06-25,0.0,0.0,"The learning objective is integral to collaborative filtering systems, where
the Bayesian Personalized Ranking (BPR) loss is widely used for learning
informative backbones. However, BPR often experiences slow convergence and
suboptimal local optima, partially because it only considers one negative item
for each positive item, neglecting the potential impacts of other unobserved
items. To address this issue, the recently proposed Sampled Softmax
Cross-Entropy (SSM) compares one positive sample with multiple negative
samples, leading to better performance. Our comprehensive experiments confirm
that recommender systems consistently benefit from multiple negative samples
during training. Furthermore, we introduce a \underline{Sim}plified Sampled
Softmax \underline{C}ross-\underline{E}ntropy Loss (SimCE), which simplifies
the SSM using its upper bound. Our validation on 12 benchmark datasets, using
both MF and LightGCN backbones, shows that SimCE significantly outperforms both
BPR and SSM."
An All-MLP Sequence Modeling Architecture That Excels at Copying,https://arxiv.org/abs/2406.16168,2024-06-23,2024-06-25,0.0,0.0,"Recent work demonstrated Transformers' ability to efficiently copy strings of
exponential sizes, distinguishing them from other architectures. We present the
Causal Relation Network (CausalRN), an all-MLP sequence modeling architecture
that can match Transformers on the copying task. Extending Relation Networks
(RNs), we implemented key innovations to support autoregressive sequence
modeling while maintaining computational feasibility. We discovered that
exponentially-activated RNs are reducible to linear time complexity, and
pre-activation normalization induces an infinitely growing memory pool, similar
to a KV cache. In ablation study, we found both exponential activation and
pre-activation normalization are indispensable for Transformer-level copying.
Our findings provide new insights into what actually constitutes strong
in-context retrieval."
FS-RAG - A Frame Semantics Based Approach for Improved Factual Accuracy in Large Language Models,https://arxiv.org/abs/2406.16167,2024-06-23,2024-06-25,0.0,0.0,"We present a novel extension to Retrieval Augmented Generation with the goal
of mitigating factual inaccuracies in the output of large language models.
Specifically, our method draws on the cognitive linguistic theory of frame
semantics for the indexing and retrieval of factual information relevant to
helping large language models answer queries. We conduct experiments to
demonstrate the effectiveness of this method both in terms of retrieval
effectiveness and in terms of the relevance of the frames and frame relations
automatically generated. Our results show that this novel mechanism of Frame
Semantic-based retrieval, designed to improve Retrieval Augmented Generation
(FS-RAG), is effective and offers potential for providing data-driven insights
into frame semantics theory. We provide open access to our program code and
prompts."
Composite Material Design for Optimized Fracture Toughness Using Machine Learning,https://arxiv.org/abs/2406.16166,2024-06-23,2024-06-25,0.0,0.0,"This paper investigates the optimization of 2D and 3D composite structures
using machine learning (ML) techniques, focusing on fracture toughness and
crack propagation in the Double Cantilever Beam (DCB) test. By exploring the
intricate relationship between microstructural arrangements and macroscopic
properties of composites, the study demonstrates the potential of ML as a
powerful tool to expedite the design optimization process, offering notable
advantages over traditional finite element analysis. The research encompasses
four distinct cases, examining crack propagation and fracture toughness in both
2D and 3D composite models. Through the application of ML algorithms, the study
showcases the capability for rapid and accurate exploration of vast design
spaces in composite materials. The findings highlight the efficiency of ML in
predicting mechanical behaviors with limited training data, paving the way for
broader applications in composite design and optimization. This work
contributes to advancing the understanding of ML's role in enhancing the
efficiency of composite material design processes."
Monte Carlo Planning for Stochastic Control on Constrained Markov Decision Processes,https://arxiv.org/abs/2406.16151,2024-06-23,2024-06-25,0.0,0.0,"In the world of stochastic control, especially in economics and engineering,
Markov Decision Processes (MDPs) can effectively model various stochastic
decision processes, from asset management to transportation optimization. These
underlying MDPs, upon closer examination, often reveal a specifically
constrained causal structure concerning the transition and reward dynamics. By
exploiting this structure, we can obtain a reduction in the causal
representation of the problem setting, allowing us to solve of the optimal
value function more efficiently. This work defines an MDP framework, the
\texttt{SD-MDP}, where we disentangle the causal structure of MDPs' transition
and reward dynamics, providing distinct partitions on the temporal causal
graph. With this stochastic reduction, the \texttt{SD-MDP} reflects a general
class of resource allocation problems. This disentanglement further enables us
to derive theoretical guarantees on the estimation error of the value function
under an optimal policy by allowing independent value estimation from Monte
Carlo sampling. Subsequently, by integrating this estimator into well-known
Monte Carlo planning algorithms, such as Monte Carlo Tree Search (MCTS), we
derive bounds on the simple regret of the algorithm. Finally, we quantify the
policy improvement of MCTS under the \texttt{SD-MDP} framework by demonstrating
that the MCTS planning algorithm achieves higher expected reward (lower costs)
under a constant simulation budget, on a tangible economic example based on
maritime refuelling."
Towards Open Respiratory Acoustic Foundation Models - Pretraining and Benchmarking,https://arxiv.org/abs/2406.16148,2024-06-23,2024-06-25,0.0,0.0,"Respiratory audio, such as coughing and breathing sounds, has predictive
power for a wide range of healthcare applications, yet is currently
under-explored. The main problem for those applications arises from the
difficulty in collecting large labeled task-specific data for model
development. Generalizable respiratory acoustic foundation models pretrained
with unlabeled data would offer appealing advantages and possibly unlock this
impasse. However, given the safety-critical nature of healthcare applications,
it is pivotal to also ensure openness and replicability for any proposed
foundation model solution. To this end, we introduce OPERA, an OPEn Respiratory
Acoustic foundation model pretraining and benchmarking system, as the first
approach answering this need. We curate large-scale respiratory audio datasets
(~136K samples, 440 hours), pretrain three pioneering foundation models, and
build a benchmark consisting of 19 downstream respiratory health tasks for
evaluation. Our pretrained models demonstrate superior performance (against
existing acoustic models pretrained with general audio on 16 out of 19 tasks)
and generalizability (to unseen datasets and new respiratory audio modalities).
This highlights the great promise of respiratory acoustic foundation models and
encourages more studies using OPERA as an open resource to accelerate research
on respiratory audio for health. The system is accessible from
https://github.com/evelyn0414/OPERA."
Predefined Prototypes for Intra-Class Separation and Disentanglement,https://arxiv.org/abs/2406.16145,2024-06-23,2024-06-25,0.0,0.0,"Prototypical Learning is based on the idea that there is a point (which we
call prototype) around which the embeddings of a class are clustered. It has
shown promising results in scenarios with little labeled data or to design
explainable models. Typically, prototypes are either defined as the average of
the embeddings of a class or are designed to be trainable. In this work, we
propose to predefine prototypes following human-specified criteria, which
simplify the training pipeline and brings different advantages. Specifically,
in this work we explore two of these advantages: increasing the inter-class
separability of embeddings and disentangling embeddings with respect to
different variance factors, which can translate into the possibility of having
explainable predictions. Finally, we propose different experiments that help to
understand our proposal and demonstrate empirically the mentioned advantages."
Chain-of-Probe - Examing the Necessity and Accuracy of CoT Step-by-Step,https://arxiv.org/abs/2406.16144,2024-06-23,2024-06-25,0.0,0.0,"Current research found the issue of Early Answering in large language models
(LLMs), where the models already have an answer before generating the
Chain-of-Thought (CoT). This phenomenon suggests a potential lack of necessary
dependency between the predicted answer and the reasoning process.
Consequently, two important questions arise: (1) Is CoT still necessary if the
model already has an answer? (2) Can the correctness of the answer serve as
valid evidence for the correctness of CoT? To address these questions, we
propose a method, namely Chain-of-Probe (CoP), to probe changes in the mind
during the model's reasoning. The probing results show that in a significant
number of question-answer cases, CoT appears to be unnecessary, and this
necessity correlates with the simplicity of the task, defined by reasoning
steps required. Furthermore, by analyzing patterns in mind change, we examine
the correctness of the model's reasoning. Our validation reveals that many
responses, although correct in their final answer, contain errors in their
reasoning process. To this end, we propose a strategic approach based on CoP to
prioritize answers with correct reasoning among multiple candidates, thereby
bolstering the reliability of the model's reasoning."
CBPF - Filtering Poisoned Data Based on Composite Backdoor Attack,https://arxiv.org/abs/2406.16125,2024-06-23,2024-06-25,0.0,0.0,"Backdoor attacks involve the injection of a limited quantity of poisoned
examples containing triggers into the training dataset. During the inference
stage, backdoor attacks can uphold a high level of accuracy for normal
examples, yet when presented with trigger-containing instances, the model may
erroneously predict them as the targeted class designated by the attacker. This
paper explores strategies for mitigating the risks associated with backdoor
attacks by examining the filtration of poisoned samples.We primarily leverage
two key characteristics of backdoor attacks: the ability for multiple backdoors
to exist simultaneously within a single model, and the discovery through
Composite Backdoor Attack (CBA) that altering two triggers in a sample to new
target labels does not compromise the original functionality of the triggers,
yet enables the prediction of the data as a new target class when both triggers
are present simultaneously.Therefore, a novel three-stage poisoning data
filtering approach, known as Composite Backdoor Poison Filtering (CBPF), is
proposed as an effective solution. Firstly, utilizing the identified
distinctions in output between poisoned and clean samples, a subset of data is
partitioned to include both poisoned and clean instances. Subsequently, benign
triggers are incorporated and labels are adjusted to create new target and
benign target classes, thereby prompting the poisoned and clean data to be
classified as distinct entities during the inference stage. The experimental
results indicate that CBPF is successful in filtering out malicious data
produced by six advanced attacks on CIFAR10 and ImageNet-12. On average, CBPF
attains a notable filtering success rate of 99.91% for the six attacks on
CIFAR10. Additionally, the model trained on the uncontaminated samples exhibits
sustained high accuracy levels."
Diffusion Spectral Representation for Reinforcement Learning,https://arxiv.org/abs/2406.16121,2024-06-23,2024-06-25,0.0,0.0,"Diffusion-based models have achieved notable empirical successes in
reinforcement learning (RL) due to their expressiveness in modeling complex
distributions. Despite existing methods being promising, the key challenge of
extending existing methods for broader real-world applications lies in the
computational cost at inference time, i.e., sampling from a diffusion model is
considerably slow as it often requires tens to hundreds of iterations to
generate even one sample. To circumvent this issue, we propose to leverage the
flexibility of diffusion models for RL from a representation learning
perspective. In particular, by exploiting the connection between diffusion
model and energy-based model, we develop Diffusion Spectral Representation
(Diff-SR), a coherent algorithm framework that enables extracting sufficient
representations for value functions in Markov decision processes (MDP) and
partially observable Markov decision processes (POMDP). We further demonstrate
how Diff-SR facilitates efficient policy optimization and practical algorithms
while explicitly bypassing the difficulty and inference cost of sampling from
the diffusion model. Finally, we provide comprehensive empirical studies to
verify the benefits of Diff-SR in delivering robust and advantageous
performance across various benchmarks with both fully and partially observable
settings."
Contextualized End-to-end Automatic Speech Recognition with Intermediate Biasing Loss,https://arxiv.org/abs/2406.16120,2024-06-23,2024-06-25,0.0,0.0,"Contextualized end-to-end automatic speech recognition has been an active
research area, with recent efforts focusing on the implicit learning of
contextual phrases based on the final loss objective. However, these approaches
ignore the useful contextual knowledge encoded in the intermediate layers. We
hypothesize that employing explicit biasing loss as an auxiliary task in the
encoder intermediate layers may better align text tokens or audio frames with
the desired objectives. Our proposed intermediate biasing loss brings more
regularization and contextualization to the network. Our method outperforms a
conventional contextual biasing baseline on the LibriSpeech corpus, achieving a
relative improvement of 22.5% in biased word error rate (B-WER) and up to 44%
compared to the non-contextual baseline with a biasing list size of 100.
Moreover, employing RNN-transducer-driven joint decoding further reduces the
unbiased word error rate (U-WER), resulting in a more robust network."
Multi-Scale Temporal Difference Transformer for Video-Text Retrieval,https://arxiv.org/abs/2406.16111,2024-06-23,2024-06-25,0.0,0.0,"Currently, in the field of video-text retrieval, there are many
transformer-based methods. Most of them usually stack frame features and
regrade frames as tokens, then use transformers for video temporal modeling.
However, they commonly neglect the inferior ability of the transformer modeling
local temporal information. To tackle this problem, we propose a transformer
variant named Multi-Scale Temporal Difference Transformer (MSTDT). MSTDT mainly
addresses the defects of the traditional transformer which has limited ability
to capture local temporal information. Besides, in order to better model the
detailed dynamic information, we make use of the difference feature between
frames, which practically reflects the dynamic movement of a video. We extract
the inter-frame difference feature and integrate the difference and frame
feature by the multi-scale temporal transformer. In general, our proposed MSTDT
consists of a short-term multi-scale temporal difference transformer and a
long-term temporal transformer. The former focuses on modeling local temporal
information, the latter aims at modeling global temporal information. At last,
we propose a new loss to narrow the distance of similar samples. Extensive
experiments show that backbone, such as CLIP, with MSTDT has attained a new
state-of-the-art result."
Decoder-only Architecture for Streaming End-to-end Speech Recognition,https://arxiv.org/abs/2406.16107,2024-06-23,2024-06-25,0.0,0.0,"Decoder-only language models (LMs) have been successfully adopted for
speech-processing tasks including automatic speech recognition (ASR). The LMs
have ample expressiveness and perform efficiently. This efficiency is a
suitable characteristic for streaming applications of ASR. In this work, we
propose to use a decoder-only architecture for blockwise streaming ASR. In our
approach, speech features are compressed using CTC output and context embedding
using blockwise speech subnetwork, and are sequentially provided as prompts to
the decoder. The decoder estimates the output tokens promptly at each block. To
this end, we also propose a novel training scheme using random-length prefix
prompts to make the model robust to the truncated prompts caused by blockwise
processing. An experimental comparison shows that our proposed decoder-only
streaming ASR achieves 8% relative word error rate reduction in the LibriSpeech
test-other set while being twice as fast as the baseline model."
Evaluating Ensemble Methods for News Recommender Systems,https://arxiv.org/abs/2406.16106,2024-06-23,2024-06-25,0.0,0.0,"News recommendation is crucial for facilitating individuals' access to
articles, particularly amid the increasingly digital landscape of news
consumption. Consequently, extensive research is dedicated to News Recommender
Systems (NRS) with increasingly sophisticated algorithms. Despite this
sustained scholarly inquiry, there exists a notable research gap regarding the
potential synergy achievable by amalgamating these algorithms to yield superior
outcomes. This paper endeavours to address this gap by demonstrating how
ensemble methods can be used to combine many diverse state-of-the-art
algorithms to achieve superior results on the Microsoft News dataset (MIND).
Additionally, we identify scenarios where ensemble methods fail to improve
results and offer explanations for this occurrence. Our findings demonstrate
that a combination of NRS algorithms can outperform individual algorithms,
provided that the base learners are sufficiently diverse, with improvements of
up to 5\% observed for an ensemble consisting of a content-based BERT approach
and the collaborative filtering LSTUR algorithm. Additionally, our results
demonstrate the absence of any improvement when combining insufficiently
distinct methods. These findings provide insight into successful approaches of
ensemble methods in NRS and advocates for the development of better systems
through appropriate ensemble solutions."
Towards Natural Language-Driven Assembly Using Foundation Models,https://arxiv.org/abs/2406.16093,2024-06-23,2024-06-25,0.0,0.0,"Large Language Models (LLMs) and strong vision models have enabled rapid
research and development in the field of Vision-Language-Action models that
enable robotic control. The main objective of these methods is to develop a
generalist policy that can control robots with various embodiments. However, in
industrial robotic applications such as automated assembly and disassembly,
some tasks, such as insertion, demand greater accuracy and involve intricate
factors like contact engagement, friction handling, and refined motor skills.
Implementing these skills using a generalist policy is challenging because
these policies might integrate further sensory data, including force or torque
measurements, for enhanced precision. In our method, we present a global
control policy based on LLMs that can transfer the control policy to a finite
set of skills that are specifically trained to perform high-precision tasks
through dynamic context switching. The integration of LLMs into this framework
underscores their significance in not only interpreting and processing language
inputs but also in enriching the control mechanisms for diverse and intricate
robotic operations."
Imperative Learning - A Self-supervised Neural-Symbolic Learning Framework for Robot Autonomy,https://arxiv.org/abs/2406.16087,2024-06-23,2024-06-25,0.0,0.0,"Data-driven methods such as reinforcement and imitation learning have
achieved remarkable success in robot autonomy. However, their data-centric
nature still hinders them from generalizing well to ever-changing environments.
Moreover, collecting large datasets for robotic tasks is often impractical and
expensive. To overcome these challenges, we introduce a new self-supervised
neural-symbolic (NeSy) computational framework, imperative learning (IL), for
robot autonomy, leveraging the generalization abilities of symbolic reasoning.
The framework of IL consists of three primary components: a neural module, a
reasoning engine, and a memory system. We formulate IL as a special bilevel
optimization (BLO), which enables reciprocal learning over the three modules.
This overcomes the label-intensive obstacles associated with data-driven
approaches and takes advantage of symbolic reasoning concerning logical
reasoning, physical principles, geometric analysis, etc. We discuss several
optimization techniques for IL and verify their effectiveness in five distinct
robot autonomy tasks including path planning, rule induction, optimal control,
visual odometry, and multi-robot routing. Through various experiments, we show
that IL can significantly enhance robot autonomy capabilities and we anticipate
that it will catalyze further research across diverse domains."
SEAM - A Stochastic Benchmark for Multi-Document Tasks,https://arxiv.org/abs/2406.16086,2024-06-23,2024-06-25,0.0,0.0,"Various tasks, such as summarization, multi-hop question answering, or
coreference resolution, are naturally phrased over collections of real-world
documents. Such tasks present a unique set of challenges, revolving around the
lack of coherent narrative structure across documents, which often leads to
contradiction, omission, or repetition of information. Despite their real-world
application and challenging properties, there is currently no benchmark which
specifically measures the abilities of large language models (LLMs) on
multi-document tasks. To bridge this gap, we present SEAM (a Stochastic
Evaluation Approach for Multi-document tasks), a conglomerate benchmark over a
diverse set of multi-document datasets, setting conventional evaluation
criteria, input-output formats, and evaluation protocols. In particular, SEAM
addresses the sensitivity of LLMs to minor prompt variations through repeated
evaluations, where in each evaluation we sample uniformly at random the values
of arbitrary factors (e.g., the order of documents). We evaluate different LLMs
on SEAM finding that multi-document tasks pose a significant challenge for
LLMs, even for state-of-the-art models with 70B parameters. In addition, we
show that the stochastic approach uncovers underlying statistical trends which
cannot be observed in a static benchmark. We hope that SEAM will spur progress
via consistent and meaningful evaluation of multi-document tasks."
EERPD - Leveraging Emotion and Emotion Regulation for Improving Personality Detection,https://arxiv.org/abs/2406.16079,2024-06-23,2024-06-25,0.0,0.0,"Personality is a fundamental construct in psychology, reflecting an
individual's behavior, thinking, and emotional patterns. Previous researches
have made some progress in personality detection, primarily by utilizing the
whole text to predict personality. However, these studies generally tend to
overlook psychological knowledge: they rarely apply the well-established
correlations between emotion regulation and personality. Based on this, we
propose a new personality detection method called EERPD. This method introduces
the use of emotion regulation, a psychological concept highly correlated with
personality, for personality prediction. By combining this feature with emotion
features, it retrieves few-shot examples and provides process CoTs for
inferring labels from text. This approach enhances the understanding of LLM for
personality within text and improves the performance in personality detection.
Experimental results demonstrate that EERPD significantly enhances the accuracy
and robustness of personality detection, outperforming previous SOTA by
15.05/4.29 in average F1 on the two benchmark datasets."
First Heuristic Then Rational - Dynamic Use of Heuristics in Language Model Reasoning,https://arxiv.org/abs/2406.16078,2024-06-23,2024-06-25,0.0,0.0,"Multi-step reasoning is widely adopted in the community to explore the better
performance of language models (LMs). We report on the systematic strategy that
LMs use in this process. Our controlled experiments reveal that LMs rely more
heavily on heuristics, such as lexical overlap, in the earlier stages of
reasoning when more steps are required to reach an answer. Conversely, as LMs
progress closer to the final answer, their reliance on heuristics decreases.
This suggests that LMs track only a limited number of future steps and
dynamically combine heuristic strategies with logical ones in tasks involving
multi-step reasoning."
Detecting Abnormal Operations in Concentrated Solar Power Plants from Irregular Sequences of Thermal Images,https://arxiv.org/abs/2406.16077,2024-06-23,2024-06-25,0.0,0.0,"Concentrated Solar Power (CSP) plants store energy by heating a storage
medium with an array of mirrors that focus sunlight onto solar receivers atop a
central tower. Operating at high temperatures these receivers face risks such
as freezing, deformation, and corrosion, leading to operational failures,
downtime, or costly equipment damage. We study the problem of anomaly detection
(AD) in sequences of thermal images collected over a year from an operational
CSP plant. These images are captured at irregular intervals ranging from one to
five minutes throughout the day by infrared cameras mounted on solar receivers.
Our goal is to develop a method to extract useful representations from
high-dimensional thermal images for AD. It should be able to handle temporal
features of the data, which include irregularity, temporal dependency between
images and non-stationarity due to a strong daily seasonal pattern. The
co-occurrence of low-temperature anomalies that resemble normal images from the
start and the end of the operational cycle with high-temperature anomalies
poses an additional challenge. We first evaluate state-of-the-art deep
image-based AD methods, which have been shown to be effective in deriving
meaningful image representations for the detection of anomalies. Then, we
introduce a forecasting-based AD method that predicts future thermal images
from past sequences and timestamps via a deep sequence model. This method
effectively captures specific temporal data features and distinguishes between
difficult-to-detect temperature-based anomalies. Our experiments demonstrate
the effectiveness of our approach compared to multiple SOTA baselines across
multiple evaluation metrics. We have also successfully deployed our solution on
five months of unseen data, providing critical insights for the maintenance of
the CSP plant. Our code is available at: https://tinyurl.com/ForecastAD"
"Dancing in the syntax forest - fast, accurate and explainable sentiment analysis with SALSA",https://arxiv.org/abs/2406.16071,2024-06-23,2024-06-25,0.0,0.0,"Sentiment analysis is a key technology for companies and institutions to
gauge public opinion on products, services or events. However, for large-scale
sentiment analysis to be accessible to entities with modest computational
resources, it needs to be performed in a resource-efficient way. While some
efficient sentiment analysis systems exist, they tend to apply shallow
heuristics, which do not take into account syntactic phenomena that can
radically change sentiment. Conversely, alternatives that take syntax into
account are computationally expensive. The SALSA project, funded by the
European Research Council under a Proof-of-Concept Grant, aims to leverage
recently-developed fast syntactic parsing techniques to build sentiment
analysis systems that are lightweight and efficient, while still providing
accuracy and explainability through the explicit use of syntax. We intend our
approaches to be the backbone of a working product of interest for SMEs to use
in production."
FastMem - Fast Memorization of Prompt Improves Context Awareness of Large Language Models,https://arxiv.org/abs/2406.16069,2024-06-23,2024-06-25,0.0,0.0,"Large language models (LLMs) excel in generating coherent text, but they
often struggle with context awareness, leading to inaccuracies in tasks
requiring faithful adherence to provided information. We introduce FastMem, a
novel method designed to enhance instruction fine-tuned LLMs' context awareness
through fast memorization of the prompt. FastMem maximizes the likelihood of
the prompt before inference by fine-tuning only the last Feed-Forward Network
(FFN) module. This targeted approach ensures efficient optimization without
overfitting, significantly improving the model's ability to comprehend and
accurately follow the context. Our experiments demonstrate substantial gains in
reading comprehension, text summarization and adherence to output structures.
For instance, FastMem improves the accuracy of Llama 3-8B-Inst on the NQ-SWAP
dataset from 59.1% to 71.6%, and reduces the output structure failure rate of
Qwen 1.5-4B-Chat from 34.9% to 25.5%. Extensive experimental results highlight
FastMem's potential to offer a robust solution to enhance the reliability and
accuracy of LLMs in various applications. Our code is available at:
https://github.com/IAAR-Shanghai/FastMem"
Towards Real-Time Neural Volumetric Rendering on Mobile Devices - A Measurement Study,https://arxiv.org/abs/2406.16068,2024-06-23,2024-06-25,0.0,0.0,"Neural Radiance Fields (NeRF) is an emerging technique to synthesize 3D
objects from 2D images with a wide range of potential applications. However,
rendering existing NeRF models is extremely computation intensive, making it
challenging to support real-time interaction on mobile devices. In this paper,
we take the first initiative to examine the state-of-the-art real-time NeRF
rendering technique from a system perspective. We first define the entire
working pipeline of the NeRF serving system. We then identify possible control
knobs that are critical to the system from the communication, computation, and
visual performance perspective. Furthermore, an extensive measurement study is
conducted to reveal the effects of these control knobs on system performance.
Our measurement results reveal that different control knobs contribute
differently towards improving the system performance, with the mesh granularity
being the most effective knob and the quantization being the least effective
knob. In addition, diverse hardware device settings and network conditions have
to be considered to fully unleash the benefit of operating under the
appropriate knobs"
PORT - Preference Optimization on Reasoning Traces,https://arxiv.org/abs/2406.16061,2024-06-23,2024-06-25,0.0,0.0,"Preference optimization methods have been successfully applied to improve not
only the alignment of large language models (LLMs) with human values, but also
specific natural language tasks such as summarization and stylistic
continuations. This paper proposes using preference optimization methods on
Chain-of-Thought steps in order to improve the reasoning performances of
language models. While the chosen answers are obtained from datasets that
include reasoning traces, we propose two complementary schemes for generating
rejected answers: digit corruption, and weak LLM prompting. Our approach leads
to increased accuracy on the GSM8K, AQuA-RAT, and ARC benchmarks for
Falcon2-11B and Mistral-7B. For example, the approach can lead to up to a
relative 8.47% increase in accuracy on the GSM8K benchmark without any extra
annotations. This work suggests that spending resources on creating more
datasets of reasoning traces would further boost LLM performances on informal
reasoning tasks."
Pivotal Auto-Encoder via Self-Normalizing ReLU,https://arxiv.org/abs/2406.16052,2024-06-23,2024-06-25,0.0,0.0,"Sparse auto-encoders are useful for extracting low-dimensional
representations from high-dimensional data. However, their performance degrades
sharply when the input noise at test time differs from the noise employed
during training. This limitation hinders the applicability of auto-encoders in
real-world scenarios where the level of noise in the input is unpredictable. In
this paper, we formalize single hidden layer sparse auto-encoders as a
transform learning problem. Leveraging the transform modeling interpretation,
we propose an optimization problem that leads to a predictive model invariant
to the noise level at test time. In other words, the same pre-trained model is
able to generalize to different noise levels. The proposed optimization
algorithm, derived from the square root lasso, is translated into a new,
computationally efficient auto-encoding architecture. After proving that our
new method is invariant to the noise level, we evaluate our approach by
training networks using the proposed architecture for denoising tasks. Our
experimental results demonstrate that the trained models yield a significant
improvement in stability against varying types of noise compared to commonly
used architectures."
Combine and Conquer - A Meta-Analysis on Data Shift and Out-of-Distribution Detection,https://arxiv.org/abs/2406.16045,2024-06-23,2024-06-25,0.0,0.0,"This paper introduces a universal approach to seamlessly combine
out-of-distribution (OOD) detection scores. These scores encompass a wide range
of techniques that leverage the self-confidence of deep learning models and the
anomalous behavior of features in the latent space. Not surprisingly, combining
such a varied population using simple statistics proves inadequate. To overcome
this challenge, we propose a quantile normalization to map these scores into
p-values, effectively framing the problem into a multi-variate hypothesis test.
Then, we combine these tests using established meta-analysis tools, resulting
in a more effective detector with consolidated decision boundaries.
Furthermore, we create a probabilistic interpretable criterion by mapping the
final statistics into a distribution with known parameters. Through empirical
investigation, we explore different types of shifts, each exerting varying
degrees of impact on data. Our results demonstrate that our approach
significantly improves overall robustness and performance across diverse OOD
detection scenarios. Notably, our framework is easily extensible for future
developments in detection scores and stands as the first to combine decision
boundaries in this context. The code and artifacts associated with this work
are publicly available\footnote{\url{https://github.com/edadaltocg/detectors}}."
Meta-FL - A Novel Meta-Learning Framework for Optimizing Heterogeneous Model Aggregation in Federated Learning,https://arxiv.org/abs/2406.16035,2024-06-23,2024-06-25,0.0,0.0,"Federated Learning (FL) enables collaborative model training across diverse
entities while safeguarding data privacy. However, FL faces challenges such as
data heterogeneity and model diversity. The Meta-Federated Learning (Meta-FL)
framework has been introduced to tackle these challenges. Meta-FL employs an
optimization-based Meta-Aggregator to navigate the complexities of
heterogeneous model updates. The Meta-Aggregator enhances the global model's
performance by leveraging meta-features, ensuring a tailored aggregation that
accounts for each local model's accuracy. Empirical evaluation across four
healthcare-related datasets demonstrates the Meta-FL framework's adaptability,
efficiency, scalability, and robustness, outperforming conventional FL
approaches. Furthermore, Meta-FL's remarkable efficiency and scalability are
evident in its achievement of superior accuracy with fewer communication rounds
and its capacity to manage expanding federated networks without compromising
performance."
Unlocking the Future - Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models,https://arxiv.org/abs/2406.16033,2024-06-23,2024-06-25,0.0,0.0,"Planning, as the core module of agents, is crucial in various fields such as
embodied agents, web navigation, and tool using. With the development of large
language models (LLMs), some researchers treat large language models as
intelligent agents to stimulate and evaluate their planning capabilities.
However, the planning mechanism is still unclear. In this work, we focus on
exploring the look-ahead planning mechanism in large language models from the
perspectives of information flow and internal representations. First, we study
how planning is done internally by analyzing the multi-layer perception (MLP)
and multi-head self-attention (MHSA) components at the last token. We find that
the output of MHSA in the middle layers at the last token can directly decode
the decision to some extent. Based on this discovery, we further trace the
source of MHSA by information flow, and we reveal that MHSA mainly extracts
information from spans of the goal states and recent steps. According to
information flow, we continue to study what information is encoded within it.
Specifically, we explore whether future decisions have been encoded in advance
in the representation of flow. We demonstrate that the middle and upper layers
encode a few short-term future decisions to some extent when planning is
successful. Overall, our research analyzes the look-ahead planning mechanisms
of LLMs, facilitating future research on LLMs performing planning tasks."
Effect of Random Learning Rate - Theoretical Analysis of SGD Dynamics in Non-Convex Optimization via Stationary Distribution,https://arxiv.org/abs/2406.16032,2024-06-23,2024-06-25,0.0,0.0,"We consider a variant of the stochastic gradient descent (SGD) with a random
learning rate and reveal its convergence properties. SGD is a widely used
stochastic optimization algorithm in machine learning, especially deep
learning. Numerous studies reveal the convergence properties of SGD and its
simplified variants. Among these, the analysis of convergence using a
stationary distribution of updated parameters provides generalizable results.
However, to obtain a stationary distribution, the update direction of the
parameters must not degenerate, which limits the applicable variants of SGD. In
this study, we consider a novel SGD variant, Poisson SGD, which has degenerated
parameter update directions and instead utilizes a random learning rate.
Consequently, we demonstrate that a distribution of a parameter updated by
Poisson SGD converges to a stationary distribution under weak assumptions on a
loss function. Based on this, we further show that Poisson SGD finds global
minima in non-convex optimization problems and also evaluate the generalization
error using this method. As a proof technique, we approximate the distribution
by Poisson SGD with that of the bouncy particle sampler (BPS) and derive its
stationary distribution, using the theoretical advance of the piece-wise
deterministic Markov process (PDMP)."
Zero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages,https://arxiv.org/abs/2406.16030,2024-06-23,2024-06-25,0.0,0.0,"Existing zero-shot cross-lingual NER approaches require substantial prior
knowledge of the target language, which is impractical for low-resource
languages. In this paper, we propose a novel approach to NER using phonemic
representation based on the International Phonetic Alphabet (IPA) to bridge the
gap between representations of different languages. Our experiments show that
our method significantly outperforms baseline models in extremely low-resource
languages, with the highest average F-1 score (46.38%) and lowest standard
deviation (12.67), particularly demonstrating its robustness with non-Latin
scripts."
TimeAutoDiff - Combining Autoencoder and Diffusion model for time series tabular data synthesizing,https://arxiv.org/abs/2406.16028,2024-06-23,2024-06-25,0.0,0.0,"In this paper, we leverage the power of latent diffusion models to generate
synthetic time series tabular data. Along with the temporal and feature
correlations, the heterogeneous nature of the feature in the table has been one
of the main obstacles in time series tabular data modeling. We tackle this
problem by combining the ideas of the variational auto-encoder (VAE) and the
denoising diffusion probabilistic model (DDPM). Our model named as
\texttt{TimeAutoDiff} has several key advantages including (1) Generality: the
ability to handle the broad spectrum of time series tabular data from single to
multi-sequence datasets; (2) Good fidelity and utility guarantees: numerical
experiments on six publicly available datasets demonstrating significant
improvements over state-of-the-art models in generating time series tabular
data, across four metrics measuring fidelity and utility; (3) Fast sampling
speed: entire time series data generation as opposed to the sequential data
sampling schemes implemented in the existing diffusion-based models, eventually
leading to significant improvements in sampling speed, (4) Entity conditional
generation: the first implementation of conditional generation of
multi-sequence time series tabular data with heterogenous features in the
literature, enabling scenario exploration across multiple scientific and
engineering domains. Codes are in preparation for release to the public, but
available upon request."
Harvesting Events from Multiple Sources - Towards a Cross-Document Event Extraction Paradigm,https://arxiv.org/abs/2406.16021,2024-06-23,2024-06-25,0.0,0.0,"Document-level event extraction aims to extract structured event information
from unstructured text. However, a single document often contains limited event
information and the roles of different event arguments may be biased due to the
influence of the information source. This paper addresses the limitations of
traditional document-level event extraction by proposing the task of
cross-document event extraction (CDEE) to integrate event information from
multiple documents and provide a comprehensive perspective on events. We
construct a novel cross-document event extraction dataset, namely CLES, which
contains 20,059 documents and 37,688 mention-level events, where over 70% of
them are cross-document. To build a benchmark, we propose a CDEE pipeline that
includes 5 steps, namely event extraction, coreference resolution, entity
normalization, role normalization and entity-role resolution. Our CDEE pipeline
achieves about 72% F1 in end-to-end cross-document event extraction, suggesting
the challenge of this task. Our work builds a new line of information
extraction research and will attract new research attention."
AudioBench - A Universal Benchmark for Audio Large Language Models,https://arxiv.org/abs/2406.16020,2024-06-23,2024-06-25,0.0,0.0,"We introduce AudioBench, a universal benchmark designed to evaluate Audio
Large Language Models (AudioLLMs). It encompasses 8 distinct tasks and 26
datasets, among which, 7 are newly proposed datasets. The evaluation targets
three main aspects: speech understanding, audio scene understanding, and voice
understanding (paralinguistic). Despite recent advancements, there lacks a
comprehensive benchmark for AudioLLMs on instruction following capabilities
conditioned on audio signals. AudioBench addresses this gap by setting up
datasets as well as desired evaluation metrics. Besides, we also evaluated the
capabilities of five popular models and found that no single model excels
consistently across all tasks. We outline the research outlook for AudioLLMs
and anticipate that our open-sourced evaluation toolkit, data, and leaderboard
will offer a robust testbed for future model developments."
Database-Augmented Query Representation for Information Retrieval,https://arxiv.org/abs/2406.16013,2024-06-23,2024-06-25,0.0,0.0,"Information retrieval models that aim to search for the documents relevant to
the given query have shown many successes, which have been applied to diverse
tasks. However, the query provided by the user is oftentimes very short, which
challenges the retrievers to correctly fetch relevant documents. To tackle
this, existing studies have proposed expanding the query with a couple of
additional (user-related) features related to the query. Yet, they may be
suboptimal to effectively augment the query, though there is plenty of
information available to augment it in a relational database. Motivated by
this, we present a novel retrieval framework called Database-Augmented Query
representation (DAQu), which augments the original query with various
(query-related) metadata across multiple tables. In addition, as the number of
features in the metadata can be very large and there is no order among them, we
encode them with our graph-based set encoding strategy, which considers
hierarchies of features in the database without order. We validate DAQu in
diverse retrieval scenarios that can incorporate metadata from the relational
database, demonstrating that ours significantly enhances overall retrieval
performance, compared to existing query augmentation methods."
Found in the Middle - Calibrating Positional Attention Bias Improves Long Context Utilization,https://arxiv.org/abs/2406.16008,2024-06-23,2024-06-25,0.0,0.0,"Large language models (LLMs), even when specifically trained to process long
input contexts, struggle to capture relevant information located in the middle
of their input. This phenomenon has been known as the lost-in-the-middle
problem. In this work, we make three contributions. First, we set out to
understand the factors that cause this phenomenon. In doing so, we establish a
connection between lost-in-the-middle to LLMs' intrinsic attention bias: LLMs
exhibit a U-shaped attention bias where the tokens at the beginning and at the
end of its input receive higher attention, regardless of their relevance.
Second, we mitigate this positional bias through a calibration mechanism,
found-in-the-middle, that allows the model to attend to contexts faithfully
according to their relevance, even though when they are in the middle. Third,
we show found-in-the-middle not only achieves better performance in locating
relevant information within a long context, but also eventually leads to
improved retrieval-augmented generation (RAG) performance across various tasks,
outperforming existing methods by up to 15 percentage points. These findings
open up future directions in understanding LLM attention bias and its potential
consequences."
Distributed Rule Vectors is A Key Mechanism in Large Language Models' In-Context Learning,https://arxiv.org/abs/2406.16007,2024-06-23,2024-06-25,0.0,0.0,"Large Language Models (LLMs) have demonstrated remarkable abilities, one of
the most important being In-Context Learning (ICL). With ICL, LLMs can derive
the underlying rule from a few demonstrations and provide answers that comply
with the rule. Previous work hypothesized that the network creates a ""task
vector"" in specific positions during ICL. Patching the ""task vector"" allows
LLMs to achieve zero-shot performance similar to few-shot learning. However, we
discover that such ""task vectors"" do not exist in tasks where the rule has to
be defined through multiple demonstrations. Instead, the rule information
provided by each demonstration is first transmitted to its answer position and
forms its own rule vector. Importantly, all the rule vectors contribute to the
output in a distributed manner. We further show that the rule vectors encode a
high-level abstraction of rules extracted from the demonstrations. These
results are further validated in a series of tasks that rely on rules dependent
on multiple demonstrations. Our study provides novel insights into the
mechanism underlying ICL in LLMs, demonstrating how ICL may be achieved through
an information aggregation mechanism."
Bounding-Box Inference for Error-Aware Model-Based Reinforcement Learning,https://arxiv.org/abs/2406.16006,2024-06-23,2024-06-25,0.0,0.0,"In model-based reinforcement learning, simulated experiences from the learned
model are often treated as equivalent to experience from the real environment.
However, when the model is inaccurate, it can catastrophically interfere with
policy learning. Alternatively, the agent might learn about the model's
accuracy and selectively use it only when it can provide reliable predictions.
We empirically explore model uncertainty measures for selective planning and
show that best results require distribution insensitive inference to estimate
the uncertainty over model-based updates. To that end, we propose and evaluate
bounding-box inference, which operates on bounding-boxes around sets of
possible states and other quantities. We find that bounding-box inference can
reliably support effective selective planning."
Predicting Individual Depression Symptoms from Acoustic Features During Speech,https://arxiv.org/abs/2406.16000,2024-06-23,2024-06-25,0.0,0.0,"Current automatic depression detection systems provide predictions directly
without relying on the individual symptoms/items of depression as denoted in
the clinical depression rating scales. In contrast, clinicians assess each item
in the depression rating scale in a clinical setting, thus implicitly providing
a more detailed rationale for a depression diagnosis. In this work, we make a
first step towards using the acoustic features of speech to predict individual
items of the depression rating scale before obtaining the final depression
prediction. For this, we use convolutional (CNN) and recurrent (long short-term
memory (LSTM)) neural networks. We consider different approaches to learning
the temporal context of speech. Further, we analyze two variants of voting
schemes for individual item prediction and depression detection. We also
include an animated visualization that shows an example of item prediction over
time as the speech progresses."
Memorizing Documents with Guidance in Large Language Models,https://arxiv.org/abs/2406.15996,2024-06-23,2024-06-25,0.0,0.0,"Training data plays a pivotal role in AI models. Large language models (LLMs)
are trained with massive amounts of documents, and their parameters hold
document-related contents. Recently, several studies identified
content-specific locations in LLMs by examining the parameters. Instead of the
post hoc interpretation, we propose another approach. We propose document-wise
memory architecture to track document memories in training. The proposed
architecture maps document representations to memory entries, which softly mask
memories in the forward process of LLMs. Additionally, we propose document
guidance loss, which increases the likelihood of text with document memories
and reduces the likelihood of the text with the memories of other documents.
Experimental results on Wikitext-103-v1 with Pythia-1B show that the proposed
methods provide different memory entries for documents and high recall of
document-related content in generation with trained document-wise memories."
Can LLM Graph Reasoning Generalize beyond Pattern Memorization?,https://arxiv.org/abs/2406.15992,2024-06-23,2024-06-25,0.0,0.0,"Large language models (LLMs) demonstrate great potential for problems with
implicit graphical structures, while recent works seek to enhance the graph
reasoning capabilities of LLMs through specialized instruction tuning. The
resulting 'graph LLMs' are evaluated with in-distribution settings only, thus
it remains underexplored whether LLMs are learning generalizable graph
reasoning skills or merely memorizing patterns in the synthetic training data.
To this end, we propose the NLGift benchmark, an evaluation suite of LLM graph
reasoning generalization: whether LLMs could go beyond semantic, numeric,
structural, reasoning patterns in the synthetic training data and improve
utility on real-world graph-based tasks. Extensive experiments with two LLMs
across four graph reasoning tasks demonstrate that while generalization on
simple patterns (semantic, numeric) is somewhat satisfactory, LLMs struggle to
generalize across reasoning and real-world patterns, casting doubt on the
benefit of synthetic graph tuning for real-world tasks with underlying network
structures. We explore three strategies to improve LLM graph reasoning
generalization, and we find that while post-training alignment is most
promising for real-world tasks, empowering LLM graph reasoning to go beyond
pattern memorization remains an open research question."
Enhancing Cross-Document Event Coreference Resolution by Discourse Structure and Semantic Information,https://arxiv.org/abs/2406.15990,2024-06-23,2024-06-25,0.0,0.0,"Existing cross-document event coreference resolution models, which either
compute mention similarity directly or enhance mention representation by
extracting event arguments (such as location, time, agent, and patient),
lacking the ability to utilize document-level information. As a result, they
struggle to capture long-distance dependencies. This shortcoming leads to their
underwhelming performance in determining coreference for the events where their
argument information relies on long-distance dependencies. In light of these
limitations, we propose the construction of document-level Rhetorical Structure
Theory (RST) trees and cross-document Lexical Chains to model the structural
and semantic information of documents. Subsequently, cross-document
heterogeneous graphs are constructed and GAT is utilized to learn the
representations of events. Finally, a pair scorer calculates the similarity
between each pair of events and co-referred events can be recognized using
standard clustering algorithm. Additionally, as the existing cross-document
event coreference datasets are limited to English, we have developed a
large-scale Chinese cross-document event coreference dataset to fill this gap,
which comprises 53,066 event mentions and 4,476 clusters. After applying our
model on the English and Chinese datasets respectively, it outperforms all
baselines by large margins."
Deep-MPC - A DAGGER-Driven Imitation Learning Strategy for Optimal Constrained Battery Charging,https://arxiv.org/abs/2406.15985,2024-06-23,2024-06-25,0.0,0.0,"In the realm of battery charging, several complex aspects demand meticulous
attention, including thermal management, capacity degradation, and the need for
rapid charging while maintaining safety and battery lifespan. By employing the
imitation learning paradigm, this manuscript introduces an innovative solution
to confront the inherent challenges often associated with conventional
predictive control strategies for constrained battery charging. A significant
contribution of this study lies in the adaptation of the Dataset Aggregation
(DAGGER) algorithm to address scenarios where battery parameters are uncertain,
and internal states are unobservable. Results drawn from a practical battery
simulator that incorporates an electrochemical model highlight substantial
improvements in battery charging performance, particularly in meeting all
safety constraints and outperforming traditional strategies in computational
processing."
Learning with Noisy Ground Truth - From 2D Classification to 3D Reconstruction,https://arxiv.org/abs/2406.15982,2024-06-23,2024-06-25,0.0,0.0,"Deep neural networks has been highly successful in data-intense computer
vision applications, while such success relies heavily on the massive and clean
data. In real-world scenarios, clean data sometimes is difficult to obtain. For
example, in image classification and segmentation tasks, precise annotations of
millions samples are generally very expensive and time-consuming. In 3D static
scene reconstruction task, most NeRF related methods require the foundational
assumption of the static scene (e.g. consistent lighting condition and
persistent object positions), which is often violated in real-world scenarios.
To address these problem, learning with noisy ground truth (LNGT) has emerged
as an effective learning method and shows great potential. In this short
survey, we propose a formal definition unify the analysis of LNGT LNGT in the
context of different machine learning tasks (classification and regression).
Based on this definition, we propose a novel taxonomy to classify the existing
work according to the error decomposition with the fundamental definition of
machine learning. Further, we provide in-depth analysis on memorization effect
and insightful discussion about potential future research opportunities from 2D
classification to 3D reconstruction, in the hope of providing guidance to
follow-up research."
Serial Position Effects of Large Language Models,https://arxiv.org/abs/2406.15981,2024-06-23,2024-06-25,0.0,0.0,"Large Language Models (LLMs) have shown remarkable capabilities in zero-shot
learning applications, generating responses to queries using only pre-training
information without the need for additional fine-tuning. This represents a
significant departure from traditional machine learning approaches. Previous
research has indicated that LLMs may exhibit serial position effects, such as
primacy and recency biases, which are well-documented cognitive biases in human
psychology. Our extensive testing across various tasks and models confirms the
widespread occurrence of these effects, although their intensity varies. We
also discovered that while carefully designed prompts can somewhat mitigate
these biases, their effectiveness is inconsistent. These findings underscore
the significance of serial position effects during the inference process,
particularly in scenarios where there are no ground truth labels, highlighting
the need for greater focus on addressing these effects in LLM applications."
EVCL - Elastic Variational Continual Learning with Weight Consolidation,https://arxiv.org/abs/2406.15972,2024-06-23,2024-06-25,0.0,0.0,"Continual learning aims to allow models to learn new tasks without forgetting
what has been learned before. This work introduces Elastic Variational
Continual Learning with Weight Consolidation (EVCL), a novel hybrid model that
integrates the variational posterior approximation mechanism of Variational
Continual Learning (VCL) with the regularization-based parameter-protection
strategy of Elastic Weight Consolidation (EWC). By combining the strengths of
both methods, EVCL effectively mitigates catastrophic forgetting and enables
better capture of dependencies between model parameters and task-specific data.
Evaluated on five discriminative tasks, EVCL consistently outperforms existing
baselines in both domain-incremental and task-incremental learning scenarios
for deep discriminative models."
Imperfect-Recall Games - Equilibrium Concepts and Their Complexity,https://arxiv.org/abs/2406.15970,2024-06-23,2024-06-25,0.0,0.0,"We investigate optimal decision making under imperfect recall, that is, when
an agent forgets information it once held before. An example is the
absentminded driver game, as well as team games in which the members have
limited communication capabilities. In the framework of extensive-form games
with imperfect recall, we analyze the computational complexities of finding
equilibria in multiplayer settings across three different solution concepts:
Nash, multiselves based on evidential decision theory (EDT), and multiselves
based on causal decision theory (CDT). We are interested in both exact and
approximate solution computation. As special cases, we consider (1)
single-player games, (2) two-player zero-sum games and relationships to maximin
values, and (3) games without exogenous stochasticity (chance nodes). We relate
these problems to the complexity classes P, PPAD, PLS, $\Sigma_2^P$ ,
$\exists$R, and $\exists \forall$R."
ReCaLL - Membership Inference via Relative Conditional Log-Likelihoods,https://arxiv.org/abs/2406.15968,2024-06-23,2024-06-25,0.0,0.0,"The rapid scaling of large language models (LLMs) has raised concerns about
the transparency and fair use of the pretraining data used for training them.
Detecting such content is challenging due to the scale of the data and limited
exposure of each instance during training. We propose ReCaLL (Relative
Conditional Log-Likelihood), a novel membership inference attack (MIA) to
detect LLMs' pretraining data by leveraging their conditional language modeling
capabilities. ReCaLL examines the relative change in conditional
log-likelihoods when prefixing target data points with non-member context. Our
empirical findings show that conditioning member data on non-member prefixes
induces a larger decrease in log-likelihood compared to non-member data. We
conduct comprehensive experiments and show that ReCaLL achieves
state-of-the-art performance on the WikiMIA dataset, even with random and
synthetic prefixes, and can be further improved using an ensemble approach.
Moreover, we conduct an in-depth analysis of LLMs' behavior with different
membership contexts, providing insights into how LLMs leverage membership
information for effective inference at both the sequence and token level."
Evaluating the Effectiveness of the Foundational Models for Q&A Classification in Mental Health care,https://arxiv.org/abs/2406.15966,2024-06-23,2024-06-25,0.0,0.0,"Pre-trained Language Models (PLMs) have the potential to transform mental
health support by providing accessible and culturally sensitive resources.
However, despite this potential, their effectiveness in mental health care and
specifically for the Arabic language has not been extensively explored. To
bridge this gap, this study evaluates the effectiveness of foundational models
for classification of Questions and Answers (Q&A) in the domain of mental
health care. We leverage the MentalQA dataset, an Arabic collection featuring
Q&A interactions related to mental health. In this study, we conducted
experiments using four different types of learning approaches: traditional
feature extraction, PLMs as feature extractors, Fine-tuning PLMs and prompting
large language models (GPT-3.5 and GPT-4) in zero-shot and few-shot learning
settings. While traditional feature extractors combined with Support Vector
Machines (SVM) showed promising performance, PLMs exhibited even better results
due to their ability to capture semantic meaning. For example, MARBERT achieved
the highest performance with a Jaccard Score of 0.80 for question
classification and a Jaccard Score of 0.86 for answer classification. We
further conducted an in-depth analysis including examining the effects of
fine-tuning versus non-fine-tuning, the impact of varying data size, and
conducting error analysis. Our analysis demonstrates that fine-tuning proved to
be beneficial for enhancing the performance of PLMs, and the size of the
training data played a crucial role in achieving high performance. We also
explored prompting, where few-shot learning with GPT-3.5 yielded promising
results. There was an improvement of 12% for question and classification and
45% for answer classification. Based on our findings, it can be concluded that
PLMs and prompt-based approaches hold promise for mental health support in
Arabic."
Automating Transfer of Robot Task Plans using Functorial Data Migrations,https://arxiv.org/abs/2406.15961,2024-06-22,2024-06-25,0.0,0.0,"This paper introduces a novel approach to ontology-based robot plan transfer
using functorial data migrations from category theory. Functors provide
structured maps between domain types and predicates which can be used to
transfer plans from a source domain to a target domain without the need for
replanning. Unlike methods that create models for transferring specific plans,
our approach can be applied to any plan within a given domain. We demonstrate
this approach by transferring a task plan from the canonical Blocksworld domain
to one compatible with the AI2-THOR Kitchen environment. In addition, we
discuss practical applications that may enhance the adaptability of robotic
task planning in general."
"Fair Clustering - Critique, Caveats, and Future Directions",https://arxiv.org/abs/2406.15960,2024-06-22,2024-06-25,0.0,0.0,"Clustering is a fundamental problem in machine learning and operations
research. Therefore, given the fact that fairness considerations have become of
paramount importance in algorithm design, fairness in clustering has received
significant attention from the research community. The literature on fair
clustering has resulted in a collection of interesting fairness notions and
elaborate algorithms. In this paper, we take a critical view of fair
clustering, identifying a collection of ignored issues such as the lack of a
clear utility characterization and the difficulty in accounting for the
downstream effects of a fair clustering algorithm in machine learning settings.
In some cases, we demonstrate examples where the application of a fair
clustering algorithm can have significant negative impacts on social welfare.
We end by identifying a collection of steps that would lead towards more
impactful research in fair clustering."
A Nonoverlapping Domain Decomposition Method for Extreme Learning Machines - Elliptic Problems,https://arxiv.org/abs/2406.15959,2024-06-22,2024-06-25,0.0,0.0,"Extreme learning machine (ELM) is a methodology for solving partial
differential equations (PDEs) using a single hidden layer feed-forward neural
network. It presets the weight/bias coefficients in the hidden layer with
random values, which remain fixed throughout the computation, and uses a linear
least squares method for training the parameters of the output layer of the
neural network. It is known to be much faster than Physics informed neural
networks. However, classical ELM is still computationally expensive when a high
level of representation is desired in the solution as this requires solving a
large least squares system. In this paper, we propose a nonoverlapping domain
decomposition method (DDM) for ELMs that not only reduces the training time of
ELMs, but is also suitable for parallel computation. In numerical analysis,
DDMs have been widely studied to reduce the time to obtain finite element
solutions for elliptic PDEs through parallel computation. Among these
approaches, nonoverlapping DDMs are attracting the most attention. Motivated by
these methods, we introduce local neural networks, which are valid only at
corresponding subdomains, and an auxiliary variable at the interface. We
construct a system on the variable and the parameters of local neural networks.
A Schur complement system on the interface can be derived by eliminating the
parameters of the output layer. The auxiliary variable is then directly
obtained by solving the reduced system after which the parameters for each
local neural network are solved in parallel. A method for initializing the
hidden layer parameters suitable for high approximation quality in large
systems is also proposed. Numerical results that verify the acceleration
performance of the proposed method with respect to the number of subdomains are
presented."
Bone Fracture Classification using Transfer Learning,https://arxiv.org/abs/2406.15958,2024-06-22,2024-06-25,0.0,0.0,"The manual examination of X-ray images for fractures is a time-consuming
process that is prone to human error. In this work, we introduce a robust yet
simple training loop for the classification of fractures, which significantly
outperforms existing methods. Our method achieves superior performance in less
than ten epochs and utilizes the latest dataset to deliver the best-performing
model for this task. We emphasize the importance of training deep learning
models responsibly and efficiently, as well as the critical role of selecting
high-quality datasets."
Beyond the Doors of Perception - Vision Transformers Represent Relations Between Objects,https://arxiv.org/abs/2406.15955,2024-06-22,2024-06-25,0.0,0.0,"Though vision transformers (ViTs) have achieved state-of-the-art performance
in a variety of settings, they exhibit surprising failures when performing
tasks involving visual relations. This begs the question: how do ViTs attempt
to perform tasks that require computing visual relations between objects? Prior
efforts to interpret ViTs tend to focus on characterizing relevant low-level
visual features. In contrast, we adopt methods from mechanistic
interpretability to study the higher-level visual algorithms that ViTs use to
perform abstract visual reasoning. We present a case study of a fundamental,
yet surprisingly difficult, relational reasoning task: judging whether two
visual entities are the same or different. We find that pretrained ViTs
fine-tuned on this task often exhibit two qualitatively different stages of
processing despite having no obvious inductive biases to do so: 1) a perceptual
stage wherein local object features are extracted and stored in a disentangled
representation, and 2) a relational stage wherein object representations are
compared. In the second stage, we find evidence that ViTs can learn to
represent somewhat abstract visual relations, a capability that has long been
considered out of reach for artificial neural networks. Finally, we demonstrate
that failure points at either stage can prevent a model from learning a
generalizable solution to our fairly simple tasks. By understanding ViTs in
terms of discrete processing stages, one can more precisely diagnose and
rectify shortcomings of existing and future models."
Modular Pluralism - Pluralistic Alignment via Multi-LLM Collaboration,https://arxiv.org/abs/2406.15951,2024-06-22,2024-06-25,0.0,0.0,"While existing alignment paradigms have been integral in developing large
language models (LLMs), LLMs often learn an averaged human preference and
struggle to model diverse preferences across cultures, demographics, and
communities. We propose Modular Pluralism, a modular framework based on
multi-LLM collaboration for pluralistic alignment: it ""plugs into"" a base LLM a
pool of smaller but specialized community LMs, where models collaborate in
distinct modes to flexibility support three modes of pluralism: Overton,
steerable, and distributional. Modular Pluralism is uniquely compatible with
black-box LLMs and offers the modular control of adding new community LMs for
previously underrepresented communities. We evaluate Modular Pluralism with six
tasks and four datasets featuring questions/instructions with value-laden and
perspective-informed responses. Extensive experiments demonstrate that Modular
Pluralism advances the three pluralism objectives across six black-box and
open-source LLMs. Further analysis reveals that LLMs are generally faithful to
the inputs from smaller community LLMs, allowing seamless patching by adding a
new community LM to better cover previously underrepresented communities."
Teaching LLMs to Abstain across Languages via Multilingual Feedback,https://arxiv.org/abs/2406.15948,2024-06-22,2024-06-25,0.0,0.0,"Multilingual LLMs often have knowledge disparities across languages, with
larger gaps in under-resourced languages. Teaching LLMs to abstain in the face
of knowledge gaps is thus a promising strategy to mitigate hallucinations in
multilingual settings. However, previous studies on LLM abstention primarily
focus on English; we find that directly applying existing solutions beyond
English results in up to 20.5% performance gaps between high and low-resource
languages, potentially due to LLMs' drop in calibration and reasoning beyond a
few resource-rich languages. To this end, we propose strategies to enhance LLM
abstention by learning from multilingual feedback, where LLMs self-reflect on
proposed answers in one language by generating multiple feedback items in
related languages: we show that this helps identifying the knowledge gaps
across diverse languages, cultures, and communities. Extensive experiments
demonstrate that our multilingual feedback approach outperforms various strong
baselines, achieving up to 9.2% improvement for low-resource languages across
three black-box and open models on three datasets, featuring open-book,
closed-book, and commonsense QA. Further analysis reveals that multilingual
feedback is both an effective and a more equitable abstain strategy to serve
diverse language speakers, and cultural factors have great impact on language
selection and LLM abstention behavior, highlighting future directions for
multilingual and multi-cultural reliable language modeling."
Towards Exact Computation of Inductive Bias,https://arxiv.org/abs/2406.15941,2024-06-22,2024-06-25,0.0,0.0,"Much research in machine learning involves finding appropriate inductive
biases (e.g. convolutional neural networks, momentum-based optimizers,
transformers) to promote generalization on tasks. However, quantification of
the amount of inductive bias associated with these architectures and
hyperparameters has been limited. We propose a novel method for efficiently
computing the inductive bias required for generalization on a task with a fixed
training data budget; formally, this corresponds to the amount of information
required to specify well-generalizing models within a specific hypothesis space
of models. Our approach involves modeling the loss distribution of random
hypotheses drawn from a hypothesis space to estimate the required inductive
bias for a task relative to these hypotheses. Unlike prior work, our method
provides a direct estimate of inductive bias without using bounds and is
applicable to diverse hypothesis spaces. Moreover, we derive approximation
error bounds for our estimation approach in terms of the number of sampled
hypotheses. Consistent with prior results, our empirical results demonstrate
that higher dimensional tasks require greater inductive bias. We show that
relative to other expressive model classes, neural networks as a model class
encode large amounts of inductive bias. Furthermore, our measure quantifies the
relative difference in inductive bias between different neural network
architectures. Our proposed inductive bias metric provides an
information-theoretic interpretation of the benefits of specific model
architectures for certain tasks and provides a quantitative guide to developing
tasks requiring greater inductive bias, thereby encouraging the development of
more powerful inductive biases."
Beyond Individual Facts - Investigating Categorical Knowledge Locality of Taxonomy and Meronomy Concepts in GPT Models,https://arxiv.org/abs/2406.15940,2024-06-22,2024-06-25,0.0,0.0,"The location of knowledge within Generative Pre-trained Transformer
(GPT)-like models has seen extensive recent investigation. However, much of the
work is focused towards determining locations of individual facts, with the end
goal being the editing of facts that are outdated, erroneous, or otherwise
harmful, without the time and expense of retraining the entire model. In this
work, we investigate a broader view of knowledge location, that of concepts or
clusters of related information, instead of disparate individual facts. To do
this, we first curate a novel dataset, called DARC, that includes a total of 34
concepts of ~120K factual statements divided into two types of hierarchical
categories, namely taxonomy and meronomy. Next, we utilize existing causal
mediation analysis methods developed for determining regions of importance for
individual facts and apply them to a series of related categories to provide
detailed investigation into whether concepts are associated with distinct
regions within these models. We find that related categories exhibit similar
areas of importance in contrast to less similar categories. However,
fine-grained localization of individual category subsets to specific regions is
not apparent."
RuleR - Improving LLM Controllability by Rule-based Data Recycling,https://arxiv.org/abs/2406.15938,2024-06-22,2024-06-25,0.0,0.0,"Large language models (LLMs) still lack delicate controllability over their
responses, which is critical to enhancing their performance and the user
experience. However, curating supervised fine-tuning (SFT) datasets to improve
LLM controllability usually relies on human experts or proprietary LLMs, which
requires additional costs. To bridge this gap, we propose Rule-based Data
Recycling (RuleR), a data augmentation method incorporating multiple
constraints into the original data samples according to predefined rules, which
creates new training tasks to consolidate the controllability of LLMs. Instead
of creating new data from scratch, RuleR ``recycles'' existing data by simply
applying rule-based edits to their responses and appending the
rule-instructions in their original instructions. Experimental results
demonstrate RuleR's effectiveness in improving LLM controllability while
maintaining general instruction-following capabilities. The code will be
released on https://github.com/MingLiiii/RuleR."
An Automated SQL Query Grading System Using An Attention-Based Convolutional Neural Network,https://arxiv.org/abs/2406.15936,2024-06-22,2024-06-25,0.0,0.0,"Grading SQL queries can be a time-consuming, tedious and challenging task,
especially as the number of student submissions increases. Several systems have
been introduced in an attempt to mitigate these challenges, but those systems
have their own limitations. This paper describes our novel approach to
automating the process of grading SQL queries. Unlike previous approaches, we
employ a unique convolutional neural network architecture that employs a
parameter-sharing approach for different machine learning tasks that enables
the architecture to induce different knowledge representations of the data to
increase its potential for understanding SQL statements."
Multistep Criticality Search and Power Shaping in Microreactors with Reinforcement Learning,https://arxiv.org/abs/2406.15931,2024-06-22,2024-06-25,0.0,0.0,"Reducing operation and maintenance costs is a key objective for advanced
reactors in general and microreactors in particular. To achieve this reduction,
developing robust autonomous control algorithms is essential to ensure safe and
autonomous reactor operation. Recently, artificial intelligence and machine
learning algorithms, specifically reinforcement learning (RL) algorithms, have
seen rapid increased application to control problems, such as plasma control in
fusion tokamaks and building energy management. In this work, we introduce the
use of RL for intelligent control in nuclear microreactors. The RL agent is
trained using proximal policy optimization (PPO) and advantage actor-critic
(A2C), cutting-edge deep RL techniques, based on a high-fidelity simulation of
a microreactor design inspired by the Westinghouse eVinci\textsuperscript{TM}
design. We utilized a Serpent model to generate data on drum positions, core
criticality, and core power distribution for training a feedforward neural
network surrogate model. This surrogate model was then used to guide a PPO and
A2C control policies in determining the optimal drum position across various
reactor burnup states, ensuring critical core conditions and symmetrical power
distribution across all six core portions. The results demonstrate the
excellent performance of PPO in identifying optimal drum positions, achieving a
hextant power tilt ratio of approximately 1.002 (within the limit of $<$ 1.02)
and maintaining criticality within a 10 pcm range. A2C did not provide as
competitive of a performance as PPO in terms of performance metrics for all
burnup steps considered in the cycle. Additionally, the results highlight the
capability of well-trained RL control policies to quickly identify control
actions, suggesting a promising approach for enabling real-time autonomous
control through digital twins."
Semantic Entropy Probes - Robust and Cheap Hallucination Detection in LLMs,https://arxiv.org/abs/2406.15927,2024-06-22,2024-06-25,0.0,0.0,"We propose semantic entropy probes (SEPs), a cheap and reliable method for
uncertainty quantification in Large Language Models (LLMs). Hallucinations,
which are plausible-sounding but factually incorrect and arbitrary model
generations, present a major challenge to the practical adoption of LLMs.
Recent work by Farquhar et al. (2024) proposes semantic entropy (SE), which can
detect hallucinations by estimating uncertainty in the space semantic meaning
for a set of model generations. However, the 5-to-10-fold increase in
computation cost associated with SE computation hinders practical adoption. To
address this, we propose SEPs, which directly approximate SE from the hidden
states of a single generation. SEPs are simple to train and do not require
sampling multiple model generations at test time, reducing the overhead of
semantic uncertainty quantification to almost zero. We show that SEPs retain
high performance for hallucination detection and generalize better to
out-of-distribution data than previous probing methods that directly predict
model accuracy. Our results across models and tasks suggest that model hidden
states capture SE, and our ablation studies give further insights into the
token positions and model layers for which this is the case."
Credit Attribution and Stable Compression,https://arxiv.org/abs/2406.15916,2024-06-22,2024-06-25,0.0,0.0,"Credit attribution is crucial across various fields. In academic research,
proper citation acknowledges prior work and establishes original contributions.
Similarly, in generative models, such as those trained on existing artworks or
music, it is important to ensure that any generated content influenced by these
works appropriately credits the original creators.
  We study credit attribution by machine learning algorithms. We propose new
definitions--relaxations of Differential Privacy--that weaken the stability
guarantees for a designated subset of $k$ datapoints. These $k$ datapoints can
be used non-stably with permission from their owners, potentially in exchange
for compensation. Meanwhile, the remaining datapoints are guaranteed to have no
significant influence on the algorithm's output.
  Our framework extends well-studied notions of stability, including
Differential Privacy ($k = 0$), differentially private learning with public
data (where the $k$ public datapoints are fixed in advance), and stable sample
compression (where the $k$ datapoints are selected adaptively by the
algorithm). We examine the expressive power of these stability notions within
the PAC learning framework, provide a comprehensive characterization of
learnability for algorithms adhering to these principles, and propose
directions and questions for future research."
OpticGAI - Generative AI-aided Deep Reinforcement Learning for Optical Networks Optimization,https://arxiv.org/abs/2406.15906,2024-06-22,2024-06-25,0.0,0.0,"Deep Reinforcement Learning (DRL) is regarded as a promising tool for optical
network optimization. However, the flexibility and efficiency of current
DRL-based solutions for optical network optimization require further
improvement. Currently, generative models have showcased their significant
performance advantages across various domains. In this paper, we introduce
OpticGAI, the AI-generated policy design paradigm for optical networks. In
detail, it is implemented as a novel DRL framework that utilizes generative
models to learn the optimal policy network. Furthermore, we assess the
performance of OpticGAI on two NP-hard optical network problems, Routing and
Wavelength Assignment (RWA) and dynamic Routing, Modulation, and Spectrum
Allocation (RMSA), to show the feasibility of the AI-generated policy paradigm.
Simulation results have shown that OpticGAI achieves the highest reward and the
lowest blocking rate of both RWA and RMSA problems. OpticGAI poses a promising
direction for future research on generative AI-enhanced flexible optical
network optimization."
"Learning When the Concept Shifts - Confounding, Invariance, and Dimension Reduction",https://arxiv.org/abs/2406.15904,2024-06-22,2024-06-25,0.0,0.0,"Practitioners often deploy a learned prediction model in a new environment
where the joint distribution of covariate and response has shifted. In
observational data, the distribution shift is often driven by unobserved
confounding factors lurking in the environment, with the underlying mechanism
unknown. Confounding can obfuscate the definition of the best prediction model
(concept shift) and shift covariates to domains yet unseen (covariate shift).
Therefore, a model maximizing prediction accuracy in the source environment
could suffer a significant accuracy drop in the target environment. This
motivates us to study the domain adaptation problem with observational data:
given labeled covariate and response pairs from a source environment, and
unlabeled covariates from a target environment, how can one predict the missing
target response reliably? We root the adaptation problem in a linear structural
causal model to address endogeneity and unobserved confounding. We study the
necessity and benefit of leveraging exogenous, invariant covariate
representations to cure concept shifts and improve target prediction. This
further motivates a new representation learning method for adaptation that
optimizes for a lower-dimensional linear subspace and, subsequently, a
prediction model confined to that subspace. The procedure operates on a
non-convex objective-that naturally interpolates between predictability and
stability/invariance-constrained on the Stiefel manifold. We study the
optimization landscape and prove that, when the regularization is sufficient,
nearly all local optima align with an invariant linear subspace resilient to
both concept and covariate shift. In terms of predictability, we show a model
that uses the learned lower-dimensional subspace can incur a nearly ideal gap
between target and source risk. Three real-world data sets are investigated to
validate our method and theory."
Defection-Free Collaboration between Competitors in a Learning System,https://arxiv.org/abs/2406.15898,2024-06-22,2024-06-25,0.0,0.0,"We study collaborative learning systems in which the participants are
competitors who will defect from the system if they lose revenue by
collaborating. As such, we frame the system as a duopoly of competitive firms
who are each engaged in training machine-learning models and selling their
predictions to a market of consumers. We first examine a fully collaborative
scheme in which both firms share their models with each other and show that
this leads to a market collapse with the revenues of both firms going to zero.
We next show that one-sided collaboration in which only the firm with the
lower-quality model shares improves the revenue of both firms. Finally, we
propose a more equitable, *defection-free* scheme in which both firms share
with each other while losing no revenue, and we show that our algorithm
converges to the Nash bargaining solution."
Fusing Audio and Metadata Embeddings Improves Language-based Audio Retrieval,https://arxiv.org/abs/2406.15897,2024-06-22,2024-06-25,0.0,0.0,"Matching raw audio signals with textual descriptions requires understanding
the audio's content and the description's semantics and then drawing
connections between the two modalities. This paper investigates a hybrid
retrieval system that utilizes audio metadata as an additional clue to
understand the content of audio signals before matching them with textual
queries. We experimented with metadata often attached to audio recordings, such
as keywords and natural-language descriptions, and we investigated late and
mid-level fusion strategies to merge audio and metadata. Our hybrid approach
with keyword metadata and late fusion improved the retrieval performance over a
content-based baseline by 2.36 and 3.69 pp. mAP@10 on the ClothoV2 and
AudioCaps benchmarks, respectively."
Statistical Models of Top-$k$ Partial Orders,https://arxiv.org/abs/2406.15893,2024-06-22,2024-06-25,0.0,0.0,"In many contexts involving ranked preferences, agents submit partial orders
over available alternatives. Statistical models often treat these as marginal
in the space of total orders, but this approach overlooks information contained
in the list length itself. In this work, we introduce and taxonomize approaches
for jointly modeling distributions over top-$k$ partial orders and list lengths
$k$, considering two classes of approaches: composite models that view a
partial order as a truncation of a total order, and augmented ranking models
that model the construction of the list as a sequence of choice decisions,
including the decision to stop. For composite models, we consider three
dependency structures for joint modeling of order and truncation length. For
augmented ranking models, we consider different assumptions on how the
stop-token choice is modeled. Using data consisting of partial rankings from
San Francisco school choice and San Francisco ranked choice elections, we
evaluate how well the models predict observed data and generate realistic
synthetic datasets. We find that composite models, explicitly modeling length
as a categorical variable, produce synthetic datasets with accurate length
distributions, and an augmented model with position-dependent item utilities
jointly models length and preferences in the training data best, as measured by
negative log loss. Methods from this work have significant implications on the
simulation and evaluation of real-world social systems that solicit ranked
preferences."
The Unlikely Duel - Evaluating Creative Writing in LLMs through a Unique Scenario,https://arxiv.org/abs/2406.15891,2024-06-22,2024-06-25,0.0,0.0,"This is a summary of the paper ""A Confederacy of Models: a Comprehensive
Evaluation of LLMs on Creative Writing"", which was published in Findings of
EMNLP 2023. We evaluate a range of recent state-of-the-art, instruction-tuned
large language models (LLMs) on an English creative writing task, and compare
them to human writers. For this purpose, we use a specifically-tailored prompt
(based on an epic combat between Ignatius J. Reilly, main character of John
Kennedy Toole's ""A Confederacy of Dunces"", and a pterodactyl) to minimize the
risk of training data leakage and force the models to be creative rather than
reusing existing stories. The same prompt is presented to LLMs and human
writers, and evaluation is performed by humans using a detailed rubric
including various aspects like fluency, style, originality or humor. Results
show that some state-of-the-art commercial LLMs match or slightly outperform
our human writers in most of the evaluated dimensions. Open-source LLMs lag
behind. Humans keep a close lead in originality, and only the top three LLMs
can handle humor at human-like levels."
Language Alignment via Nash-learning and Adaptive feedback,https://arxiv.org/abs/2406.15890,2024-06-22,2024-06-25,0.0,0.0,"Recent research has shown the potential of Nash Learning via Human Feedback
for large language model alignment by incorporating the notion of a preference
model in a minimax game setup. We take this idea further by casting the
alignment as a mirror descent algorithm against the adaptive feedback of an
improved opponent, thereby removing the need for learning a preference model or
the existence of an annotated dataset altogether. The resulting algorithm,
which we refer to as Language Alignment via Nash-learning and Adaptive feedback
(LANA), is capable of self-alignment without the need for a human-annotated
preference dataset. We support this statement with various experiments and
mathematical discussion."
"The Music Maestro or The Musically Challenged, A Massive Music Evaluation Benchmark for Large Language Models",https://arxiv.org/abs/2406.15885,2024-06-22,2024-06-25,0.0,0.0,"Benchmark plays a pivotal role in assessing the advancements of large
language models (LLMs). While numerous benchmarks have been proposed to
evaluate LLMs' capabilities, there is a notable absence of a dedicated
benchmark for assessing their musical abilities. To address this gap, we
present ZIQI-Eval, a comprehensive and large-scale music benchmark specifically
designed to evaluate the music-related capabilities of LLMs. ZIQI-Eval
encompasses a wide range of questions, covering 10 major categories and 56
subcategories, resulting in over 14,000 meticulously curated data entries. By
leveraging ZIQI-Eval, we conduct a comprehensive evaluation over 16 LLMs to
evaluate and analyze LLMs' performance in the domain of music. Results indicate
that all LLMs perform poorly on the ZIQI-Eval benchmark, suggesting significant
room for improvement in their musical capabilities. With ZIQI-Eval, we aim to
provide a standardized and robust evaluation framework that facilitates a
comprehensive assessment of LLMs' music-related abilities. The dataset is
available at GitHub\footnote{https://github.com/zcli-charlie/ZIQI-Eval} and
HuggingFace\footnote{https://huggingface.co/datasets/MYTH-Lab/ZIQI-Eval}."
SimSMoE - Solving Representational Collapse via Similarity Measure,https://arxiv.org/abs/2406.15883,2024-06-22,2024-06-25,0.0,0.0,"Sparse mixture of experts (SMoE) have emerged as an effective approach for
scaling large language models while keeping a constant computational cost.
Regardless of several notable successes of SMoE, effective training such
architecture remains elusive due to the representation collapse problem, which
in turn harms model performance and causes parameter redundancy. In this work,
we present Similarity-based Sparse Mixture of Experts (SimSMoE), a novel
similarity of neural network algorithm, that guarantees a solution to address
the representation collapse issue between experts given a fixed FLOPs budget.
We conduct extensive empirical evaluations on three large language models for
both Pre-training and Fine-tuning tasks to illustrate the efficacy, robustness,
and scalability of our method. The results demonstrate that SimSMoE
significantly enhances existing routing policy and outperforms other SMoE
training methods in performance for the tasks."
Fast Tree-Field Integrators - From Low Displacement Rank to Topological Transformers,https://arxiv.org/abs/2406.15881,2024-06-22,2024-06-25,0.0,0.0,"We present a new class of fast polylog-linear algorithms based on the theory
of structured matrices (in particular low displacement rank) for integrating
tensor fields defined on weighted trees. Several applications of the resulting
fast tree-field integrators (FTFIs) are presented, including (a) approximation
of graph metrics with tree metrics, (b) graph classification, (c) modeling on
meshes, and finally (d) Topological Transformers (TTs) (Choromanski et al.,
2022) for images. For Topological Transformers, we propose new relative
position encoding (RPE) masking mechanisms with as few as three extra learnable
parameters per Transformer layer, leading to 1.0-1.5%+ accuracy gains.
Importantly, most of FTFIs are exact methods, thus numerically equivalent to
their brute-force counterparts. When applied to graphs with thousands of nodes,
those exact algorithms provide 5.7-13x speedups. We also provide an extensive
theoretical analysis of our methods."
BigCodeBench - Benchmarking Code Generation with Diverse Function Calls and Complex Instructions,https://arxiv.org/abs/2406.15877,2024-06-22,2024-06-25,0.0,0.0,"Automated software engineering has been greatly empowered by the recent
advances in Large Language Models (LLMs) for programming. While current
benchmarks have shown that LLMs can perform various software engineering tasks
like human developers, the majority of their evaluations are limited to short
and self-contained algorithmic tasks. Solving challenging and practical
programming tasks requires the capability of utilizing diverse function calls
as tools to efficiently implement functionalities like data analysis and web
development. In addition, using multiple tools to solve a task needs
compositional reasoning by accurately understanding complex instructions.
Fulfilling both of these characteristics can pose a great challenge for LLMs.
To assess how well LLMs can solve challenging and practical programming tasks,
we introduce Bench, a benchmark that challenges LLMs to invoke multiple
function calls as tools from 139 libraries and 7 domains for 1,140 fine-grained
programming tasks. To evaluate LLMs rigorously, each programming task
encompasses 5.6 test cases with an average branch coverage of 99%. In addition,
we propose a natural-language-oriented variant of Bench, Benchi, that
automatically transforms the original docstrings into short instructions only
with essential information. Our extensive evaluation of 60 LLMs shows that LLMs
are not yet capable of following complex instructions to use function calls
precisely, with scores up to 60%, significantly lower than the human
performance of 97%. The results underscore the need for further advancements in
this area."
NeuralSCF - Neural network self-consistent fields for density functional theory,https://arxiv.org/abs/2406.15873,2024-06-22,2024-06-25,0.0,0.0,"Kohn-Sham density functional theory (KS-DFT) has found widespread application
in accurate electronic structure calculations. However, it can be
computationally demanding especially for large-scale simulations, motivating
recent efforts toward its machine-learning (ML) acceleration. We propose a
neural network self-consistent fields (NeuralSCF) framework that establishes
the Kohn-Sham density map as a deep learning objective, which encodes the
mechanics of the Kohn-Sham equations. Modeling this map with an
SE(3)-equivariant graph transformer, NeuralSCF emulates the Kohn-Sham
self-consistent iterations to obtain electron densities, from which other
properties can be derived. NeuralSCF achieves state-of-the-art accuracy in
electron density prediction and derived properties, featuring exceptional
zero-shot generalization to a remarkable range of out-of-distribution systems.
NeuralSCF reveals that learning from KS-DFT's intrinsic mechanics significantly
enhances the model's accuracy and transferability, offering a promising
stepping stone for accelerating electronic structure calculations through
mechanics learning."
Uncovering Hidden Intentions - Exploring Prompt Recovery for Deeper Insights into Generated Texts,https://arxiv.org/abs/2406.15871,2024-06-22,2024-06-25,0.0,0.0,"Today, the detection of AI-generated content is receiving more and more
attention. Our idea is to go beyond detection and try to recover the prompt
used to generate a text. This paper, to the best of our knowledge, introduces
the first investigation in this particular domain without a closed set of
tasks. Our goal is to study if this approach is promising. We experiment with
zero-shot and few-shot in-context learning but also with LoRA fine-tuning.
After that, we evaluate the benefits of using a semi-synthetic dataset. For
this first study, we limit ourselves to text generated by a single model. The
results show that it is possible to recover the original prompt with a
reasonable degree of accuracy."
Speech Analysis of Language Varieties in Italy,https://arxiv.org/abs/2406.15862,2024-06-22,2024-06-25,0.0,0.0,"Italy exhibits rich linguistic diversity across its territory due to the
distinct regional languages spoken in different areas. Recent advances in
self-supervised learning provide new opportunities to analyze Italy's
linguistic varieties using speech data alone. This includes the potential to
leverage representations learned from large amounts of data to better examine
nuances between closely related linguistic varieties. In this study, we focus
on automatically identifying the geographic region of origin of speech samples
drawn from Italy's diverse language varieties. We leverage self-supervised
learning models to tackle this task and analyze differences and similarities
between Italy's regional languages. In doing so, we also seek to uncover new
insights into the relationships among these diverse yet closely related
varieties, which may help linguists understand their interconnected evolution
and regional development over time and space. To improve the discriminative
ability of learned representations, we evaluate several supervised contrastive
learning objectives, both as pre-training steps and additional fine-tuning
objectives. Experimental evidence shows that pre-trained self-supervised models
can effectively identify regions from speech recording. Additionally,
incorporating contrastive objectives during fine-tuning improves classification
accuracy and yields embeddings that distinctly separate regional varieties,
demonstrating the value of combining self-supervised pre-training and
contrastive learning for this task."
LLM-Powered Explanations - Unraveling Recommendations Through Subgraph Reasoning,https://arxiv.org/abs/2406.15859,2024-06-22,2024-06-25,0.0,0.0,"Recommender systems are pivotal in enhancing user experiences across various
web applications by analyzing the complicated relationships between users and
items. Knowledge graphs(KGs) have been widely used to enhance the performance
of recommender systems. However, KGs are known to be noisy and incomplete,
which are hard to provide reliable explanations for recommendation results. An
explainable recommender system is crucial for the product development and
subsequent decision-making. To address these challenges, we introduce a novel
recommender that synergies Large Language Models (LLMs) and KGs to enhance the
recommendation and provide interpretable results. Specifically, we first
harness the power of LLMs to augment KG reconstruction. LLMs comprehend and
decompose user reviews into new triples that are added into KG. In this way, we
can enrich KGs with explainable paths that express user preferences. To enhance
the recommendation on augmented KGs, we introduce a novel subgraph reasoning
module that effectively measures the importance of nodes and discovers
reasoning for recommendation. Finally, these reasoning paths are fed into the
LLMs to generate interpretable explanations of the recommendation results. Our
approach significantly enhances both the effectiveness and interpretability of
recommender systems, especially in cross-selling scenarios where traditional
methods falter. The effectiveness of our approach has been rigorously tested on
four open real-world datasets, with our methods demonstrating a superior
performance over contemporary state-of-the-art techniques by an average
improvement of 12%. The application of our model in a multinational engineering
and technology company cross-selling recommendation system further underscores
its practical utility and potential to redefine recommendation practices
through improved accuracy and user trust."
Injectivity of ReLU-layers - Perspectives from Frame Theory,https://arxiv.org/abs/2406.15856,2024-06-22,2024-06-25,0.0,0.0,"Injectivity is the defining property of a mapping that ensures no information
is lost and any input can be perfectly reconstructed from its output. By
performing hard thresholding, the ReLU function naturally interferes with this
property, making the injectivity analysis of ReLU-layers in neural networks a
challenging yet intriguing task that has not yet been fully solved. This
article establishes a frame theoretic perspective to approach this problem. The
main objective is to develop the most general characterization of the
injectivity behavior of ReLU-layers in terms of all three involved ingredients:
(i) the weights, (ii) the bias, and (iii) the domain where the data is drawn
from. Maintaining a focus on practical applications, we limit our attention to
bounded domains and present two methods for numerically approximating a maximal
bias for given weights and data domains. These methods provide sufficient
conditions for the injectivity of a ReLU-layer on those domains and yield a
novel practical methodology for studying the information loss in ReLU layers.
Finally, we derive explicit reconstruction formulas based on the duality
concept from frame theory."
Next Level Message-Passing with Hierarchical Support Graphs,https://arxiv.org/abs/2406.15852,2024-06-22,2024-06-25,0.0,0.0,"Message-Passing Neural Networks (MPNNs) are extensively employed in graph
learning tasks but suffer from limitations such as the restricted scope of
information exchange, by being confined to neighboring nodes during each round
of message passing. Various strategies have been proposed to address these
limitations, including incorporating virtual nodes to facilitate global
information exchange. In this study, we introduce the Hierarchical Support
Graph (HSG), an extension of the virtual node concept created through recursive
coarsening of the original graph. This approach provides a flexible framework
for enhancing information flow in graphs, independent of the specific MPNN
layers utilized. We present a theoretical analysis of HSGs, investigate their
empirical performance, and demonstrate that HSGs can surpass other methods
augmented with virtual nodes, achieving state-of-the-art results across
multiple datasets."
Learning Abstract World Model for Value-preserving Planning with Options,https://arxiv.org/abs/2406.15850,2024-06-22,2024-06-25,0.0,0.0,"General-purpose agents require fine-grained controls and rich sensory inputs
to perform a wide range of tasks. However, this complexity often leads to
intractable decision-making. Traditionally, agents are provided with
task-specific action and observation spaces to mitigate this challenge, but
this reduces autonomy. Instead, agents must be capable of building state-action
spaces at the correct abstraction level from their sensorimotor experiences. We
leverage the structure of a given set of temporally-extended actions to learn
abstract Markov decision processes (MDPs) that operate at a higher level of
temporal and state granularity. We characterize state abstractions necessary to
ensure that planning with these skills, by simulating trajectories in the
abstract MDP, results in policies with bounded value loss in the original MDP.
We evaluate our approach in goal-based navigation environments that require
continuous abstract states to plan successfully and show that abstract model
learning improves the sample efficiency of planning and learning."
Enhancing Solar Driver Forecasting with Multivariate Transformers,https://arxiv.org/abs/2406.15847,2024-06-22,2024-06-25,0.0,0.0,"In this work, we develop a comprehensive framework for F10.7, S10.7, M10.7,
and Y10.7 solar driver forecasting with a time series Transformer (PatchTST).
To ensure an equal representation of high and low levels of solar activity, we
construct a custom loss function to weight samples based on the distance
between the solar driver's historical distribution and the training set. The
solar driver forecasting framework includes an 18-day lookback window and
forecasts 6 days into the future. When benchmarked against the Space
Environment Technologies (SET) dataset, our model consistently produces
forecasts with a lower standard mean error in nearly all cases, with improved
prediction accuracy during periods of high solar activity. All the code is
available on Github https://github.com/ARCLab-MIT/sw-driver-forecaster."
Revisiting Interpolation Augmentation for Speech-to-Text Generation,https://arxiv.org/abs/2406.15846,2024-06-22,2024-06-25,0.0,0.0,"Speech-to-text (S2T) generation systems frequently face challenges in
low-resource scenarios, primarily due to the lack of extensive labeled
datasets. One emerging solution is constructing virtual training samples by
interpolating inputs and labels, which has notably enhanced system
generalization in other domains. Despite its potential, this technique's
application in S2T tasks has remained under-explored. In this paper, we delve
into the utility of interpolation augmentation, guided by several pivotal
questions. Our findings reveal that employing an appropriate strategy in
interpolation augmentation significantly enhances performance across diverse
tasks, architectures, and data scales, offering a promising avenue for more
robust S2T systems in resource-constrained settings."
The Effect of Similarity Measures on Accurate Stability Estimates for Local Surrogate Models in Text-based Explainable AI,https://arxiv.org/abs/2406.15839,2024-06-22,2024-06-25,0.0,0.0,"Recent work has investigated the vulnerability of local surrogate methods to
adversarial perturbations on a machine learning (ML) model's inputs, where the
explanation is manipulated while the meaning and structure of the original
input remains similar under the complex model. While weaknesses across many
methods have been shown to exist, the reasons behind why still remain little
explored. Central to the concept of adversarial attacks on explainable AI (XAI)
is the similarity measure used to calculate how one explanation differs from
another A poor choice of similarity measure can result in erroneous conclusions
on the efficacy of an XAI method. Too sensitive a measure results in
exaggerated vulnerability, while too coarse understates its weakness. We
investigate a variety of similarity measures designed for text-based ranked
lists including Kendall's Tau, Spearman's Footrule and Rank-biased Overlap to
determine how substantial changes in the type of measure or threshold of
success affect the conclusions generated from common adversarial attack
processes. Certain measures are found to be overly sensitive, resulting in
erroneous estimates of stability."
Decentralized Transformers with Centralized Aggregation are Sample-Efficient Multi-Agent World Models,https://arxiv.org/abs/2406.15836,2024-06-22,2024-06-25,0.0,0.0,"Learning a world model for model-free Reinforcement Learning (RL) agents can
significantly improve the sample efficiency by learning policies in
imagination. However, building a world model for Multi-Agent RL (MARL) can be
particularly challenging due to the scalability issue in a centralized
architecture arising from a large number of agents, and also the
non-stationarity issue in a decentralized architecture stemming from the
inter-dependency among agents. To address both challenges, we propose a novel
world model for MARL that learns decentralized local dynamics for scalability,
combined with a centralized representation aggregation from all agents. We cast
the dynamics learning as an auto-regressive sequence modeling problem over
discrete tokens by leveraging the expressive Transformer architecture, in order
to model complex local dynamics across different agents and provide accurate
and consistent long-term imaginations. As the first pioneering
Transformer-based world model for multi-agent systems, we introduce a Perceiver
Transformer as an effective solution to enable centralized representation
aggregation within this context. Results on Starcraft Multi-Agent Challenge
(SMAC) show that it outperforms strong model-free approaches and existing
model-based methods in both sample efficiency and overall performance."
CaT-BENCH - Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans,https://arxiv.org/abs/2406.15823,2024-06-22,2024-06-25,0.0,0.0,"Understanding the abilities of LLMs to reason about natural language plans,
such as instructional text and recipes, is critical to reliably using them in
decision-making systems. A fundamental aspect of plans is the temporal order in
which their steps needs to be executed, which reflects the underlying causal
dependencies between them. We introduce CaT-Bench, a benchmark of Step Order
Prediction questions, which test whether a step must necessarily occur before
or after another in cooking recipe plans. We use this to evaluate how well
frontier LLMs understand causal and temporal dependencies. We find that SOTA
LLMs are underwhelming (best zero-shot is only 0.59 in F1), and are biased
towards predicting dependence more often, perhaps relying on temporal order of
steps as a heuristic. While prompting for explanations and using few-shot
examples improve performance, the best F1 result is only 0.73. Further, human
evaluation of explanations along with answer correctness show that, on average,
humans do not agree with model reasoning. Surprisingly, we also find that
explaining after answering leads to better performance than normal
chain-of-thought prompting, and LLM answers are not consistent across questions
about the same step pairs. Overall, results show that LLMs' ability to detect
dependence between steps has significant room for improvement."
Automatic AI Model Selection for Wireless Systems - Online Learning via Digital Twinning,https://arxiv.org/abs/2406.15819,2024-06-22,2024-06-25,0.0,0.0,"In modern wireless network architectures, such as O-RAN, artificial
intelligence (AI)-based applications are deployed at intelligent controllers to
carry out functionalities like scheduling or power control. The AI ""apps"" are
selected on the basis of contextual information such as network conditions,
topology, traffic statistics, and design goals. The mapping between context and
AI model parameters is ideally done in a zero-shot fashion via an automatic
model selection (AMS) mapping that leverages only contextual information
without requiring any current data. This paper introduces a general methodology
for the online optimization of AMS mappings. Optimizing an AMS mapping is
challenging, as it requires exposure to data collected from many different
contexts. Therefore, if carried out online, this initial optimization phase
would be extremely time consuming. A possible solution is to leverage a digital
twin of the physical system to generate synthetic data from multiple simulated
contexts. However, given that the simulator at the digital twin is imperfect, a
direct use of simulated data for the optimization of the AMS mapping would
yield poor performance when tested in the real system. This paper proposes a
novel method for the online optimization of AMS mapping that corrects for the
bias of the simulator by means of limited real data collected from the physical
system. Experimental results for a graph neural network-based power control app
demonstrate the significant advantages of the proposed approach."
Intrinsic Dimension Correlation - uncovering nonlinear connections in multimodal representations,https://arxiv.org/abs/2406.15812,2024-06-22,2024-06-25,0.0,0.0,"To gain insight into the mechanisms behind machine learning methods, it is
crucial to establish connections among the features describing data points.
However, these correlations often exhibit a high-dimensional and strongly
nonlinear nature, which makes them challenging to detect using standard
methods. This paper exploits the entanglement between intrinsic dimensionality
and correlation to propose a metric that quantifies the (potentially nonlinear)
correlation between high-dimensional manifolds. We first validate our method on
synthetic data in controlled environments, showcasing its advantages and
drawbacks compared to existing techniques. Subsequently, we extend our analysis
to large-scale applications in neural network representations. Specifically, we
focus on latent representations of multimodal data, uncovering clear
correlations between paired visual and textual embeddings, whereas existing
methods struggle significantly in detecting similarity. Our results indicate
the presence of highly nonlinear correlation patterns between latent manifolds."
LaMSUM - A Novel Framework for Extractive Summarization of User Generated Content using LLMs,https://arxiv.org/abs/2406.15809,2024-06-22,2024-06-25,0.0,0.0,"Large Language Models (LLMs) have demonstrated impressive performance across
a wide range of NLP tasks, including summarization. LLMs inherently produce
abstractive summaries by paraphrasing the original text, while the generation
of extractive summaries - selecting specific subsets from the original text -
remains largely unexplored. LLMs have a limited context window size,
restricting the amount of data that can be processed at once. We tackle this
challenge by introducing LaMSUM, a novel multi-level framework designed to
generate extractive summaries from large collections of user-generated text
using LLMs. LaMSUM integrates summarization with different voting methods to
achieve robust summaries. Extensive evaluation using four popular LLMs (Llama
3, Mixtral, Gemini, GPT-4o) demonstrates that LaMSUM outperforms
state-of-the-art extractive summarization methods. Overall, this work
represents one of the first attempts to achieve extractive summarization by
leveraging the power of LLMs, and is likely to spark further interest within
the research community."
Understanding Student and Academic Staff Perceptions of AI Use in Assessment and Feedback,https://arxiv.org/abs/2406.15808,2024-06-22,2024-06-25,0.0,0.0,"The rise of Artificial Intelligence (AI) and Generative Artificial
Intelligence (GenAI) in higher education necessitates assessment reform. This
study addresses a critical gap by exploring student and academic staff
experiences with AI and GenAI tools, focusing on their familiarity and comfort
with current and potential future applications in learning and assessment. An
online survey collected data from 35 academic staff and 282 students across two
universities in Vietnam and one in Singapore, examining GenAI familiarity,
perceptions of its use in assessment marking and feedback, knowledge checking
and participation, and experiences of GenAI text detection.
  Descriptive statistics and reflexive thematic analysis revealed a generally
low familiarity with GenAI among both groups. GenAI feedback was viewed
negatively; however, it was viewed more positively when combined with
instructor feedback. Academic staff were more accepting of GenAI text detection
tools and grade adjustments based on detection results compared to students.
Qualitative analysis identified three themes: unclear understanding of text
detection tools, variability in experiences with GenAI detectors, and mixed
feelings about GenAI's future impact on educational assessment. These findings
have major implications regarding the development of policies and practices for
GenAI-enabled assessment and feedback in higher education."
Synergistic Deep Graph Clustering Network,https://arxiv.org/abs/2406.15797,2024-06-22,2024-06-25,0.0,0.0,"Employing graph neural networks (GNNs) to learn cohesive and discriminative
node representations for clustering has shown promising results in deep graph
clustering. However, existing methods disregard the reciprocal relationship
between representation learning and structure augmentation. This study suggests
that enhancing embedding and structure synergistically becomes imperative for
GNNs to unleash their potential in deep graph clustering. A reliable structure
promotes obtaining more cohesive node representations, while high-quality node
representations can guide the augmentation of the structure, enhancing
structural reliability in return. Moreover, the generalization ability of
existing GNNs-based models is relatively poor. While they perform well on
graphs with high homogeneity, they perform poorly on graphs with low
homogeneity. To this end, we propose a graph clustering framework named
Synergistic Deep Graph Clustering Network (SynC). In our approach, we design a
Transform Input Graph Auto-Encoder (TIGAE) to obtain high-quality embeddings
for guiding structure augmentation. Then, we re-capture neighborhood
representations on the augmented graph to obtain clustering-friendly embeddings
and conduct self-supervised clustering. Notably, representation learning and
structure augmentation share weights, significantly reducing the number of
model parameters. Additionally, we introduce a structure fine-tuning strategy
to improve the model's generalization. Extensive experiments on benchmark
datasets demonstrate the superiority and effectiveness of our method. The code
is released on GitHub and Code Ocean."
Rethinking Entity-level Unlearning for Large Language Models,https://arxiv.org/abs/2406.15796,2024-06-22,2024-06-25,0.0,0.0,"Large language model unlearning has garnered increasing attention due to its
potential to address security and privacy concerns, leading to extensive
research in the field. However, much of this research has concentrated on
instance-level unlearning, specifically targeting the removal of predefined
instances containing sensitive content. This focus has left a significant gap
in the exploration of full entity-level unlearning, which is critical in
real-world scenarios such as copyright protection. To this end, we propose a
novel task of Entity-level unlearning, which aims to erase entity-related
knowledge from the target model completely. To thoroughly investigate this
task, we systematically evaluate trending unlearning algorithms, revealing that
current methods struggle to achieve effective entity-level unlearning. Then, we
further explore the factors that influence the performance of the unlearning
algorithms, identifying that knowledge coverage and the size of the forget set
play pivotal roles. Notably, our analysis also uncovers that entities
introduced through fine-tuning are more vulnerable to unlearning than
pre-trained entities. These findings collectively offer valuable insights for
advancing entity-level unlearning for LLMs."
Privacy Implications of Explainable AI in Data-Driven Systems,https://arxiv.org/abs/2406.15789,2024-06-22,2024-06-25,0.0,0.0,"Machine learning (ML) models, demonstrably powerful, suffer from a lack of
interpretability. The absence of transparency, often referred to as the black
box nature of ML models, undermines trust and urges the need for efforts to
enhance their explainability. Explainable AI (XAI) techniques address this
challenge by providing frameworks and methods to explain the internal
decision-making processes of these complex models. Techniques like
Counterfactual Explanations (CF) and Feature Importance play a crucial role in
achieving this goal. Furthermore, high-quality and diverse data remains the
foundational element for robust and trustworthy ML applications. In many
applications, the data used to train ML and XAI explainers contain sensitive
information. In this context, numerous privacy-preserving techniques can be
employed to safeguard sensitive information in the data, such as differential
privacy. Subsequently, a conflict between XAI and privacy solutions emerges due
to their opposing goals. Since XAI techniques provide reasoning for the model
behavior, they reveal information relative to ML models, such as their decision
boundaries, the values of features, or the gradients of deep learning models
when explanations are exposed to a third entity. Attackers can initiate privacy
breaching attacks using these explanations, to perform model extraction,
inference, and membership attacks. This dilemma underscores the challenge of
finding the right equilibrium between understanding ML decision-making and
safeguarding privacy."
Distributionally Robust Constrained Reinforcement Learning under Strong Duality,https://arxiv.org/abs/2406.15788,2024-06-22,2024-06-25,0.0,0.0,"We study the problem of Distributionally Robust Constrained RL (DRC-RL),
where the goal is to maximize the expected reward subject to environmental
distribution shifts and constraints. This setting captures situations where
training and testing environments differ, and policies must satisfy constraints
motivated by safety or limited budgets. Despite significant progress toward
algorithm design for the separate problems of distributionally robust RL and
constrained RL, there do not yet exist algorithms with end-to-end convergence
guarantees for DRC-RL. We develop an algorithmic framework based on strong
duality that enables the first efficient and provable solution in a class of
environmental uncertainties. Further, our framework exposes an inherent
structure of DRC-RL that arises from the combination of distributional
robustness and constraints, which prevents a popular class of iterative methods
from tractably solving DRC-RL, despite such frameworks being applicable for
each of distributionally robust RL and constrained RL individually. Finally, we
conduct experiments on a car racing benchmark to evaluate the effectiveness of
the proposed algorithm."
What Matters in Transformers? Not All Attention is Needed,https://arxiv.org/abs/2406.15786,2024-06-22,2024-06-25,0.0,0.0,"Scaling Transformer-based large language models (LLMs) has demonstrated
promising performance across various tasks. However, it also introduces
redundant structures, posing challenges for real-world deployment. Despite some
recognition of redundancy in LLMs, the variability of redundancy across
different modules, such as MLP and Attention layers, is under-explored. In this
work, we investigate the varying redundancy across different modules within
Transformers, including Blocks, MLP, and Attention layers, using a
similarity-based metric. This metric operates on the premise that redundant
structures produce outputs highly similar to their inputs. Surprisingly, while
attention layers are essential for transformers and distinguish them from other
mainstream architectures, we found that a large proportion of attention layers
exhibit excessively high similarity and can be safely pruned without degrading
performance, leading to reduced memory and computation costs. Additionally, we
further propose a method that jointly drops Attention and MLP layers, achieving
improved performance and dropping ratios. Extensive experiments demonstrate the
effectiveness of our methods, e.g., Llama-3-70B maintains comparable
performance even after pruning half of the attention layers. Our findings
provide valuable insights for future network architecture design. The code is
released at: \url{https://github.com/Shwai-He/LLM-Drop}."
Data Issues in Industrial AI System - A Meta-Review and Research Strategy,https://arxiv.org/abs/2406.15784,2024-06-22,2024-06-25,0.0,0.0,"In the era of Industry 4.0, artificial intelligence (AI) is assuming an
increasingly pivotal role within industrial systems. Despite the recent trend
within various industries to adopt AI, the actual adoption of AI is not as
developed as perceived. A significant factor contributing to this lag is the
data issues in AI implementation. How to address these data issues stands as a
significant concern confronting both industry and academia. To address data
issues, the first step involves mapping out these issues. Therefore, this study
conducts a meta-review to explore data issues and methods within the
implementation of industrial AI. Seventy-two data issues are identified and
categorized into various stages of the data lifecycle, including data source
and collection, data access and storage, data integration and interoperation,
data pre-processing, data processing, data security and privacy, and AI
technology adoption. Subsequently, the study analyzes the data requirements of
various AI algorithms. Building on the aforementioned analyses, it proposes a
data management framework, addressing how data issues can be systematically
resolved at every stage of the data lifecycle. Finally, the study highlights
future research directions. In doing so, this study enriches the existing body
of knowledge and provides guidelines for professionals navigating the complex
landscape of achieving data usability and usefulness in industrial AI."
DABL - Detecting Semantic Anomalies in Business Processes Using Large Language Models,https://arxiv.org/abs/2406.15781,2024-06-22,2024-06-25,0.0,0.0,"Detecting anomalies in business processes is crucial for ensuring operational
success. While many existing methods rely on statistical frequency to detect
anomalies, it's important to note that infrequent behavior doesn't necessarily
imply undesirability. To address this challenge, detecting anomalies from a
semantic viewpoint proves to be a more effective approach. However, current
semantic anomaly detection methods treat a trace (i.e., process instance) as
multiple event pairs, disrupting long-distance dependencies. In this paper, we
introduce DABL, a novel approach for detecting semantic anomalies in business
processes using large language models (LLMs). We collect 143,137 real-world
process models from various domains. By generating normal traces through the
playout of these process models and simulating both ordering and exclusion
anomalies, we fine-tune Llama 2 using the resulting log. Through extensive
experiments, we demonstrate that DABL surpasses existing state-of-the-art
semantic anomaly detection methods in terms of both generalization ability and
learning of given processes. Users can directly apply DABL to detect semantic
anomalies in their own datasets without the need for additional training.
Furthermore, DABL offers the capability to interpret the causes of anomalies in
natural language, providing valuable insights into the detected anomalies."
ObjectNLQ @ Ego4D Episodic Memory Challenge 2024,https://arxiv.org/abs/2406.15778,2024-06-22,2024-06-25,0.0,0.0,"In this report, we present our approach for the Natural Language Query track
and Goal Step track of the Ego4D Episodic Memory Benchmark at CVPR 2024. Both
challenges require the localization of actions within long video sequences
using textual queries. To enhance localization accuracy, our method not only
processes the temporal information of videos but also identifies fine-grained
objects spatially within the frames. To this end, we introduce a novel
approach, termed ObjectNLQ, which incorporates an object branch to augment the
video representation with detailed object information, thereby improving
grounding efficiency. ObjectNLQ achieves a mean R@1 of 23.15, ranking 2nd in
the Natural Language Queries Challenge, and gains 33.00 in terms of the metric
R@1, IoU=0.3, ranking 3rd in the Goal Step Challenge. Our code will be released
at https://github.com/Yisen-Feng/ObjectNLQ."
HCQA @ Ego4D EgoSchema Challenge 2024,https://arxiv.org/abs/2406.15771,2024-06-22,2024-06-25,0.0,0.0,"In this report, we present our champion solution for Ego4D EgoSchema
Challenge in CVPR 2024. To deeply integrate the powerful egocentric captioning
model and question reasoning model, we propose a novel Hierarchical
Comprehension scheme for egocentric video Question Answering, named HCQA. It
consists of three stages: Fine-grained Caption Generation, Context-driven
Summarization, and Inference-guided Answering. Given a long-form video, HCQA
captures local detailed visual information and global summarised visual
information via Fine-grained Caption Generation and Context-driven
Summarization, respectively. Then in Inference-guided Answering, HCQA utilizes
this hierarchical information to reason and answer given question. On the
EgoSchema blind test set, HCQA achieves 75% accuracy in answering over 5,000
human curated multiple-choice questions. Our code will be released at
https://github.com/Hyu-Zhang/HCQA."
Continual Learning with Diffusion-based Generative Replay for Industrial Streaming Data,https://arxiv.org/abs/2406.15766,2024-06-22,2024-06-25,0.0,0.0,"The Industrial Internet of Things (IIoT) integrates interconnected sensors
and devices to support industrial applications, but its dynamic environments
pose challenges related to data drift. Considering the limited resources and
the need to effectively adapt models to new data distributions, this paper
introduces a Continual Learning (CL) approach, i.e., Distillation-based
Self-Guidance (DSG), to address challenges presented by industrial streaming
data via a novel generative replay mechanism. DSG utilizes knowledge
distillation to transfer knowledge from the previous diffusion-based generator
to the updated one, improving both the stability of the generator and the
quality of reproduced data, thereby enhancing the mitigation of catastrophic
forgetting. Experimental results on CWRU, DSA, and WISDM datasets demonstrate
the effectiveness of DSG. DSG outperforms the state-of-the-art baseline in
accuracy, demonstrating improvements ranging from 2.9% to 5.0% on key datasets,
showcasing its potential for practical industrial applications."
Unveiling and Harnessing Hidden Attention Sinks - Enhancing Large Language Models without Training through Attention Calibration,https://arxiv.org/abs/2406.15765,2024-06-22,2024-06-25,0.0,0.0,"Attention is a fundamental component behind the remarkable achievements of
large language models (LLMs). However, our current understanding of the
attention mechanism, especially regarding how attention distributions are
established, remains limited. Inspired by recent studies that explore the
presence of attention sink in the initial token, which receives
disproportionately large attention scores despite their lack of semantic
importance, this work delves deeper into this phenomenon. We aim to provide a
more profound understanding of the existence of attention sinks within LLMs and
to uncover ways to enhance the achievable accuracy of LLMs by directly
optimizing the attention distributions, without the need for weight finetuning.
Specifically, this work begins with comprehensive visualizations of the
attention distributions in LLMs during inference across various inputs and
tasks. Based on these visualizations, to the best of our knowledge, we are the
first to discover that (1) attention sinks occur not only at the start of
sequences but also within later tokens of the input, and (2) not all attention
sinks have a positive impact on the achievable accuracy of LLMs. Building upon
our findings, we propose a training-free Attention Calibration Technique (ACT)
that automatically optimizes the attention distributions on the fly during
inference in an input-adaptive manner. Extensive experiments validate that ACT
consistently enhances the accuracy of various LLMs across different
applications. Specifically, ACT achieves an average improvement of up to 7.30%
in accuracy across different datasets when applied to Llama-30B. Our code is
available at https://github.com/GATECH-EIC/ACT."
AllMatch - Exploiting All Unlabeled Data for Semi-Supervised Learning,https://arxiv.org/abs/2406.15763,2024-06-22,2024-06-25,0.0,0.0,"Existing semi-supervised learning algorithms adopt pseudo-labeling and
consistency regulation techniques to introduce supervision signals for
unlabeled samples. To overcome the inherent limitation of threshold-based
pseudo-labeling, prior studies have attempted to align the confidence threshold
with the evolving learning status of the model, which is estimated through the
predictions made on the unlabeled data. In this paper, we further reveal that
classifier weights can reflect the differentiated learning status across
categories and consequently propose a class-specific adaptive threshold
mechanism. Additionally, considering that even the optimal threshold scheme
cannot resolve the problem of discarding unlabeled samples, a binary
classification consistency regulation approach is designed to distinguish
candidate classes from negative options for all unlabeled samples. By combining
the above strategies, we present a novel SSL algorithm named AllMatch, which
achieves improved pseudo-label accuracy and a 100% utilization ratio for the
unlabeled data. We extensively evaluate our approach on multiple benchmarks,
encompassing both balanced and imbalanced settings. The results demonstrate
that AllMatch consistently outperforms existing state-of-the-art methods."
Rethinking the Diffusion Models for Numerical Tabular Data Imputation from the Perspective of Wasserstein Gradient Flow,https://arxiv.org/abs/2406.15762,2024-06-22,2024-06-25,0.0,0.0,"Diffusion models (DMs) have gained attention in Missing Data Imputation
(MDI), but there remain two long-neglected issues to be addressed: (1).
Inaccurate Imputation, which arises from inherently
sample-diversification-pursuing generative process of DMs. (2). Difficult
Training, which stems from intricate design required for the mask matrix in
model training stage. To address these concerns within the realm of numerical
tabular datasets, we introduce a novel principled approach termed Kernelized
Negative Entropy-regularized Wasserstein gradient flow Imputation (KnewImp).
Specifically, based on Wasserstein gradient flow (WGF) framework, we first
prove that issue (1) stems from the cost functionals implicitly maximized in
DM-based MDI are equivalent to the MDI's objective plus
diversification-promoting non-negative terms. Based on this, we then design a
novel cost functional with diversification-discouraging negative entropy and
derive our KnewImp approach within WGF framework and reproducing kernel Hilbert
space. After that, we prove that the imputation procedure of KnewImp can be
derived from another cost functional related to the joint distribution,
eliminating the need for the mask matrix and hence naturally addressing issue
(2). Extensive experiments demonstrate that our proposed KnewImp approach
significantly outperforms existing state-of-the-art methods."
ICM Ensemble with Novel Betting Functions for Concept Drift,https://arxiv.org/abs/2406.15760,2024-06-22,2024-06-25,0.0,0.0,"This study builds upon our previous work by introducing a refined Inductive
Conformal Martingale (ICM) approach for addressing Concept Drift (CD).
Specifically, we enhance our previously proposed CAUTIOUS betting function to
incorporate multiple density estimators for improving detection ability. We
also combine this betting function with two base estimators that have not been
previously utilized within the ICM framework: the Interpolated Histogram and
Nearest Neighbor Density Estimators. We assess these extensions using both a
single ICM and an ensemble of ICMs. For the latter, we conduct a comprehensive
experimental investigation into the influence of the ensemble size on
prediction accuracy and the number of available predictions. Our experimental
results on four benchmark datasets demonstrate that the proposed approach
surpasses our previous methodology in terms of performance while matching or in
many cases exceeding that of three contemporary state-of-the-art techniques."
EDGE-LLM - Enabling Efficient Large Language Model Adaptation on Edge Devices via Layerwise Unified Compression and Adaptive Layer Tuning and Voting,https://arxiv.org/abs/2406.15758,2024-06-22,2024-06-25,0.0,0.0,"Efficient adaption of large language models (LLMs) on edge devices is
essential for applications requiring continuous and privacy-preserving
adaptation and inference. However, existing tuning techniques fall short
because of the high computation and memory overheads. To this end, we introduce
a computation- and memory-efficient LLM tuning framework, called Edge-LLM, to
facilitate affordable and effective LLM adaptation on edge devices.
Specifically, Edge-LLM features three core components: (1) a layer-wise unified
compression (LUC) technique to reduce the computation overhead by generating
layer-wise pruning sparsity and quantization bit-width policies, (2) an
adaptive layer tuning and voting scheme to reduce the memory overhead by
reducing the backpropagation depth, and (3) a complementary hardware scheduling
strategy to handle the irregular computation patterns introduced by LUC and
adaptive layer tuning, thereby achieving efficient computation and data
movements. Extensive experiments demonstrate that Edge-LLM achieves a 2.92x
speed up and a 4x memory overhead reduction as compared to vanilla tuning
methods with comparable task accuracy. Our code is available at
https://github.com/GATECH-EIC/Edge-LLM"
Fine-grained Background Representation for Weakly Supervised Semantic Segmentation,https://arxiv.org/abs/2406.15755,2024-06-22,2024-06-25,0.0,0.0,"Generating reliable pseudo masks from image-level labels is challenging in
the weakly supervised semantic segmentation (WSSS) task due to the lack of
spatial information. Prevalent class activation map (CAM)-based solutions are
challenged to discriminate the foreground (FG) objects from the suspicious
background (BG) pixels (a.k.a. co-occurring) and learn the integral object
regions. This paper proposes a simple fine-grained background representation
(FBR) method to discover and represent diverse BG semantics and address the
co-occurring problems. We abandon using the class prototype or pixel-level
features for BG representation. Instead, we develop a novel primitive, negative
region of interest (NROI), to capture the fine-grained BG semantic information
and conduct the pixel-to-NROI contrast to distinguish the confusing BG pixels.
We also present an active sampling strategy to mine the FG negatives
on-the-fly, enabling efficient pixel-to-pixel intra-foreground contrastive
learning to activate the entire object region. Thanks to the simplicity of
design and convenience in use, our proposed method can be seamlessly plugged
into various models, yielding new state-of-the-art results under various WSSS
settings across benchmarks. Leveraging solely image-level (I) labels as
supervision, our method achieves 73.2 mIoU and 45.6 mIoU segmentation results
on Pascal Voc and MS COCO test sets, respectively. Furthermore, by
incorporating saliency maps as an additional supervision signal (I+S), we
attain 74.9 mIoU on Pascal Voc test set. Concurrently, our FBR approach
demonstrates meaningful performance gains in weakly-supervised instance
segmentation (WSIS) tasks, showcasing its robustness and strong generalization
capabilities across diverse domains."
Multimodal Segmentation for Vocal Tract Modeling,https://arxiv.org/abs/2406.15754,2024-06-22,2024-06-25,0.0,0.0,"Accurate modeling of the vocal tract is necessary to construct articulatory
representations for interpretable speech processing and linguistics. However,
vocal tract modeling is challenging because many internal articulators are
occluded from external motion capture technologies. Real-time magnetic
resonance imaging (RT-MRI) allows measuring precise movements of internal
articulators during speech, but annotated datasets of MRI are limited in size
due to time-consuming and computationally expensive labeling methods. We first
present a deep labeling strategy for the RT-MRI video using a vision-only
segmentation approach. We then introduce a multimodal algorithm using audio to
improve segmentation of vocal articulators. Together, we set a new benchmark
for vocal tract modeling in MRI video segmentation and use this to release
labels for a 75-speaker RT-MRI dataset, increasing the amount of labeled public
RT-MRI data of the vocal tract by over a factor of 9. The code and dataset
labels can be found at \url{rishiraij.github.io/multimodal-mri-avatar/}."
The Perils of Optimizing Learned Reward Functions - Low Training Error Does Not Guarantee Low Regret,https://arxiv.org/abs/2406.15753,2024-06-22,2024-06-25,0.0,0.0,"In reinforcement learning, specifying reward functions that capture the
intended task can be very challenging. Reward learning aims to address this
issue by learning the reward function. However, a learned reward model may have
a low error on the training distribution, and yet subsequently produce a policy
with large regret. We say that such a reward model has an error-regret
mismatch. The main source of an error-regret mismatch is the distributional
shift that commonly occurs during policy optimization. In this paper, we
mathematically show that a sufficiently low expected test error of the reward
model guarantees low worst-case regret, but that for any fixed expected test
error, there exist realistic data distributions that allow for error-regret
mismatch to occur. We then show that similar problems persist even when using
policy regularization techniques, commonly employed in methods such as RLHF.
Our theoretical results highlight the importance of developing new ways to
measure the quality of learned reward models."
TacoLM - GaTed Attention Equipped Codec Language Model are Efficient Zero-Shot Text to Speech Synthesizers,https://arxiv.org/abs/2406.15752,2024-06-22,2024-06-25,0.0,0.0,"Neural codec language model (LM) has demonstrated strong capability in
zero-shot text-to-speech (TTS) synthesis. However, the codec LM often suffers
from limitations in inference speed and stability, due to its auto-regressive
nature and implicit alignment between text and audio. In this work, to handle
these challenges, we introduce a new variant of neural codec LM, namely TacoLM.
Specifically, TacoLM introduces a gated attention mechanism to improve the
training and inference efficiency and reduce the model size. Meanwhile, an
additional gated cross-attention layer is included for each decoder layer,
which improves the efficiency and content accuracy of the synthesized speech.
In the evaluation of the Librispeech corpus, the proposed TacoLM achieves a
better word error rate, speaker similarity, and mean opinion score, with 90%
fewer parameters and 5.2 times speed up, compared with VALL-E. Demo and code is
available at https://ereboas.github.io/TacoLM/."
Modeling Unknown Stochastic Dynamical System Subject to External Excitation,https://arxiv.org/abs/2406.15747,2024-06-22,2024-06-25,0.0,0.0,"We present a numerical method for learning unknown nonautonomous stochastic
dynamical system, i.e., stochastic system subject to time dependent excitation
or control signals. Our basic assumption is that the governing equations for
the stochastic system are unavailable. However, short bursts of input/output
(I/O) data consisting of certain known excitation signals and their
corresponding system responses are available. When a sufficient amount of such
I/O data are available, our method is capable of learning the unknown dynamics
and producing an accurate predictive model for the stochastic responses of the
system subject to arbitrary excitation signals not in the training data. Our
method has two key components: (1) a local approximation of the training I/O
data to transfer the learning into a parameterized form; and (2) a generative
model to approximate the underlying unknown stochastic flow map in
distribution. After presenting the method in detail, we present a comprehensive
set of numerical examples to demonstrate the performance of the proposed
method, especially for long-term system predictions."
Evaluating Large Vision-and-Language Models on Children's Mathematical Olympiads,https://arxiv.org/abs/2406.15736,2024-06-22,2024-06-25,0.0,0.0,"Recent years have seen a significant progress in the general-purpose problem
solving abilities of large vision and language models (LVLMs), such as ChatGPT,
Gemini, etc.; some of these breakthroughs even seem to enable AI models to
outperform human abilities in varied tasks that demand higher-order cognitive
skills. Are the current large AI models indeed capable of generalized problem
solving as humans do? A systematic analysis of AI capabilities for joint vision
and text reasoning, however, is missing in the current scientific literature.
In this paper, we make an effort towards filling this gap, by evaluating
state-of-the-art LVLMs on their mathematical and algorithmic reasoning
abilities using visuo-linguistic problems from children's Olympiads.
Specifically, we consider problems from the Mathematical Kangaroo (MK)
Olympiad, which is a popular international competition targeted at children
from grades 1-12, that tests children's deeper mathematical abilities using
puzzles that are appropriately gauged to their age and skills. Using the
puzzles from MK, we created a dataset, dubbed SMART-840, consisting of 840
problems from years 2020-2024. With our dataset, we analyze LVLMs power on
mathematical reasoning; their responses on our puzzles offer a direct way to
compare against that of children. Our results show that modern LVLMs do
demonstrate increasingly powerful reasoning skills in solving problems for
higher grades, but lack the foundations to correctly answer problems designed
for younger children. Further analysis shows that there is no significant
correlation between the reasoning capabilities of AI models and that of young
children, and their capabilities appear to be based on a different type of
reasoning than the cumulative knowledge that underlies children's mathematics
and logic skills."
Identifying and Solving Conditional Image Leakage in Image-to-Video Diffusion Model,https://arxiv.org/abs/2406.15735,2024-06-22,2024-06-25,0.0,0.0,"Diffusion models have obtained substantial progress in image-to-video (I2V)
generation. However, such models are not fully understood. In this paper, we
report a significant but previously overlooked issue in I2V diffusion models
(I2V-DMs), namely, conditional image leakage. I2V-DMs tend to over-rely on the
conditional image at large time steps, neglecting the crucial task of
predicting the clean video from noisy inputs, which results in videos lacking
dynamic and vivid motion. We further address this challenge from both inference
and training aspects by presenting plug-and-play strategies accordingly. First,
we introduce a training-free inference strategy that starts the generation
process from an earlier time step to avoid the unreliable late-time steps of
I2V-DMs, as well as an initial noise distribution with optimal analytic
expressions (Analytic-Init) by minimizing the KL divergence between it and the
actual marginal distribution to effectively bridge the training-inference gap.
Second, to mitigate conditional image leakage during training, we design a
time-dependent noise distribution for the conditional image, which favors high
noise levels at large time steps to sufficiently interfere with the conditional
image. We validate these strategies on various I2V-DMs using our collected
open-domain image benchmark and the UCF101 dataset. Extensive results
demonstrate that our methods outperform baselines by producing videos with more
dynamic and natural motion without compromising image alignment and temporal
consistency. The project page: \url{https://cond-image-leak.github.io/}."
RankAdaptor - Hierarchical Dynamic Low-Rank Adaptation for Structural Pruned LLMs,https://arxiv.org/abs/2406.15734,2024-06-22,2024-06-25,0.0,0.0,"The efficient compression of large language models (LLMs) is becoming
increasingly popular. However, recovering the accuracy of compressed LLMs is
still a major challenge. Structural pruning with standard Low-Rank Adaptation
(LoRA) is a common technique in current LLM compression. In structural pruning,
the model architecture is modified unevenly, resulting in suboptimal
performance in various downstream tasks via standard LoRA with fixed rank. To
address this problem, we introduce RankAdaptor, an efficient fine-tuning method
with hierarchical dynamic rank scheduling for pruned LLMs. An end-to-end
automatic optimization flow is developed that utilizes a lightweight
performance model to determine the different ranks during fine-tuning.
Comprehensive experiments on popular benchmarks show that RankAdaptor
consistently outperforms standard LoRA with structural pruning over different
pruning settings. Without increasing the trainable parameters, RankAdaptor
further reduces the accuracy performance gap between the recovery of the pruned
model and the original model compared to standard LoRA."
AI-Driven Approaches for Optimizing Power Consumption - A Comprehensive Survey,https://arxiv.org/abs/2406.15732,2024-06-22,2024-06-25,0.0,0.0,"Reduced environmental effect, lower operating costs, and a stable and
sustainable energy supply for current and future generations are the main
reasons why power optimization is important. Power optimization makes ensuring
that energy is used more effectively, cutting down on waste and optimizing the
utilization of resources.In today's world, power optimization and artificial
intelligence (AI) integration are essential to changing the way energy is
produced, used, and distributed. Real-time monitoring and analysis of power
usage trends is made possible by AI-driven algorithms and predictive analytics,
which enable dynamic modifications to effectively satisfy demand. Efficiency
and sustainability are increased when power consumption is optimized in
different sectors thanks to the use of intelligent systems. This survey paper
comprises an extensive review of the several AI techniques used for power
optimization as well as a methodical analysis of the literature for the study
of various intelligent system application domains across different disciplines
of power consumption.This literature review identifies the performance and
outcomes of 17 different research methods by assessing them, and it aims to
distill valuable insights into their strengths and limitations. Furthermore,
this article outlines future directions in the integration of AI for power
consumption optimization."
Breaking Secure Aggregation - Label Leakage from Aggregated Gradients in Federated Learning,https://arxiv.org/abs/2406.15731,2024-06-22,2024-06-25,0.0,0.0,"Federated Learning (FL) exhibits privacy vulnerabilities under gradient
inversion attacks (GIAs), which can extract private information from individual
gradients. To enhance privacy, FL incorporates Secure Aggregation (SA) to
prevent the server from obtaining individual gradients, thus effectively
resisting GIAs. In this paper, we propose a stealthy label inference attack to
bypass SA and recover individual clients' private labels. Specifically, we
conduct a theoretical analysis of label inference from the aggregated gradients
that are exclusively obtained after implementing SA. The analysis results
reveal that the inputs (embeddings) and outputs (logits) of the final fully
connected layer (FCL) contribute to gradient disaggregation and label
restoration. To preset the embeddings and logits of FCL, we craft a fishing
model by solely modifying the parameters of a single batch normalization (BN)
layer in the original model. Distributing client-specific fishing models, the
server can derive the individual gradients regarding the bias of FCL by
resolving a linear system with expected embeddings and the aggregated gradients
as coefficients. Then the labels of each client can be precisely computed based
on preset logits and gradients of FCL's bias. Extensive experiments show that
our attack achieves large-scale label recovery with 100\% accuracy on various
datasets and model architectures."
Acoustic Feature Mixup for Balanced Multi-aspect Pronunciation Assessment,https://arxiv.org/abs/2406.15723,2024-06-22,2024-06-25,0.0,0.0,"In automated pronunciation assessment, recent emphasis progressively lies on
evaluating multiple aspects to provide enriched feedback. However, acquiring
multi-aspect-score labeled data for non-native language learners' speech poses
challenges; moreover, it often leads to score-imbalanced distributions. In this
paper, we propose two Acoustic Feature Mixup strategies, linearly and
non-linearly interpolating with the in-batch averaged feature, to address data
scarcity and score-label imbalances. Primarily using goodness-of-pronunciation
as an acoustic feature, we tailor mixup designs to suit pronunciation
assessment. Further, we integrate fine-grained error-rate features by comparing
speech recognition results with the original answer phonemes, giving direct
hints for mispronunciation. Effective mixing of the acoustic features notably
enhances overall scoring performances on the speechocean762 dataset, and
detailed analysis highlights our potential to predict unseen distortions."
Scaling Laws for Fact Memorization of Large Language Models,https://arxiv.org/abs/2406.15720,2024-06-22,2024-06-25,0.0,0.0,"Fact knowledge memorization is crucial for Large Language Models (LLM) to
generate factual and reliable responses. However, the behaviors of LLM fact
memorization remain under-explored. In this paper, we analyze the scaling laws
for LLM's fact knowledge and LLMs' behaviors of memorizing different types of
facts. We find that LLMs' fact knowledge capacity has a linear and negative
exponential law relationship with model size and training epochs, respectively.
Estimated by the built scaling law, memorizing the whole Wikidata's facts
requires training an LLM with 1000B non-embed parameters for 100 epochs,
suggesting that using LLMs to memorize all public facts is almost implausible
for a general pre-training setting. Meanwhile, we find that LLMs can generalize
on unseen fact knowledge and its scaling law is similar to general
pre-training. Additionally, we analyze the compatibility and preference of
LLMs' fact memorization. For compatibility, we find LLMs struggle with
memorizing redundant facts in a unified way. Only when correlated facts have
the same direction and structure, the LLM can compatibly memorize them. This
shows the inefficiency of LLM memorization for redundant facts. For preference,
the LLM pays more attention to memorizing more frequent and difficult facts,
and the subsequent facts can overwrite prior facts' memorization, which
significantly hinders low-frequency facts memorization. Our findings reveal the
capacity and characteristics of LLMs' fact knowledge learning, which provide
directions for LLMs' fact knowledge augmentation."
Beyond the Turn-Based Game - Enabling Real-Time Conversations with Duplex Models,https://arxiv.org/abs/2406.15718,2024-06-22,2024-06-25,0.0,0.0,"As large language models (LLMs) increasingly permeate daily lives, there is a
growing demand for real-time interactions that mirror human conversations.
Traditional turn-based chat systems driven by LLMs prevent users from verbally
interacting with the system while it is generating responses. To overcome these
limitations, we adapt existing LLMs to \textit{duplex models} so that these
LLMs can listen for users while generating output and dynamically adjust
themselves to provide users with instant feedback. % such as in response to
interruptions. Specifically, we divide the queries and responses of
conversations into several time slices and then adopt a
time-division-multiplexing (TDM) encoding-decoding strategy to
pseudo-simultaneously process these slices. Furthermore, to make LLMs
proficient enough to handle real-time conversations, we build a fine-tuning
dataset consisting of alternating time slices of queries and responses as well
as covering typical feedback types in instantaneous interactions. Our
experiments show that although the queries and responses of conversations are
segmented into incomplete slices for processing, LLMs can preserve their
original performance on standard benchmarks with a few fine-tuning steps on our
dataset. Automatic and human evaluation indicate that duplex models make
user-AI interactions more natural and human-like, and greatly improve user
satisfaction compared to vanilla LLMs. Our duplex model and dataset will be
released."
Efficient Low-rank Identification via Accelerated Iteratively Reweighted Nuclear Norm Minimization,https://arxiv.org/abs/2406.15713,2024-06-22,2024-06-25,0.0,0.0,"This paper considers the problem of minimizing the sum of a smooth function
and the Schatten-$p$ norm of the matrix. Our contribution involves proposing
accelerated iteratively reweighted nuclear norm methods designed for solving
the nonconvex low-rank minimization problem. Two major novelties characterize
our approach. Firstly, the proposed method possesses a rank identification
property, enabling the provable identification of the ""correct"" rank of the
stationary point within a finite number of iterations. Secondly, we introduce
an adaptive updating strategy for smoothing parameters. This strategy
automatically fixes parameters associated with zero singular values as
constants upon detecting the ""correct"" rank while quickly driving the rest of
the parameters to zero. This adaptive behavior transforms the algorithm into
one that effectively solves smooth problems after a few iterations, setting our
work apart from existing iteratively reweighted methods for low-rank
optimization. We prove the global convergence of the proposed algorithm,
guaranteeing that every limit point of the iterates is a critical point.
Furthermore, a local convergence rate analysis is provided under the
Kurdyka-{\L}ojasiewicz property. We conduct numerical experiments using both
synthetic and real data to showcase our algorithm's efficiency and superiority
over existing methods."
Teach Better or Show Smarter? On Instructions and Exemplars in Automatic Prompt Optimization,https://arxiv.org/abs/2406.15708,2024-06-22,2024-06-25,0.0,0.0,"Large language models have demonstrated remarkable capabilities, but their
performance is heavily reliant on effective prompt engineering. Automatic
prompt optimization (APO) methods are designed to automate this and can be
broadly categorized into those targeting instructions (instruction
optimization, IO) vs. those targeting exemplars (exemplar selection, ES).
Despite their shared objective, these have evolved rather independently, with
IO recently receiving more research attention. This paper seeks to bridge this
gap by comprehensively comparing the performance of representative IO and ES
techniques, both isolation and combination, on a diverse set of challenging
tasks. Our findings reveal that intelligently reusing model-generated
input-output pairs obtained from evaluating prompts on the validation set as
exemplars consistently improves performance over IO methods but is currently
under-investigated. We also find that despite the recent focus on IO, how we
select exemplars can outweigh how we optimize instructions, with ES strategies
as simple as random search outperforming state-of-the-art IO methods with seed
instructions without any optimization. Moreover, we observe synergy between ES
and IO, with optimal combinations surpassing individual contributions. We
conclude that studying exemplar selection as a standalone method and its
optimal combination with instruction optimization remains a crucial aspect of
APO and deserves greater consideration in future research, even in the era of
highly capable instruction-following models."
SS-Bench - A Benchmark for Social Story Generation and Evaluation,https://arxiv.org/abs/2406.15695,2024-06-22,2024-06-25,0.0,0.0,"Children with Autism Spectrum Disorder (ASD) often misunderstand social
situations and struggle to participate in daily routines. Social Stories are
traditionally crafted by psychology experts under strict constraints to address
these challenges but are costly and limited in diversity. As Large Language
Models (LLMs) advance, there's an opportunity to develop more automated,
affordable, and accessible methods to generate Social Stories in real-time with
broad coverage. However, adapting LLMs to meet the unique and strict
constraints of Social Stories is a challenging issue. To this end, we propose
\textbf{SS-GEN}, a \textbf{S}ocial \textbf{S}tory \textbf{GEN}eration framework
with LLMs. Firstly, we develop a constraint-driven sophisticated strategy named
\textbf{\textsc{StarSow}} to hierarchically prompt LLMs to generate Social
Stories at scale, followed by rigorous human filtering to build a high-quality
dataset. Additionally, we introduce \textbf{quality assessment criteria} to
evaluate the effectiveness of these generated stories. Considering that
powerful closed-source large models require very complex instructions and
expensive API fees, we finally fine-tune smaller language models with our
curated high-quality dataset, achieving comparable results at lower costs and
with simpler instruction and deployment. This work marks a significant step in
leveraging AI to personalize Social Stories cost-effectively for autistic
children at scale, which we hope can encourage future research. The prompt,
code and data will release in the \texttt{Technical Appendix} and \texttt{Code
\& Data Appendix} at \url{https://github.com/MIMIFY/SS-GEN}."
Inferring Pluggable Types with Machine Learning,https://arxiv.org/abs/2406.15676,2024-06-21,2024-06-25,0.0,0.0,"Pluggable type systems allow programmers to extend the type system of a
programming language to enforce semantic properties defined by the programmer.
Pluggable type systems are difficult to deploy in legacy codebases because they
require programmers to write type annotations manually. This paper investigates
how to use machine learning to infer type qualifiers automatically. We propose
a novel representation, NaP-AST, that encodes minimal dataflow hints for the
effective inference of type qualifiers. We evaluate several model architectures
for inferring type qualifiers, including Graph Transformer Network, Graph
Convolutional Network and Large Language Model. We further validated these
models by applying them to 12 open-source programs from a prior evaluation of
the NullAway pluggable typechecker, lowering warnings in all but one
unannotated project. We discovered that GTN shows the best performance, with a
recall of .89 and precision of 0.6. Furthermore, we conduct a study to estimate
the number of Java classes needed for good performance of the trained model.
For our feasibility study, performance improved around 16k classes, and
deteriorated due to overfitting around 22k classes."
Combining Neural Networks and Symbolic Regression for Analytical Lyapunov Function Discovery,https://arxiv.org/abs/2406.15675,2024-06-21,2024-06-25,0.0,0.0,"We propose CoNSAL (Combining Neural networks and Symbolic regression for
Analytical Lyapunov function) to construct analytical Lyapunov functions for
nonlinear dynamic systems. This framework contains a neural Lyapunov function
and a symbolic regression component, where symbolic regression is applied to
distill the neural network to precise analytical forms. Our approach utilizes
symbolic regression not only as a tool for translation but also as a means to
uncover counterexamples. This procedure terminates when no counterexamples are
found in the analytical formulation. Compared with previous results, CoNSAL
directly produces an analytical form of the Lyapunov function with improved
interpretability in both the learning process and the final results. We apply
CoNSAL to 2-D inverted pendulum, path following, Van Der Pol Oscillator, 3-D
trig dynamics, 4-D rotating wheel pendulum, 6-D 3-bus power system, and
demonstrate that our algorithm successfully finds their valid Lyapunov
functions. Code examples are available at https://github.com/HaohanZou/CoNSAL."
Large Language Models have Intrinsic Self-Correction Ability,https://arxiv.org/abs/2406.15673,2024-06-21,2024-06-25,0.0,0.0,"Large language models (LLMs) have attracted significant attention for their
remarkable abilities in various natural language processing tasks, but they
suffer from hallucinations that will cause performance degradation. One
promising solution to improve the LLMs' performance is to ask LLMs to revise
their answer after generation, a technique known as self-correction. Among the
two types of self-correction, intrinsic self-correction is considered a
promising direction because it does not utilize external knowledge. However,
recent works doubt the validity of LLM's ability to conduct intrinsic
self-correction. In this paper, we present a novel perspective on the intrinsic
self-correction capabilities of LLMs through theoretical analyses and empirical
experiments. In addition, we identify two critical factors for successful
self-correction: zero temperature and fair prompts. Leveraging these factors,
we demonstrate that intrinsic self-correction ability is exhibited across
multiple existing LLMs. Our findings offer insights into the fundamental
theories underlying the self-correction behavior of LLMs and remark on the
importance of unbiased prompts and zero temperature settings in harnessing
their full potential."
PI-Whisper - An Adaptive and Incremental ASR Framework for Diverse and Evolving Speaker Characteristics,https://arxiv.org/abs/2406.15668,2024-06-21,2024-06-25,0.0,0.0,"As edge-based automatic speech recognition (ASR) technologies become
increasingly prevalent for the development of intelligent and personalized
assistants, three important challenges must be addressed for these
resource-constrained ASR models, i.e., adaptivity, incrementality, and
inclusivity. We propose a novel ASR framework, PI-Whisper, in this work and
show how it can improve an ASR's recognition capabilities adaptively by
identifying different speakers' characteristics in real-time, how such an
adaption can be performed incrementally without repetitive retraining, and how
it can improve the equity and fairness for diverse speaker groups. More
impressively, our proposed PI-Whisper framework attains all of these nice
properties while still achieving state-of-the-art accuracy with up to 13.7%
reduction of the word error rate (WER) with linear scalability with respect to
computing resources."
Flat Posterior Does Matter For Bayesian Transfer Learning,https://arxiv.org/abs/2406.15664,2024-06-21,2024-06-25,0.0,0.0,"The large-scale pre-trained neural network has achieved notable success in
enhancing performance for downstream tasks. Another promising approach for
generalization is Bayesian Neural Network (BNN), which integrates Bayesian
methods into neural network architectures, offering advantages such as Bayesian
Model averaging (BMA) and uncertainty quantification. Despite these benefits,
transfer learning for BNNs has not been widely investigated and shows limited
improvement. We hypothesize that this issue arises from the inability to find
flat minima, which is crucial for generalization performance. To address this,
we evaluate the sharpness of BNNs in various settings, revealing their
insufficiency in seeking flat minima and the influence of flatness on BMA
performance. Therefore, we propose Sharpness-aware Bayesian Model Averaging
(SA-BMA), a Bayesian-fitting flat posterior seeking optimizer integrated with
Bayesian transfer learning. SA-BMA calculates the divergence between posteriors
in the parameter space, aligning with the nature of BNNs, and serves as a
generalized version of existing sharpness-aware optimizers. We validate that
SA-BMA improves generalization performance in few-shot classification and
distribution shift scenarios by ensuring flatness."
The Stochastic Occupation Kernel Method for System Identification,https://arxiv.org/abs/2406.15661,2024-06-21,2024-06-25,0.0,0.0,"The method of occupation kernels has been used to learn ordinary differential
equations from data in a non-parametric way. We propose a two-step method for
learning the drift and diffusion of a stochastic differential equation given
snapshots of the process. In the first step, we learn the drift by applying the
occupation kernel algorithm to the expected value of the process. In the second
step, we learn the diffusion given the drift using a semi-definite program.
Specifically, we learn the diffusion squared as a non-negative function in a
RKHS associated with the square of a kernel. We present examples and
simulations."
Contextual Sprint Classification in Soccer Based on Deep Learning,https://arxiv.org/abs/2406.15659,2024-06-21,2024-06-25,0.0,0.0,"The analysis of high-intensity runs (or sprints) in soccer has long been a
topic of interest for sports science researchers and practitioners. In
particular, recent studies suggested contextualizing sprints based on their
tactical purposes to better understand the physical-tactical requirements of
modern match-play. However, they have a limitation in scalability, as human
experts have to manually classify hundreds of sprints for every match. To
address this challenge, this paper proposes a deep learning framework for
automatically classifying sprints in soccer into contextual categories. The
proposed model covers the permutation-invariant and sequential nature of
multi-agent trajectories in soccer by deploying Set Transformers and a
bidirectional GRU. We train the model with category labels made through the
collaboration of human annotators and a rule-based classifier. Experimental
results show that our model classifies sprints in the test dataset into 15
categories with the accuracy of 77.65%, implying the potential of the proposed
framework for facilitating the integrated analysis of soccer sprints at scale."
TorchSpatial - A Location Encoding Framework and Benchmark for Spatial Representation Learning,https://arxiv.org/abs/2406.15658,2024-06-21,2024-06-25,0.0,0.0,"Spatial representation learning (SRL) aims at learning general-purpose neural
network representations from various types of spatial data (e.g., points,
polylines, polygons, networks, images, etc.) in their native formats. Learning
good spatial representations is a fundamental problem for various downstream
applications such as species distribution modeling, weather forecasting,
trajectory generation, geographic question answering, etc. Even though SRL has
become the foundation of almost all geospatial artificial intelligence (GeoAI)
research, we have not yet seen significant efforts to develop an extensive deep
learning framework and benchmark to support SRL model development and
evaluation. To fill this gap, we propose TorchSpatial, a learning framework and
benchmark for location (point) encoding, which is one of the most fundamental
data types of spatial representation learning. TorchSpatial contains three key
components: 1) a unified location encoding framework that consolidates 15
commonly recognized location encoders, ensuring scalability and reproducibility
of the implementations; 2) the LocBench benchmark tasks encompassing 7
geo-aware image classification and 4 geo-aware image regression datasets; 3) a
comprehensive suite of evaluation metrics to quantify geo-aware models' overall
performance as well as their geographic bias, with a novel Geo-Bias Score
metric. Finally, we provide a detailed analysis and insights into the model
performance and geographic bias of different location encoders. We believe
TorchSpatial will foster future advancement of spatial representation learning
and spatial fairness in GeoAI research. The TorchSpatial model framework,
LocBench, and Geo-Bias Score evaluation framework are available at
https://github.com/seai-lab/TorchSpatial."
Testing the Feasibility of Linear Programs with Bandit Feedback,https://arxiv.org/abs/2406.15648,2024-06-21,2024-06-25,0.0,0.0,"While the recent literature has seen a surge in the study of constrained
bandit problems, all existing methods for these begin by assuming the
feasibility of the underlying problem. We initiate the study of testing such
feasibility assumptions, and in particular address the problem in the linear
bandit setting, thus characterising the costs of feasibility testing for an
unknown linear program using bandit feedback. Concretely, we test if $\exists
x: Ax \ge 0$ for an unknown $A \in \mathbb{R}^{m \times d}$, by playing a
sequence of actions $x_t\in \mathbb{R}^d$, and observing $Ax_t +
\mathrm{noise}$ in response. By identifying the hypothesis as determining the
sign of the value of a minimax game, we construct a novel test based on
low-regret algorithms and a nonasymptotic law of iterated logarithms. We prove
that this test is reliable, and adapts to the `signal level,' $\Gamma,$ of any
instance, with mean sample costs scaling as $\widetilde{O}(d^2/\Gamma^2)$. We
complement this by a minimax lower bound of $\Omega(d/\Gamma^2)$ for sample
costs of reliable tests, dominating prior asymptotic lower bounds by capturing
the dependence on $d$, and thus elucidating a basic insight missing in the
extant literature on such problems."
Generating Music with Structure Using Self-Similarity as Attention,https://arxiv.org/abs/2406.15647,2024-06-21,2024-06-25,0.0,0.0,"Despite the innovations in deep learning and generative AI, creating long
term structure as well as the layers of repeated structure common in musical
works remains an open challenge in music generation. We propose an attention
layer that uses a novel approach applying user-supplied self-similarity
matrices to previous time steps, and demonstrate it in our Similarity
Incentivized Neural Generator (SING) system, a deep learning autonomous music
generation system with two layers. The first is a vanilla Long Short Term
Memory layer, and the second is the proposed attention layer. During
generation, this attention mechanism imposes a suggested structure from a
template piece on the generated music. We train SING on the MAESTRO dataset
using a novel variable batching method, and compare its performance to the same
model without the attention mechanism. The addition of our proposed attention
mechanism significantly improves the network's ability to replicate specific
structures, and it performs better on an unseen test set than a model without
the attention mechanism."
DataFreeShield - Defending Adversarial Attacks without Training Data,https://arxiv.org/abs/2406.15635,2024-06-21,2024-06-25,0.0,0.0,"Recent advances in adversarial robustness rely on an abundant set of training
data, where using external or additional datasets has become a common setting.
However, in real life, the training data is often kept private for security and
privacy issues, while only the pretrained weight is available to the public. In
such scenarios, existing methods that assume accessibility to the original data
become inapplicable. Thus we investigate the pivotal problem of data-free
adversarial robustness, where we try to achieve adversarial robustness without
accessing any real data. Through a preliminary study, we highlight the severity
of the problem by showing that robustness without the original dataset is
difficult to achieve, even with similar domain datasets. To address this issue,
we propose DataFreeShield, which tackles the problem from two perspectives:
surrogate dataset generation and adversarial training using the generated data.
Through extensive validation, we show that DataFreeShield outperforms
baselines, demonstrating that the proposed method sets the first entirely
data-free solution for the adversarial robustness problem."
Benchmarking Uncertainty Quantification Methods for Large Language Models with LM-Polygraph,https://arxiv.org/abs/2406.15627,2024-06-21,2024-06-25,0.0,0.0,"Uncertainty quantification (UQ) is becoming increasingly recognized as a
critical component of applications that rely on machine learning (ML). The
rapid proliferation of large language models (LLMs) has stimulated researchers
to seek efficient and effective approaches to UQ in text generation tasks, as
in addition to their emerging capabilities, these models have introduced new
challenges for building safe applications. As with other ML models, LLMs are
prone to make incorrect predictions, ``hallucinate'' by fabricating claims, or
simply generate low-quality output for a given input. UQ is a key element in
dealing with these challenges. However research to date on UQ methods for LLMs
has been fragmented, with disparate evaluation methods. In this work, we tackle
this issue by introducing a novel benchmark that implements a collection of
state-of-the-art UQ baselines, and provides an environment for controllable and
consistent evaluation of novel techniques by researchers in various text
generation tasks. Our benchmark also supports the assessment of confidence
normalization methods in terms of their ability to provide interpretable
scores. Using our benchmark, we conduct a large-scale empirical investigation
of UQ and normalization techniques across nine tasks and shed light on the most
promising approaches."
Shortcomings of LLMs for Low-Resource Translation - Retrieval and Understanding are Both the Problem,https://arxiv.org/abs/2406.15625,2024-06-21,2024-06-25,0.0,0.0,"This work investigates the in-context learning abilities of pretrained large
language models (LLMs) when instructed to translate text from a low-resource
language into a high-resource language as part of an automated machine
translation pipeline. We conduct a set of experiments translating Southern
Quechua to Spanish and examine the informativity of various types of
information retrieved from a constrained database of digitized pedagogical
materials (dictionaries and grammar lessons) and parallel corpora. Using both
automatic and human evaluation of model output, we conduct ablation studies
that manipulate (1) context type (morpheme translations, grammar descriptions,
and corpus examples), (2) retrieval methods (automated vs. manual), and (3)
model type. Our results suggest that even relatively small LLMs are capable of
utilizing prompt context for zero-shot low-resource translation when provided a
minimally sufficient amount of relevant linguistic information. However, the
variable effects of prompt type, retrieval method, model type, and
language-specific factors highlight the limitations of using even the best LLMs
as translation systems for the majority of the world's 7,000+ languages and
their speakers."
Marrying Compressed Sensing and Deep Signal Separation,https://arxiv.org/abs/2406.15623,2024-06-21,2024-06-25,0.0,0.0,"Blind signal separation (BSS) is an important and challenging signal
processing task. Given an observed signal which is a superposition of a
collection of unknown (hidden/latent) signals, BSS aims at recovering the
separate, underlying signals from only the observed mixed signal. As an
underdetermined problem, BSS is notoriously difficult to solve in general, and
modern deep learning has provided engineers with an effective set of tools to
solve this problem. For example, autoencoders learn a low-dimensional hidden
encoding of the input data which can then be used to perform signal separation.
In real-time systems, a common bottleneck is the transmission of data
(communications) to a central command in order to await decisions. Bandwidth
limits dictate the frequency and resolution of the data being transmitted. To
overcome this, compressed sensing (CS) technology allows for the direct
acquisition of compressed data with a near optimal reconstruction guarantee.
This paper addresses the question: can compressive acquisition be combined with
deep learning for BSS to provide a complete acquire-separate-predict pipeline?
In other words, the aim is to perform BSS on a compressively acquired signal
directly without ever having to decompress the signal. We consider image data
(MNIST and E-MNIST) and show how our compressive autoencoder approach solves
the problem of compressive BSS. We also provide some theoretical insights into
the problem."
Physics Informed Machine Learning (PIML) methods for estimating the remaining useful lifetime (RUL) of aircraft engines,https://arxiv.org/abs/2406.15619,2024-06-21,2024-06-25,0.0,0.0,"This paper is aimed at using the newly developing field of physics informed
machine learning (PIML) to develop models for predicting the remaining useful
lifetime (RUL) aircraft engines. We consider the well-known benchmark NASA
Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) data as the main
data for this paper, which consists of sensor outputs in a variety of different
operating modes. C-MAPSS is a well-studied dataset with much existing work in
the literature that address RUL prediction with classical and deep learning
methods. In the absence of published empirical physical laws governing the
C-MAPSS data, our approach first uses stochastic methods to estimate the
governing physics models from the noisy time series data. In our approach, we
model the various sensor readings as being governed by stochastic differential
equations, and we estimate the corresponding transition density mean and
variance functions of the underlying processes. We then augment LSTM
(long-short term memory) models with the learned mean and variance functions
during training and inferencing. Our PIML based approach is different from
previous methods, and we use the data to first learn the physics. Our results
indicate that PIML discovery and solutions methods are well suited for this
problem and outperform previous data-only deep learning methods for this data
set and task. Moreover, the framework developed herein is flexible, and can be
adapted to other situations (other sensor modalities or combined multi-physics
environments), including cases where the underlying physics is only partially
observed or known."
BrowNNe - Brownian Nonlocal Neurons & Activation Functions,https://arxiv.org/abs/2406.15617,2024-06-21,2024-06-25,0.0,0.0,"It is generally thought that the use of stochastic activation functions in
deep learning architectures yield models with superior generalization
abilities. However, a sufficiently rigorous statement and theoretical proof of
this heuristic is lacking in the literature. In this paper, we provide several
novel contributions to the literature in this regard. Defining a new notion of
nonlocal directional derivative, we analyze its theoretical properties
(existence and convergence). Second, using a probabilistic reformulation, we
show that nonlocal derivatives are epsilon-sub gradients, and derive sample
complexity results for convergence of stochastic gradient descent-like methods
using nonlocal derivatives. Finally, using our analysis of the nonlocal
gradient of Holder continuous functions, we observe that sample paths of
Brownian motion admit nonlocal directional derivatives, and the nonlocal
derivatives of Brownian motion are seen to be Gaussian processes with
computable mean and standard deviation. Using the theory of nonlocal
directional derivatives, we solve a highly nondifferentiable and nonconvex
model problem of parameter estimation on image articulation manifolds. Using
Brownian motion infused ReLU activation functions with the nonlocal gradient in
place of the usual gradient during backpropagation, we also perform experiments
on multiple well-studied deep learning architectures. Our experiments indicate
the superior generalization capabilities of Brownian neural activation
functions in low-training data regimes, where the use of stochastic neurons
beats the deterministic ReLU counterpart."
MOUNTAINEER - Topology-Driven Visual Analytics for Comparing Local Explanations,https://arxiv.org/abs/2406.15613,2024-06-21,2024-06-25,0.0,0.0,"With the increasing use of black-box Machine Learning (ML) techniques in
critical applications, there is a growing demand for methods that can provide
transparency and accountability for model predictions. As a result, a large
number of local explainability methods for black-box models have been developed
and popularized. However, machine learning explanations are still hard to
evaluate and compare due to the high dimensionality, heterogeneous
representations, varying scales, and stochastic nature of some of these
methods. Topological Data Analysis (TDA) can be an effective method in this
domain since it can be used to transform attributions into uniform graph
representations, providing a common ground for comparison across different
explanation methods.
  We present a novel topology-driven visual analytics tool, Mountaineer, that
allows ML practitioners to interactively analyze and compare these
representations by linking the topological graphs back to the original data
distribution, model predictions, and feature attributions. Mountaineer
facilitates rapid and iterative exploration of ML explanations, enabling
experts to gain deeper insights into the explanation techniques, understand the
underlying data distributions, and thus reach well-founded conclusions about
model behavior. Furthermore, we demonstrate the utility of Mountaineer through
two case studies using real-world data. In the first, we show how Mountaineer
enabled us to compare black-box ML explanations and discern regions of and
causes of disagreements between different explanations. In the second, we
demonstrate how the tool can be used to compare and understand ML models
themselves. Finally, we conducted interviews with three industry experts to
help us evaluate our work."
Catastrophic-risk-aware reinforcement learning with extreme-value-theory-based policy gradients,https://arxiv.org/abs/2406.15612,2024-06-21,2024-06-25,0.0,0.0,"This paper tackles the problem of mitigating catastrophic risk (which is risk
with very low frequency but very high severity) in the context of a sequential
decision making process. This problem is particularly challenging due to the
scarcity of observations in the far tail of the distribution of cumulative
costs (negative rewards). A policy gradient algorithm is developed, that we
call POTPG. It is based on approximations of the tail risk derived from extreme
value theory. Numerical experiments highlight the out-performance of our method
over common benchmarks, relying on the empirical distribution. An application
to financial risk management, more precisely to the dynamic hedging of a
financial option, is presented."
Pareto-Optimal Learning from Preferences with Hidden Context,https://arxiv.org/abs/2406.15599,2024-06-21,2024-06-25,0.0,0.0,"Ensuring AI models align with human values is essential for their safety and
functionality. Reinforcement learning from human feedback (RLHF) uses human
preferences to achieve this alignment. However, preferences sourced from
diverse populations can result in point estimates of human values that may be
sub-optimal or unfair to specific groups. We propose Pareto Optimal Preference
Learning (POPL), which frames discrepant group preferences as objectives with
potential trade-offs, aiming for policies that are Pareto-optimal on the
preference dataset. POPL utilizes Lexicase selection, an iterative process to
select diverse and Pareto-optimal solutions. Our empirical evaluations
demonstrate that POPL surpasses baseline methods in learning sets of reward
functions, effectively catering to distinct groups without access to group
numbers or membership labels. Furthermore, we illustrate that POPL can serve as
a foundation for techniques optimizing specific notions of group fairness,
ensuring inclusive and equitable AI model alignment."
Detecting and Classifying Flares in High-Resolution Solar Spectra with Supervised Machine Learning,https://arxiv.org/abs/2406.15594,2024-06-21,2024-06-25,0.0,0.0,"Flares are a well-studied aspect of the Sun's magnetic activity. Detecting
and classifying solar flares can inform the analysis of contamination caused by
stellar flares in exoplanet transmission spectra. In this paper, we present a
standardized procedure to classify solar flares with the aid of supervised
machine learning. Using flare data from the RHESSI mission and solar spectra
from the HARPS-N instrument, we trained several supervised machine learning
models, and found that the best performing algorithm is a C-Support Vector
Machine (SVC) with non-linear kernels, specifically Radial Basis Functions
(RBF). The best-trained model, SVC with RBF kernels, achieves an average
aggregate accuracy score of 0.65, and categorical accuracy scores of over 0.70
for the no-flare and weak-flare classes, respectively. In comparison, a blind
classification algorithm would have an accuracy score of 0.33. Testing showed
that the model is able to detect and classify solar flares in entirely new data
with different characteristics and distributions from those of the training
set. Future efforts could focus on enhancing classification accuracy,
investigating the efficacy of alternative models, particularly deep learning
models, and incorporating more datasets to extend the application of this
framework to stars that host exoplanets."
News Deja Vu - Connecting Past and Present with Semantic Search,https://arxiv.org/abs/2406.15593,2024-06-21,2024-06-25,0.0,0.0,"Social scientists and the general public often analyze contemporary events by
drawing parallels with the past, a process complicated by the vast, noisy, and
unstructured nature of historical texts. For example, hundreds of millions of
page scans from historical newspapers have been noisily transcribed.
Traditional sparse methods for searching for relevant material in these vast
corpora, e.g., with keywords, can be brittle given complex vocabularies and OCR
noise. This study introduces News Deja Vu, a novel semantic search tool that
leverages transformer large language models and a bi-encoder approach to
identify historical news articles that are most similar to modern news queries.
News Deja Vu first recognizes and masks entities, in order to focus on broader
parallels rather than the specific named entities being discussed. Then, a
contrastively trained, lightweight bi-encoder retrieves historical articles
that are most similar semantically to a modern query, illustrating how
phenomena that might seem unique to the present have varied historical
precedents. Aimed at social scientists, the user-friendly News Deja Vu package
is designed to be accessible for those who lack extensive familiarity with deep
learning. It works with large text datasets, and we show how it can be deployed
to a massive scale corpus of historical, open-source news articles. While human
expertise remains important for drawing deeper insights, News Deja Vu provides
a powerful tool for exploring parallels in how people have perceived past and
present."
TinyStyler - Efficient Few-Shot Text Style Transfer with Authorship Embeddings,https://arxiv.org/abs/2406.15586,2024-06-21,2024-06-25,0.0,0.0,"The goal of text style transfer is to transform the style of texts while
preserving their original meaning, often with only a few examples of the target
style. Existing style transfer methods generally rely on the few-shot
capabilities of large language models or on complex controllable text
generation approaches that are inefficient and underperform on fluency metrics.
We introduce TinyStyler, a lightweight but effective approach, which leverages
a small language model (800M params) and pre-trained authorship embeddings to
perform efficient, few-shot text style transfer. We evaluate on the challenging
task of authorship style transfer and find TinyStyler outperforms strong
approaches such as GPT-4. We also evaluate TinyStyler's ability to perform text
attribute style transfer (formal $\leftrightarrow$ informal) with automatic and
human evaluations and find that the approach outperforms recent controllable
text generation methods. Our model has been made publicly available at
https://huggingface.co/tinystyler/tinystyler ."
Detecting AI-Generated Text - Factors Influencing Detectability with Current Methods,https://arxiv.org/abs/2406.15583,2024-06-21,2024-06-25,0.0,0.0,"Large language models (LLMs) have advanced to a point that even humans have
difficulty discerning whether a text was generated by another human, or by a
computer. However, knowing whether a text was produced by human or artificial
intelligence (AI) is important to determining its trustworthiness, and has
applications in many domains including detecting fraud and academic dishonesty,
as well as combating the spread of misinformation and political propaganda. The
task of AI-generated text (AIGT) detection is therefore both very challenging,
and highly critical. In this survey, we summarize state-of-the art approaches
to AIGT detection, including watermarking, statistical and stylistic analysis,
and machine learning classification. We also provide information about existing
datasets for this task. Synthesizing the research findings, we aim to provide
insight into the salient factors that combine to determine how ""detectable""
AIGT text is under different scenarios, and to make practical recommendations
for future work towards this significant technical and societal challenge."
Sketch-GNN - Scalable Graph Neural Networks with Sublinear Training Complexity,https://arxiv.org/abs/2406.15575,2024-06-21,2024-06-25,0.0,0.0,"Graph Neural Networks (GNNs) are widely applied to graph learning problems
such as node classification. When scaling up the underlying graphs of GNNs to a
larger size, we are forced to either train on the complete graph and keep the
full graph adjacency and node embeddings in memory (which is often infeasible)
or mini-batch sample the graph (which results in exponentially growing
computational complexities with respect to the number of GNN layers). Various
sampling-based and historical-embedding-based methods are proposed to avoid
this exponential growth of complexities. However, none of these solutions
eliminates the linear dependence on graph size. This paper proposes a
sketch-based algorithm whose training time and memory grow sublinearly with
respect to graph size by training GNNs atop a few compact sketches of graph
adjacency and node embeddings. Based on polynomial tensor-sketch (PTS) theory,
our framework provides a novel protocol for sketching non-linear activations
and graph convolution matrices in GNNs, as opposed to existing methods that
sketch linear weights or gradients in neural networks. In addition, we develop
a locality-sensitive hashing (LSH) technique that can be trained to improve the
quality of sketches. Experiments on large-graph benchmarks demonstrate the
scalability and competitive performance of our Sketch-GNNs versus their
full-size GNN counterparts."
DEM - Distribution Edited Model for Training with Mixed Data Distributions,https://arxiv.org/abs/2406.15570,2024-06-21,2024-06-25,0.0,0.0,"Training with mixed data distributions is a common and important part of
creating multi-task and instruction-following models. The diversity of the data
distributions and cost of joint training makes the optimization procedure
extremely challenging. Data mixing methods partially address this problem,
albeit having a sub-optimal performance across data sources and require
multiple expensive training runs. In this paper, we propose a simple and
efficient alternative for better optimization of the data sources by combining
models individually trained on each data source with the base model using basic
element-wise vector operations. The resulting model, namely Distribution Edited
Model (DEM), is 11x cheaper than standard data mixing and outperforms strong
baselines on a variety of benchmarks, yielding up to 6.2% improvement on MMLU,
11.5% on BBH, 16.1% on DROP, and 9.3% on HELM with models of size 3B to 13B.
Notably, DEM does not require full re-training when modifying a single
data-source, thus making it very flexible and scalable for training with
diverse data sources."
Robust Reinforcement Learning from Corrupted Human Feedback,https://arxiv.org/abs/2406.15568,2024-06-21,2024-06-25,0.0,0.0,"Reinforcement learning from human feedback (RLHF) provides a principled
framework for aligning AI systems with human preference data. For various
reasons, e.g., personal bias, context ambiguity, lack of training, etc, human
annotators may give incorrect or inconsistent preference labels. To tackle this
challenge, we propose a robust RLHF approach -- $R^3M$, which models the
potentially corrupted preference label as sparse outliers. Accordingly, we
formulate the robust reward learning as an $\ell_1$-regularized maximum
likelihood estimation problem. Computationally, we develop an efficient
alternating optimization algorithm, which only incurs negligible computational
overhead compared with the standard RLHF approach. Theoretically, we prove that
under proper regularity conditions, $R^3M$ can consistently learn the
underlying reward and identify outliers, provided that the number of outlier
labels scales sublinearly with the preference sample size. Furthermore, we
remark that $R^3M$ is versatile and can be extended to various preference
optimization methods, including direct preference optimization (DPO). Our
experiments on robotic control and natural language generation with large
language models (LLMs) show that $R^3M$ improves robustness of the reward
against several types of perturbations to the preference data."
Unseen Object Reasoning with Shared Appearance Cues,https://arxiv.org/abs/2406.15565,2024-06-21,2024-06-25,0.0,0.0,"This paper introduces an innovative approach to open world recognition (OWR),
where we leverage knowledge acquired from known objects to address the
recognition of previously unseen objects. The traditional method of object
modeling relies on supervised learning with strict closed-set assumptions,
presupposing that objects encountered during inference are already known at the
training phase. However, this assumption proves inadequate for real-world
scenarios due to the impracticality of accounting for the immense diversity of
objects. Our hypothesis posits that object appearances can be represented as
collections of ""shareable"" mid-level features, arranged in constellations to
form object instances. By adopting this framework, we can efficiently dissect
and represent both known and unknown objects in terms of their appearance cues.
Our paper introduces a straightforward yet elegant method for modeling novel or
unseen objects, utilizing established appearance cues and accounting for
inherent uncertainties. This representation not only enables the detection of
out-of-distribution objects or novel categories among unseen objects but also
facilitates a deeper level of reasoning, empowering the identification of the
superclass to which an unknown instance belongs. This novel approach holds
promise for advancing open world recognition in diverse applications."
"A SMART Mnemonic Sounds like ""Glue Tonic"" - Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick",https://arxiv.org/abs/2406.15352,2024-06-21,2024-06-25,0.0,0.0,"Keyword mnemonics are memorable explanations that link new terms to simpler
keywords. Prior works generate mnemonics for students, but they do not guide
models toward mnemonics students prefer and aid learning. We build SMART, a
mnemonic generator trained on feedback from real students learning new terms.
To train SMART, we first fine-tune LLaMA-2 on a curated set of user-written
mnemonics. We then use LLM alignment to enhance SMART: we deploy mnemonics
generated by SMART in a flashcard app to find preferences on mnemonics students
favor. We gather 2684 preferences from 45 students across two types: expressed
(inferred from ratings) and observed (inferred from student learning), yielding
three key findings. First, expressed and observed preferences disagree; what
students think is helpful does not fully capture what is truly helpful. Second,
Bayesian models can synthesize complementary data from multiple preference
types into a single effectiveness signal. SMART is tuned via Direct Preference
Optimization on this signal, which we show resolves ties and missing labels in
the typical method of pairwise comparisons, augmenting data for LLM output
quality gains. Third, mnemonic experts assess SMART as matching GPT-4, at much
lower deployment costs, showing the utility of capturing diverse student
feedback to align LLMs in education."
Privacy Preserved Blood Glucose Level Cross-Prediction - An Asynchronous Decentralized Federated Learning Approach,https://arxiv.org/abs/2406.15346,2024-06-21,2024-06-25,0.0,0.0,"Newly diagnosed Type 1 Diabetes (T1D) patients often struggle to obtain
effective Blood Glucose (BG) prediction models due to the lack of sufficient BG
data from Continuous Glucose Monitoring (CGM), presenting a significant ""cold
start"" problem in patient care. Utilizing population models to address this
challenge is a potential solution, but collecting patient data for training
population models in a privacy-conscious manner is challenging, especially
given that such data is often stored on personal devices. Considering the
privacy protection and addressing the ""cold start"" problem in diabetes care, we
propose ""GluADFL"", blood Glucose prediction by Asynchronous Decentralized
Federated Learning. We compared GluADFL with eight baseline methods using four
distinct T1D datasets, comprising 298 participants, which demonstrated its
superior performance in accurately predicting BG levels for cross-patient
analysis. Furthermore, patients' data might be stored and shared across various
communication networks in GluADFL, ranging from highly interconnected (e.g.,
random, performs the best among others) to more structured topologies (e.g.,
cluster and ring), suitable for various social networks. The asynchronous
training framework supports flexible participation. By adjusting the ratios of
inactive participants, we found it remains stable if less than 70% are
inactive. Our results confirm that GluADFL offers a practical,
privacy-preserving solution for BG prediction in T1D, significantly enhancing
the quality of diabetes management."
GenoTEX - A Benchmark for Evaluating LLM-Based Exploration of Gene Expression Data in Alignment with Bioinformaticians,https://arxiv.org/abs/2406.15341,2024-06-21,2024-06-25,0.0,0.0,"Recent advancements in machine learning have significantly improved the
identification of disease-associated genes from gene expression datasets.
However, these processes often require extensive expertise and manual effort,
limiting their scalability. Large Language Model (LLM)-based agents have shown
promise in automating these tasks due to their increasing problem-solving
abilities. To support the evaluation and development of such methods, we
introduce GenoTEX, a benchmark dataset for the automatic exploration of gene
expression data, involving the tasks of dataset selection, preprocessing, and
statistical analysis. GenoTEX provides annotated code and results for solving a
wide range of gene identification problems, in a full analysis pipeline that
follows the standard of computational genomics. These annotations are curated
by human bioinformaticians who carefully analyze the datasets to ensure
accuracy and reliability. To provide baselines for these tasks, we present
GenoAgents, a team of LLM-based agents designed with context-aware planning,
iterative correction, and domain expert consultation to collaboratively explore
gene datasets. Our experiments with GenoAgents demonstrate the potential of
LLM-based approaches in genomics data analysis, while error analysis highlights
the challenges and areas for future improvement. We propose GenoTEX as a
promising resource for benchmarking and enhancing AI-driven methods for
genomics data analysis. We make our benchmark publicly available at
\url{https://github.com/Liu-Hy/GenoTex}."
Image Conductor - Precision Control for Interactive Video Synthesis,https://arxiv.org/abs/2406.15339,2024-06-21,2024-06-25,0.0,0.0,"Filmmaking and animation production often require sophisticated techniques
for coordinating camera transitions and object movements, typically involving
labor-intensive real-world capturing. Despite advancements in generative AI for
video creation, achieving precise control over motion for interactive video
asset generation remains challenging. To this end, we propose Image Conductor,
a method for precise control of camera transitions and object movements to
generate video assets from a single image. An well-cultivated training strategy
is proposed to separate distinct camera and object motion by camera LoRA
weights and object LoRA weights. To further address cinematographic variations
from ill-posed trajectories, we introduce a camera-free guidance technique
during inference, enhancing object movements while eliminating camera
transitions. Additionally, we develop a trajectory-oriented video motion data
curation pipeline for training. Quantitative and qualitative experiments
demonstrate our method's precision and fine-grained control in generating
motion-controllable videos from images, advancing the practical application of
interactive video synthesis. Project webpage available at
https://liyaowei-stu.github.io/project/ImageConductor/"
Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning,https://arxiv.org/abs/2406.15334,2024-06-21,2024-06-25,0.0,0.0,"The recent success of interleaved Large Multimodal Models (LMMs) in few-shot
learning suggests that in-context learning (ICL) with many examples can be
promising for learning new tasks. However, this many-shot multimodal ICL
setting has one crucial problem: it is fundamentally limited by the model's
context length set at pretraining. The problem is especially prominent in the
multimodal domain, which processes both text and images, requiring additional
tokens. This motivates the need for a multimodal method to compress many shots
into fewer tokens without finetuning. In this work, we enable LMMs to perform
multimodal, many-shot in-context learning by leveraging Multimodal Task Vectors
(MTV)--compact implicit representations of in-context examples compressed in
the model's attention heads. Specifically, we first demonstrate the existence
of such MTV in LMMs and then leverage these extracted MTV to enable many-shot
in-context learning for various vision-and-language tasks. Our experiments
suggest that MTV can scale in performance with the number of compressed shots
and generalize to similar out-of-domain tasks without additional context length
for inference."
